version: 1.0

example1:
  Request: "Collect error log from /var/log/app.log from linux1 and linux2, compress them, transfer to merge1 and produce /tmp/merged.csv"
  Device-Info:
    - device_id: linux1
      os: linux
      metadata: {capabilities: [ssh, tar], network_access: true}
    - device_id: linux2
      os: linux
      metadata: {capabilities: [ssh, tar], network_access: true}
    - device_id: merge1
      os: linux
      metadata: {capabilities: [ssh, python3, disk], network_access: true}
  Current-Constellation: "Three tasks exist: collect-logs-linux1 (COMPLETED), collect-logs-linux2 (COMPLETED), merge-csv (PENDING). Task-1 and Task-2 collected error logs successfully but Task-3 lacks critical error details to generate proper CSV."
  Response:
    thought: |
      Task-1 'collect-logs-linux1' completed and found 15 critical errors: DatabaseConnectionTimeout (5 occurrences), NullPointerException in UserService (3), OutOfMemoryError (2), FileNotFoundException in /data/config.xml (3), SocketException in API Gateway (2).
      Task-2 'collect-logs-linux2' completed and found 12 critical errors: DatabaseConnectionTimeout (4 occurrences), SSLHandshakeException (3), DiskSpaceWarning at 95% (2), ThreadPoolExhausted in WorkerPool (2), ConfigurationMismatch in redis.conf (1).
      Task-3 'merge-csv' is PENDING and modifiable, but currently lacks detailed error information to produce a meaningful CSV report.
      The merge task needs to be enriched with specific error log details from both linux1 and linux2 to generate a comprehensive CSV with error types, counts, and severity.
      Therefore, update task-3 with tips containing the collected error details to ensure proper CSV generation.
    status: "CONTINUE"
    action:
      - function: "update_task"
        arguments:
          task_id: "task-3"
          name: "merge-csv-with-error-details"
          tips:
            - "linux1 errors: DatabaseConnectionTimeout(5), NullPointerException-UserService(3), OutOfMemoryError(2), FileNotFoundException-config.xml(3), SocketException-APIGateway(2)"
            - "linux2 errors: DatabaseConnectionTimeout(4), SSLHandshakeException(3), DiskSpaceWarning-95%(2), ThreadPoolExhausted-WorkerPool(2), ConfigurationMismatch-redis.conf(1)"
            - "Generate CSV with columns: error_type, server, count, severity, first_occurrence_time"
            - "Merge duplicate error types across servers and calculate total counts"
    results: "Error logs from linux1 and linux2 were successfully collected, enriched merge task with detailed error information, and generated comprehensive CSV report at /tmp/merged.csv with error type breakdown and severity analysis."

example2:
  Request: "Dump the Postgres database on db1, create a compressed backup, and upload it to s3 via uploader1"
  Device-Info:
    - device_id: db1
      os: linux
      metadata: {capabilities: [postgres, pg_dump], network_access: true}
    - device_id: uploader1
      os: linux
      metadata: {capabilities: [s3_upload, awscli], network_access: true}
  Current-Constellation: "Two tasks exist: database dump (completed) and S3 upload (pending). Dependency needs update due to artifact filename."
  Response:
    thought: |
      Task-1 'dump-db' has succeeded and produced '/backups/db_backup_2025-10-02.sql.gz'.
      Task-2 'upload-to-s3' is PENDING; dependency expects '/backups/db_backup.sql.gz' which mismatches actual artifact.
      Dependency line-1 is modifiable and task-2 status allows modification.
      Therefore, the dependency condition should be updated to match the produced artifact to ensure upload succeeds.
    status: "CONTINUE"
    action:
      - function: "update_dependency"
        arguments:
          dependency_id: "line-1"
          condition_description: "exit code == 0 and /backups/db_backup_2025-10-02.sql.gz exists on uploader1"
    results: "Database dump completed and backup uploaded to S3 successfully after dependency path update."

example3:
  Request: "Deploy microservice image to app1 and app2, then run health-check"
  Device-Info:
    - device_id: builder1
      os: linux
      metadata: {capabilities: [docker, git]}
    - device_id: app1
      os: linux
      metadata: {capabilities: [docker]}
    - device_id: app2
      os: linux
      metadata: {capabilities: [docker]}
    - device_id: tester1
      os: linux
      metadata: {capabilities: [curl]}
  Current-Constellation: "Deploy to app2 failed, deploy to app1 succeeded, health-check waiting; DAG partially blocked by failed task."
  Response:
    thought: |
      Deployment on app1 succeeded, app2 failed (network timeout). Tasks health-check and smoke-test are WAITING_DEPENDENCY and modifiable.
      Dependency line-4 depends on failed deploy-app2; cannot modify task-4 itself (FAILED, read-only).
      To proceed, add a remediation task 'redeploy-app2-retry' using builder1 to push image to app2.
      Rewire health-check dependency to wait on remediation task instead of failed task-4.
      Remove dependency line-4 (task-4 → task-5), which is modifiable.
      This allows DAG to remain acyclic and enables workflow continuation without touching successful tasks.
    status: "CONTINUE"
    action:
      - function: add_task
        arguments:
          task_id: "task-redeploy-app2"
          name: "redeploy-app2-retry"
          description: "On builder1: pull registry/myapp:latest, transfer image to app2, run container, return 'DEPLOY_OK: app2'."
          target_device_id: "builder1"
          tips: ["Use docker save|scp|docker load if app2 cannot pull from registry"]
      - function: add_dependency
        arguments:
          from_task_id: "task-redeploy-app2"
          to_task_id: "task-5"
          condition_description: "exit code == 0 and DEPLOY_OK: app2"
      - function: remove_dependency
        arguments:
          dependency_id: "line-4"
    results: "Deployment remediation task added; health-check and smoke-test will execute once app2 redeployment succeeds."

example4:
  Request: "Edge devices should download firmware update; if primary edge cannot fetch update, fallback to the mirror edge"
  Device-Info:
    - device_id: edge-primary
      os: linux
      metadata: {capabilities: [download], network_access: false}
    - device_id: edge-mirror
      os: linux
      metadata: {capabilities: [download], network_access: true}
    - device_id: orchestrator
      os: linux
      metadata: {capabilities: [orchestrate, ssh], network_access: true}
  Current-Constellation: "Primary edge download task is PENDING but lacks network; orchestrator verification task waiting dependency."
  Response:
    thought: |
      Primary edge lacks network_access; original task-1 assumes direct download which will fail.
      Task-1 is PENDING and modifiable; reassign to edge-mirror (has network) and adjust description to scp result to orchestrator.
      Dependency task-1 → task-2 remains valid; no further structural changes needed.
      This ensures firmware fetch is feasible, DAG remains valid, and verification task can proceed.
    status: "CONTINUE"
    action:
      - function: update_task
        arguments:
          task_id: "task-1"
          target_device_id: "edge-mirror"
          name: "download-via-mirror"
          description: "On edge-mirror: download firmware and transfer to orchestrator:/tmp/firmware.bin. Return 'DOWNLOAD_OK' on success."
    results: "Firmware downloaded via mirror edge and staged on orchestrator; verification can now proceed."

example5:
  Request: "Merge telemetry summaries from two processors and produce a final report (CSV & PDF)"
  Device-Info:
    - device_id: proc-a
      os: linux
      metadata: {capabilities: [process]}
    - device_id: proc-b
      os: linux
      metadata: {capabilities: [process]}
    - device_id: reporting
      os: linux
      metadata: {capabilities: [python3, pandoc]}
  Current-Constellation: "Processing tasks completed; merge and report generation pending. Need explicit CSV conversion step for deterministic output."
  Response:
    thought: |
      Tasks process-a and process-b succeeded and produced JSON summaries.
      merge-summaries PENDING, generate-report WAITING_DEPENDENCY.
      To ensure deterministic CSV, insert 'convert-merged-json-to-csv' after merge-summaries, before generate-report.
      Remove old merge→generate dependency, add two new dependencies: merge→convert, convert→generate.
      DAG remains acyclic, preserves completed tasks.
    status: "CONTINUE"
    action:
      - function: add_task
        arguments:
          task_id: "task-convert"
          name: "convert-merged-json-to-csv"
          description: "Read /tmp/merged.json and write /tmp/merged.csv with header; return 'CONVERT_OK' on success."
          target_device_id: "reporting"
          tips: ["Use python3 to produce consistent CSV"]
      - function: remove_dependency
        arguments: {dependency_id: "line-3"}
      - function: add_dependency
        arguments:
          from_task_id: "task-3"
          to_task_id: "task-convert"
          condition_description: "exit code == 0 and /tmp/merged.json exists on reporting"
      - function: add_dependency
        arguments:
          from_task_id: "task-convert"
          to_task_id: "task-4"
          condition_description: "exit code == 0 and /tmp/merged.csv exists on reporting"
    results: "Telemetry summaries merged and converted to CSV; final CSV and PDF reports generated successfully."

example6:
  Request: "Provide inventory summary (no actions) — user asks only for current registered devices"
  Device-Info:
    - device_id: admin-laptop
      os: macos
      metadata: {capabilities: [ssh, query]}
    - device_id: node1
      os: linux
      metadata: {capabilities: [agent]}
    - device_id: node2
      os: linux
      metadata: {capabilities: [agent]}
  Current-Constellation: "No tasks exist; user query only for information display."
  Response:
    thought: |
      User request is purely informational, requires no modification of DAG or actions.
      Device inventory query can be answered from Device-Info metadata.
      No tasks to add, dependencies or constellation updates are needed.
      Response can directly summarize current devices for user.
    status: "FINISH"
    action: []
    results: "Current registered devices: admin-laptop (macOS), node1 (Linux), node2 (Linux)."
