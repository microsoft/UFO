{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to UFO\u00b2's Document! \u2002 \u2002 \u2002 \u2002 \u2002 Introduction UFO now evolves into UFO\u00b2 (Desktop AgentOS), a new generation of agent framework that can run on Windows desktop OS. It is designed to automate and orchestrate tasks across multiple applications, enabling users to seamlessly interact with their operating system using natural language commands beyond just UI automation . \u2728 Key Capabilities Feature Description Deep OS Integration Combines Windows UIA, Win32 and WinCOM for first\u2011class control detection and native commands. Picture\u2011in\u2011Picture Desktop (coming soon) Automation runs in a sandboxed virtual desktop so you can keep using your main screen. Hybrid GUI + API Actions Chooses native APIs when available, falls back to clicks/keystrokes when not\u2014fast and robust. Speculative Multi\u2011Action Bundles several predicted steps into one LLM call, validated live\u2014up to 51 % fewer queries. Continuous Knowledge Substrate Mixes docs, Bing search, user demos and execution traces via RAG for agents that learn over time. UIA + Visual Control Detection Detects standard and custom controls with a hybrid UIA + vision pipeline. Please refer to the UFO\u00b2 paper and the hyperlinked sections for more details on each capability. \ud83c\udfd7\ufe0f Architecture overview UFO\u00b2 operates as a Desktop AgentOS , encompassing a multi-agent framework that includes: HostAgent \u2013 Parses the natural\u2011language goal, launches the necessary applications, spins up / coordinates AppAgents, and steers a global finite\u2011state machine (FSM). AppAgents \u2013 One per application; each runs a ReAct loop with multimodal perception, hybrid control detection, retrieval\u2011augmented knowledge, and the Puppeteer executor that chooses between GUI actions and native APIs. Knowledge Substrate \u2013 Blends offline documentation, online search, demonstrations, and execution traces into a vector store that is retrieved on\u2011the\u2011fly at inference. Speculative Executor \u2013 Slashes LLM latency by predicting batches of likely actions and validating them against live UIA state in a single shot. Picture\u2011in\u2011Picture Desktop (coming soon) \u2013 Runs the agent in an isolated virtual desktop so your main workspace and input devices remain untouched. For a deep dive see our technical report . \ud83d\ude80 Quick Start Please follow the Quick Start Guide to get started with UFO. Note This repository is intended solely for research purposes. The code provided herein is not designed, tested, or validated for third-party production use. Users are expected to exercise their own judgment and due diligence when utilizing any part of this codebase. Microsoft is committed to building Responsible and Trustworthy AI. To learn more about our principles and practices, please refer to our principles and approach . \ud83c\udf10 Media Coverage Check out our official deep dive of UFO on this Youtube Video . UFO sightings have garnered attention from various media outlets, including: \u5fae\u8f6f\u6b63\u5f0f\u5f00\u6e90UFO\u00b2\uff0cWindows\u684c\u9762\u8fc8\u5165\u300cAgentOS \u65f6\u4ee3\u300d Microsoft's UFO abducts traditional user interfaces for a smarter Windows experience \ud83d\ude80 UFO & GPT-4-V: Sit back and relax, mientras GPT lo hace todo\ud83c\udf0c The AI PC - The Future of Computers? - Microsoft UFO \u4e0b\u4e00\u4ee3Windows\u7cfb\u7edf\u66dd\u5149\uff1a\u57fa\u4e8eGPT-4V\uff0cAgent\u8de8\u5e94\u7528\u8c03\u5ea6\uff0c\u4ee3\u53f7UFO \u4e0b\u4e00\u4ee3\u667a\u80fd\u7248 Windows \u8981\u6765\u4e86\uff1f\u5fae\u8f6f\u63a8\u51fa\u9996\u4e2a Windows Agent\uff0c\u547d\u540d\u4e3a UFO\uff01 Microsoft\u767a\u306e\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u7248\u300cUFO\u300d\u767b\u5834\uff01\u3000Windows\u3092\u81ea\u52d5\u64cd\u7e26\u3059\u308bAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u8a66\u3059 \u2753Get help \u2754GitHub Issues (prefered) For other communications, please contact ufo-agent@microsoft.com \ud83d\udcda Citation If you build on this work, please cite our the AgentOS framework: UFO\u00b2 \u2013 The Desktop AgentOS (2025) https://arxiv.org/abs/2504.14603 @article{zhang2025ufo2, title = {{UFO2: The Desktop AgentOS}}, author = {Zhang, Chaoyun and Huang, He and Ni, Chiming and Mu, Jian and Qin, Si and He, Shilin and Wang, Lu and Yang, Fangkai and Zhao, Pu and Du, Chao and Li, Liqun and Kang, Yu and Jiang, Zhao and Zheng, Suzhen and Wang, Rujia and Qian, Jiaxu and Ma, Minghua and Lou, Jian-Guang and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei}, journal = {arXiv preprint arXiv:2504.14603}, year = {2025} } UFO \u2013 A UI\u2011Focused Agent for Windows OS Interaction (2024) https://arxiv.org/abs/2402.07939 @article{zhang2024ufo, title = {{UFO: A UI-Focused Agent for Windows OS Interaction}}, author = {Zhang, Chaoyun and Li, Liqun and He, Shilin and Zhang, Xu and Qiao, Bo and Qin, Si and Ma, Minghua and Kang, Yu and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei and Zhang, Qi}, journal = {arXiv preprint arXiv:2402.07939}, year = {2024} } \ud83d\udcdd Roadmap The UFO\u00b2 team is actively working on the following features and improvements: Picture\u2011in\u2011Picture Mode \u2013 Completed and will be available in the next release AgentOS\u2011as\u2011a\u2011Service \u2013 Completed and will be available in the next release Auto\u2011Debugging Toolkit \u2013 Completed and will be available in the next release Integration with MCP and Agent2Agent Communication \u2013 Planned; under implementation \ud83c\udfa8 Related Projects TaskWeaver \u2014 a code\u2011first LLM agent for data analytics: https://github.com/microsoft/TaskWeaver LLM\u2011Brained GUI Agents: A Survey : https://arxiv.org/abs/2411.18279 \u2022 GitHub \u2022 Interactive site window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-FX17ZGJYGC');","title":"Home"},{"location":"#welcome-to-ufo2s-document","text":"","title":"Welcome to UFO\u00b2's Document!"},{"location":"#introduction","text":"UFO now evolves into UFO\u00b2 (Desktop AgentOS), a new generation of agent framework that can run on Windows desktop OS. It is designed to automate and orchestrate tasks across multiple applications, enabling users to seamlessly interact with their operating system using natural language commands beyond just UI automation .","title":"Introduction"},{"location":"#key-capabilities","text":"Feature Description Deep OS Integration Combines Windows UIA, Win32 and WinCOM for first\u2011class control detection and native commands. Picture\u2011in\u2011Picture Desktop (coming soon) Automation runs in a sandboxed virtual desktop so you can keep using your main screen. Hybrid GUI + API Actions Chooses native APIs when available, falls back to clicks/keystrokes when not\u2014fast and robust. Speculative Multi\u2011Action Bundles several predicted steps into one LLM call, validated live\u2014up to 51 % fewer queries. Continuous Knowledge Substrate Mixes docs, Bing search, user demos and execution traces via RAG for agents that learn over time. UIA + Visual Control Detection Detects standard and custom controls with a hybrid UIA + vision pipeline. Please refer to the UFO\u00b2 paper and the hyperlinked sections for more details on each capability.","title":"\u2728 Key Capabilities"},{"location":"#architecture-overview","text":"UFO\u00b2 operates as a Desktop AgentOS , encompassing a multi-agent framework that includes: HostAgent \u2013 Parses the natural\u2011language goal, launches the necessary applications, spins up / coordinates AppAgents, and steers a global finite\u2011state machine (FSM). AppAgents \u2013 One per application; each runs a ReAct loop with multimodal perception, hybrid control detection, retrieval\u2011augmented knowledge, and the Puppeteer executor that chooses between GUI actions and native APIs. Knowledge Substrate \u2013 Blends offline documentation, online search, demonstrations, and execution traces into a vector store that is retrieved on\u2011the\u2011fly at inference. Speculative Executor \u2013 Slashes LLM latency by predicting batches of likely actions and validating them against live UIA state in a single shot. Picture\u2011in\u2011Picture Desktop (coming soon) \u2013 Runs the agent in an isolated virtual desktop so your main workspace and input devices remain untouched. For a deep dive see our technical report .","title":"\ud83c\udfd7\ufe0f Architecture overview"},{"location":"#quick-start","text":"Please follow the Quick Start Guide to get started with UFO. Note This repository is intended solely for research purposes. The code provided herein is not designed, tested, or validated for third-party production use. Users are expected to exercise their own judgment and due diligence when utilizing any part of this codebase. Microsoft is committed to building Responsible and Trustworthy AI. To learn more about our principles and practices, please refer to our principles and approach .","title":"\ud83d\ude80 Quick Start"},{"location":"#media-coverage","text":"Check out our official deep dive of UFO on this Youtube Video . UFO sightings have garnered attention from various media outlets, including: \u5fae\u8f6f\u6b63\u5f0f\u5f00\u6e90UFO\u00b2\uff0cWindows\u684c\u9762\u8fc8\u5165\u300cAgentOS \u65f6\u4ee3\u300d Microsoft's UFO abducts traditional user interfaces for a smarter Windows experience \ud83d\ude80 UFO & GPT-4-V: Sit back and relax, mientras GPT lo hace todo\ud83c\udf0c The AI PC - The Future of Computers? - Microsoft UFO \u4e0b\u4e00\u4ee3Windows\u7cfb\u7edf\u66dd\u5149\uff1a\u57fa\u4e8eGPT-4V\uff0cAgent\u8de8\u5e94\u7528\u8c03\u5ea6\uff0c\u4ee3\u53f7UFO \u4e0b\u4e00\u4ee3\u667a\u80fd\u7248 Windows \u8981\u6765\u4e86\uff1f\u5fae\u8f6f\u63a8\u51fa\u9996\u4e2a Windows Agent\uff0c\u547d\u540d\u4e3a UFO\uff01 Microsoft\u767a\u306e\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u7248\u300cUFO\u300d\u767b\u5834\uff01\u3000Windows\u3092\u81ea\u52d5\u64cd\u7e26\u3059\u308bAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u8a66\u3059","title":"\ud83c\udf10 Media Coverage"},{"location":"#get-help","text":"\u2754GitHub Issues (prefered) For other communications, please contact ufo-agent@microsoft.com","title":"\u2753Get help"},{"location":"#citation","text":"If you build on this work, please cite our the AgentOS framework: UFO\u00b2 \u2013 The Desktop AgentOS (2025) https://arxiv.org/abs/2504.14603 @article{zhang2025ufo2, title = {{UFO2: The Desktop AgentOS}}, author = {Zhang, Chaoyun and Huang, He and Ni, Chiming and Mu, Jian and Qin, Si and He, Shilin and Wang, Lu and Yang, Fangkai and Zhao, Pu and Du, Chao and Li, Liqun and Kang, Yu and Jiang, Zhao and Zheng, Suzhen and Wang, Rujia and Qian, Jiaxu and Ma, Minghua and Lou, Jian-Guang and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei}, journal = {arXiv preprint arXiv:2504.14603}, year = {2025} } UFO \u2013 A UI\u2011Focused Agent for Windows OS Interaction (2024) https://arxiv.org/abs/2402.07939 @article{zhang2024ufo, title = {{UFO: A UI-Focused Agent for Windows OS Interaction}}, author = {Zhang, Chaoyun and Li, Liqun and He, Shilin and Zhang, Xu and Qiao, Bo and Qin, Si and Ma, Minghua and Kang, Yu and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei and Zhang, Qi}, journal = {arXiv preprint arXiv:2402.07939}, year = {2024} }","title":"\ud83d\udcda Citation"},{"location":"#roadmap","text":"The UFO\u00b2 team is actively working on the following features and improvements: Picture\u2011in\u2011Picture Mode \u2013 Completed and will be available in the next release AgentOS\u2011as\u2011a\u2011Service \u2013 Completed and will be available in the next release Auto\u2011Debugging Toolkit \u2013 Completed and will be available in the next release Integration with MCP and Agent2Agent Communication \u2013 Planned; under implementation","title":"\ud83d\udcdd Roadmap"},{"location":"#related-projects","text":"TaskWeaver \u2014 a code\u2011first LLM agent for data analytics: https://github.com/microsoft/TaskWeaver LLM\u2011Brained GUI Agents: A Survey : https://arxiv.org/abs/2411.18279 \u2022 GitHub \u2022 Interactive site window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-FX17ZGJYGC');","title":"\ud83c\udfa8 Related Projects"},{"location":"faq/","text":"FAQ We provide answers to some frequently asked questions about the UFO. Q1: Why is it called UFO? A: UFO stands for U I Fo cused agent. The name is inspired by the concept of an unidentified flying object (UFO) that is mysterious and futuristic. Q2: Can I use UFO on Linux or macOS? A: UFO is currently only supported on Windows OS. Q3: Why the latency of UFO is high? A: The latency of UFO depends on the response time of the LLMs and the network speed. If you are using GPT, it usually takes dozens of seconds to generate a response in one step. The workload of the GPT endpoint may also affect the latency. Q4: What models does UFO support? A: UFO supports various language models, including OpenAI and Azure OpenAI models, QWEN, google Gimini, Ollama, and more. You can find the full list of supported models in the Supported Models section of the documentation. Q5: Can I use non-vision models in UFO? A: Yes, you can use non-vision models in UFO. You can set the VISUAL_MODE to False in the config.yaml file to disable the visual mode and use non-vision models. However, UFO is designed to work with vision models, and using non-vision models may affect the performance. Q6: Can I host my own LLM endpoint? A: Yes, you can host your custom LLM endpoint and configure UFO to use it. Check the documentation in the Supported Models section for more details. Q7: Can I use non-English requests in UFO? A: It depends on the language model you are using. Most of LLMs support multiple languages, and you can specify the language in the request. However, the performance may vary for different languages. Q8: Why it shows the error Error making API request: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')) ? A: This means the LLM endpoint is not accessible. You can check the network connection (e.g. VPN) and the status of the LLM endpoint. Info To get more support, please submit an issue on the GitHub Issues , or send an email to ufo-agent@microsoft.com .","title":"FAQ"},{"location":"faq/#faq","text":"We provide answers to some frequently asked questions about the UFO.","title":"FAQ"},{"location":"faq/#q1-why-is-it-called-ufo","text":"A: UFO stands for U I Fo cused agent. The name is inspired by the concept of an unidentified flying object (UFO) that is mysterious and futuristic.","title":"Q1: Why is it called UFO?"},{"location":"faq/#q2-can-i-use-ufo-on-linux-or-macos","text":"A: UFO is currently only supported on Windows OS.","title":"Q2: Can I use UFO on Linux or macOS?"},{"location":"faq/#q3-why-the-latency-of-ufo-is-high","text":"A: The latency of UFO depends on the response time of the LLMs and the network speed. If you are using GPT, it usually takes dozens of seconds to generate a response in one step. The workload of the GPT endpoint may also affect the latency.","title":"Q3: Why the latency of UFO is high?"},{"location":"faq/#q4-what-models-does-ufo-support","text":"A: UFO supports various language models, including OpenAI and Azure OpenAI models, QWEN, google Gimini, Ollama, and more. You can find the full list of supported models in the Supported Models section of the documentation.","title":"Q4: What models does UFO support?"},{"location":"faq/#q5-can-i-use-non-vision-models-in-ufo","text":"A: Yes, you can use non-vision models in UFO. You can set the VISUAL_MODE to False in the config.yaml file to disable the visual mode and use non-vision models. However, UFO is designed to work with vision models, and using non-vision models may affect the performance.","title":"Q5: Can I use non-vision models in UFO?"},{"location":"faq/#q6-can-i-host-my-own-llm-endpoint","text":"A: Yes, you can host your custom LLM endpoint and configure UFO to use it. Check the documentation in the Supported Models section for more details.","title":"Q6: Can I host my own LLM endpoint?"},{"location":"faq/#q7-can-i-use-non-english-requests-in-ufo","text":"A: It depends on the language model you are using. Most of LLMs support multiple languages, and you can specify the language in the request. However, the performance may vary for different languages.","title":"Q7: Can I use non-English requests in UFO?"},{"location":"faq/#q8-why-it-shows-the-error-error-making-api-request-connection-aborted-remotedisconnectedremote-end-closed-connection-without-response","text":"A: This means the LLM endpoint is not accessible. You can check the network connection (e.g. VPN) and the status of the LLM endpoint. Info To get more support, please submit an issue on the GitHub Issues , or send an email to ufo-agent@microsoft.com .","title":"Q8: Why it shows the error Error making API request: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))?"},{"location":"project_directory_structure/","text":"The UFO project is organized into a well-defined directory structure to facilitate development, deployment, and documentation. Below is an overview of each directory and file, along with their purpose: \ud83d\udce6project \u2523 \ud83d\udcc2documents # Folder to store project documentation \u2523 \ud83d\udcc2learner # Folder to build the vector database for help documents \u2523 \ud83d\udcc2model_worker # Folder to store tools for deploying your own model \u2523 \ud83d\udcc2record_processor # Folder to parse human demonstrations from Windows Step Recorder and build the vector database \u2523 \ud83d\udcc2dataflow # Folder for the code of data collection pipeline for Large Action Model (LAM) \u2523 \ud83d\udcc2vetordb # Folder to store all data in the vector database for RAG (Retrieval-Augmented Generation) \u2523 \ud83d\udcc2logs # Folder to store logs, generated after the program starts \u2517 \ud83d\udcc2ufo # Directory containing main project code \u2523 \ud83d\udcc2module # Directory for the basic module of UFO, e.g., session and round \u2523 \ud83d\udcc2agents # Code implementation of agents in UFO \u2523 \ud83d\udcc2automator # Implementation of the skill set of agents to automate applications \u2523 \ud83d\udcc2experience # Parse and save the agent's self-experience \u2523 \ud83d\udcc2llm # Folder to store the LLM (Large Language Model) implementation \u2523 \ud83d\udcc2prompter # Prompt constructor for the agent \u2523 \ud83d\udcc2prompts # Prompt templates and files to construct the full prompt \u2523 \ud83d\udcc2rag # Implementation of RAG from different sources to enhance agents' abilities \u2523 \ud83d\udcc2trajectory # Implementation of loading and parsing trajectories of task completion \u2523 \ud83d\udcc2utils # Utility functions \u2523 \ud83d\udcc2config # Configuration files \u2523 \ud83d\udcdcconfig.yaml # User configuration file for LLM and other settings \u2523 \ud83d\udcdcconfig_dev.yaml # Configuration file for developers \u2517 ... \u2517 \ud83d\udcc4ufo.py # Main entry point for the UFO client Directory and File Descriptions documents Purpose: Stores all the project documentation. Details: This may include design documents, user manuals, API documentation, and any other relevant project documentation. learner Purpose: Used to build the vector database for help documents. Details: This directory contains scripts and tools to process help documents and create a searchable vector database, enhancing the agents' ability for task completion. model_worker Purpose: Contains tools and scripts necessary for deploying custom models. Details: This includes model deployment configurations, and management tools for integrating custom models into the project. dataflow Purpose: Contains the code for the data collection pipeline for the Large Action Model (LAM). Details: This directory includes scripts and tools for collecting and processing data to train the Large Action Model, improving the agents' performance and capabilities. record_processor Purpose: Parses human demonstrations recorded using the Windows Step Recorder and builds the vector database. Details: This directory includes parsers, data processing scripts, and tools to convert human demonstrations into a format suitable for agent's retrieval. vetordb Purpose: Stores all data within the vector database for Retrieval-Augmented Generation (RAG). Details: This directory is essential for maintaining the data that enhances the agents' ability to retrieve relevant information and generate more accurate responses. logs Purpose: Stores log files generated by the application. Details: This directory helps in monitoring, debugging, and analyzing the application's performance and behavior. Logs are generated dynamically as the application runs. ufo Purpose: The core directory containing the main project code. Details: This directory is further subdivided into multiple subdirectories, each serving a specific purpose within the project. module Purpose: Contains the basic modules of the UFO project, such as session management and rounds. Details: This includes foundational classes and functions that are used throughout the project. agents Purpose: Houses the code implementations of various agents in the UFO project. Details: Agents are components that perform specific tasks within the system, and this directory contains their logic, components, and behavior. automator Purpose: Implements the skill set of agents to automate applications. Details: This includes scripts and tools that enable agents to interact with and automate tasks in various applications, such as mouse and keyboard actions and API calls. experience Purpose: Parses and saves the agent's self-experience. Details: This directory contains mechanisms for agents to learn from their actions and outcomes, improving their performance over time. llm Purpose: Stores the implementation of the Large Language Model (LLM). Details: This includes the implementation of APIs for different language models, such as GPT, Genimi, QWEN, etc., that are used by the agents. prompter Purpose: Constructs prompts for the agents. Details: This directory includes prompt construction logic and tools that help agents generate meaningful prompts for user interactions. prompts Purpose: Contains prompt templates and files used to construct the full prompt. Details: This includes predefined prompt structures and content that are used to create meaningful interactions with the agents. rag Purpose: Implements Retrieval-Augmented Generation (RAG) from different sources to enhance the agents' abilities. etails: This directory includes scripts and tools for integrating various data sources into the RAG framework, improving the accuracy and relevance of the agents' outputs. trajectory Purpose: Implements loading and parsing of task completion trajectories. Details: This directory includes tools and scripts to load and parse task completion trajectories, enabling agents to learn from past experiences or for evaluation purposes. utils Purpose: Contains utility functions. Details: This directory includes helper functions, common utilities, and other reusable code snippets that support the project's operations. config Purpose: Stores configuration files. Details: This directory includes different configuration files for various environments and purposes. config.yaml: User configuration file for LLM and other settings. You need to rename config.yaml.template to config.yaml and edit the configuration settings as needed. config_dev.yaml : Developer-specific configuration file with settings tailored for development purposes. ufo.py Purpose: Main entry point for the UFO client. Details: This script initializes and starts the UFO application.","title":"Project Directory Structure"},{"location":"project_directory_structure/#directory-and-file-descriptions","text":"","title":"Directory and File Descriptions"},{"location":"project_directory_structure/#documents","text":"Purpose: Stores all the project documentation. Details: This may include design documents, user manuals, API documentation, and any other relevant project documentation.","title":"documents"},{"location":"project_directory_structure/#learner","text":"Purpose: Used to build the vector database for help documents. Details: This directory contains scripts and tools to process help documents and create a searchable vector database, enhancing the agents' ability for task completion.","title":"learner"},{"location":"project_directory_structure/#model_worker","text":"Purpose: Contains tools and scripts necessary for deploying custom models. Details: This includes model deployment configurations, and management tools for integrating custom models into the project.","title":"model_worker"},{"location":"project_directory_structure/#dataflow","text":"Purpose: Contains the code for the data collection pipeline for the Large Action Model (LAM). Details: This directory includes scripts and tools for collecting and processing data to train the Large Action Model, improving the agents' performance and capabilities.","title":"dataflow"},{"location":"project_directory_structure/#record_processor","text":"Purpose: Parses human demonstrations recorded using the Windows Step Recorder and builds the vector database. Details: This directory includes parsers, data processing scripts, and tools to convert human demonstrations into a format suitable for agent's retrieval.","title":"record_processor"},{"location":"project_directory_structure/#vetordb","text":"Purpose: Stores all data within the vector database for Retrieval-Augmented Generation (RAG). Details: This directory is essential for maintaining the data that enhances the agents' ability to retrieve relevant information and generate more accurate responses.","title":"vetordb"},{"location":"project_directory_structure/#logs","text":"Purpose: Stores log files generated by the application. Details: This directory helps in monitoring, debugging, and analyzing the application's performance and behavior. Logs are generated dynamically as the application runs.","title":"logs"},{"location":"project_directory_structure/#ufo","text":"Purpose: The core directory containing the main project code. Details: This directory is further subdivided into multiple subdirectories, each serving a specific purpose within the project.","title":"ufo"},{"location":"project_directory_structure/#module","text":"Purpose: Contains the basic modules of the UFO project, such as session management and rounds. Details: This includes foundational classes and functions that are used throughout the project.","title":"module"},{"location":"project_directory_structure/#agents","text":"Purpose: Houses the code implementations of various agents in the UFO project. Details: Agents are components that perform specific tasks within the system, and this directory contains their logic, components, and behavior.","title":"agents"},{"location":"project_directory_structure/#automator","text":"Purpose: Implements the skill set of agents to automate applications. Details: This includes scripts and tools that enable agents to interact with and automate tasks in various applications, such as mouse and keyboard actions and API calls.","title":"automator"},{"location":"project_directory_structure/#experience","text":"Purpose: Parses and saves the agent's self-experience. Details: This directory contains mechanisms for agents to learn from their actions and outcomes, improving their performance over time.","title":"experience"},{"location":"project_directory_structure/#llm","text":"Purpose: Stores the implementation of the Large Language Model (LLM). Details: This includes the implementation of APIs for different language models, such as GPT, Genimi, QWEN, etc., that are used by the agents.","title":"llm"},{"location":"project_directory_structure/#prompter","text":"Purpose: Constructs prompts for the agents. Details: This directory includes prompt construction logic and tools that help agents generate meaningful prompts for user interactions.","title":"prompter"},{"location":"project_directory_structure/#prompts","text":"Purpose: Contains prompt templates and files used to construct the full prompt. Details: This includes predefined prompt structures and content that are used to create meaningful interactions with the agents.","title":"prompts"},{"location":"project_directory_structure/#rag","text":"Purpose: Implements Retrieval-Augmented Generation (RAG) from different sources to enhance the agents' abilities. etails: This directory includes scripts and tools for integrating various data sources into the RAG framework, improving the accuracy and relevance of the agents' outputs.","title":"rag"},{"location":"project_directory_structure/#trajectory","text":"Purpose: Implements loading and parsing of task completion trajectories. Details: This directory includes tools and scripts to load and parse task completion trajectories, enabling agents to learn from past experiences or for evaluation purposes.","title":"trajectory"},{"location":"project_directory_structure/#utils","text":"Purpose: Contains utility functions. Details: This directory includes helper functions, common utilities, and other reusable code snippets that support the project's operations.","title":"utils"},{"location":"project_directory_structure/#config","text":"Purpose: Stores configuration files. Details: This directory includes different configuration files for various environments and purposes. config.yaml: User configuration file for LLM and other settings. You need to rename config.yaml.template to config.yaml and edit the configuration settings as needed. config_dev.yaml : Developer-specific configuration file with settings tailored for development purposes.","title":"config"},{"location":"project_directory_structure/#ufopy","text":"Purpose: Main entry point for the UFO client. Details: This script initializes and starts the UFO application.","title":"ufo.py"},{"location":"about/CODE_OF_CONDUCT/","text":"Microsoft Open Source Code of Conduct This project has adopted the Microsoft Open Source Code of Conduct . Resources: Microsoft Open Source Code of Conduct Microsoft Code of Conduct FAQ Contact opencode@microsoft.com with questions or concerns","title":"Code of Conduct"},{"location":"about/CODE_OF_CONDUCT/#microsoft-open-source-code-of-conduct","text":"This project has adopted the Microsoft Open Source Code of Conduct . Resources: Microsoft Open Source Code of Conduct Microsoft Code of Conduct FAQ Contact opencode@microsoft.com with questions or concerns","title":"Microsoft Open Source Code of Conduct"},{"location":"about/CONTRIBUTING/","text":"Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com. When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA. Note You should sunmit your pull request to the pre-release branch, not the main branch. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Contributing"},{"location":"about/CONTRIBUTING/#contributing","text":"This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com. When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA. Note You should sunmit your pull request to the pre-release branch, not the main branch. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Contributing"},{"location":"about/DISCLAIMER/","text":"Disclaimer: Code Execution and Data Handling Notice By choosing to run the provided code, you acknowledge and agree to the following terms and conditions regarding the functionality and data handling practices: 1. Code Functionality: The code you are about to execute has the capability to capture screenshots of your working desktop environment and active applications. These screenshots will be processed and sent to the GPT model for inference. 2. Data Privacy and Storage: It is crucial to note that Microsoft, the provider of this code, explicitly states that it does not collect or save any of the transmitted data. The captured screenshots are processed in real-time for the purpose of inference, and no permanent storage or record of this data is retained by Microsoft. 3. User Responsibility: By running the code, you understand and accept the responsibility for the content and nature of the data present on your desktop during the execution period. It is your responsibility to ensure that no sensitive or confidential information is visible or captured during this process. 4. Security Measures: Microsoft has implemented security measures to safeguard the action execution. However, it is recommended that you run the code in a secure and controlled environment to minimize potential risks. Ensure that you are running the latest security updates on your system. 5. Consent for Inference: You explicitly provide consent for the GPT model to analyze the captured screenshots for the purpose of generating relevant outputs. This consent is inherent in the act of executing the code. 6. No Guarantee of Accuracy: The outputs generated by the GPT model are based on patterns learned during training and may not always be accurate or contextually relevant. Microsoft does not guarantee the accuracy or suitability of the inferences made by the model. 7. Indemnification: Users agree to defend, indemnify, and hold Microsoft harmless from and against all damages, costs, and attorneys' fees in connection with any claims arising from the use of this Repo. 8. Reporting Infringements: If anyone believes that this Repo infringes on their rights, please notify the project owner via the provided project owner email. Microsoft will investigate and take appropriate actions as necessary. 9. Modifications to the Disclaimer: Microsoft reserves the right to update or modify this disclaimer at any time without prior notice. It is your responsibility to review the disclaimer periodically for any changes. By proceeding to execute the code, you acknowledge that you have read, understood, and agreed to the terms outlined in this disclaimer. If you do not agree with these terms, refrain from running the provided code.","title":"Disclaimer"},{"location":"about/DISCLAIMER/#disclaimer-code-execution-and-data-handling-notice","text":"By choosing to run the provided code, you acknowledge and agree to the following terms and conditions regarding the functionality and data handling practices:","title":"Disclaimer: Code Execution and Data Handling Notice"},{"location":"about/DISCLAIMER/#1-code-functionality","text":"The code you are about to execute has the capability to capture screenshots of your working desktop environment and active applications. These screenshots will be processed and sent to the GPT model for inference.","title":"1. Code Functionality:"},{"location":"about/DISCLAIMER/#2-data-privacy-and-storage","text":"It is crucial to note that Microsoft, the provider of this code, explicitly states that it does not collect or save any of the transmitted data. The captured screenshots are processed in real-time for the purpose of inference, and no permanent storage or record of this data is retained by Microsoft.","title":"2. Data Privacy and Storage:"},{"location":"about/DISCLAIMER/#3-user-responsibility","text":"By running the code, you understand and accept the responsibility for the content and nature of the data present on your desktop during the execution period. It is your responsibility to ensure that no sensitive or confidential information is visible or captured during this process.","title":"3. User Responsibility:"},{"location":"about/DISCLAIMER/#4-security-measures","text":"Microsoft has implemented security measures to safeguard the action execution. However, it is recommended that you run the code in a secure and controlled environment to minimize potential risks. Ensure that you are running the latest security updates on your system.","title":"4. Security Measures:"},{"location":"about/DISCLAIMER/#5-consent-for-inference","text":"You explicitly provide consent for the GPT model to analyze the captured screenshots for the purpose of generating relevant outputs. This consent is inherent in the act of executing the code.","title":"5. Consent for Inference:"},{"location":"about/DISCLAIMER/#6-no-guarantee-of-accuracy","text":"The outputs generated by the GPT model are based on patterns learned during training and may not always be accurate or contextually relevant. Microsoft does not guarantee the accuracy or suitability of the inferences made by the model.","title":"6. No Guarantee of Accuracy:"},{"location":"about/DISCLAIMER/#7-indemnification","text":"Users agree to defend, indemnify, and hold Microsoft harmless from and against all damages, costs, and attorneys' fees in connection with any claims arising from the use of this Repo.","title":"7. Indemnification:"},{"location":"about/DISCLAIMER/#8-reporting-infringements","text":"If anyone believes that this Repo infringes on their rights, please notify the project owner via the provided project owner email. Microsoft will investigate and take appropriate actions as necessary.","title":"8. Reporting Infringements:"},{"location":"about/DISCLAIMER/#9-modifications-to-the-disclaimer","text":"Microsoft reserves the right to update or modify this disclaimer at any time without prior notice. It is your responsibility to review the disclaimer periodically for any changes. By proceeding to execute the code, you acknowledge that you have read, understood, and agreed to the terms outlined in this disclaimer. If you do not agree with these terms, refrain from running the provided code.","title":"9. Modifications to the Disclaimer:"},{"location":"about/LICENSE/","text":"Copyright (c) Microsoft Corporation. MIT License Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED AS IS , WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"about/LICENSE/#mit-license","text":"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED AS IS , WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"about/SUPPORT/","text":"Support How to file issues and get help This project uses GitHub Issues to track bugs and feature requests. Please search the existing issues before filing new issues to avoid duplicates. For new issues, file your bug or feature request as a new Issue. You may use GitHub Issues to raise questions, bug reports, and feature requests. For help and questions about using this project, please please contact ufo-agent@microsoft.com . Microsoft Support Policy Support for this PROJECT or PRODUCT is limited to the resources listed above.","title":"Support"},{"location":"about/SUPPORT/#support","text":"","title":"Support"},{"location":"about/SUPPORT/#how-to-file-issues-and-get-help","text":"This project uses GitHub Issues to track bugs and feature requests. Please search the existing issues before filing new issues to avoid duplicates. For new issues, file your bug or feature request as a new Issue. You may use GitHub Issues to raise questions, bug reports, and feature requests. For help and questions about using this project, please please contact ufo-agent@microsoft.com .","title":"How to file issues and get help"},{"location":"about/SUPPORT/#microsoft-support-policy","text":"Support for this PROJECT or PRODUCT is limited to the resources listed above.","title":"Microsoft Support Policy"},{"location":"advanced_usage/batch_mode/","text":"Batch Mode Batch mode is a feature of UFO, the agent allows batch automation of tasks. Quick Start Step 1: Create a Plan file Before starting the Batch mode, you need to create a plan file that contains the list of steps for the agent to follow. The plan file is a JSON file that contains the following fields: Field Description Type task The task description. String object The application or file to interact with. String close Determines whether to close the corresponding application or file after completing the task. Boolean Below is an example of a plan file: { \"task\": \"Type in a text of 'Test For Fun' with heading 1 level\", \"object\": \"draft.docx\", \"close\": False } Note The object field is the application or file that the agent will interact with. The object must be active (can be minimized) when starting the Batch mode. The structure of your files should be as follows, where tasks is the directory for your tasks and files is where your object files are stored: Parent tasks files Step 2: Start the Batch Mode To start the Batch mode, run the following command: # assume you are in the cloned UFO folder python ufo.py --task_name {task_name} --mode batch_normal --plan {plan_file} Tip Replace {task_name} with the name of the task and {plan_file} with the Path_to_Parent/Plan_file . Evaluation You may want to evaluate the task is completed successfully or not by following the plan. UFO will call the EvaluationAgent to evaluate the task if EVA_SESSION is set to True in the config_dev.yaml file. You can check the evaluation log in the logs/{task_name}/evaluation.log file. References The batch mode employs a PlanReader to parse the plan file and create a FromFileSession to follow the plan. PlanReader The PlanReader is located in the ufo/module/sessions/plan_reader.py file. The reader for a plan file. Initialize a plan reader. Parameters: plan_file ( str ) \u2013 The path of the plan file. Source code in module/sessions/plan_reader.py 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , plan_file : str ): \"\"\" Initialize a plan reader. :param plan_file: The path of the plan file. \"\"\" self . plan_file = plan_file with open ( plan_file , \"r\" ) as f : self . plan = json . load ( f ) self . remaining_steps = self . get_steps () self . support_apps = [ \"WINWORD.EXE\" , \"EXCEL.EXE\" , \"POWERPNT.EXE\" ] get_close () Check if the plan is closed. Returns: bool \u2013 True if the plan need closed, False otherwise. Source code in module/sessions/plan_reader.py 30 31 32 33 34 35 36 def get_close ( self ) -> bool : \"\"\" Check if the plan is closed. :return: True if the plan need closed, False otherwise. \"\"\" return self . plan . get ( \"close\" , False ) get_host_agent_request () Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def get_host_agent_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" object_name = self . get_operation_object () request = ( f \"Open and select the application of { object_name } , and output the FINISH status immediately. \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request get_host_request () Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def get_host_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" task = self . get_task () object_name = self . get_operation_object () if object_name in self . support_apps : request = task else : request = ( f \"Your task is ' { task } '. And open the application of { object_name } . \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request get_initial_request () Get the initial request in the plan. Returns: str \u2013 The initial request. Source code in module/sessions/plan_reader.py 62 63 64 65 66 67 68 69 70 71 72 73 def get_initial_request ( self ) -> str : \"\"\" Get the initial request in the plan. :return: The initial request. \"\"\" task = self . get_task () object_name = self . get_operation_object () request = f \" { task } in { object_name } \" return request get_operation_object () Get the operation object in the step. Returns: str \u2013 The operation object. Source code in module/sessions/plan_reader.py 54 55 56 57 58 59 60 def get_operation_object ( self ) -> str : \"\"\" Get the operation object in the step. :return: The operation object. \"\"\" return self . plan . get ( \"object\" , None ) . lower () get_root_path () Get the root path of the plan. Returns: str \u2013 The root path of the plan. Source code in module/sessions/plan_reader.py 148 149 150 151 152 153 154 def get_root_path ( self ) -> str : \"\"\" Get the root path of the plan. :return: The root path of the plan. \"\"\" return os . path . dirname ( os . path . abspath ( self . plan_file )) get_steps () Get the steps in the plan. Returns: List [ str ] \u2013 The steps in the plan. Source code in module/sessions/plan_reader.py 46 47 48 49 50 51 52 def get_steps ( self ) -> List [ str ]: \"\"\" Get the steps in the plan. :return: The steps in the plan. \"\"\" return self . plan . get ( \"steps\" , []) get_support_apps () Get the support apps in the plan. Returns: List [ str ] \u2013 The support apps in the plan. Source code in module/sessions/plan_reader.py 103 104 105 106 107 108 109 def get_support_apps ( self ) -> List [ str ]: \"\"\" Get the support apps in the plan. :return: The support apps in the plan. \"\"\" return self . support_apps get_task () Get the task name. Returns: str \u2013 The task name. Source code in module/sessions/plan_reader.py 38 39 40 41 42 43 44 def get_task ( self ) -> str : \"\"\" Get the task name. :return: The task name. \"\"\" return self . plan . get ( \"task\" , \"\" ) next_step () Get the next step in the plan. Returns: Optional [ str ] \u2013 The next step. Source code in module/sessions/plan_reader.py 128 129 130 131 132 133 134 135 136 137 138 def next_step ( self ) -> Optional [ str ]: \"\"\" Get the next step in the plan. :return: The next step. \"\"\" if self . remaining_steps : step = self . remaining_steps . pop ( 0 ) return step return None task_finished () Check if the task is finished. Returns: bool \u2013 True if the task is finished, False otherwise. Source code in module/sessions/plan_reader.py 140 141 142 143 144 145 146 def task_finished ( self ) -> bool : \"\"\" Check if the task is finished. :return: True if the task is finished, False otherwise. \"\"\" return not self . remaining_steps FollowerSession The FromFileSession is also located in the ufo/module/sessions/session.py file. Bases: BaseSession A session for UFO from files. Initialize a session. Parameters: task ( str ) \u2013 The name of current task. plan_file ( str ) \u2013 The path of the plan file to follow. should_evaluate ( bool ) \u2013 Whether to evaluate the session. id ( int ) \u2013 The id of the session. Source code in module/sessions/session.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 def __init__ ( self , task : str , plan_file : str , should_evaluate : bool , id : int ) -> None : \"\"\" Initialize a session. :param task: The name of current task. :param plan_file: The path of the plan file to follow. :param should_evaluate: Whether to evaluate the session. :param id: The id of the session. \"\"\" super () . __init__ ( task , should_evaluate , id ) self . plan_file = plan_file self . plan_reader = PlanReader ( plan_file ) self . support_apps = self . plan_reader . get_support_apps () self . close = self . plan_reader . get_close () self . task_name = task . split ( \"/\" )[ 1 ] self . object_name = \"\" create_new_round () Create a new round. Source code in module/sessions/session.py 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 def create_new_round ( self ) -> None : \"\"\" Create a new round. \"\"\" # Get a request for the new round. request = self . next_request () # Create a new round and return None if the session is finished. if self . is_finished (): return None self . _host_agent . set_state ( ContinueHostAgentState ()) round = BaseRound ( request = request , agent = self . _host_agent , context = self . context , should_evaluate = configs . get ( \"EVA_ROUND\" , False ), id = self . total_rounds , ) self . add_round ( round . id , round ) return round get_app_com ( object_name ) Get the COM object name based on the object name. Parameters: object_name ( str ) \u2013 The name of the object. Returns: str \u2013 The COM object name. Source code in module/sessions/session.py 467 468 469 470 471 472 473 474 475 476 477 478 479 def get_app_com ( self , object_name : str ) -> str : \"\"\" Get the COM object name based on the object name. :param object_name: The name of the object. :return: The COM object name. \"\"\" application_mapping = { \".docx\" : \"Word.Application\" , \".xlsx\" : \"Excel.Application\" , \".pptx\" : \"PowerPoint.Application\" , } self . app_name = application_mapping . get ( object_name ) return self . app_name get_app_name ( object_name ) Get the application name based on the object name. Parameters: object_name ( str ) \u2013 The name of the object. Returns: str \u2013 The application name. Source code in module/sessions/session.py 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 def get_app_name ( self , object_name : str ) -> str : \"\"\" Get the application name based on the object name. :param object_name: The name of the object. :return: The application name. \"\"\" application_mapping = { \".docx\" : \"WINWORD.EXE\" , \".xlsx\" : \"EXCEL.EXE\" , \".pptx\" : \"POWERPNT.EXE\" , # \"outlook\": \"olk.exe\", # \"onenote\": \"ONENOTE.EXE\", } self . app_name = application_mapping . get ( object_name ) return self . app_name next_request () Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/session.py 438 439 440 441 442 443 444 445 446 447 448 449 def next_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" if self . total_rounds == 0 : utils . print_with_color ( self . plan_reader . get_host_request (), \"cyan\" ) return self . plan_reader . get_host_request () else : self . _finish = True return record_task_done () Record the task done. Source code in module/sessions/session.py 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 def record_task_done ( self ) -> None : \"\"\" Record the task done. \"\"\" is_record = configs . get ( \"TASK_STATUS\" , True ) if is_record : file_path = configs . get ( \"TASK_STATUS_FILE\" , os . path . join ( self . plan_file , \"../..\" , \"tasks_status.json\" ), ) task_done = json . load ( open ( file_path , \"r\" )) task_done [ self . task_name ] = True json . dump ( task_done , open ( file_path , \"w\" ), indent = 4 , ) request_to_evaluate () Get the request to evaluate. return: The request(s) to evaluate. Source code in module/sessions/session.py 543 544 545 546 547 548 def request_to_evaluate ( self ) -> str : \"\"\" Get the request to evaluate. return: The request(s) to evaluate. \"\"\" return self . plan_reader . get_task () run () Run the session. Source code in module/sessions/session.py 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 def run ( self ) -> None : \"\"\" Run the session. \"\"\" self . setup_application_environment () try : super () . run () self . record_task_done () except Exception as e : import traceback traceback . print_exc () print ( f \"An error occurred: { e } \" ) # Close the APP if the user ask so. self . terminate_application_processes () setup_application_environment () Sets up the application environment by determining the application name and command based on the operation object, and then launching the application. Raises: Exception: If an error occurs during the execution of the command or while interacting with the application via COM. Source code in module/sessions/session.py 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def setup_application_environment ( self ): \"\"\" Sets up the application environment by determining the application name and command based on the operation object, and then launching the application. Raises: Exception: If an error occurs during the execution of the command or while interacting with the application via COM. \"\"\" self . object_name = self . plan_reader . get_operation_object () if self . object_name : suffix = os . path . splitext ( self . object_name )[ 1 ] self . app_name = self . get_app_name ( suffix ) print ( \"app_name:\" , self . app_name ) if self . app_name not in self . support_apps : print ( f \"The app { self . app_name } is not supported.\" ) return # The app is not supported, so we don't need to setup the environment. file = self . plan_reader . get_file_path () code_snippet = f \"import os \\n os.system('start { self . app_name } \\\" { file } \\\" ')\" code_snippet = code_snippet . replace ( \" \\\\ \" , \" \\\\\\\\ \" ) # escape backslashes try : exec ( code_snippet , globals ()) app_com = self . get_app_com ( suffix ) time . sleep ( 2 ) # wait for the app to boot word_app = win32com . client . Dispatch ( app_com ) word_app . WindowState = 1 # wdWindowStateMaximize except Exception as e : print ( f \"An error occurred: { e } \" ) terminate_application_processes () Terminates specific application processes based on the provided conditions. Source code in module/sessions/session.py 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 def terminate_application_processes ( self ): \"\"\" Terminates specific application processes based on the provided conditions. \"\"\" if self . close : if self . object_name : for process in psutil . process_iter ([ \"name\" ]): if process . info [ \"name\" ] == self . app_name : os . system ( f \"taskkill /f /im { self . app_name } \" ) time . sleep ( 1 ) else : app_names = [ \"WINWORD.EXE\" , \"EXCEL.EXE\" , \"POWERPNT.EXE\" ] for process in psutil . process_iter ([ \"name\" ]): if process . info [ \"name\" ] in app_names : os . system ( f \"taskkill /f /im { process . info [ 'name' ] } \" ) time . sleep ( 1 )","title":"Batch Mode"},{"location":"advanced_usage/batch_mode/#batch-mode","text":"Batch mode is a feature of UFO, the agent allows batch automation of tasks.","title":"Batch Mode"},{"location":"advanced_usage/batch_mode/#quick-start","text":"","title":"Quick Start"},{"location":"advanced_usage/batch_mode/#step-1-create-a-plan-file","text":"Before starting the Batch mode, you need to create a plan file that contains the list of steps for the agent to follow. The plan file is a JSON file that contains the following fields: Field Description Type task The task description. String object The application or file to interact with. String close Determines whether to close the corresponding application or file after completing the task. Boolean Below is an example of a plan file: { \"task\": \"Type in a text of 'Test For Fun' with heading 1 level\", \"object\": \"draft.docx\", \"close\": False } Note The object field is the application or file that the agent will interact with. The object must be active (can be minimized) when starting the Batch mode. The structure of your files should be as follows, where tasks is the directory for your tasks and files is where your object files are stored: Parent tasks files","title":"Step 1: Create a Plan file"},{"location":"advanced_usage/batch_mode/#step-2-start-the-batch-mode","text":"To start the Batch mode, run the following command: # assume you are in the cloned UFO folder python ufo.py --task_name {task_name} --mode batch_normal --plan {plan_file} Tip Replace {task_name} with the name of the task and {plan_file} with the Path_to_Parent/Plan_file .","title":"Step 2: Start the Batch Mode"},{"location":"advanced_usage/batch_mode/#evaluation","text":"You may want to evaluate the task is completed successfully or not by following the plan. UFO will call the EvaluationAgent to evaluate the task if EVA_SESSION is set to True in the config_dev.yaml file. You can check the evaluation log in the logs/{task_name}/evaluation.log file.","title":"Evaluation"},{"location":"advanced_usage/batch_mode/#references","text":"The batch mode employs a PlanReader to parse the plan file and create a FromFileSession to follow the plan.","title":"References"},{"location":"advanced_usage/batch_mode/#planreader","text":"The PlanReader is located in the ufo/module/sessions/plan_reader.py file. The reader for a plan file. Initialize a plan reader. Parameters: plan_file ( str ) \u2013 The path of the plan file. Source code in module/sessions/plan_reader.py 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , plan_file : str ): \"\"\" Initialize a plan reader. :param plan_file: The path of the plan file. \"\"\" self . plan_file = plan_file with open ( plan_file , \"r\" ) as f : self . plan = json . load ( f ) self . remaining_steps = self . get_steps () self . support_apps = [ \"WINWORD.EXE\" , \"EXCEL.EXE\" , \"POWERPNT.EXE\" ]","title":"PlanReader"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_close","text":"Check if the plan is closed. Returns: bool \u2013 True if the plan need closed, False otherwise. Source code in module/sessions/plan_reader.py 30 31 32 33 34 35 36 def get_close ( self ) -> bool : \"\"\" Check if the plan is closed. :return: True if the plan need closed, False otherwise. \"\"\" return self . plan . get ( \"close\" , False )","title":"get_close"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_host_agent_request","text":"Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def get_host_agent_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" object_name = self . get_operation_object () request = ( f \"Open and select the application of { object_name } , and output the FINISH status immediately. \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request","title":"get_host_agent_request"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_host_request","text":"Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def get_host_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" task = self . get_task () object_name = self . get_operation_object () if object_name in self . support_apps : request = task else : request = ( f \"Your task is ' { task } '. And open the application of { object_name } . \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request","title":"get_host_request"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_initial_request","text":"Get the initial request in the plan. Returns: str \u2013 The initial request. Source code in module/sessions/plan_reader.py 62 63 64 65 66 67 68 69 70 71 72 73 def get_initial_request ( self ) -> str : \"\"\" Get the initial request in the plan. :return: The initial request. \"\"\" task = self . get_task () object_name = self . get_operation_object () request = f \" { task } in { object_name } \" return request","title":"get_initial_request"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_operation_object","text":"Get the operation object in the step. Returns: str \u2013 The operation object. Source code in module/sessions/plan_reader.py 54 55 56 57 58 59 60 def get_operation_object ( self ) -> str : \"\"\" Get the operation object in the step. :return: The operation object. \"\"\" return self . plan . get ( \"object\" , None ) . lower ()","title":"get_operation_object"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_root_path","text":"Get the root path of the plan. Returns: str \u2013 The root path of the plan. Source code in module/sessions/plan_reader.py 148 149 150 151 152 153 154 def get_root_path ( self ) -> str : \"\"\" Get the root path of the plan. :return: The root path of the plan. \"\"\" return os . path . dirname ( os . path . abspath ( self . plan_file ))","title":"get_root_path"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_steps","text":"Get the steps in the plan. Returns: List [ str ] \u2013 The steps in the plan. Source code in module/sessions/plan_reader.py 46 47 48 49 50 51 52 def get_steps ( self ) -> List [ str ]: \"\"\" Get the steps in the plan. :return: The steps in the plan. \"\"\" return self . plan . get ( \"steps\" , [])","title":"get_steps"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_support_apps","text":"Get the support apps in the plan. Returns: List [ str ] \u2013 The support apps in the plan. Source code in module/sessions/plan_reader.py 103 104 105 106 107 108 109 def get_support_apps ( self ) -> List [ str ]: \"\"\" Get the support apps in the plan. :return: The support apps in the plan. \"\"\" return self . support_apps","title":"get_support_apps"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.get_task","text":"Get the task name. Returns: str \u2013 The task name. Source code in module/sessions/plan_reader.py 38 39 40 41 42 43 44 def get_task ( self ) -> str : \"\"\" Get the task name. :return: The task name. \"\"\" return self . plan . get ( \"task\" , \"\" )","title":"get_task"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.next_step","text":"Get the next step in the plan. Returns: Optional [ str ] \u2013 The next step. Source code in module/sessions/plan_reader.py 128 129 130 131 132 133 134 135 136 137 138 def next_step ( self ) -> Optional [ str ]: \"\"\" Get the next step in the plan. :return: The next step. \"\"\" if self . remaining_steps : step = self . remaining_steps . pop ( 0 ) return step return None","title":"next_step"},{"location":"advanced_usage/batch_mode/#module.sessions.plan_reader.PlanReader.task_finished","text":"Check if the task is finished. Returns: bool \u2013 True if the task is finished, False otherwise. Source code in module/sessions/plan_reader.py 140 141 142 143 144 145 146 def task_finished ( self ) -> bool : \"\"\" Check if the task is finished. :return: True if the task is finished, False otherwise. \"\"\" return not self . remaining_steps","title":"task_finished"},{"location":"advanced_usage/batch_mode/#followersession","text":"The FromFileSession is also located in the ufo/module/sessions/session.py file. Bases: BaseSession A session for UFO from files. Initialize a session. Parameters: task ( str ) \u2013 The name of current task. plan_file ( str ) \u2013 The path of the plan file to follow. should_evaluate ( bool ) \u2013 Whether to evaluate the session. id ( int ) \u2013 The id of the session. Source code in module/sessions/session.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 def __init__ ( self , task : str , plan_file : str , should_evaluate : bool , id : int ) -> None : \"\"\" Initialize a session. :param task: The name of current task. :param plan_file: The path of the plan file to follow. :param should_evaluate: Whether to evaluate the session. :param id: The id of the session. \"\"\" super () . __init__ ( task , should_evaluate , id ) self . plan_file = plan_file self . plan_reader = PlanReader ( plan_file ) self . support_apps = self . plan_reader . get_support_apps () self . close = self . plan_reader . get_close () self . task_name = task . split ( \"/\" )[ 1 ] self . object_name = \"\"","title":"FollowerSession"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.create_new_round","text":"Create a new round. Source code in module/sessions/session.py 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 def create_new_round ( self ) -> None : \"\"\" Create a new round. \"\"\" # Get a request for the new round. request = self . next_request () # Create a new round and return None if the session is finished. if self . is_finished (): return None self . _host_agent . set_state ( ContinueHostAgentState ()) round = BaseRound ( request = request , agent = self . _host_agent , context = self . context , should_evaluate = configs . get ( \"EVA_ROUND\" , False ), id = self . total_rounds , ) self . add_round ( round . id , round ) return round","title":"create_new_round"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.get_app_com","text":"Get the COM object name based on the object name. Parameters: object_name ( str ) \u2013 The name of the object. Returns: str \u2013 The COM object name. Source code in module/sessions/session.py 467 468 469 470 471 472 473 474 475 476 477 478 479 def get_app_com ( self , object_name : str ) -> str : \"\"\" Get the COM object name based on the object name. :param object_name: The name of the object. :return: The COM object name. \"\"\" application_mapping = { \".docx\" : \"Word.Application\" , \".xlsx\" : \"Excel.Application\" , \".pptx\" : \"PowerPoint.Application\" , } self . app_name = application_mapping . get ( object_name ) return self . app_name","title":"get_app_com"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.get_app_name","text":"Get the application name based on the object name. Parameters: object_name ( str ) \u2013 The name of the object. Returns: str \u2013 The application name. Source code in module/sessions/session.py 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 def get_app_name ( self , object_name : str ) -> str : \"\"\" Get the application name based on the object name. :param object_name: The name of the object. :return: The application name. \"\"\" application_mapping = { \".docx\" : \"WINWORD.EXE\" , \".xlsx\" : \"EXCEL.EXE\" , \".pptx\" : \"POWERPNT.EXE\" , # \"outlook\": \"olk.exe\", # \"onenote\": \"ONENOTE.EXE\", } self . app_name = application_mapping . get ( object_name ) return self . app_name","title":"get_app_name"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.next_request","text":"Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/session.py 438 439 440 441 442 443 444 445 446 447 448 449 def next_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" if self . total_rounds == 0 : utils . print_with_color ( self . plan_reader . get_host_request (), \"cyan\" ) return self . plan_reader . get_host_request () else : self . _finish = True return","title":"next_request"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.record_task_done","text":"Record the task done. Source code in module/sessions/session.py 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 def record_task_done ( self ) -> None : \"\"\" Record the task done. \"\"\" is_record = configs . get ( \"TASK_STATUS\" , True ) if is_record : file_path = configs . get ( \"TASK_STATUS_FILE\" , os . path . join ( self . plan_file , \"../..\" , \"tasks_status.json\" ), ) task_done = json . load ( open ( file_path , \"r\" )) task_done [ self . task_name ] = True json . dump ( task_done , open ( file_path , \"w\" ), indent = 4 , )","title":"record_task_done"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.request_to_evaluate","text":"Get the request to evaluate. return: The request(s) to evaluate. Source code in module/sessions/session.py 543 544 545 546 547 548 def request_to_evaluate ( self ) -> str : \"\"\" Get the request to evaluate. return: The request(s) to evaluate. \"\"\" return self . plan_reader . get_task ()","title":"request_to_evaluate"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.run","text":"Run the session. Source code in module/sessions/session.py 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 def run ( self ) -> None : \"\"\" Run the session. \"\"\" self . setup_application_environment () try : super () . run () self . record_task_done () except Exception as e : import traceback traceback . print_exc () print ( f \"An error occurred: { e } \" ) # Close the APP if the user ask so. self . terminate_application_processes ()","title":"run"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.setup_application_environment","text":"Sets up the application environment by determining the application name and command based on the operation object, and then launching the application. Raises: Exception: If an error occurs during the execution of the command or while interacting with the application via COM. Source code in module/sessions/session.py 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def setup_application_environment ( self ): \"\"\" Sets up the application environment by determining the application name and command based on the operation object, and then launching the application. Raises: Exception: If an error occurs during the execution of the command or while interacting with the application via COM. \"\"\" self . object_name = self . plan_reader . get_operation_object () if self . object_name : suffix = os . path . splitext ( self . object_name )[ 1 ] self . app_name = self . get_app_name ( suffix ) print ( \"app_name:\" , self . app_name ) if self . app_name not in self . support_apps : print ( f \"The app { self . app_name } is not supported.\" ) return # The app is not supported, so we don't need to setup the environment. file = self . plan_reader . get_file_path () code_snippet = f \"import os \\n os.system('start { self . app_name } \\\" { file } \\\" ')\" code_snippet = code_snippet . replace ( \" \\\\ \" , \" \\\\\\\\ \" ) # escape backslashes try : exec ( code_snippet , globals ()) app_com = self . get_app_com ( suffix ) time . sleep ( 2 ) # wait for the app to boot word_app = win32com . client . Dispatch ( app_com ) word_app . WindowState = 1 # wdWindowStateMaximize except Exception as e : print ( f \"An error occurred: { e } \" )","title":"setup_application_environment"},{"location":"advanced_usage/batch_mode/#module.sessions.session.FromFileSession.terminate_application_processes","text":"Terminates specific application processes based on the provided conditions. Source code in module/sessions/session.py 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 def terminate_application_processes ( self ): \"\"\" Terminates specific application processes based on the provided conditions. \"\"\" if self . close : if self . object_name : for process in psutil . process_iter ([ \"name\" ]): if process . info [ \"name\" ] == self . app_name : os . system ( f \"taskkill /f /im { self . app_name } \" ) time . sleep ( 1 ) else : app_names = [ \"WINWORD.EXE\" , \"EXCEL.EXE\" , \"POWERPNT.EXE\" ] for process in psutil . process_iter ([ \"name\" ]): if process . info [ \"name\" ] in app_names : os . system ( f \"taskkill /f /im { process . info [ 'name' ] } \" ) time . sleep ( 1 )","title":"terminate_application_processes"},{"location":"advanced_usage/customization/","text":"Customization Sometimes, UFO may need additional context or information to complete a task. These information are important and customized for each user. UFO can ask the user for additional information and save it in the local memory for future reference. This customization feature allows UFO to provide a more personalized experience to the user. Scenario Let's consider a scenario where UFO needs additional information to complete a task. UFO is tasked with booking a cab for the user. To book a cab, UFO needs to know the exact address of the user. UFO will ask the user for the address and save it in the local memory for future reference. Next time, when UFO is asked to complete a task that requires the user's address, UFO will use the saved address to complete the task, without asking the user again. Implementation We currently implement the customization feature in the HostAgent class. When the HostAgent needs additional information, it will transit to the PENDING state and ask the user for the information. The user will provide the information, and the HostAgent will save it in the local memory base for future reference. The saved information is stored in the blackboard and can be accessed by all agents in the session. Note The customization memory base is only saved in a local file . These information will not upload to the cloud or any other storage to protect the user's privacy. Configuration You can configure the customization feature by setting the following field in the config_dev.yaml file. Configuration Option Description Type Default Value USE_CUSTOMIZATION Whether to enable the customization. Boolean True QA_PAIR_FILE The path for the historical QA pairs. String \"customization/historical_qa.txt\" QA_PAIR_NUM The number of QA pairs for the customization. Integer 20","title":"Customization"},{"location":"advanced_usage/customization/#customization","text":"Sometimes, UFO may need additional context or information to complete a task. These information are important and customized for each user. UFO can ask the user for additional information and save it in the local memory for future reference. This customization feature allows UFO to provide a more personalized experience to the user.","title":"Customization"},{"location":"advanced_usage/customization/#scenario","text":"Let's consider a scenario where UFO needs additional information to complete a task. UFO is tasked with booking a cab for the user. To book a cab, UFO needs to know the exact address of the user. UFO will ask the user for the address and save it in the local memory for future reference. Next time, when UFO is asked to complete a task that requires the user's address, UFO will use the saved address to complete the task, without asking the user again.","title":"Scenario"},{"location":"advanced_usage/customization/#implementation","text":"We currently implement the customization feature in the HostAgent class. When the HostAgent needs additional information, it will transit to the PENDING state and ask the user for the information. The user will provide the information, and the HostAgent will save it in the local memory base for future reference. The saved information is stored in the blackboard and can be accessed by all agents in the session. Note The customization memory base is only saved in a local file . These information will not upload to the cloud or any other storage to protect the user's privacy.","title":"Implementation"},{"location":"advanced_usage/customization/#configuration","text":"You can configure the customization feature by setting the following field in the config_dev.yaml file. Configuration Option Description Type Default Value USE_CUSTOMIZATION Whether to enable the customization. Boolean True QA_PAIR_FILE The path for the historical QA pairs. String \"customization/historical_qa.txt\" QA_PAIR_NUM The number of QA pairs for the customization. Integer 20","title":"Configuration"},{"location":"advanced_usage/follower_mode/","text":"Follower Mode The Follower mode is a feature of UFO that the agent follows a list of pre-defined steps in natural language to take actions on applications. Different from the normal mode, this mode creates an FollowerAgent that follows the plan list provided by the user to interact with the application, instead of generating the plan itself. This mode is useful for debugging and software testing or verification. Quick Start Step 1: Create a Plan file Before starting the Follower mode, you need to create a plan file that contains the list of steps for the agent to follow. The plan file is a JSON file that contains the following fields: Field Description Type task The task description. String steps The list of steps for the agent to follow. List of Strings object The application or file to interact with. String Below is an example of a plan file: { \"task\": \"Type in a text of 'Test For Fun' with heading 1 level\", \"steps\": [ \"1.type in 'Test For Fun'\", \"2.Select the 'Test For Fun' text\", \"3.Click 'Home' tab to show the 'Styles' ribbon tab\", \"4.Click 'Styles' ribbon tab to show the style 'Heading 1'\", \"5.Click 'Heading 1' style to apply the style to the selected text\" ], \"object\": \"draft.docx\" } Note The object field is the application or file that the agent will interact with. The object must be active (can be minimized) when starting the Follower mode. Step 2: Start the Follower Mode To start the Follower mode, run the following command: # assume you are in the cloned UFO folder python ufo.py --task_name {task_name} --mode follower --plan {plan_file} Tip Replace {task_name} with the name of the task and {plan_file} with the path to the plan file. Step 3: Run in Batch (Optional) You can also run the Follower mode in batch mode by providing a folder containing multiple plan files. The agent will follow the plans in the folder one by one. To run in batch mode, run the following command: # assume you are in the cloned UFO folder python ufo.py --task_name {task_name} --mode follower --plan {plan_folder} UFO will automatically detect the plan files in the folder and run them one by one. Tip Replace {task_name} with the name of the task and {plan_folder} with the path to the folder containing plan files. Evaluation You may want to evaluate the task is completed successfully or not by following the plan. UFO will call the EvaluationAgent to evaluate the task if EVA_SESSION is set to True in the config_dev.yaml file. You can check the evaluation log in the logs/{task_name}/evaluation.log file. References The follower mode employs a PlanReader to parse the plan file and create a FollowerSession to follow the plan. PlanReader The PlanReader is located in the ufo/module/sessions/plan_reader.py file. The reader for a plan file. Initialize a plan reader. Parameters: plan_file ( str ) \u2013 The path of the plan file. Source code in module/sessions/plan_reader.py 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , plan_file : str ): \"\"\" Initialize a plan reader. :param plan_file: The path of the plan file. \"\"\" self . plan_file = plan_file with open ( plan_file , \"r\" ) as f : self . plan = json . load ( f ) self . remaining_steps = self . get_steps () self . support_apps = [ \"WINWORD.EXE\" , \"EXCEL.EXE\" , \"POWERPNT.EXE\" ] get_close () Check if the plan is closed. Returns: bool \u2013 True if the plan need closed, False otherwise. Source code in module/sessions/plan_reader.py 30 31 32 33 34 35 36 def get_close ( self ) -> bool : \"\"\" Check if the plan is closed. :return: True if the plan need closed, False otherwise. \"\"\" return self . plan . get ( \"close\" , False ) get_host_agent_request () Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def get_host_agent_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" object_name = self . get_operation_object () request = ( f \"Open and select the application of { object_name } , and output the FINISH status immediately. \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request get_host_request () Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def get_host_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" task = self . get_task () object_name = self . get_operation_object () if object_name in self . support_apps : request = task else : request = ( f \"Your task is ' { task } '. And open the application of { object_name } . \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request get_initial_request () Get the initial request in the plan. Returns: str \u2013 The initial request. Source code in module/sessions/plan_reader.py 62 63 64 65 66 67 68 69 70 71 72 73 def get_initial_request ( self ) -> str : \"\"\" Get the initial request in the plan. :return: The initial request. \"\"\" task = self . get_task () object_name = self . get_operation_object () request = f \" { task } in { object_name } \" return request get_operation_object () Get the operation object in the step. Returns: str \u2013 The operation object. Source code in module/sessions/plan_reader.py 54 55 56 57 58 59 60 def get_operation_object ( self ) -> str : \"\"\" Get the operation object in the step. :return: The operation object. \"\"\" return self . plan . get ( \"object\" , None ) . lower () get_root_path () Get the root path of the plan. Returns: str \u2013 The root path of the plan. Source code in module/sessions/plan_reader.py 148 149 150 151 152 153 154 def get_root_path ( self ) -> str : \"\"\" Get the root path of the plan. :return: The root path of the plan. \"\"\" return os . path . dirname ( os . path . abspath ( self . plan_file )) get_steps () Get the steps in the plan. Returns: List [ str ] \u2013 The steps in the plan. Source code in module/sessions/plan_reader.py 46 47 48 49 50 51 52 def get_steps ( self ) -> List [ str ]: \"\"\" Get the steps in the plan. :return: The steps in the plan. \"\"\" return self . plan . get ( \"steps\" , []) get_support_apps () Get the support apps in the plan. Returns: List [ str ] \u2013 The support apps in the plan. Source code in module/sessions/plan_reader.py 103 104 105 106 107 108 109 def get_support_apps ( self ) -> List [ str ]: \"\"\" Get the support apps in the plan. :return: The support apps in the plan. \"\"\" return self . support_apps get_task () Get the task name. Returns: str \u2013 The task name. Source code in module/sessions/plan_reader.py 38 39 40 41 42 43 44 def get_task ( self ) -> str : \"\"\" Get the task name. :return: The task name. \"\"\" return self . plan . get ( \"task\" , \"\" ) next_step () Get the next step in the plan. Returns: Optional [ str ] \u2013 The next step. Source code in module/sessions/plan_reader.py 128 129 130 131 132 133 134 135 136 137 138 def next_step ( self ) -> Optional [ str ]: \"\"\" Get the next step in the plan. :return: The next step. \"\"\" if self . remaining_steps : step = self . remaining_steps . pop ( 0 ) return step return None task_finished () Check if the task is finished. Returns: bool \u2013 True if the task is finished, False otherwise. Source code in module/sessions/plan_reader.py 140 141 142 143 144 145 146 def task_finished ( self ) -> bool : \"\"\" Check if the task is finished. :return: True if the task is finished, False otherwise. \"\"\" return not self . remaining_steps FollowerSession The FollowerSession is also located in the ufo/module/sessions/session.py file. Bases: BaseSession A session for following a list of plan for action taken. This session is used for the follower agent, which accepts a plan file to follow using the PlanReader. Initialize a session. Parameters: task ( str ) \u2013 The name of current task. plan_file ( str ) \u2013 The path of the plan file to follow. should_evaluate ( bool ) \u2013 Whether to evaluate the session. id ( int ) \u2013 The id of the session. Source code in module/sessions/session.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 def __init__ ( self , task : str , plan_file : str , should_evaluate : bool , id : int ) -> None : \"\"\" Initialize a session. :param task: The name of current task. :param plan_file: The path of the plan file to follow. :param should_evaluate: Whether to evaluate the session. :param id: The id of the session. \"\"\" super () . __init__ ( task , should_evaluate , id ) self . plan_reader = PlanReader ( plan_file ) create_new_round () Create a new round. Source code in module/sessions/session.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 def create_new_round ( self ) -> None : \"\"\" Create a new round. \"\"\" # Get a request for the new round. request = self . next_request () # Create a new round and return None if the session is finished. if self . is_finished (): return None if self . total_rounds == 0 : utils . print_with_color ( \"Complete the following request:\" , \"yellow\" ) utils . print_with_color ( self . plan_reader . get_initial_request (), \"cyan\" ) agent = self . _host_agent else : self . context . set ( ContextNames . SUBTASK , request ) agent = self . _host_agent . create_app_agent ( application_window_name = self . context . get ( ContextNames . APPLICATION_PROCESS_NAME ), application_root_name = self . context . get ( ContextNames . APPLICATION_ROOT_NAME ), request = request , mode = self . context . get ( ContextNames . MODE ), ) # Clear the memory and set the state to continue the app agent. agent . clear_memory () agent . blackboard . requests . clear () agent . set_state ( ContinueAppAgentState ()) round = BaseRound ( request = request , agent = agent , context = self . context , should_evaluate = configs . get ( \"EVA_ROUND\" , False ), id = self . total_rounds , ) self . add_round ( round . id , round ) return round next_request () Get the request for the new round. Source code in module/sessions/session.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 def next_request ( self ) -> str : \"\"\" Get the request for the new round. \"\"\" # If the task is finished, return an empty string. if self . plan_reader . task_finished (): self . _finish = True return \"\" # Get the request from the plan reader. if self . total_rounds == 0 : return self . plan_reader . get_host_agent_request () else : return self . plan_reader . next_step () request_to_evaluate () Get the request to evaluate. return: The request(s) to evaluate. Source code in module/sessions/session.py 371 372 373 374 375 376 377 def request_to_evaluate ( self ) -> str : \"\"\" Get the request to evaluate. return: The request(s) to evaluate. \"\"\" return self . plan_reader . get_task ()","title":"Follower Mode"},{"location":"advanced_usage/follower_mode/#follower-mode","text":"The Follower mode is a feature of UFO that the agent follows a list of pre-defined steps in natural language to take actions on applications. Different from the normal mode, this mode creates an FollowerAgent that follows the plan list provided by the user to interact with the application, instead of generating the plan itself. This mode is useful for debugging and software testing or verification.","title":"Follower Mode"},{"location":"advanced_usage/follower_mode/#quick-start","text":"","title":"Quick Start"},{"location":"advanced_usage/follower_mode/#step-1-create-a-plan-file","text":"Before starting the Follower mode, you need to create a plan file that contains the list of steps for the agent to follow. The plan file is a JSON file that contains the following fields: Field Description Type task The task description. String steps The list of steps for the agent to follow. List of Strings object The application or file to interact with. String Below is an example of a plan file: { \"task\": \"Type in a text of 'Test For Fun' with heading 1 level\", \"steps\": [ \"1.type in 'Test For Fun'\", \"2.Select the 'Test For Fun' text\", \"3.Click 'Home' tab to show the 'Styles' ribbon tab\", \"4.Click 'Styles' ribbon tab to show the style 'Heading 1'\", \"5.Click 'Heading 1' style to apply the style to the selected text\" ], \"object\": \"draft.docx\" } Note The object field is the application or file that the agent will interact with. The object must be active (can be minimized) when starting the Follower mode.","title":"Step 1: Create a Plan file"},{"location":"advanced_usage/follower_mode/#step-2-start-the-follower-mode","text":"To start the Follower mode, run the following command: # assume you are in the cloned UFO folder python ufo.py --task_name {task_name} --mode follower --plan {plan_file} Tip Replace {task_name} with the name of the task and {plan_file} with the path to the plan file.","title":"Step 2: Start the Follower Mode"},{"location":"advanced_usage/follower_mode/#step-3-run-in-batch-optional","text":"You can also run the Follower mode in batch mode by providing a folder containing multiple plan files. The agent will follow the plans in the folder one by one. To run in batch mode, run the following command: # assume you are in the cloned UFO folder python ufo.py --task_name {task_name} --mode follower --plan {plan_folder} UFO will automatically detect the plan files in the folder and run them one by one. Tip Replace {task_name} with the name of the task and {plan_folder} with the path to the folder containing plan files.","title":"Step 3: Run in Batch (Optional)"},{"location":"advanced_usage/follower_mode/#evaluation","text":"You may want to evaluate the task is completed successfully or not by following the plan. UFO will call the EvaluationAgent to evaluate the task if EVA_SESSION is set to True in the config_dev.yaml file. You can check the evaluation log in the logs/{task_name}/evaluation.log file.","title":"Evaluation"},{"location":"advanced_usage/follower_mode/#references","text":"The follower mode employs a PlanReader to parse the plan file and create a FollowerSession to follow the plan.","title":"References"},{"location":"advanced_usage/follower_mode/#planreader","text":"The PlanReader is located in the ufo/module/sessions/plan_reader.py file. The reader for a plan file. Initialize a plan reader. Parameters: plan_file ( str ) \u2013 The path of the plan file. Source code in module/sessions/plan_reader.py 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , plan_file : str ): \"\"\" Initialize a plan reader. :param plan_file: The path of the plan file. \"\"\" self . plan_file = plan_file with open ( plan_file , \"r\" ) as f : self . plan = json . load ( f ) self . remaining_steps = self . get_steps () self . support_apps = [ \"WINWORD.EXE\" , \"EXCEL.EXE\" , \"POWERPNT.EXE\" ]","title":"PlanReader"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_close","text":"Check if the plan is closed. Returns: bool \u2013 True if the plan need closed, False otherwise. Source code in module/sessions/plan_reader.py 30 31 32 33 34 35 36 def get_close ( self ) -> bool : \"\"\" Check if the plan is closed. :return: True if the plan need closed, False otherwise. \"\"\" return self . plan . get ( \"close\" , False )","title":"get_close"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_host_agent_request","text":"Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def get_host_agent_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" object_name = self . get_operation_object () request = ( f \"Open and select the application of { object_name } , and output the FINISH status immediately. \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request","title":"get_host_agent_request"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_host_request","text":"Get the request for the host agent. Returns: str \u2013 The request for the host agent. Source code in module/sessions/plan_reader.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def get_host_request ( self ) -> str : \"\"\" Get the request for the host agent. :return: The request for the host agent. \"\"\" task = self . get_task () object_name = self . get_operation_object () if object_name in self . support_apps : request = task else : request = ( f \"Your task is ' { task } '. And open the application of { object_name } . \" \"You must output the selected application with their control text and label even if it is already open.\" ) return request","title":"get_host_request"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_initial_request","text":"Get the initial request in the plan. Returns: str \u2013 The initial request. Source code in module/sessions/plan_reader.py 62 63 64 65 66 67 68 69 70 71 72 73 def get_initial_request ( self ) -> str : \"\"\" Get the initial request in the plan. :return: The initial request. \"\"\" task = self . get_task () object_name = self . get_operation_object () request = f \" { task } in { object_name } \" return request","title":"get_initial_request"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_operation_object","text":"Get the operation object in the step. Returns: str \u2013 The operation object. Source code in module/sessions/plan_reader.py 54 55 56 57 58 59 60 def get_operation_object ( self ) -> str : \"\"\" Get the operation object in the step. :return: The operation object. \"\"\" return self . plan . get ( \"object\" , None ) . lower ()","title":"get_operation_object"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_root_path","text":"Get the root path of the plan. Returns: str \u2013 The root path of the plan. Source code in module/sessions/plan_reader.py 148 149 150 151 152 153 154 def get_root_path ( self ) -> str : \"\"\" Get the root path of the plan. :return: The root path of the plan. \"\"\" return os . path . dirname ( os . path . abspath ( self . plan_file ))","title":"get_root_path"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_steps","text":"Get the steps in the plan. Returns: List [ str ] \u2013 The steps in the plan. Source code in module/sessions/plan_reader.py 46 47 48 49 50 51 52 def get_steps ( self ) -> List [ str ]: \"\"\" Get the steps in the plan. :return: The steps in the plan. \"\"\" return self . plan . get ( \"steps\" , [])","title":"get_steps"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_support_apps","text":"Get the support apps in the plan. Returns: List [ str ] \u2013 The support apps in the plan. Source code in module/sessions/plan_reader.py 103 104 105 106 107 108 109 def get_support_apps ( self ) -> List [ str ]: \"\"\" Get the support apps in the plan. :return: The support apps in the plan. \"\"\" return self . support_apps","title":"get_support_apps"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.get_task","text":"Get the task name. Returns: str \u2013 The task name. Source code in module/sessions/plan_reader.py 38 39 40 41 42 43 44 def get_task ( self ) -> str : \"\"\" Get the task name. :return: The task name. \"\"\" return self . plan . get ( \"task\" , \"\" )","title":"get_task"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.next_step","text":"Get the next step in the plan. Returns: Optional [ str ] \u2013 The next step. Source code in module/sessions/plan_reader.py 128 129 130 131 132 133 134 135 136 137 138 def next_step ( self ) -> Optional [ str ]: \"\"\" Get the next step in the plan. :return: The next step. \"\"\" if self . remaining_steps : step = self . remaining_steps . pop ( 0 ) return step return None","title":"next_step"},{"location":"advanced_usage/follower_mode/#module.sessions.plan_reader.PlanReader.task_finished","text":"Check if the task is finished. Returns: bool \u2013 True if the task is finished, False otherwise. Source code in module/sessions/plan_reader.py 140 141 142 143 144 145 146 def task_finished ( self ) -> bool : \"\"\" Check if the task is finished. :return: True if the task is finished, False otherwise. \"\"\" return not self . remaining_steps","title":"task_finished"},{"location":"advanced_usage/follower_mode/#followersession","text":"The FollowerSession is also located in the ufo/module/sessions/session.py file. Bases: BaseSession A session for following a list of plan for action taken. This session is used for the follower agent, which accepts a plan file to follow using the PlanReader. Initialize a session. Parameters: task ( str ) \u2013 The name of current task. plan_file ( str ) \u2013 The path of the plan file to follow. should_evaluate ( bool ) \u2013 Whether to evaluate the session. id ( int ) \u2013 The id of the session. Source code in module/sessions/session.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 def __init__ ( self , task : str , plan_file : str , should_evaluate : bool , id : int ) -> None : \"\"\" Initialize a session. :param task: The name of current task. :param plan_file: The path of the plan file to follow. :param should_evaluate: Whether to evaluate the session. :param id: The id of the session. \"\"\" super () . __init__ ( task , should_evaluate , id ) self . plan_reader = PlanReader ( plan_file )","title":"FollowerSession"},{"location":"advanced_usage/follower_mode/#module.sessions.session.FollowerSession.create_new_round","text":"Create a new round. Source code in module/sessions/session.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 def create_new_round ( self ) -> None : \"\"\" Create a new round. \"\"\" # Get a request for the new round. request = self . next_request () # Create a new round and return None if the session is finished. if self . is_finished (): return None if self . total_rounds == 0 : utils . print_with_color ( \"Complete the following request:\" , \"yellow\" ) utils . print_with_color ( self . plan_reader . get_initial_request (), \"cyan\" ) agent = self . _host_agent else : self . context . set ( ContextNames . SUBTASK , request ) agent = self . _host_agent . create_app_agent ( application_window_name = self . context . get ( ContextNames . APPLICATION_PROCESS_NAME ), application_root_name = self . context . get ( ContextNames . APPLICATION_ROOT_NAME ), request = request , mode = self . context . get ( ContextNames . MODE ), ) # Clear the memory and set the state to continue the app agent. agent . clear_memory () agent . blackboard . requests . clear () agent . set_state ( ContinueAppAgentState ()) round = BaseRound ( request = request , agent = agent , context = self . context , should_evaluate = configs . get ( \"EVA_ROUND\" , False ), id = self . total_rounds , ) self . add_round ( round . id , round ) return round","title":"create_new_round"},{"location":"advanced_usage/follower_mode/#module.sessions.session.FollowerSession.next_request","text":"Get the request for the new round. Source code in module/sessions/session.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 def next_request ( self ) -> str : \"\"\" Get the request for the new round. \"\"\" # If the task is finished, return an empty string. if self . plan_reader . task_finished (): self . _finish = True return \"\" # Get the request from the plan reader. if self . total_rounds == 0 : return self . plan_reader . get_host_agent_request () else : return self . plan_reader . next_step ()","title":"next_request"},{"location":"advanced_usage/follower_mode/#module.sessions.session.FollowerSession.request_to_evaluate","text":"Get the request to evaluate. return: The request(s) to evaluate. Source code in module/sessions/session.py 371 372 373 374 375 376 377 def request_to_evaluate ( self ) -> str : \"\"\" Get the request to evaluate. return: The request(s) to evaluate. \"\"\" return self . plan_reader . get_task ()","title":"request_to_evaluate"},{"location":"advanced_usage/multi_action/","text":"Speculative Multi-Action Execution UFO\u00b2 introduces a new feature called Speculative Multi-Action Execution . This feature allows the agent to bundle several predicted steps into one LLM call, which are then validated live. This approach can lead to up to 51% fewer queries compared to inferring each step separately. The agent will first predict a batch of likely actions and then validate them against the live UIA state in a single shot. We illustrate the speculative multi-action execution in the figure below: Configuration To activate the speculative multi-action execution, you need to set ACTION_SEQUENCE to True in the config_dev.yaml file. ACTION_SEQUENCE: True References The implementation of the speculative multi-action execution is located in the ufo/agents/processors/actions.py file. The following classes are used for the speculative multi-action execution: Source code in agents/processors/actions.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def __init__ ( self , function : str = \"\" , args : Dict [ str , Any ] = {}, control_label : str = \"\" , control_text : str = \"\" , after_status : str = \"\" , results : Optional [ ActionExecutionLog ] = None , configs = Config . get_instance () . config_data , ): self . _function = function self . _args = args self . _control_label = control_label self . _control_text = control_text self . _after_status = after_status self . _results = ActionExecutionLog () if results is None else results self . _configs = configs self . _control_log = BaseControlLog () after_status property Get the status. Returns: str \u2013 The status. args property Get the arguments. Returns: Dict [ str , Any ] \u2013 The arguments. command_string property Generate a function call string. Returns: str \u2013 The function call string. control_label property Get the control label. Returns: str \u2013 The control label. control_log property writable Get the control log. Returns: BaseControlLog \u2013 The control log. control_text property Get the control text. Returns: str \u2013 The control text. function property Get the function name. Returns: str \u2013 The function. results property writable Get the results. Returns: ActionExecutionLog \u2013 The results. action_flow ( puppeteer , control_dict , application_window ) Execute the action flow. Parameters: puppeteer ( AppPuppeteer ) \u2013 The puppeteer that controls the application. control_dict ( Dict [ str , UIAWrapper ] ) \u2013 The control dictionary. application_window ( UIAWrapper ) \u2013 The application window where the control is located. Returns: Tuple [ ActionExecutionLog , BaseControlLog ] \u2013 The action execution log. Source code in agents/processors/actions.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 def action_flow ( self , puppeteer : AppPuppeteer , control_dict : Dict [ str , UIAWrapper ], application_window : UIAWrapper , ) -> Tuple [ ActionExecutionLog , BaseControlLog ]: \"\"\" Execute the action flow. :param puppeteer: The puppeteer that controls the application. :param control_dict: The control dictionary. :param application_window: The application window where the control is located. :return: The action execution log. \"\"\" control_selected : UIAWrapper = control_dict . get ( self . control_label , None ) # If the control is selected, but not available, return an error. if control_selected is not None and not self . _control_validation ( control_selected ): self . results = ActionExecutionLog ( status = \"error\" , traceback = \"Control is not available.\" , error = \"Control is not available.\" , ) self . _control_log = BaseControlLog () return self . results # Create the control receiver. puppeteer . receiver_manager . create_ui_control_receiver ( control_selected , application_window ) if self . function : if self . _configs . get ( \"SHOW_VISUAL_OUTLINE_ON_SCREEN\" , True ): if control_selected : control_selected . draw_outline ( colour = \"red\" , thickness = 3 ) time . sleep ( self . _configs . get ( \"RECTANGLE_TIME\" , 0 )) self . _control_log = self . _get_control_log ( control_selected = control_selected , application_window = application_window ) try : return_value = self . execute ( puppeteer = puppeteer ) if not utils . is_json_serializable ( return_value ): return_value = \"\" self . results = ActionExecutionLog ( status = \"success\" , return_value = return_value , ) except Exception as e : import traceback self . results = ActionExecutionLog ( status = \"error\" , traceback = traceback . format_exc (), error = str ( e ), ) return self . results count_repeat_times ( previous_actions ) Get the times of the same action in the previous actions. Parameters: previous_actions ( List [ Dict [ str , Any ]] ) \u2013 The previous actions. Returns: int \u2013 The times of the same action in the previous actions. Source code in agents/processors/actions.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def count_repeat_times ( self , previous_actions : List [ Dict [ str , Any ]]) -> int : \"\"\" Get the times of the same action in the previous actions. :param previous_actions: The previous actions. :return: The times of the same action in the previous actions. \"\"\" count = 0 for action in previous_actions [:: - 1 ]: if self . is_same_action ( action ): count += 1 else : break return count execute ( puppeteer ) Execute the action. Parameters: puppeteer ( AppPuppeteer ) \u2013 The puppeteer that controls the application. Source code in agents/processors/actions.py 234 235 236 237 238 239 def execute ( self , puppeteer : AppPuppeteer ) -> Any : \"\"\" Execute the action. :param puppeteer: The puppeteer that controls the application. \"\"\" return puppeteer . execute_command ( self . function , self . args ) get_operation_point_list () Get the operation points of the action. Returns: List [ Tuple [ int ]] \u2013 The operation points of the action. Source code in agents/processors/actions.py 364 365 366 367 368 369 370 371 372 373 374 375 def get_operation_point_list ( self ) -> List [ Tuple [ int ]]: \"\"\" Get the operation points of the action. :return: The operation points of the action. \"\"\" if \"path\" in self . args : return [( point [ \"x\" ], point [ \"y\" ]) for point in self . args [ \"path\" ]] elif \"x\" in self . args and \"y\" in self . args : return [( self . args [ \"x\" ], self . args [ \"y\" ])] else : return [] is_same_action ( action_to_compare ) Check whether the two actions are the same. Parameters: action_to_compare ( Dict [ str , Any ] ) \u2013 The action to compare with the current action. Returns: bool \u2013 Whether the two actions are the same. Source code in agents/processors/actions.py 159 160 161 162 163 164 165 166 167 168 169 170 def is_same_action ( self , action_to_compare : Dict [ str , Any ]) -> bool : \"\"\" Check whether the two actions are the same. :param action_to_compare: The action to compare with the current action. :return: Whether the two actions are the same. \"\"\" return ( self . function == action_to_compare . get ( \"Function\" ) and self . args == action_to_compare . get ( \"Args\" ) and self . control_text == action_to_compare . get ( \"ControlText\" ) ) print_result () Print the action execution result. Source code in agents/processors/actions.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 def print_result ( self ) -> None : \"\"\" Print the action execution result. \"\"\" utils . print_with_color ( \"Selected item\ud83d\udd79\ufe0f: {control_text} , Label: {label} \" . format ( control_text = self . control_text , label = self . control_label ), \"yellow\" , ) utils . print_with_color ( \"Action applied\u2692\ufe0f: {action} \" . format ( action = self . command_string ), \"blue\" ) result_color = \"red\" if self . results . status != \"success\" else \"green\" utils . print_with_color ( \"Execution result\ud83d\udcdc: {result} \" . format ( result = asdict ( self . results )), result_color , ) to_dict ( previous_actions ) Convert the action to a dictionary. Parameters: previous_actions ( Optional [ List [ Dict [ str , Any ]]] ) \u2013 The previous actions. Returns: Dict [ str , Any ] \u2013 The dictionary of the action. Source code in agents/processors/actions.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def to_dict ( self , previous_actions : Optional [ List [ Dict [ str , Any ]]] ) -> Dict [ str , Any ]: \"\"\" Convert the action to a dictionary. :param previous_actions: The previous actions. :return: The dictionary of the action. \"\"\" action_dict = { \"Function\" : self . function , \"Args\" : self . args , \"ControlLabel\" : self . control_label , \"ControlText\" : self . control_text , \"Status\" : self . after_status , \"Results\" : asdict ( self . results ), } # Add the repetitive times of the same action in the previous actions if the previous actions are provided. if previous_actions : action_dict [ \"RepeatTimes\" ] = self . count_repeat_times ( previous_actions ) return action_dict to_string ( previous_actions ) Convert the action to a string. Parameters: previous_actions ( Optional [ List [ OneStepAction ]] ) \u2013 The previous actions. Returns: str \u2013 The string of the action. Source code in agents/processors/actions.py 211 212 213 214 215 216 217 def to_string ( self , previous_actions : Optional [ List [ \"OneStepAction\" ]]) -> str : \"\"\" Convert the action to a string. :param previous_actions: The previous actions. :return: The string of the action. \"\"\" return json . dumps ( self . to_dict ( previous_actions ), ensure_ascii = False )","title":"Speculative Multi-Action Execution"},{"location":"advanced_usage/multi_action/#speculative-multi-action-execution","text":"UFO\u00b2 introduces a new feature called Speculative Multi-Action Execution . This feature allows the agent to bundle several predicted steps into one LLM call, which are then validated live. This approach can lead to up to 51% fewer queries compared to inferring each step separately. The agent will first predict a batch of likely actions and then validate them against the live UIA state in a single shot. We illustrate the speculative multi-action execution in the figure below:","title":"Speculative Multi-Action Execution"},{"location":"advanced_usage/multi_action/#configuration","text":"To activate the speculative multi-action execution, you need to set ACTION_SEQUENCE to True in the config_dev.yaml file. ACTION_SEQUENCE: True","title":"Configuration"},{"location":"advanced_usage/multi_action/#references","text":"The implementation of the speculative multi-action execution is located in the ufo/agents/processors/actions.py file. The following classes are used for the speculative multi-action execution: Source code in agents/processors/actions.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def __init__ ( self , function : str = \"\" , args : Dict [ str , Any ] = {}, control_label : str = \"\" , control_text : str = \"\" , after_status : str = \"\" , results : Optional [ ActionExecutionLog ] = None , configs = Config . get_instance () . config_data , ): self . _function = function self . _args = args self . _control_label = control_label self . _control_text = control_text self . _after_status = after_status self . _results = ActionExecutionLog () if results is None else results self . _configs = configs self . _control_log = BaseControlLog ()","title":"References"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.after_status","text":"Get the status. Returns: str \u2013 The status.","title":"after_status"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.args","text":"Get the arguments. Returns: Dict [ str , Any ] \u2013 The arguments.","title":"args"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.command_string","text":"Generate a function call string. Returns: str \u2013 The function call string.","title":"command_string"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.control_label","text":"Get the control label. Returns: str \u2013 The control label.","title":"control_label"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.control_log","text":"Get the control log. Returns: BaseControlLog \u2013 The control log.","title":"control_log"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.control_text","text":"Get the control text. Returns: str \u2013 The control text.","title":"control_text"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.function","text":"Get the function name. Returns: str \u2013 The function.","title":"function"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.results","text":"Get the results. Returns: ActionExecutionLog \u2013 The results.","title":"results"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.action_flow","text":"Execute the action flow. Parameters: puppeteer ( AppPuppeteer ) \u2013 The puppeteer that controls the application. control_dict ( Dict [ str , UIAWrapper ] ) \u2013 The control dictionary. application_window ( UIAWrapper ) \u2013 The application window where the control is located. Returns: Tuple [ ActionExecutionLog , BaseControlLog ] \u2013 The action execution log. Source code in agents/processors/actions.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 def action_flow ( self , puppeteer : AppPuppeteer , control_dict : Dict [ str , UIAWrapper ], application_window : UIAWrapper , ) -> Tuple [ ActionExecutionLog , BaseControlLog ]: \"\"\" Execute the action flow. :param puppeteer: The puppeteer that controls the application. :param control_dict: The control dictionary. :param application_window: The application window where the control is located. :return: The action execution log. \"\"\" control_selected : UIAWrapper = control_dict . get ( self . control_label , None ) # If the control is selected, but not available, return an error. if control_selected is not None and not self . _control_validation ( control_selected ): self . results = ActionExecutionLog ( status = \"error\" , traceback = \"Control is not available.\" , error = \"Control is not available.\" , ) self . _control_log = BaseControlLog () return self . results # Create the control receiver. puppeteer . receiver_manager . create_ui_control_receiver ( control_selected , application_window ) if self . function : if self . _configs . get ( \"SHOW_VISUAL_OUTLINE_ON_SCREEN\" , True ): if control_selected : control_selected . draw_outline ( colour = \"red\" , thickness = 3 ) time . sleep ( self . _configs . get ( \"RECTANGLE_TIME\" , 0 )) self . _control_log = self . _get_control_log ( control_selected = control_selected , application_window = application_window ) try : return_value = self . execute ( puppeteer = puppeteer ) if not utils . is_json_serializable ( return_value ): return_value = \"\" self . results = ActionExecutionLog ( status = \"success\" , return_value = return_value , ) except Exception as e : import traceback self . results = ActionExecutionLog ( status = \"error\" , traceback = traceback . format_exc (), error = str ( e ), ) return self . results","title":"action_flow"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.count_repeat_times","text":"Get the times of the same action in the previous actions. Parameters: previous_actions ( List [ Dict [ str , Any ]] ) \u2013 The previous actions. Returns: int \u2013 The times of the same action in the previous actions. Source code in agents/processors/actions.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def count_repeat_times ( self , previous_actions : List [ Dict [ str , Any ]]) -> int : \"\"\" Get the times of the same action in the previous actions. :param previous_actions: The previous actions. :return: The times of the same action in the previous actions. \"\"\" count = 0 for action in previous_actions [:: - 1 ]: if self . is_same_action ( action ): count += 1 else : break return count","title":"count_repeat_times"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.execute","text":"Execute the action. Parameters: puppeteer ( AppPuppeteer ) \u2013 The puppeteer that controls the application. Source code in agents/processors/actions.py 234 235 236 237 238 239 def execute ( self , puppeteer : AppPuppeteer ) -> Any : \"\"\" Execute the action. :param puppeteer: The puppeteer that controls the application. \"\"\" return puppeteer . execute_command ( self . function , self . args )","title":"execute"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.get_operation_point_list","text":"Get the operation points of the action. Returns: List [ Tuple [ int ]] \u2013 The operation points of the action. Source code in agents/processors/actions.py 364 365 366 367 368 369 370 371 372 373 374 375 def get_operation_point_list ( self ) -> List [ Tuple [ int ]]: \"\"\" Get the operation points of the action. :return: The operation points of the action. \"\"\" if \"path\" in self . args : return [( point [ \"x\" ], point [ \"y\" ]) for point in self . args [ \"path\" ]] elif \"x\" in self . args and \"y\" in self . args : return [( self . args [ \"x\" ], self . args [ \"y\" ])] else : return []","title":"get_operation_point_list"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.is_same_action","text":"Check whether the two actions are the same. Parameters: action_to_compare ( Dict [ str , Any ] ) \u2013 The action to compare with the current action. Returns: bool \u2013 Whether the two actions are the same. Source code in agents/processors/actions.py 159 160 161 162 163 164 165 166 167 168 169 170 def is_same_action ( self , action_to_compare : Dict [ str , Any ]) -> bool : \"\"\" Check whether the two actions are the same. :param action_to_compare: The action to compare with the current action. :return: Whether the two actions are the same. \"\"\" return ( self . function == action_to_compare . get ( \"Function\" ) and self . args == action_to_compare . get ( \"Args\" ) and self . control_text == action_to_compare . get ( \"ControlText\" ) )","title":"is_same_action"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.print_result","text":"Print the action execution result. Source code in agents/processors/actions.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 def print_result ( self ) -> None : \"\"\" Print the action execution result. \"\"\" utils . print_with_color ( \"Selected item\ud83d\udd79\ufe0f: {control_text} , Label: {label} \" . format ( control_text = self . control_text , label = self . control_label ), \"yellow\" , ) utils . print_with_color ( \"Action applied\u2692\ufe0f: {action} \" . format ( action = self . command_string ), \"blue\" ) result_color = \"red\" if self . results . status != \"success\" else \"green\" utils . print_with_color ( \"Execution result\ud83d\udcdc: {result} \" . format ( result = asdict ( self . results )), result_color , )","title":"print_result"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.to_dict","text":"Convert the action to a dictionary. Parameters: previous_actions ( Optional [ List [ Dict [ str , Any ]]] ) \u2013 The previous actions. Returns: Dict [ str , Any ] \u2013 The dictionary of the action. Source code in agents/processors/actions.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def to_dict ( self , previous_actions : Optional [ List [ Dict [ str , Any ]]] ) -> Dict [ str , Any ]: \"\"\" Convert the action to a dictionary. :param previous_actions: The previous actions. :return: The dictionary of the action. \"\"\" action_dict = { \"Function\" : self . function , \"Args\" : self . args , \"ControlLabel\" : self . control_label , \"ControlText\" : self . control_text , \"Status\" : self . after_status , \"Results\" : asdict ( self . results ), } # Add the repetitive times of the same action in the previous actions if the previous actions are provided. if previous_actions : action_dict [ \"RepeatTimes\" ] = self . count_repeat_times ( previous_actions ) return action_dict","title":"to_dict"},{"location":"advanced_usage/multi_action/#agents.processors.actions.OneStepAction.to_string","text":"Convert the action to a string. Parameters: previous_actions ( Optional [ List [ OneStepAction ]] ) \u2013 The previous actions. Returns: str \u2013 The string of the action. Source code in agents/processors/actions.py 211 212 213 214 215 216 217 def to_string ( self , previous_actions : Optional [ List [ \"OneStepAction\" ]]) -> str : \"\"\" Convert the action to a string. :param previous_actions: The previous actions. :return: The string of the action. \"\"\" return json . dumps ( self . to_dict ( previous_actions ), ensure_ascii = False )","title":"to_string"},{"location":"advanced_usage/operator_as_app_agent/","text":"Operator as an AppAgent UFO\u00b2 supports wrapping any third-party agent as an AppAgent , allowing it to be invoked by the HostAgent within a multi-agent workflow. This section demonstrates how to run Operator , an OpenAI-based Conversational UI Agent (CUA), as an AppAgent inside the UFO\u00b2 ecosystem. \ud83d\udce6 Prerequisites Before proceeding, please ensure that the Operator has been properly configured. You can follow the setup instructions in the OpenAI CUA (Operator) guide . \ud83d\ude80 Running the Operator UFO\u00b2 provides two modes for running the Operator: Single Agent Mode \u2014 Use UFO\u00b2 as the launcher to run Operator in standalone mode. AppAgent Mode \u2014 Run Operator as an AppAgent , enabling it to be orchestrated by the HostAgent as part of a broader task decomposition. \ud83d\udd39 Single Agent Mode In this mode, the Operator functions independently but is launched through UFO\u00b2. This is useful for debugging or quick prototyping. python -m ufo -m operator -t <your_task_name> -r <your_request> \ud83d\udd38 AppAgent Mode This mode wraps Operator as an AppAgent ( normal_operator ) so that it can be triggered as a sub-agent within a full HostAgent workflow. python -m ufo -m normal_operator -t <your_task_name> -r <your_request> \ud83d\udcdd Logs In both modes, execution logs will be saved in the following directory: logs/<your_task_name>/ These logs follow the same structure and conventions as previous UFO\u00b2 sessions.","title":"Operator-as-a-AppAgent"},{"location":"advanced_usage/operator_as_app_agent/#operator-as-an-appagent","text":"UFO\u00b2 supports wrapping any third-party agent as an AppAgent , allowing it to be invoked by the HostAgent within a multi-agent workflow. This section demonstrates how to run Operator , an OpenAI-based Conversational UI Agent (CUA), as an AppAgent inside the UFO\u00b2 ecosystem.","title":"Operator as an AppAgent"},{"location":"advanced_usage/operator_as_app_agent/#prerequisites","text":"Before proceeding, please ensure that the Operator has been properly configured. You can follow the setup instructions in the OpenAI CUA (Operator) guide .","title":"\ud83d\udce6 Prerequisites"},{"location":"advanced_usage/operator_as_app_agent/#running-the-operator","text":"UFO\u00b2 provides two modes for running the Operator: Single Agent Mode \u2014 Use UFO\u00b2 as the launcher to run Operator in standalone mode. AppAgent Mode \u2014 Run Operator as an AppAgent , enabling it to be orchestrated by the HostAgent as part of a broader task decomposition.","title":"\ud83d\ude80 Running the Operator"},{"location":"advanced_usage/operator_as_app_agent/#single-agent-mode","text":"In this mode, the Operator functions independently but is launched through UFO\u00b2. This is useful for debugging or quick prototyping. python -m ufo -m operator -t <your_task_name> -r <your_request>","title":"\ud83d\udd39 Single Agent Mode"},{"location":"advanced_usage/operator_as_app_agent/#appagent-mode","text":"This mode wraps Operator as an AppAgent ( normal_operator ) so that it can be triggered as a sub-agent within a full HostAgent workflow. python -m ufo -m normal_operator -t <your_task_name> -r <your_request>","title":"\ud83d\udd38 AppAgent Mode"},{"location":"advanced_usage/operator_as_app_agent/#logs","text":"In both modes, execution logs will be saved in the following directory: logs/<your_task_name>/ These logs follow the same structure and conventions as previous UFO\u00b2 sessions.","title":"\ud83d\udcdd Logs"},{"location":"advanced_usage/control_detection/hybrid_detection/","text":"Hybrid Detection We also support hybrid control detection using both UIA and OmniParser-v2. This method is useful for detecting standard controls in the application using the UI Automation (UIA) framework, and for detecting custom controls in the application that may not be recognized by standard UIA methods. The visually detected controls are merged with the UIA controls by removing the duplicate controls based on IOU. We illustrate the hybrid control detection in the figure below: Configuration Before using the hybrid control detection, you need to deploy and configure the OmniParser model. You can refer to the OmniParser deployment for more details. To activate the icon control filtering, you need to set CONTROL_BACKEND to [\"uia\", \"omniparser\"] in the config_dev.yaml file. CONTROL_BACKEND: [\"uia\", \"omniparser\"] Reference The following classes are used for visual control detection in OmniParser: Bases: BasicGrounding The OmniparserGrounding class is a subclass of BasicGrounding, which is used to represent the Omniparser grounding model. parse_results ( results , application_window = None ) Parse the grounding results string into a list of control elements infomation dictionaries. Parameters: results ( List [ Dict [ str , Any ]] ) \u2013 The list of grounding results dictionaries from the grounding model. application_window ( UIAWrapper , default: None ) \u2013 The application window to get the absolute coordinates. Returns: List [ Dict [ str , Any ]] \u2013 The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } Source code in automator/ui_control/grounding/omniparser.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def parse_results ( self , results : List [ Dict [ str , Any ]], application_window : UIAWrapper = None ) -> List [ Dict [ str , Any ]]: \"\"\" Parse the grounding results string into a list of control elements infomation dictionaries. :param results: The list of grounding results dictionaries from the grounding model. :param application_window: The application window to get the absolute coordinates. :return: The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } \"\"\" control_elements_info = [] if application_window is None : application_rect = RECT ( 0 , 0 , 0 , 0 ) else : try : application_rect = application_window . rectangle () except Exception : application_rect = RECT ( 0 , 0 , 0 , 0 ) for control_info in results : if not self . _filter_interactivity and control_info . get ( \"interactivity\" , True ): continue application_left , application_top = ( application_rect . left , application_rect . top , ) control_box = control_info . get ( \"bbox\" , [ 0 , 0 , 0 , 0 ]) control_left = int ( application_left + control_box [ 0 ] * application_rect . width () ) control_top = int ( application_top + control_box [ 1 ] * application_rect . height () ) control_right = int ( application_left + control_box [ 2 ] * application_rect . width () ) control_bottom = int ( application_top + control_box [ 3 ] * application_rect . height () ) control_elements_info . append ( { \"control_type\" : control_info . get ( \"type\" , \"Button\" ), \"name\" : control_info . get ( \"content\" , \"\" ), \"x0\" : control_left , \"y0\" : control_top , \"x1\" : control_right , \"y1\" : control_bottom , } ) return control_elements_info predict ( image_path , box_threshold = 0.05 , iou_threshold = 0.1 , use_paddleocr = True , imgsz = 640 , api_name = '/process' ) Predict the grounding for the given image. Parameters: image_path ( str ) \u2013 The path to the image. box_threshold ( float , default: 0.05 ) \u2013 The threshold for the bounding box. iou_threshold ( float , default: 0.1 ) \u2013 The threshold for the intersection over union. use_paddleocr ( bool , default: True ) \u2013 Whether to use paddleocr. imgsz ( int , default: 640 ) \u2013 The image size. api_name ( str , default: '/process' ) \u2013 The name of the API. Returns: List [ Dict [ str , Any ]] \u2013 The predicted grounding results string. Source code in automator/ui_control/grounding/omniparser.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def predict ( self , image_path : str , box_threshold : float = 0.05 , iou_threshold : float = 0.1 , use_paddleocr : bool = True , imgsz : int = 640 , api_name : str = \"/process\" , ) -> List [ Dict [ str , Any ]]: \"\"\" Predict the grounding for the given image. :param image_path: The path to the image. :param box_threshold: The threshold for the bounding box. :param iou_threshold: The threshold for the intersection over union. :param use_paddleocr: Whether to use paddleocr. :param imgsz: The image size. :param api_name: The name of the API. :return: The predicted grounding results string. \"\"\" list_of_grounding_results = [] if not os . path . exists ( image_path ): print_with_color ( f \"Warning: The image path { image_path } does not exist.\" , \"yellow\" ) return list_of_grounding_results try : results = self . service . chat_completion ( image_path , box_threshold , iou_threshold , use_paddleocr , imgsz , api_name ) grounding_results = results [ 1 ] . splitlines () except Exception as e : print_with_color ( f \"Warning: Failed to get grounding results for Omniparser. Error: { e } \" , \"yellow\" , ) return list_of_grounding_results for item in grounding_results : try : item = json . loads ( item ) list_of_grounding_results . append ( item ) except json . JSONDecodeError : try : # the item string is a string converted from python's dict item = ast . literal_eval ( item [ item . index ( \"{\" ): item . rindex ( \"}\" ) + 1 ]) list_of_grounding_results . append ( item ) except Exception : pass return list_of_grounding_results","title":"Hybrid Detection"},{"location":"advanced_usage/control_detection/hybrid_detection/#hybrid-detection","text":"We also support hybrid control detection using both UIA and OmniParser-v2. This method is useful for detecting standard controls in the application using the UI Automation (UIA) framework, and for detecting custom controls in the application that may not be recognized by standard UIA methods. The visually detected controls are merged with the UIA controls by removing the duplicate controls based on IOU. We illustrate the hybrid control detection in the figure below:","title":"Hybrid Detection"},{"location":"advanced_usage/control_detection/hybrid_detection/#configuration","text":"Before using the hybrid control detection, you need to deploy and configure the OmniParser model. You can refer to the OmniParser deployment for more details. To activate the icon control filtering, you need to set CONTROL_BACKEND to [\"uia\", \"omniparser\"] in the config_dev.yaml file. CONTROL_BACKEND: [\"uia\", \"omniparser\"]","title":"Configuration"},{"location":"advanced_usage/control_detection/hybrid_detection/#reference","text":"The following classes are used for visual control detection in OmniParser: Bases: BasicGrounding The OmniparserGrounding class is a subclass of BasicGrounding, which is used to represent the Omniparser grounding model.","title":"Reference"},{"location":"advanced_usage/control_detection/hybrid_detection/#automator.ui_control.grounding.omniparser.OmniparserGrounding.parse_results","text":"Parse the grounding results string into a list of control elements infomation dictionaries. Parameters: results ( List [ Dict [ str , Any ]] ) \u2013 The list of grounding results dictionaries from the grounding model. application_window ( UIAWrapper , default: None ) \u2013 The application window to get the absolute coordinates. Returns: List [ Dict [ str , Any ]] \u2013 The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } Source code in automator/ui_control/grounding/omniparser.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def parse_results ( self , results : List [ Dict [ str , Any ]], application_window : UIAWrapper = None ) -> List [ Dict [ str , Any ]]: \"\"\" Parse the grounding results string into a list of control elements infomation dictionaries. :param results: The list of grounding results dictionaries from the grounding model. :param application_window: The application window to get the absolute coordinates. :return: The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } \"\"\" control_elements_info = [] if application_window is None : application_rect = RECT ( 0 , 0 , 0 , 0 ) else : try : application_rect = application_window . rectangle () except Exception : application_rect = RECT ( 0 , 0 , 0 , 0 ) for control_info in results : if not self . _filter_interactivity and control_info . get ( \"interactivity\" , True ): continue application_left , application_top = ( application_rect . left , application_rect . top , ) control_box = control_info . get ( \"bbox\" , [ 0 , 0 , 0 , 0 ]) control_left = int ( application_left + control_box [ 0 ] * application_rect . width () ) control_top = int ( application_top + control_box [ 1 ] * application_rect . height () ) control_right = int ( application_left + control_box [ 2 ] * application_rect . width () ) control_bottom = int ( application_top + control_box [ 3 ] * application_rect . height () ) control_elements_info . append ( { \"control_type\" : control_info . get ( \"type\" , \"Button\" ), \"name\" : control_info . get ( \"content\" , \"\" ), \"x0\" : control_left , \"y0\" : control_top , \"x1\" : control_right , \"y1\" : control_bottom , } ) return control_elements_info","title":"parse_results"},{"location":"advanced_usage/control_detection/hybrid_detection/#automator.ui_control.grounding.omniparser.OmniparserGrounding.predict","text":"Predict the grounding for the given image. Parameters: image_path ( str ) \u2013 The path to the image. box_threshold ( float , default: 0.05 ) \u2013 The threshold for the bounding box. iou_threshold ( float , default: 0.1 ) \u2013 The threshold for the intersection over union. use_paddleocr ( bool , default: True ) \u2013 Whether to use paddleocr. imgsz ( int , default: 640 ) \u2013 The image size. api_name ( str , default: '/process' ) \u2013 The name of the API. Returns: List [ Dict [ str , Any ]] \u2013 The predicted grounding results string. Source code in automator/ui_control/grounding/omniparser.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def predict ( self , image_path : str , box_threshold : float = 0.05 , iou_threshold : float = 0.1 , use_paddleocr : bool = True , imgsz : int = 640 , api_name : str = \"/process\" , ) -> List [ Dict [ str , Any ]]: \"\"\" Predict the grounding for the given image. :param image_path: The path to the image. :param box_threshold: The threshold for the bounding box. :param iou_threshold: The threshold for the intersection over union. :param use_paddleocr: Whether to use paddleocr. :param imgsz: The image size. :param api_name: The name of the API. :return: The predicted grounding results string. \"\"\" list_of_grounding_results = [] if not os . path . exists ( image_path ): print_with_color ( f \"Warning: The image path { image_path } does not exist.\" , \"yellow\" ) return list_of_grounding_results try : results = self . service . chat_completion ( image_path , box_threshold , iou_threshold , use_paddleocr , imgsz , api_name ) grounding_results = results [ 1 ] . splitlines () except Exception as e : print_with_color ( f \"Warning: Failed to get grounding results for Omniparser. Error: { e } \" , \"yellow\" , ) return list_of_grounding_results for item in grounding_results : try : item = json . loads ( item ) list_of_grounding_results . append ( item ) except json . JSONDecodeError : try : # the item string is a string converted from python's dict item = ast . literal_eval ( item [ item . index ( \"{\" ): item . rindex ( \"}\" ) + 1 ]) list_of_grounding_results . append ( item ) except Exception : pass return list_of_grounding_results","title":"predict"},{"location":"advanced_usage/control_detection/overview/","text":"Control Detection We support different control detection methods to detect the controls in the application to accommodate both standard (UIA) and custom controls (Visual). The control detection methods include: Mechanism Description UIA The UI Automation (UIA) framework is used to detect standard controls in the application. It provides a set of APIs to access and manipulate the UI elements in Windows applications. Visual The visual control detection method uses OmniParser visual detection to detect custom controls in the application. It uses computer vision techniques to identify and interact with the UI elements based on their visual appearance. Hybrid The hybrid control detection method combines both UIA and visual detection methods to detect the controls in the application. It first tries to use the UIA method, and if it fails, it falls back to the visual method. Configuration To configure the control detection method, you can set the CONTROL_BACKEND parameter in the config_dev.yaml file. The available options are uia , and onmiparser . If you want to use the hybrid method, you can set it to [\"uia\", \"onmiparser\"] . CONTROL_BACKEND: [\"uia\"]","title":"Overview"},{"location":"advanced_usage/control_detection/overview/#control-detection","text":"We support different control detection methods to detect the controls in the application to accommodate both standard (UIA) and custom controls (Visual). The control detection methods include: Mechanism Description UIA The UI Automation (UIA) framework is used to detect standard controls in the application. It provides a set of APIs to access and manipulate the UI elements in Windows applications. Visual The visual control detection method uses OmniParser visual detection to detect custom controls in the application. It uses computer vision techniques to identify and interact with the UI elements based on their visual appearance. Hybrid The hybrid control detection method combines both UIA and visual detection methods to detect the controls in the application. It first tries to use the UIA method, and if it fails, it falls back to the visual method.","title":"Control Detection"},{"location":"advanced_usage/control_detection/overview/#configuration","text":"To configure the control detection method, you can set the CONTROL_BACKEND parameter in the config_dev.yaml file. The available options are uia , and onmiparser . If you want to use the hybrid method, you can set it to [\"uia\", \"onmiparser\"] . CONTROL_BACKEND: [\"uia\"]","title":"Configuration"},{"location":"advanced_usage/control_detection/uia_detection/","text":"UIA Control Detection UIA control detection is a method to detect standard controls in the application using the UI Automation (UIA) framework. It provides a set of APIs to access and manipulate the UI elements in Windows applications. Note The UIA control detection may fail to detect non-standard controls or custom controls in the application. Configuration To activate the icon control filtering, you need to set CONTROL_BACKEND to [\"uia\"] in the config_dev.yaml file. CONTROL_BACKEND: [\"uia\"] Reference The singleton facade class for control inspector. Initialize the control inspector. Parameters: backend ( str , default: 'uia' ) \u2013 The backend to use. Source code in automator/ui_control/inspector.py 478 479 480 481 482 483 def __init__ ( self , backend : str = \"uia\" ) -> None : \"\"\" Initialize the control inspector. :param backend: The backend to use. \"\"\" self . backend = backend desktop property Get all the desktop windows. Returns: UIAWrapper \u2013 The uia wrapper of the desktop. __new__ ( backend = 'uia' ) Singleton pattern. Source code in automator/ui_control/inspector.py 467 468 469 470 471 472 473 474 475 476 def __new__ ( cls , backend : str = \"uia\" ) -> \"ControlInspectorFacade\" : \"\"\" Singleton pattern. \"\"\" if backend not in cls . _instances : instance = super () . __new__ ( cls ) instance . backend = backend instance . backend_strategy = BackendFactory . create_backend ( backend ) cls . _instances [ backend ] = instance return cls . _instances [ backend ] find_control_elements_in_descendants ( window , control_type_list = [], class_name_list = [], title_list = [], is_visible = True , is_enabled = True , depth = 0 ) Find control elements in descendants of the window. Parameters: window ( UIAWrapper ) \u2013 The window to find control elements. control_type_list ( List [ str ] , default: [] ) \u2013 The control types to find. class_name_list ( List [ str ] , default: [] ) \u2013 The class names to find. title_list ( List [ str ] , default: [] ) \u2013 The titles to find. is_visible ( bool , default: True ) \u2013 Whether the control elements are visible. is_enabled ( bool , default: True ) \u2013 Whether the control elements are enabled. depth ( int , default: 0 ) \u2013 The depth of the descendants to find. Returns: List [ UIAWrapper ] \u2013 The control elements found. Source code in automator/ui_control/inspector.py 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 def find_control_elements_in_descendants ( self , window : UIAWrapper , control_type_list : List [ str ] = [], class_name_list : List [ str ] = [], title_list : List [ str ] = [], is_visible : bool = True , is_enabled : bool = True , depth : int = 0 , ) -> List [ UIAWrapper ]: \"\"\" Find control elements in descendants of the window. :param window: The window to find control elements. :param control_type_list: The control types to find. :param class_name_list: The class names to find. :param title_list: The titles to find. :param is_visible: Whether the control elements are visible. :param is_enabled: Whether the control elements are enabled. :param depth: The depth of the descendants to find. :return: The control elements found. \"\"\" if self . backend == \"uia\" : return self . backend_strategy . find_control_elements_in_descendants ( window , control_type_list , [], title_list , is_visible , is_enabled , depth ) elif self . backend == \"win32\" : return self . backend_strategy . find_control_elements_in_descendants ( window , [], class_name_list , title_list , is_visible , is_enabled , depth ) else : return [] get_application_root_name ( window ) staticmethod Get the application name of the window. Parameters: window ( UIAWrapper ) \u2013 The window to get the application name. Returns: str \u2013 The root application name of the window. Empty string (\"\") if failed to get the name. Source code in automator/ui_control/inspector.py 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 @staticmethod def get_application_root_name ( window : UIAWrapper ) -> str : \"\"\" Get the application name of the window. :param window: The window to get the application name. :return: The root application name of the window. Empty string (\"\") if failed to get the name. \"\"\" if window == None : return \"\" process_id = window . process_id () try : process = psutil . Process ( process_id ) return process . name () except psutil . NoSuchProcess : return \"\" get_check_state ( control_item ) staticmethod get the check state of the control item param control_item: the control item to get the check state return: the check state of the control item Source code in automator/ui_control/inspector.py 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 @staticmethod def get_check_state ( control_item : auto . Control ) -> bool | None : \"\"\" get the check state of the control item param control_item: the control item to get the check state return: the check state of the control item \"\"\" is_checked = None is_selected = None try : assert isinstance ( control_item , auto . Control ), f \" { control_item =} is not a Control\" is_checked = ( control_item . GetLegacyIAccessiblePattern () . State & auto . AccessibleState . Checked == auto . AccessibleState . Checked ) if is_checked : return is_checked is_selected = ( control_item . GetLegacyIAccessiblePattern () . State & auto . AccessibleState . Selected == auto . AccessibleState . Selected ) if is_selected : return is_selected return None except Exception as e : # print(f'item {control_item} not available for check state.') # print(e) return None get_control_info ( window , field_list = []) staticmethod Get control info of the window. Parameters: window ( UIAWrapper ) \u2013 The window to get control info. field_list ( List [ str ] , default: [] ) \u2013 The fields to get. return: The control info of the window. Source code in automator/ui_control/inspector.py 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 @staticmethod def get_control_info ( window : UIAWrapper , field_list : List [ str ] = [] ) -> Dict [ str , str ]: \"\"\" Get control info of the window. :param window: The window to get control info. :param field_list: The fields to get. return: The control info of the window. \"\"\" control_info : Dict [ str , str ] = {} def assign ( prop_name : str , prop_value_func : Callable [[], str ]) -> None : if len ( field_list ) > 0 and prop_name not in field_list : return control_info [ prop_name ] = prop_value_func () try : assign ( \"control_type\" , lambda : window . element_info . control_type ) assign ( \"control_id\" , lambda : window . element_info . control_id ) assign ( \"control_class\" , lambda : window . element_info . class_name ) assign ( \"control_name\" , lambda : window . element_info . name ) rectangle = window . element_info . rectangle assign ( \"control_rect\" , lambda : ( rectangle . left , rectangle . top , rectangle . right , rectangle . bottom , ), ) assign ( \"control_text\" , lambda : window . element_info . name ) assign ( \"control_title\" , lambda : window . window_text ()) assign ( \"selected\" , lambda : ControlInspectorFacade . get_check_state ( window )) try : source = window . element_info . source assign ( \"source\" , lambda : source ) except : assign ( \"source\" , lambda : \"\" ) return control_info except : return {} get_control_info_batch ( window_list , field_list = []) Get control info of the window. Parameters: window_list ( List [ UIAWrapper ] ) \u2013 The list of windows to get control info. field_list ( List [ str ] , default: [] ) \u2013 The fields to get. return: The list of control info of the window. Source code in automator/ui_control/inspector.py 566 567 568 569 570 571 572 573 574 575 576 577 578 def get_control_info_batch ( self , window_list : List [ UIAWrapper ], field_list : List [ str ] = [] ) -> List [ Dict [ str , str ]]: \"\"\" Get control info of the window. :param window_list: The list of windows to get control info. :param field_list: The fields to get. return: The list of control info of the window. \"\"\" control_info_list = [] for window in window_list : control_info_list . append ( self . get_control_info ( window , field_list )) return control_info_list get_control_info_list_of_dict ( window_dict , field_list = []) Get control info of the window. Parameters: window_dict ( Dict [ str , UIAWrapper ] ) \u2013 The dict of windows to get control info. field_list ( List [ str ] , default: [] ) \u2013 The fields to get. return: The list of control info of the window. Source code in automator/ui_control/inspector.py 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 def get_control_info_list_of_dict ( self , window_dict : Dict [ str , UIAWrapper ], field_list : List [ str ] = [] ) -> List [ Dict [ str , str ]]: \"\"\" Get control info of the window. :param window_dict: The dict of windows to get control info. :param field_list: The fields to get. return: The list of control info of the window. \"\"\" control_info_list = [] for key in window_dict . keys (): window = window_dict [ key ] control_info = self . get_control_info ( window , field_list ) control_info [ \"label\" ] = key control_info_list . append ( control_info ) return control_info_list get_desktop_app_dict ( remove_empty = True ) Get all the apps on the desktop and return as a dict. Parameters: remove_empty ( bool , default: True ) \u2013 Whether to remove empty titles. Returns: Dict [ str , UIAWrapper ] \u2013 The apps on the desktop as a dict. Source code in automator/ui_control/inspector.py 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 def get_desktop_app_dict ( self , remove_empty : bool = True ) -> Dict [ str , UIAWrapper ]: \"\"\" Get all the apps on the desktop and return as a dict. :param remove_empty: Whether to remove empty titles. :return: The apps on the desktop as a dict. \"\"\" desktop_windows = self . get_desktop_windows ( remove_empty ) desktop_windows_with_gui = [] for window in desktop_windows : try : window . is_normal () desktop_windows_with_gui . append ( window ) except : pass desktop_windows_dict = dict ( zip ( [ str ( i + 1 ) for i in range ( len ( desktop_windows_with_gui ))], desktop_windows_with_gui , ) ) return desktop_windows_dict get_desktop_app_info ( desktop_windows_dict , field_list = [ 'control_text' , 'control_type' ]) Get control info of all the apps on the desktop. Parameters: desktop_windows_dict ( Dict [ str , UIAWrapper ] ) \u2013 The dict of apps on the desktop. field_list ( List [ str ] , default: ['control_text', 'control_type'] ) \u2013 The fields of app info to get. Returns: List [ Dict [ str , str ]] \u2013 The control info of all the apps on the desktop. Source code in automator/ui_control/inspector.py 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 def get_desktop_app_info ( self , desktop_windows_dict : Dict [ str , UIAWrapper ], field_list : List [ str ] = [ \"control_text\" , \"control_type\" ], ) -> List [ Dict [ str , str ]]: \"\"\" Get control info of all the apps on the desktop. :param desktop_windows_dict: The dict of apps on the desktop. :param field_list: The fields of app info to get. :return: The control info of all the apps on the desktop. \"\"\" desktop_windows_info = self . get_control_info_list_of_dict ( desktop_windows_dict , field_list ) return desktop_windows_info get_desktop_windows ( remove_empty = True ) Get all the apps on the desktop. Parameters: remove_empty ( bool , default: True ) \u2013 Whether to remove empty titles. Returns: List [ UIAWrapper ] \u2013 The apps on the desktop. Source code in automator/ui_control/inspector.py 485 486 487 488 489 490 491 def get_desktop_windows ( self , remove_empty : bool = True ) -> List [ UIAWrapper ]: \"\"\" Get all the apps on the desktop. :param remove_empty: Whether to remove empty titles. :return: The apps on the desktop. \"\"\" return self . backend_strategy . get_desktop_windows ( remove_empty )","title":"UIA Detection"},{"location":"advanced_usage/control_detection/uia_detection/#uia-control-detection","text":"UIA control detection is a method to detect standard controls in the application using the UI Automation (UIA) framework. It provides a set of APIs to access and manipulate the UI elements in Windows applications. Note The UIA control detection may fail to detect non-standard controls or custom controls in the application.","title":"UIA Control Detection"},{"location":"advanced_usage/control_detection/uia_detection/#configuration","text":"To activate the icon control filtering, you need to set CONTROL_BACKEND to [\"uia\"] in the config_dev.yaml file. CONTROL_BACKEND: [\"uia\"]","title":"Configuration"},{"location":"advanced_usage/control_detection/uia_detection/#reference","text":"The singleton facade class for control inspector. Initialize the control inspector. Parameters: backend ( str , default: 'uia' ) \u2013 The backend to use. Source code in automator/ui_control/inspector.py 478 479 480 481 482 483 def __init__ ( self , backend : str = \"uia\" ) -> None : \"\"\" Initialize the control inspector. :param backend: The backend to use. \"\"\" self . backend = backend","title":"Reference"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.desktop","text":"Get all the desktop windows. Returns: UIAWrapper \u2013 The uia wrapper of the desktop.","title":"desktop"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.__new__","text":"Singleton pattern. Source code in automator/ui_control/inspector.py 467 468 469 470 471 472 473 474 475 476 def __new__ ( cls , backend : str = \"uia\" ) -> \"ControlInspectorFacade\" : \"\"\" Singleton pattern. \"\"\" if backend not in cls . _instances : instance = super () . __new__ ( cls ) instance . backend = backend instance . backend_strategy = BackendFactory . create_backend ( backend ) cls . _instances [ backend ] = instance return cls . _instances [ backend ]","title":"__new__"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.find_control_elements_in_descendants","text":"Find control elements in descendants of the window. Parameters: window ( UIAWrapper ) \u2013 The window to find control elements. control_type_list ( List [ str ] , default: [] ) \u2013 The control types to find. class_name_list ( List [ str ] , default: [] ) \u2013 The class names to find. title_list ( List [ str ] , default: [] ) \u2013 The titles to find. is_visible ( bool , default: True ) \u2013 Whether the control elements are visible. is_enabled ( bool , default: True ) \u2013 Whether the control elements are enabled. depth ( int , default: 0 ) \u2013 The depth of the descendants to find. Returns: List [ UIAWrapper ] \u2013 The control elements found. Source code in automator/ui_control/inspector.py 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 def find_control_elements_in_descendants ( self , window : UIAWrapper , control_type_list : List [ str ] = [], class_name_list : List [ str ] = [], title_list : List [ str ] = [], is_visible : bool = True , is_enabled : bool = True , depth : int = 0 , ) -> List [ UIAWrapper ]: \"\"\" Find control elements in descendants of the window. :param window: The window to find control elements. :param control_type_list: The control types to find. :param class_name_list: The class names to find. :param title_list: The titles to find. :param is_visible: Whether the control elements are visible. :param is_enabled: Whether the control elements are enabled. :param depth: The depth of the descendants to find. :return: The control elements found. \"\"\" if self . backend == \"uia\" : return self . backend_strategy . find_control_elements_in_descendants ( window , control_type_list , [], title_list , is_visible , is_enabled , depth ) elif self . backend == \"win32\" : return self . backend_strategy . find_control_elements_in_descendants ( window , [], class_name_list , title_list , is_visible , is_enabled , depth ) else : return []","title":"find_control_elements_in_descendants"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_application_root_name","text":"Get the application name of the window. Parameters: window ( UIAWrapper ) \u2013 The window to get the application name. Returns: str \u2013 The root application name of the window. Empty string (\"\") if failed to get the name. Source code in automator/ui_control/inspector.py 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 @staticmethod def get_application_root_name ( window : UIAWrapper ) -> str : \"\"\" Get the application name of the window. :param window: The window to get the application name. :return: The root application name of the window. Empty string (\"\") if failed to get the name. \"\"\" if window == None : return \"\" process_id = window . process_id () try : process = psutil . Process ( process_id ) return process . name () except psutil . NoSuchProcess : return \"\"","title":"get_application_root_name"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_check_state","text":"get the check state of the control item param control_item: the control item to get the check state return: the check state of the control item Source code in automator/ui_control/inspector.py 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 @staticmethod def get_check_state ( control_item : auto . Control ) -> bool | None : \"\"\" get the check state of the control item param control_item: the control item to get the check state return: the check state of the control item \"\"\" is_checked = None is_selected = None try : assert isinstance ( control_item , auto . Control ), f \" { control_item =} is not a Control\" is_checked = ( control_item . GetLegacyIAccessiblePattern () . State & auto . AccessibleState . Checked == auto . AccessibleState . Checked ) if is_checked : return is_checked is_selected = ( control_item . GetLegacyIAccessiblePattern () . State & auto . AccessibleState . Selected == auto . AccessibleState . Selected ) if is_selected : return is_selected return None except Exception as e : # print(f'item {control_item} not available for check state.') # print(e) return None","title":"get_check_state"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_control_info","text":"Get control info of the window. Parameters: window ( UIAWrapper ) \u2013 The window to get control info. field_list ( List [ str ] , default: [] ) \u2013 The fields to get. return: The control info of the window. Source code in automator/ui_control/inspector.py 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 @staticmethod def get_control_info ( window : UIAWrapper , field_list : List [ str ] = [] ) -> Dict [ str , str ]: \"\"\" Get control info of the window. :param window: The window to get control info. :param field_list: The fields to get. return: The control info of the window. \"\"\" control_info : Dict [ str , str ] = {} def assign ( prop_name : str , prop_value_func : Callable [[], str ]) -> None : if len ( field_list ) > 0 and prop_name not in field_list : return control_info [ prop_name ] = prop_value_func () try : assign ( \"control_type\" , lambda : window . element_info . control_type ) assign ( \"control_id\" , lambda : window . element_info . control_id ) assign ( \"control_class\" , lambda : window . element_info . class_name ) assign ( \"control_name\" , lambda : window . element_info . name ) rectangle = window . element_info . rectangle assign ( \"control_rect\" , lambda : ( rectangle . left , rectangle . top , rectangle . right , rectangle . bottom , ), ) assign ( \"control_text\" , lambda : window . element_info . name ) assign ( \"control_title\" , lambda : window . window_text ()) assign ( \"selected\" , lambda : ControlInspectorFacade . get_check_state ( window )) try : source = window . element_info . source assign ( \"source\" , lambda : source ) except : assign ( \"source\" , lambda : \"\" ) return control_info except : return {}","title":"get_control_info"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_control_info_batch","text":"Get control info of the window. Parameters: window_list ( List [ UIAWrapper ] ) \u2013 The list of windows to get control info. field_list ( List [ str ] , default: [] ) \u2013 The fields to get. return: The list of control info of the window. Source code in automator/ui_control/inspector.py 566 567 568 569 570 571 572 573 574 575 576 577 578 def get_control_info_batch ( self , window_list : List [ UIAWrapper ], field_list : List [ str ] = [] ) -> List [ Dict [ str , str ]]: \"\"\" Get control info of the window. :param window_list: The list of windows to get control info. :param field_list: The fields to get. return: The list of control info of the window. \"\"\" control_info_list = [] for window in window_list : control_info_list . append ( self . get_control_info ( window , field_list )) return control_info_list","title":"get_control_info_batch"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_control_info_list_of_dict","text":"Get control info of the window. Parameters: window_dict ( Dict [ str , UIAWrapper ] ) \u2013 The dict of windows to get control info. field_list ( List [ str ] , default: [] ) \u2013 The fields to get. return: The list of control info of the window. Source code in automator/ui_control/inspector.py 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 def get_control_info_list_of_dict ( self , window_dict : Dict [ str , UIAWrapper ], field_list : List [ str ] = [] ) -> List [ Dict [ str , str ]]: \"\"\" Get control info of the window. :param window_dict: The dict of windows to get control info. :param field_list: The fields to get. return: The list of control info of the window. \"\"\" control_info_list = [] for key in window_dict . keys (): window = window_dict [ key ] control_info = self . get_control_info ( window , field_list ) control_info [ \"label\" ] = key control_info_list . append ( control_info ) return control_info_list","title":"get_control_info_list_of_dict"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_desktop_app_dict","text":"Get all the apps on the desktop and return as a dict. Parameters: remove_empty ( bool , default: True ) \u2013 Whether to remove empty titles. Returns: Dict [ str , UIAWrapper ] \u2013 The apps on the desktop as a dict. Source code in automator/ui_control/inspector.py 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 def get_desktop_app_dict ( self , remove_empty : bool = True ) -> Dict [ str , UIAWrapper ]: \"\"\" Get all the apps on the desktop and return as a dict. :param remove_empty: Whether to remove empty titles. :return: The apps on the desktop as a dict. \"\"\" desktop_windows = self . get_desktop_windows ( remove_empty ) desktop_windows_with_gui = [] for window in desktop_windows : try : window . is_normal () desktop_windows_with_gui . append ( window ) except : pass desktop_windows_dict = dict ( zip ( [ str ( i + 1 ) for i in range ( len ( desktop_windows_with_gui ))], desktop_windows_with_gui , ) ) return desktop_windows_dict","title":"get_desktop_app_dict"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_desktop_app_info","text":"Get control info of all the apps on the desktop. Parameters: desktop_windows_dict ( Dict [ str , UIAWrapper ] ) \u2013 The dict of apps on the desktop. field_list ( List [ str ] , default: ['control_text', 'control_type'] ) \u2013 The fields of app info to get. Returns: List [ Dict [ str , str ]] \u2013 The control info of all the apps on the desktop. Source code in automator/ui_control/inspector.py 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 def get_desktop_app_info ( self , desktop_windows_dict : Dict [ str , UIAWrapper ], field_list : List [ str ] = [ \"control_text\" , \"control_type\" ], ) -> List [ Dict [ str , str ]]: \"\"\" Get control info of all the apps on the desktop. :param desktop_windows_dict: The dict of apps on the desktop. :param field_list: The fields of app info to get. :return: The control info of all the apps on the desktop. \"\"\" desktop_windows_info = self . get_control_info_list_of_dict ( desktop_windows_dict , field_list ) return desktop_windows_info","title":"get_desktop_app_info"},{"location":"advanced_usage/control_detection/uia_detection/#automator.ui_control.inspector.ControlInspectorFacade.get_desktop_windows","text":"Get all the apps on the desktop. Parameters: remove_empty ( bool , default: True ) \u2013 Whether to remove empty titles. Returns: List [ UIAWrapper ] \u2013 The apps on the desktop. Source code in automator/ui_control/inspector.py 485 486 487 488 489 490 491 def get_desktop_windows ( self , remove_empty : bool = True ) -> List [ UIAWrapper ]: \"\"\" Get all the apps on the desktop. :param remove_empty: Whether to remove empty titles. :return: The apps on the desktop. \"\"\" return self . backend_strategy . get_desktop_windows ( remove_empty )","title":"get_desktop_windows"},{"location":"advanced_usage/control_detection/visual_detection/","text":"Visual Control Detection (OmniParser) We also support visual control detection using OmniParser-v2 . This method is useful for detecting custom controls in the application that may not be recognized by standard UIA methods. The visual control detection uses computer vision techniques to identify and interact with the UI elements based on their visual appearance. Deployment On your remote GPU server, clone the OmniParser repository git clone https://github.com/microsoft/OmniParser.git Start omniparserserver service cd OmniParser/omnitool/omniparserserver python gradio_demo.py This will give you a short URL * Running on local URL: http://0.0.0.0:7861 * Running on public URL: https://xxxxxxxxxxxxxxxxxx.gradio.live Note: If you have any questions regarding the deployment of OmniParser, please take a look at the README from OmniParser repo. Configuration After deploying the OmniParser model, you need to configure the OmniParser settings in the config.yaml file: OMNIPARSER: { ENDPOINT: \"<YOUR_END_POINT>\", # The endpoint for the omniparser deployment BOX_THRESHOLD: 0.05, # The box confidence threshold for the omniparser, default is 0.05 IOU_THRESHOLD: 0.1, # The iou threshold for the omniparser, default is 0.1 USE_PADDLEOCR: True, # Whether to use the paddleocr for the omniparser IMGSZ: 640 # The image size for the omniparser } To activate the icon control filtering, you need to set CONTROL_BACKEND to [\"omniparser\"] in the config_dev.yaml file. CONTROL_BACKEND: [\"omniparser\"] Reference The following classes are used for visual control detection in OmniParser: Bases: BasicGrounding The OmniparserGrounding class is a subclass of BasicGrounding, which is used to represent the Omniparser grounding model. parse_results ( results , application_window = None ) Parse the grounding results string into a list of control elements infomation dictionaries. Parameters: results ( List [ Dict [ str , Any ]] ) \u2013 The list of grounding results dictionaries from the grounding model. application_window ( UIAWrapper , default: None ) \u2013 The application window to get the absolute coordinates. Returns: List [ Dict [ str , Any ]] \u2013 The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } Source code in automator/ui_control/grounding/omniparser.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def parse_results ( self , results : List [ Dict [ str , Any ]], application_window : UIAWrapper = None ) -> List [ Dict [ str , Any ]]: \"\"\" Parse the grounding results string into a list of control elements infomation dictionaries. :param results: The list of grounding results dictionaries from the grounding model. :param application_window: The application window to get the absolute coordinates. :return: The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } \"\"\" control_elements_info = [] if application_window is None : application_rect = RECT ( 0 , 0 , 0 , 0 ) else : try : application_rect = application_window . rectangle () except Exception : application_rect = RECT ( 0 , 0 , 0 , 0 ) for control_info in results : if not self . _filter_interactivity and control_info . get ( \"interactivity\" , True ): continue application_left , application_top = ( application_rect . left , application_rect . top , ) control_box = control_info . get ( \"bbox\" , [ 0 , 0 , 0 , 0 ]) control_left = int ( application_left + control_box [ 0 ] * application_rect . width () ) control_top = int ( application_top + control_box [ 1 ] * application_rect . height () ) control_right = int ( application_left + control_box [ 2 ] * application_rect . width () ) control_bottom = int ( application_top + control_box [ 3 ] * application_rect . height () ) control_elements_info . append ( { \"control_type\" : control_info . get ( \"type\" , \"Button\" ), \"name\" : control_info . get ( \"content\" , \"\" ), \"x0\" : control_left , \"y0\" : control_top , \"x1\" : control_right , \"y1\" : control_bottom , } ) return control_elements_info predict ( image_path , box_threshold = 0.05 , iou_threshold = 0.1 , use_paddleocr = True , imgsz = 640 , api_name = '/process' ) Predict the grounding for the given image. Parameters: image_path ( str ) \u2013 The path to the image. box_threshold ( float , default: 0.05 ) \u2013 The threshold for the bounding box. iou_threshold ( float , default: 0.1 ) \u2013 The threshold for the intersection over union. use_paddleocr ( bool , default: True ) \u2013 Whether to use paddleocr. imgsz ( int , default: 640 ) \u2013 The image size. api_name ( str , default: '/process' ) \u2013 The name of the API. Returns: List [ Dict [ str , Any ]] \u2013 The predicted grounding results string. Source code in automator/ui_control/grounding/omniparser.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def predict ( self , image_path : str , box_threshold : float = 0.05 , iou_threshold : float = 0.1 , use_paddleocr : bool = True , imgsz : int = 640 , api_name : str = \"/process\" , ) -> List [ Dict [ str , Any ]]: \"\"\" Predict the grounding for the given image. :param image_path: The path to the image. :param box_threshold: The threshold for the bounding box. :param iou_threshold: The threshold for the intersection over union. :param use_paddleocr: Whether to use paddleocr. :param imgsz: The image size. :param api_name: The name of the API. :return: The predicted grounding results string. \"\"\" list_of_grounding_results = [] if not os . path . exists ( image_path ): print_with_color ( f \"Warning: The image path { image_path } does not exist.\" , \"yellow\" ) return list_of_grounding_results try : results = self . service . chat_completion ( image_path , box_threshold , iou_threshold , use_paddleocr , imgsz , api_name ) grounding_results = results [ 1 ] . splitlines () except Exception as e : print_with_color ( f \"Warning: Failed to get grounding results for Omniparser. Error: { e } \" , \"yellow\" , ) return list_of_grounding_results for item in grounding_results : try : item = json . loads ( item ) list_of_grounding_results . append ( item ) except json . JSONDecodeError : try : # the item string is a string converted from python's dict item = ast . literal_eval ( item [ item . index ( \"{\" ): item . rindex ( \"}\" ) + 1 ]) list_of_grounding_results . append ( item ) except Exception : pass return list_of_grounding_results","title":"Visual Detection"},{"location":"advanced_usage/control_detection/visual_detection/#visual-control-detection-omniparser","text":"We also support visual control detection using OmniParser-v2 . This method is useful for detecting custom controls in the application that may not be recognized by standard UIA methods. The visual control detection uses computer vision techniques to identify and interact with the UI elements based on their visual appearance.","title":"Visual Control Detection (OmniParser)"},{"location":"advanced_usage/control_detection/visual_detection/#deployment","text":"On your remote GPU server, clone the OmniParser repository git clone https://github.com/microsoft/OmniParser.git Start omniparserserver service cd OmniParser/omnitool/omniparserserver python gradio_demo.py This will give you a short URL * Running on local URL: http://0.0.0.0:7861 * Running on public URL: https://xxxxxxxxxxxxxxxxxx.gradio.live Note: If you have any questions regarding the deployment of OmniParser, please take a look at the README from OmniParser repo.","title":"Deployment"},{"location":"advanced_usage/control_detection/visual_detection/#configuration","text":"After deploying the OmniParser model, you need to configure the OmniParser settings in the config.yaml file: OMNIPARSER: { ENDPOINT: \"<YOUR_END_POINT>\", # The endpoint for the omniparser deployment BOX_THRESHOLD: 0.05, # The box confidence threshold for the omniparser, default is 0.05 IOU_THRESHOLD: 0.1, # The iou threshold for the omniparser, default is 0.1 USE_PADDLEOCR: True, # Whether to use the paddleocr for the omniparser IMGSZ: 640 # The image size for the omniparser } To activate the icon control filtering, you need to set CONTROL_BACKEND to [\"omniparser\"] in the config_dev.yaml file. CONTROL_BACKEND: [\"omniparser\"]","title":"Configuration"},{"location":"advanced_usage/control_detection/visual_detection/#reference","text":"The following classes are used for visual control detection in OmniParser: Bases: BasicGrounding The OmniparserGrounding class is a subclass of BasicGrounding, which is used to represent the Omniparser grounding model.","title":"Reference"},{"location":"advanced_usage/control_detection/visual_detection/#automator.ui_control.grounding.omniparser.OmniparserGrounding.parse_results","text":"Parse the grounding results string into a list of control elements infomation dictionaries. Parameters: results ( List [ Dict [ str , Any ]] ) \u2013 The list of grounding results dictionaries from the grounding model. application_window ( UIAWrapper , default: None ) \u2013 The application window to get the absolute coordinates. Returns: List [ Dict [ str , Any ]] \u2013 The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } Source code in automator/ui_control/grounding/omniparser.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def parse_results ( self , results : List [ Dict [ str , Any ]], application_window : UIAWrapper = None ) -> List [ Dict [ str , Any ]]: \"\"\" Parse the grounding results string into a list of control elements infomation dictionaries. :param results: The list of grounding results dictionaries from the grounding model. :param application_window: The application window to get the absolute coordinates. :return: The list of control elements information dictionaries, the dictionary should contain the following keys: { \"control_type\": The control type of the element, \"name\": The name of the element, \"x0\": The absolute left coordinate of the bounding box in integer, \"y0\": The absolute top coordinate of the bounding box in integer, \"x1\": The absolute right coordinate of the bounding box in integer, \"y1\": The absolute bottom coordinate of the bounding box in integer, } \"\"\" control_elements_info = [] if application_window is None : application_rect = RECT ( 0 , 0 , 0 , 0 ) else : try : application_rect = application_window . rectangle () except Exception : application_rect = RECT ( 0 , 0 , 0 , 0 ) for control_info in results : if not self . _filter_interactivity and control_info . get ( \"interactivity\" , True ): continue application_left , application_top = ( application_rect . left , application_rect . top , ) control_box = control_info . get ( \"bbox\" , [ 0 , 0 , 0 , 0 ]) control_left = int ( application_left + control_box [ 0 ] * application_rect . width () ) control_top = int ( application_top + control_box [ 1 ] * application_rect . height () ) control_right = int ( application_left + control_box [ 2 ] * application_rect . width () ) control_bottom = int ( application_top + control_box [ 3 ] * application_rect . height () ) control_elements_info . append ( { \"control_type\" : control_info . get ( \"type\" , \"Button\" ), \"name\" : control_info . get ( \"content\" , \"\" ), \"x0\" : control_left , \"y0\" : control_top , \"x1\" : control_right , \"y1\" : control_bottom , } ) return control_elements_info","title":"parse_results"},{"location":"advanced_usage/control_detection/visual_detection/#automator.ui_control.grounding.omniparser.OmniparserGrounding.predict","text":"Predict the grounding for the given image. Parameters: image_path ( str ) \u2013 The path to the image. box_threshold ( float , default: 0.05 ) \u2013 The threshold for the bounding box. iou_threshold ( float , default: 0.1 ) \u2013 The threshold for the intersection over union. use_paddleocr ( bool , default: True ) \u2013 Whether to use paddleocr. imgsz ( int , default: 640 ) \u2013 The image size. api_name ( str , default: '/process' ) \u2013 The name of the API. Returns: List [ Dict [ str , Any ]] \u2013 The predicted grounding results string. Source code in automator/ui_control/grounding/omniparser.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def predict ( self , image_path : str , box_threshold : float = 0.05 , iou_threshold : float = 0.1 , use_paddleocr : bool = True , imgsz : int = 640 , api_name : str = \"/process\" , ) -> List [ Dict [ str , Any ]]: \"\"\" Predict the grounding for the given image. :param image_path: The path to the image. :param box_threshold: The threshold for the bounding box. :param iou_threshold: The threshold for the intersection over union. :param use_paddleocr: Whether to use paddleocr. :param imgsz: The image size. :param api_name: The name of the API. :return: The predicted grounding results string. \"\"\" list_of_grounding_results = [] if not os . path . exists ( image_path ): print_with_color ( f \"Warning: The image path { image_path } does not exist.\" , \"yellow\" ) return list_of_grounding_results try : results = self . service . chat_completion ( image_path , box_threshold , iou_threshold , use_paddleocr , imgsz , api_name ) grounding_results = results [ 1 ] . splitlines () except Exception as e : print_with_color ( f \"Warning: Failed to get grounding results for Omniparser. Error: { e } \" , \"yellow\" , ) return list_of_grounding_results for item in grounding_results : try : item = json . loads ( item ) list_of_grounding_results . append ( item ) except json . JSONDecodeError : try : # the item string is a string converted from python's dict item = ast . literal_eval ( item [ item . index ( \"{\" ): item . rindex ( \"}\" ) + 1 ]) list_of_grounding_results . append ( item ) except Exception : pass return list_of_grounding_results","title":"predict"},{"location":"advanced_usage/control_filtering/icon_filtering/","text":"Icon Filter The icon control filter is a method to filter the controls based on the similarity between the control icon image and the agent's plan using the image/text embeddings. Configuration To activate the icon control filtering, you need to add ICON to the CONTROL_FILTER list in the config_dev.yaml file. Below is the detailed icon control filter configuration in the config_dev.yaml file: CONTROL_FILTER : A list of filtering methods that you want to apply to the controls. To activate the icon control filtering, add ICON to the list. CONTROL_FILTER_TOP_K_ICON : The number of controls to keep after filtering. CONTROL_FILTER_MODEL_ICON_NAME : The control filter model name for icon similarity. By default, it is set to \"clip-ViT-B-32\". Reference Bases: BasicControlFilter A class that represents a icon model for control filtering. control_filter ( control_dicts , cropped_icons_dict , plans , top_k ) Filters control items based on their scores and returns the top-k items. Parameters: control_dicts \u2013 The dictionary of all control items. cropped_icons_dict \u2013 The dictionary of the cropped icons. plans \u2013 The plans to compare the control icons against. top_k \u2013 The number of top items to return. Returns: \u2013 The list of top-k control items based on their scores. Source code in automator/ui_control/control_filter.py 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 def control_filter ( self , control_dicts , cropped_icons_dict , plans , top_k ): \"\"\" Filters control items based on their scores and returns the top-k items. :param control_dicts: The dictionary of all control items. :param cropped_icons_dict: The dictionary of the cropped icons. :param plans: The plans to compare the control icons against. :param top_k: The number of top items to return. :return: The list of top-k control items based on their scores. \"\"\" scores_items = [] filtered_control_dict = {} for label , cropped_icon in cropped_icons_dict . items (): score = self . control_filter_score ( cropped_icon , plans ) scores_items . append (( score , label )) topk_scores_items = heapq . nlargest ( top_k , scores_items , key = lambda x : x [ 0 ]) topk_labels = [ scores_items [ 1 ] for scores_items in topk_scores_items ] for label , control_item in control_dicts . items (): if label in topk_labels : filtered_control_dict [ label ] = control_item return filtered_control_dict control_filter_score ( control_icon , plans ) Calculates the score of a control icon based on its similarity to the given keywords. Parameters: control_icon \u2013 The control icon image. plans \u2013 The plan to compare the control icon against. Returns: \u2013 The maximum similarity score between the control icon and the keywords. Source code in automator/ui_control/control_filter.py 240 241 242 243 244 245 246 247 248 249 250 def control_filter_score ( self , control_icon , plans ): \"\"\" Calculates the score of a control icon based on its similarity to the given keywords. :param control_icon: The control icon image. :param plans: The plan to compare the control icon against. :return: The maximum similarity score between the control icon and the keywords. \"\"\" plans_embedding = self . get_embedding ( plans ) control_icon_embedding = self . get_embedding ( control_icon ) return max ( self . cos_sim ( control_icon_embedding , plans_embedding ) . tolist ()[ 0 ])","title":"Icon Filtering"},{"location":"advanced_usage/control_filtering/icon_filtering/#icon-filter","text":"The icon control filter is a method to filter the controls based on the similarity between the control icon image and the agent's plan using the image/text embeddings.","title":"Icon Filter"},{"location":"advanced_usage/control_filtering/icon_filtering/#configuration","text":"To activate the icon control filtering, you need to add ICON to the CONTROL_FILTER list in the config_dev.yaml file. Below is the detailed icon control filter configuration in the config_dev.yaml file: CONTROL_FILTER : A list of filtering methods that you want to apply to the controls. To activate the icon control filtering, add ICON to the list. CONTROL_FILTER_TOP_K_ICON : The number of controls to keep after filtering. CONTROL_FILTER_MODEL_ICON_NAME : The control filter model name for icon similarity. By default, it is set to \"clip-ViT-B-32\".","title":"Configuration"},{"location":"advanced_usage/control_filtering/icon_filtering/#reference","text":"Bases: BasicControlFilter A class that represents a icon model for control filtering.","title":"Reference"},{"location":"advanced_usage/control_filtering/icon_filtering/#automator.ui_control.control_filter.IconControlFilter.control_filter","text":"Filters control items based on their scores and returns the top-k items. Parameters: control_dicts \u2013 The dictionary of all control items. cropped_icons_dict \u2013 The dictionary of the cropped icons. plans \u2013 The plans to compare the control icons against. top_k \u2013 The number of top items to return. Returns: \u2013 The list of top-k control items based on their scores. Source code in automator/ui_control/control_filter.py 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 def control_filter ( self , control_dicts , cropped_icons_dict , plans , top_k ): \"\"\" Filters control items based on their scores and returns the top-k items. :param control_dicts: The dictionary of all control items. :param cropped_icons_dict: The dictionary of the cropped icons. :param plans: The plans to compare the control icons against. :param top_k: The number of top items to return. :return: The list of top-k control items based on their scores. \"\"\" scores_items = [] filtered_control_dict = {} for label , cropped_icon in cropped_icons_dict . items (): score = self . control_filter_score ( cropped_icon , plans ) scores_items . append (( score , label )) topk_scores_items = heapq . nlargest ( top_k , scores_items , key = lambda x : x [ 0 ]) topk_labels = [ scores_items [ 1 ] for scores_items in topk_scores_items ] for label , control_item in control_dicts . items (): if label in topk_labels : filtered_control_dict [ label ] = control_item return filtered_control_dict","title":"control_filter"},{"location":"advanced_usage/control_filtering/icon_filtering/#automator.ui_control.control_filter.IconControlFilter.control_filter_score","text":"Calculates the score of a control icon based on its similarity to the given keywords. Parameters: control_icon \u2013 The control icon image. plans \u2013 The plan to compare the control icon against. Returns: \u2013 The maximum similarity score between the control icon and the keywords. Source code in automator/ui_control/control_filter.py 240 241 242 243 244 245 246 247 248 249 250 def control_filter_score ( self , control_icon , plans ): \"\"\" Calculates the score of a control icon based on its similarity to the given keywords. :param control_icon: The control icon image. :param plans: The plan to compare the control icon against. :return: The maximum similarity score between the control icon and the keywords. \"\"\" plans_embedding = self . get_embedding ( plans ) control_icon_embedding = self . get_embedding ( control_icon ) return max ( self . cos_sim ( control_icon_embedding , plans_embedding ) . tolist ()[ 0 ])","title":"control_filter_score"},{"location":"advanced_usage/control_filtering/overview/","text":"Control Filtering There may be many controls items in the application, which may not be relevant to the task. UFO can filter out the irrelevant controls and only focus on the relevant ones. This filtering process can reduce the complexity of the task. Execept for configuring the control types for selection on CONTROL_LIST in config_dev.yaml , UFO also supports filtering the controls based on semantic similarity or keyword matching between the agent's plan and the control's information. We currerntly support the following filtering methods: Filtering Method Description Text Filter the controls based on the control text. Semantic Filter the controls based on the semantic similarity. Icon Filter the controls based on the control icon image. Configuration You can activate the control filtering by setting the CONTROL_FILTER in the config_dev.yaml file. The CONTROL_FILTER is a list of filtering methods that you want to apply to the controls, which can be TEXT , SEMANTIC , or ICON . You can configure multiple filtering methods in the CONTROL_FILTER list. Reference The implementation of the control filtering is base on the BasicControlFilter class located in the ufo/automator/ui_control/control_filter.py file. Concrete filtering class inherit from the BasicControlFilter class and implement the control_filter method to filter the controls based on the specific filtering method. BasicControlFilter represents a model for filtering control items. __new__ ( model_path ) Creates a new instance of BasicControlFilter. Parameters: model_path \u2013 The path to the model. Returns: \u2013 The BasicControlFilter instance. Source code in automator/ui_control/control_filter.py 72 73 74 75 76 77 78 79 80 81 82 def __new__ ( cls , model_path ): \"\"\" Creates a new instance of BasicControlFilter. :param model_path: The path to the model. :return: The BasicControlFilter instance. \"\"\" if model_path not in cls . _instances : instance = super ( BasicControlFilter , cls ) . __new__ ( cls ) instance . model = cls . load_model ( model_path ) cls . _instances [ model_path ] = instance return cls . _instances [ model_path ] control_filter ( control_dicts , plans , ** kwargs ) abstractmethod Calculates the cosine similarity between the embeddings of the given keywords and the control item. Parameters: control_dicts \u2013 The control item to be compared with the plans. plans \u2013 The plans to be used for calculating the similarity. Returns: \u2013 The filtered control items. Source code in automator/ui_control/control_filter.py 104 105 106 107 108 109 110 111 112 @abstractmethod def control_filter ( self , control_dicts , plans , ** kwargs ): \"\"\" Calculates the cosine similarity between the embeddings of the given keywords and the control item. :param control_dicts: The control item to be compared with the plans. :param plans: The plans to be used for calculating the similarity. :return: The filtered control items. \"\"\" pass cos_sim ( embedding1 , embedding2 ) staticmethod Computes the cosine similarity between two embeddings. Parameters: embedding1 \u2013 The first embedding. embedding2 \u2013 The second embedding. Returns: float \u2013 The cosine similarity between the two embeddings. Source code in automator/ui_control/control_filter.py 153 154 155 156 157 158 159 160 161 162 163 @staticmethod def cos_sim ( embedding1 , embedding2 ) -> float : \"\"\" Computes the cosine similarity between two embeddings. :param embedding1: The first embedding. :param embedding2: The second embedding. :return: The cosine similarity between the two embeddings. \"\"\" import sentence_transformers return sentence_transformers . util . cos_sim ( embedding1 , embedding2 ) get_embedding ( content ) Encodes the given object into an embedding. Parameters: content \u2013 The content to encode. Returns: \u2013 The embedding of the object. Source code in automator/ui_control/control_filter.py 95 96 97 98 99 100 101 102 def get_embedding ( self , content ): \"\"\" Encodes the given object into an embedding. :param content: The content to encode. :return: The embedding of the object. \"\"\" return self . model . encode ( content ) load_model ( model_path ) staticmethod Loads the model from the given model path. Parameters: model_path \u2013 The path to the model. Returns: \u2013 The loaded model. Source code in automator/ui_control/control_filter.py 84 85 86 87 88 89 90 91 92 93 @staticmethod def load_model ( model_path ): \"\"\" Loads the model from the given model path. :param model_path: The path to the model. :return: The loaded model. \"\"\" import sentence_transformers return sentence_transformers . SentenceTransformer ( model_path ) plans_to_keywords ( plans ) staticmethod Gets keywords from the plan. We only consider the words in the plan that are alphabetic or Chinese characters. Parameters: plans ( List [ str ] ) \u2013 The plan to be parsed. Returns: List [ str ] \u2013 A list of keywords extracted from the plan. Source code in automator/ui_control/control_filter.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @staticmethod def plans_to_keywords ( plans : List [ str ]) -> List [ str ]: \"\"\" Gets keywords from the plan. We only consider the words in the plan that are alphabetic or Chinese characters. :param plans: The plan to be parsed. :return: A list of keywords extracted from the plan. \"\"\" keywords = [] for plan in plans : words = plan . replace ( \"'\" , \"\" ) . strip ( \".\" ) . split () words = [ word for word in words if word . isalpha () or bool ( re . fullmatch ( r \"[\\u4e00-\\u9fa5]+\" , word )) ] keywords . extend ( words ) return keywords remove_stopwords ( keywords ) staticmethod Removes stopwords from the given list of keywords. If you are using stopwords for the first time, you need to download them using nltk.download('stopwords'). Parameters: keywords \u2013 The list of keywords to be filtered. Returns: \u2013 The list of keywords with the stopwords removed. Source code in automator/ui_control/control_filter.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @staticmethod def remove_stopwords ( keywords ): \"\"\" Removes stopwords from the given list of keywords. If you are using stopwords for the first time, you need to download them using nltk.download('stopwords'). :param keywords: The list of keywords to be filtered. :return: The list of keywords with the stopwords removed. \"\"\" try : from nltk.corpus import stopwords stopwords_list = stopwords . words ( \"english\" ) except LookupError as e : import nltk nltk . download ( \"stopwords\" ) stopwords_list = nltk . corpus . stopwords . words ( \"english\" ) return [ keyword for keyword in keywords if keyword in stopwords_list ]","title":"Overview"},{"location":"advanced_usage/control_filtering/overview/#control-filtering","text":"There may be many controls items in the application, which may not be relevant to the task. UFO can filter out the irrelevant controls and only focus on the relevant ones. This filtering process can reduce the complexity of the task. Execept for configuring the control types for selection on CONTROL_LIST in config_dev.yaml , UFO also supports filtering the controls based on semantic similarity or keyword matching between the agent's plan and the control's information. We currerntly support the following filtering methods: Filtering Method Description Text Filter the controls based on the control text. Semantic Filter the controls based on the semantic similarity. Icon Filter the controls based on the control icon image.","title":"Control Filtering"},{"location":"advanced_usage/control_filtering/overview/#configuration","text":"You can activate the control filtering by setting the CONTROL_FILTER in the config_dev.yaml file. The CONTROL_FILTER is a list of filtering methods that you want to apply to the controls, which can be TEXT , SEMANTIC , or ICON . You can configure multiple filtering methods in the CONTROL_FILTER list.","title":"Configuration"},{"location":"advanced_usage/control_filtering/overview/#reference","text":"The implementation of the control filtering is base on the BasicControlFilter class located in the ufo/automator/ui_control/control_filter.py file. Concrete filtering class inherit from the BasicControlFilter class and implement the control_filter method to filter the controls based on the specific filtering method. BasicControlFilter represents a model for filtering control items.","title":"Reference"},{"location":"advanced_usage/control_filtering/overview/#automator.ui_control.control_filter.BasicControlFilter.__new__","text":"Creates a new instance of BasicControlFilter. Parameters: model_path \u2013 The path to the model. Returns: \u2013 The BasicControlFilter instance. Source code in automator/ui_control/control_filter.py 72 73 74 75 76 77 78 79 80 81 82 def __new__ ( cls , model_path ): \"\"\" Creates a new instance of BasicControlFilter. :param model_path: The path to the model. :return: The BasicControlFilter instance. \"\"\" if model_path not in cls . _instances : instance = super ( BasicControlFilter , cls ) . __new__ ( cls ) instance . model = cls . load_model ( model_path ) cls . _instances [ model_path ] = instance return cls . _instances [ model_path ]","title":"__new__"},{"location":"advanced_usage/control_filtering/overview/#automator.ui_control.control_filter.BasicControlFilter.control_filter","text":"Calculates the cosine similarity between the embeddings of the given keywords and the control item. Parameters: control_dicts \u2013 The control item to be compared with the plans. plans \u2013 The plans to be used for calculating the similarity. Returns: \u2013 The filtered control items. Source code in automator/ui_control/control_filter.py 104 105 106 107 108 109 110 111 112 @abstractmethod def control_filter ( self , control_dicts , plans , ** kwargs ): \"\"\" Calculates the cosine similarity between the embeddings of the given keywords and the control item. :param control_dicts: The control item to be compared with the plans. :param plans: The plans to be used for calculating the similarity. :return: The filtered control items. \"\"\" pass","title":"control_filter"},{"location":"advanced_usage/control_filtering/overview/#automator.ui_control.control_filter.BasicControlFilter.cos_sim","text":"Computes the cosine similarity between two embeddings. Parameters: embedding1 \u2013 The first embedding. embedding2 \u2013 The second embedding. Returns: float \u2013 The cosine similarity between the two embeddings. Source code in automator/ui_control/control_filter.py 153 154 155 156 157 158 159 160 161 162 163 @staticmethod def cos_sim ( embedding1 , embedding2 ) -> float : \"\"\" Computes the cosine similarity between two embeddings. :param embedding1: The first embedding. :param embedding2: The second embedding. :return: The cosine similarity between the two embeddings. \"\"\" import sentence_transformers return sentence_transformers . util . cos_sim ( embedding1 , embedding2 )","title":"cos_sim"},{"location":"advanced_usage/control_filtering/overview/#automator.ui_control.control_filter.BasicControlFilter.get_embedding","text":"Encodes the given object into an embedding. Parameters: content \u2013 The content to encode. Returns: \u2013 The embedding of the object. Source code in automator/ui_control/control_filter.py 95 96 97 98 99 100 101 102 def get_embedding ( self , content ): \"\"\" Encodes the given object into an embedding. :param content: The content to encode. :return: The embedding of the object. \"\"\" return self . model . encode ( content )","title":"get_embedding"},{"location":"advanced_usage/control_filtering/overview/#automator.ui_control.control_filter.BasicControlFilter.load_model","text":"Loads the model from the given model path. Parameters: model_path \u2013 The path to the model. Returns: \u2013 The loaded model. Source code in automator/ui_control/control_filter.py 84 85 86 87 88 89 90 91 92 93 @staticmethod def load_model ( model_path ): \"\"\" Loads the model from the given model path. :param model_path: The path to the model. :return: The loaded model. \"\"\" import sentence_transformers return sentence_transformers . SentenceTransformer ( model_path )","title":"load_model"},{"location":"advanced_usage/control_filtering/overview/#automator.ui_control.control_filter.BasicControlFilter.plans_to_keywords","text":"Gets keywords from the plan. We only consider the words in the plan that are alphabetic or Chinese characters. Parameters: plans ( List [ str ] ) \u2013 The plan to be parsed. Returns: List [ str ] \u2013 A list of keywords extracted from the plan. Source code in automator/ui_control/control_filter.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @staticmethod def plans_to_keywords ( plans : List [ str ]) -> List [ str ]: \"\"\" Gets keywords from the plan. We only consider the words in the plan that are alphabetic or Chinese characters. :param plans: The plan to be parsed. :return: A list of keywords extracted from the plan. \"\"\" keywords = [] for plan in plans : words = plan . replace ( \"'\" , \"\" ) . strip ( \".\" ) . split () words = [ word for word in words if word . isalpha () or bool ( re . fullmatch ( r \"[\\u4e00-\\u9fa5]+\" , word )) ] keywords . extend ( words ) return keywords","title":"plans_to_keywords"},{"location":"advanced_usage/control_filtering/overview/#automator.ui_control.control_filter.BasicControlFilter.remove_stopwords","text":"Removes stopwords from the given list of keywords. If you are using stopwords for the first time, you need to download them using nltk.download('stopwords'). Parameters: keywords \u2013 The list of keywords to be filtered. Returns: \u2013 The list of keywords with the stopwords removed. Source code in automator/ui_control/control_filter.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @staticmethod def remove_stopwords ( keywords ): \"\"\" Removes stopwords from the given list of keywords. If you are using stopwords for the first time, you need to download them using nltk.download('stopwords'). :param keywords: The list of keywords to be filtered. :return: The list of keywords with the stopwords removed. \"\"\" try : from nltk.corpus import stopwords stopwords_list = stopwords . words ( \"english\" ) except LookupError as e : import nltk nltk . download ( \"stopwords\" ) stopwords_list = nltk . corpus . stopwords . words ( \"english\" ) return [ keyword for keyword in keywords if keyword in stopwords_list ]","title":"remove_stopwords"},{"location":"advanced_usage/control_filtering/semantic_filtering/","text":"Sematic Control Filter The semantic control filter is a method to filter the controls based on the semantic similarity between the agent's plan and the control's text using their embeddings. Configuration To activate the semantic control filtering, you need to add SEMANTIC to the CONTROL_FILTER list in the config_dev.yaml file. Below is the detailed sematic control filter configuration in the config_dev.yaml file: CONTROL_FILTER : A list of filtering methods that you want to apply to the controls. To activate the semantic control filtering, add SEMANTIC to the list. CONTROL_FILTER_TOP_K_SEMANTIC : The number of controls to keep after filtering. CONTROL_FILTER_MODEL_SEMANTIC_NAME : The control filter model name for semantic similarity. By default, it is set to \"all-MiniLM-L6-v2\". Reference Bases: BasicControlFilter A class that represents a semantic model for control filtering. control_filter ( control_dicts , plans , top_k ) Filters control items based on their similarity to a set of keywords. Parameters: control_dicts \u2013 The dictionary of control items to be filtered. plans \u2013 The list of plans to be used for filtering. top_k \u2013 The number of top control items to return. Returns: \u2013 The filtered control items. Source code in automator/ui_control/control_filter.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def control_filter ( self , control_dicts , plans , top_k ): \"\"\" Filters control items based on their similarity to a set of keywords. :param control_dicts: The dictionary of control items to be filtered. :param plans: The list of plans to be used for filtering. :param top_k: The number of top control items to return. :return: The filtered control items. \"\"\" scores_items = [] filtered_control_dict = {} for label , control_item in control_dicts . items (): control_text = control_item . element_info . name . lower () score = self . control_filter_score ( control_text , plans ) scores_items . append (( label , score )) topk_scores_items = heapq . nlargest ( top_k , ( scores_items ), key = lambda x : x [ 1 ]) topk_items = [ ( score_item [ 0 ], score_item [ 1 ]) for score_item in topk_scores_items ] for label , control_item in control_dicts . items (): if label in topk_items : filtered_control_dict [ label ] = control_item return filtered_control_dict control_filter_score ( control_text , plans ) Calculates the score for a control item based on the similarity between its text and a set of keywords. Parameters: control_text \u2013 The text of the control item. plans \u2013 The plan to be used for calculating the similarity. Returns: \u2013 The score (0-1) indicating the similarity between the control text and the keywords. Source code in automator/ui_control/control_filter.py 197 198 199 200 201 202 203 204 205 206 207 def control_filter_score ( self , control_text , plans ): \"\"\" Calculates the score for a control item based on the similarity between its text and a set of keywords. :param control_text: The text of the control item. :param plans: The plan to be used for calculating the similarity. :return: The score (0-1) indicating the similarity between the control text and the keywords. \"\"\" plan_embedding = self . get_embedding ( plans ) control_text_embedding = self . get_embedding ( control_text ) return max ( self . cos_sim ( control_text_embedding , plan_embedding ) . tolist ()[ 0 ])","title":"Semantic Filtering"},{"location":"advanced_usage/control_filtering/semantic_filtering/#sematic-control-filter","text":"The semantic control filter is a method to filter the controls based on the semantic similarity between the agent's plan and the control's text using their embeddings.","title":"Sematic Control Filter"},{"location":"advanced_usage/control_filtering/semantic_filtering/#configuration","text":"To activate the semantic control filtering, you need to add SEMANTIC to the CONTROL_FILTER list in the config_dev.yaml file. Below is the detailed sematic control filter configuration in the config_dev.yaml file: CONTROL_FILTER : A list of filtering methods that you want to apply to the controls. To activate the semantic control filtering, add SEMANTIC to the list. CONTROL_FILTER_TOP_K_SEMANTIC : The number of controls to keep after filtering. CONTROL_FILTER_MODEL_SEMANTIC_NAME : The control filter model name for semantic similarity. By default, it is set to \"all-MiniLM-L6-v2\".","title":"Configuration"},{"location":"advanced_usage/control_filtering/semantic_filtering/#reference","text":"Bases: BasicControlFilter A class that represents a semantic model for control filtering.","title":"Reference"},{"location":"advanced_usage/control_filtering/semantic_filtering/#automator.ui_control.control_filter.SemanticControlFilter.control_filter","text":"Filters control items based on their similarity to a set of keywords. Parameters: control_dicts \u2013 The dictionary of control items to be filtered. plans \u2013 The list of plans to be used for filtering. top_k \u2013 The number of top control items to return. Returns: \u2013 The filtered control items. Source code in automator/ui_control/control_filter.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def control_filter ( self , control_dicts , plans , top_k ): \"\"\" Filters control items based on their similarity to a set of keywords. :param control_dicts: The dictionary of control items to be filtered. :param plans: The list of plans to be used for filtering. :param top_k: The number of top control items to return. :return: The filtered control items. \"\"\" scores_items = [] filtered_control_dict = {} for label , control_item in control_dicts . items (): control_text = control_item . element_info . name . lower () score = self . control_filter_score ( control_text , plans ) scores_items . append (( label , score )) topk_scores_items = heapq . nlargest ( top_k , ( scores_items ), key = lambda x : x [ 1 ]) topk_items = [ ( score_item [ 0 ], score_item [ 1 ]) for score_item in topk_scores_items ] for label , control_item in control_dicts . items (): if label in topk_items : filtered_control_dict [ label ] = control_item return filtered_control_dict","title":"control_filter"},{"location":"advanced_usage/control_filtering/semantic_filtering/#automator.ui_control.control_filter.SemanticControlFilter.control_filter_score","text":"Calculates the score for a control item based on the similarity between its text and a set of keywords. Parameters: control_text \u2013 The text of the control item. plans \u2013 The plan to be used for calculating the similarity. Returns: \u2013 The score (0-1) indicating the similarity between the control text and the keywords. Source code in automator/ui_control/control_filter.py 197 198 199 200 201 202 203 204 205 206 207 def control_filter_score ( self , control_text , plans ): \"\"\" Calculates the score for a control item based on the similarity between its text and a set of keywords. :param control_text: The text of the control item. :param plans: The plan to be used for calculating the similarity. :return: The score (0-1) indicating the similarity between the control text and the keywords. \"\"\" plan_embedding = self . get_embedding ( plans ) control_text_embedding = self . get_embedding ( control_text ) return max ( self . cos_sim ( control_text_embedding , plan_embedding ) . tolist ()[ 0 ])","title":"control_filter_score"},{"location":"advanced_usage/control_filtering/text_filtering/","text":"Text Control Filter The text control filter is a method to filter the controls based on the control text. The agent's plan on the current step usually contains some keywords or phrases. This method filters the controls based on the matching between the control text and the keywords or phrases in the agent's plan. Configuration To activate the text control filtering, you need to add TEXT to the CONTROL_FILTER list in the config_dev.yaml file. Below is the detailed text control filter configuration in the config_dev.yaml file: CONTROL_FILTER : A list of filtering methods that you want to apply to the controls. To activate the text control filtering, add TEXT to the list. CONTROL_FILTER_TOP_K_PLAN : The number of agent's plan keywords or phrases to use for filtering the controls. Reference A class that provides methods for filtering control items based on plans. control_filter ( control_dicts , plans ) staticmethod Filters control items based on keywords. Parameters: control_dicts ( Dict ) \u2013 The dictionary of control items to be filtered. plans ( List [ str ] ) \u2013 The list of plans to be used for filtering. Returns: Dict \u2013 The filtered control items. Source code in automator/ui_control/control_filter.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 @staticmethod def control_filter ( control_dicts : Dict , plans : List [ str ]) -> Dict : \"\"\" Filters control items based on keywords. :param control_dicts: The dictionary of control items to be filtered. :param plans: The list of plans to be used for filtering. :return: The filtered control items. \"\"\" filtered_control_dict = {} keywords = BasicControlFilter . plans_to_keywords ( plans ) for label , control_item in control_dicts . items (): control_text = control_item . element_info . name . lower () if any ( keyword in control_text or control_text in keyword for keyword in keywords ): filtered_control_dict [ label ] = control_item return filtered_control_dict","title":"Text Filtering"},{"location":"advanced_usage/control_filtering/text_filtering/#text-control-filter","text":"The text control filter is a method to filter the controls based on the control text. The agent's plan on the current step usually contains some keywords or phrases. This method filters the controls based on the matching between the control text and the keywords or phrases in the agent's plan.","title":"Text Control Filter"},{"location":"advanced_usage/control_filtering/text_filtering/#configuration","text":"To activate the text control filtering, you need to add TEXT to the CONTROL_FILTER list in the config_dev.yaml file. Below is the detailed text control filter configuration in the config_dev.yaml file: CONTROL_FILTER : A list of filtering methods that you want to apply to the controls. To activate the text control filtering, add TEXT to the list. CONTROL_FILTER_TOP_K_PLAN : The number of agent's plan keywords or phrases to use for filtering the controls.","title":"Configuration"},{"location":"advanced_usage/control_filtering/text_filtering/#reference","text":"A class that provides methods for filtering control items based on plans.","title":"Reference"},{"location":"advanced_usage/control_filtering/text_filtering/#automator.ui_control.control_filter.TextControlFilter.control_filter","text":"Filters control items based on keywords. Parameters: control_dicts ( Dict ) \u2013 The dictionary of control items to be filtered. plans ( List [ str ] ) \u2013 The list of plans to be used for filtering. Returns: Dict \u2013 The filtered control items. Source code in automator/ui_control/control_filter.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 @staticmethod def control_filter ( control_dicts : Dict , plans : List [ str ]) -> Dict : \"\"\" Filters control items based on keywords. :param control_dicts: The dictionary of control items to be filtered. :param plans: The list of plans to be used for filtering. :return: The filtered control items. \"\"\" filtered_control_dict = {} keywords = BasicControlFilter . plans_to_keywords ( plans ) for label , control_item in control_dicts . items (): control_text = control_item . element_info . name . lower () if any ( keyword in control_text or control_text in keyword for keyword in keywords ): filtered_control_dict [ label ] = control_item return filtered_control_dict","title":"control_filter"},{"location":"advanced_usage/reinforce_appagent/experience_learning/","text":"Learning from Self-Experience When UFO successfully completes a task, user can choose to save the successful experience to reinforce the AppAgent. The AppAgent can learn from its own successful experiences to improve its performance in the future. Mechanism Step 1: Complete a Session Event : UFO completes a session Step 2: Ask User to Save Experience Action : The agent prompts the user with a choice to save the successful experience Step 3: User Chooses to Save Action : If the user chooses to save the experience Step 4: Summarize and Save the Experience Tool : ExperienceSummarizer Process : Summarize the experience into a demonstration example Save the demonstration example in the EXPERIENCE_SAVED_PATH as specified in the config_dev.yaml file The demonstration example includes similar fields as those used in the AppAgent's prompt Step 5: Retrieve and Utilize Saved Experience When : The AppAgent encounters a similar task in the future Action : Retrieve the saved experience from the experience database Outcome : Use the retrieved experience to generate a plan Workflow Diagram graph TD; A[Complete Session] --> B[Ask User to Save Experience] B --> C[User Chooses to Save] C --> D[Summarize with ExperienceSummarizer] D --> E[Save in EXPERIENCE_SAVED_PATH] F[AppAgent Encounters Similar Task] --> G[Retrieve Saved Experience] G --> H[Generate Plan] Activate the Learning from Self-Experience Step 1: Configure the AppAgent Configure the following parameters to allow UFO to use the RAG from its self-experience: Configuration Option Description Type Default Value RAG_EXPERIENCE Whether to use the RAG from its self-experience Boolean False RAG_EXPERIENCE_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 5 Reference Experience Summarizer The ExperienceSummarizer class is located in the ufo/experience/experience_summarizer.py file. The ExperienceSummarizer class provides the following methods to summarize the experience: The ExperienceSummarizer class is the summarizer for the experience learning. Initialize the ApplicationAgentPrompter. Parameters: is_visual ( bool ) \u2013 Whether the request is for visual model. prompt_template ( str ) \u2013 The path of the prompt template. example_prompt_template ( str ) \u2013 The path of the example prompt template. api_prompt_template ( str ) \u2013 The path of the api prompt template. Source code in experience/summarizer.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , is_visual : bool , prompt_template : str , example_prompt_template : str , api_prompt_template : str , ): \"\"\" Initialize the ApplicationAgentPrompter. :param is_visual: Whether the request is for visual model. :param prompt_template: The path of the prompt template. :param example_prompt_template: The path of the example prompt template. :param api_prompt_template: The path of the api prompt template. \"\"\" self . is_visual = is_visual self . prompt_template = prompt_template self . example_prompt_template = example_prompt_template self . api_prompt_template = api_prompt_template build_prompt ( log_partition ) Build the prompt. Parameters: log_partition ( dict ) \u2013 The log partition. return: The prompt. Source code in experience/summarizer.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def build_prompt ( self , log_partition : dict ) -> list : \"\"\" Build the prompt. :param log_partition: The log partition. return: The prompt. \"\"\" experience_prompter = ExperiencePrompter ( self . is_visual , self . prompt_template , self . example_prompt_template , self . api_prompt_template , ) experience_system_prompt = experience_prompter . system_prompt_construction () experience_user_prompt = experience_prompter . user_content_construction ( log_partition ) experience_prompt = experience_prompter . prompt_construction ( experience_system_prompt , experience_user_prompt ) return experience_prompt create_or_update_vector_db ( summaries , db_path ) staticmethod Create or update the vector database. Parameters: summaries ( list ) \u2013 The summaries. db_path ( str ) \u2013 The path of the vector database. Source code in experience/summarizer.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 @staticmethod def create_or_update_vector_db ( summaries : list , db_path : str ): \"\"\" Create or update the vector database. :param summaries: The summaries. :param db_path: The path of the vector database. \"\"\" document_list = [] for summary in summaries : request = summary [ \"request\" ] document_list . append ( Document ( page_content = request , metadata = summary )) db = FAISS . from_documents ( document_list , get_hugginface_embedding ()) # Check if the db exists, if not, create a new one. if os . path . exists ( db_path ): prev_db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) db . merge_from ( prev_db ) db . save_local ( db_path ) print ( f \"Updated vector DB successfully: { db_path } \" ) create_or_update_yaml ( summaries , yaml_path ) staticmethod Create or update the YAML file. Parameters: summaries ( list ) \u2013 The summaries. yaml_path ( str ) \u2013 The path of the YAML file. Source code in experience/summarizer.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 @staticmethod def create_or_update_yaml ( summaries : list , yaml_path : str ): \"\"\" Create or update the YAML file. :param summaries: The summaries. :param yaml_path: The path of the YAML file. \"\"\" # Check if the file exists, if not, create a new one if not os . path . exists ( yaml_path ): with open ( yaml_path , \"w\" ): pass print ( f \"Created new YAML file: { yaml_path } \" ) # Read existing data from the YAML file with open ( yaml_path , \"r\" ) as file : existing_data = yaml . safe_load ( file ) # Initialize index and existing_data if file is empty index = len ( existing_data ) if existing_data else 0 existing_data = existing_data or {} # Update data with new summaries for i , summary in enumerate ( summaries ): example = { f \"example { index + i } \" : summary } existing_data . update ( example ) # Write updated data back to the YAML file with open ( yaml_path , \"w\" ) as file : yaml . safe_dump ( existing_data , file , default_flow_style = False , sort_keys = False ) print ( f \"Updated existing YAML file successfully: { yaml_path } \" ) get_summary ( prompt_message ) Get the summary. Parameters: prompt_message ( list ) \u2013 The prompt message. return: The summary and the cost. Source code in experience/summarizer.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def get_summary ( self , prompt_message : list ) -> Tuple [ dict , float ]: \"\"\" Get the summary. :param prompt_message: The prompt message. return: The summary and the cost. \"\"\" # Get the completion for the prompt message response_string , cost = get_completion ( prompt_message , \"APPAGENT\" , use_backup_engine = True ) try : response_json = json_parser ( response_string ) except : response_json = None # Restructure the response if response_json : summary = dict () summary [ \"example\" ] = {} for key in [ \"Observation\" , \"Thought\" , \"ControlLabel\" , \"ControlText\" , \"Function\" , \"Args\" , \"Status\" , \"Plan\" , \"Comment\" , ]: summary [ \"example\" ][ key ] = response_json . get ( key , \"\" ) summary [ \"Tips\" ] = response_json . get ( \"Tips\" , \"\" ) return summary , cost get_summary_list ( logs ) Get the summary list. Parameters: logs ( list ) \u2013 The logs. return: The summary list and the total cost. Source code in experience/summarizer.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def get_summary_list ( self , logs : list ) -> Tuple [ list , float ]: \"\"\" Get the summary list. :param logs: The logs. return: The summary list and the total cost. \"\"\" summaries = [] total_cost = 0.0 for log_partition in logs : prompt = self . build_prompt ( log_partition ) summary , cost = self . get_summary ( prompt ) summary [ \"request\" ] = log_partition . get ( \"subtask\" ) summary [ \"Sub-task\" ] = log_partition . get ( \"subtask\" ) summary [ \"app_list\" ] = [ log_partition . get ( \"application\" )] summaries . append ( summary ) total_cost += cost return summaries , total_cost read_logs ( log_path ) staticmethod Read the log. Parameters: log_path ( str ) \u2013 The path of the log file. Source code in experience/summarizer.py 119 120 121 122 123 124 125 126 @staticmethod def read_logs ( log_path : str ) -> list : \"\"\" Read the log. :param log_path: The path of the log file. \"\"\" replay_loader = ExperienceLogLoader ( log_path ) return replay_loader . subtask_partition Experience Retriever The ExperienceRetriever class is located in the ufo/rag/retriever.py file. The ExperienceRetriever class provides the following methods to retrieve the experience: Bases: Retriever Class to create experience retrievers. Create a new ExperienceRetriever. Parameters: db_path \u2013 The path to the database. Source code in rag/retriever.py 138 139 140 141 142 143 def __init__ ( self , db_path ) -> None : \"\"\" Create a new ExperienceRetriever. :param db_path: The path to the database. \"\"\" self . indexer = self . get_indexer ( db_path ) get_indexer ( db_path ) Create an experience indexer. Parameters: db_path ( str ) \u2013 The path to the database. Source code in rag/retriever.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def get_indexer ( self , db_path : str ): \"\"\" Create an experience indexer. :param db_path: The path to the database. \"\"\" try : db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) return db except Exception as e : print_with_color ( \"Warning: Failed to load experience indexer from {path} , error: {error} .\" . format ( path = db_path , error = e ), \"yellow\" , ) return None","title":"Experience Learning"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#learning-from-self-experience","text":"When UFO successfully completes a task, user can choose to save the successful experience to reinforce the AppAgent. The AppAgent can learn from its own successful experiences to improve its performance in the future.","title":"Learning from Self-Experience"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#mechanism","text":"","title":"Mechanism"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#step-1-complete-a-session","text":"Event : UFO completes a session","title":"Step 1: Complete a Session"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#step-2-ask-user-to-save-experience","text":"Action : The agent prompts the user with a choice to save the successful experience","title":"Step 2: Ask User to Save Experience"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#step-3-user-chooses-to-save","text":"Action : If the user chooses to save the experience","title":"Step 3: User Chooses to Save"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#step-4-summarize-and-save-the-experience","text":"Tool : ExperienceSummarizer Process : Summarize the experience into a demonstration example Save the demonstration example in the EXPERIENCE_SAVED_PATH as specified in the config_dev.yaml file The demonstration example includes similar fields as those used in the AppAgent's prompt","title":"Step 4: Summarize and Save the Experience"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#step-5-retrieve-and-utilize-saved-experience","text":"When : The AppAgent encounters a similar task in the future Action : Retrieve the saved experience from the experience database Outcome : Use the retrieved experience to generate a plan","title":"Step 5: Retrieve and Utilize Saved Experience"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#workflow-diagram","text":"graph TD; A[Complete Session] --> B[Ask User to Save Experience] B --> C[User Chooses to Save] C --> D[Summarize with ExperienceSummarizer] D --> E[Save in EXPERIENCE_SAVED_PATH] F[AppAgent Encounters Similar Task] --> G[Retrieve Saved Experience] G --> H[Generate Plan]","title":"Workflow Diagram"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#activate-the-learning-from-self-experience","text":"","title":"Activate the Learning from Self-Experience"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#step-1-configure-the-appagent","text":"Configure the following parameters to allow UFO to use the RAG from its self-experience: Configuration Option Description Type Default Value RAG_EXPERIENCE Whether to use the RAG from its self-experience Boolean False RAG_EXPERIENCE_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 5","title":"Step 1: Configure the AppAgent"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#reference","text":"","title":"Reference"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience-summarizer","text":"The ExperienceSummarizer class is located in the ufo/experience/experience_summarizer.py file. The ExperienceSummarizer class provides the following methods to summarize the experience: The ExperienceSummarizer class is the summarizer for the experience learning. Initialize the ApplicationAgentPrompter. Parameters: is_visual ( bool ) \u2013 Whether the request is for visual model. prompt_template ( str ) \u2013 The path of the prompt template. example_prompt_template ( str ) \u2013 The path of the example prompt template. api_prompt_template ( str ) \u2013 The path of the api prompt template. Source code in experience/summarizer.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , is_visual : bool , prompt_template : str , example_prompt_template : str , api_prompt_template : str , ): \"\"\" Initialize the ApplicationAgentPrompter. :param is_visual: Whether the request is for visual model. :param prompt_template: The path of the prompt template. :param example_prompt_template: The path of the example prompt template. :param api_prompt_template: The path of the api prompt template. \"\"\" self . is_visual = is_visual self . prompt_template = prompt_template self . example_prompt_template = example_prompt_template self . api_prompt_template = api_prompt_template","title":"Experience Summarizer"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience.summarizer.ExperienceSummarizer.build_prompt","text":"Build the prompt. Parameters: log_partition ( dict ) \u2013 The log partition. return: The prompt. Source code in experience/summarizer.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def build_prompt ( self , log_partition : dict ) -> list : \"\"\" Build the prompt. :param log_partition: The log partition. return: The prompt. \"\"\" experience_prompter = ExperiencePrompter ( self . is_visual , self . prompt_template , self . example_prompt_template , self . api_prompt_template , ) experience_system_prompt = experience_prompter . system_prompt_construction () experience_user_prompt = experience_prompter . user_content_construction ( log_partition ) experience_prompt = experience_prompter . prompt_construction ( experience_system_prompt , experience_user_prompt ) return experience_prompt","title":"build_prompt"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience.summarizer.ExperienceSummarizer.create_or_update_vector_db","text":"Create or update the vector database. Parameters: summaries ( list ) \u2013 The summaries. db_path ( str ) \u2013 The path of the vector database. Source code in experience/summarizer.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 @staticmethod def create_or_update_vector_db ( summaries : list , db_path : str ): \"\"\" Create or update the vector database. :param summaries: The summaries. :param db_path: The path of the vector database. \"\"\" document_list = [] for summary in summaries : request = summary [ \"request\" ] document_list . append ( Document ( page_content = request , metadata = summary )) db = FAISS . from_documents ( document_list , get_hugginface_embedding ()) # Check if the db exists, if not, create a new one. if os . path . exists ( db_path ): prev_db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) db . merge_from ( prev_db ) db . save_local ( db_path ) print ( f \"Updated vector DB successfully: { db_path } \" )","title":"create_or_update_vector_db"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience.summarizer.ExperienceSummarizer.create_or_update_yaml","text":"Create or update the YAML file. Parameters: summaries ( list ) \u2013 The summaries. yaml_path ( str ) \u2013 The path of the YAML file. Source code in experience/summarizer.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 @staticmethod def create_or_update_yaml ( summaries : list , yaml_path : str ): \"\"\" Create or update the YAML file. :param summaries: The summaries. :param yaml_path: The path of the YAML file. \"\"\" # Check if the file exists, if not, create a new one if not os . path . exists ( yaml_path ): with open ( yaml_path , \"w\" ): pass print ( f \"Created new YAML file: { yaml_path } \" ) # Read existing data from the YAML file with open ( yaml_path , \"r\" ) as file : existing_data = yaml . safe_load ( file ) # Initialize index and existing_data if file is empty index = len ( existing_data ) if existing_data else 0 existing_data = existing_data or {} # Update data with new summaries for i , summary in enumerate ( summaries ): example = { f \"example { index + i } \" : summary } existing_data . update ( example ) # Write updated data back to the YAML file with open ( yaml_path , \"w\" ) as file : yaml . safe_dump ( existing_data , file , default_flow_style = False , sort_keys = False ) print ( f \"Updated existing YAML file successfully: { yaml_path } \" )","title":"create_or_update_yaml"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience.summarizer.ExperienceSummarizer.get_summary","text":"Get the summary. Parameters: prompt_message ( list ) \u2013 The prompt message. return: The summary and the cost. Source code in experience/summarizer.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def get_summary ( self , prompt_message : list ) -> Tuple [ dict , float ]: \"\"\" Get the summary. :param prompt_message: The prompt message. return: The summary and the cost. \"\"\" # Get the completion for the prompt message response_string , cost = get_completion ( prompt_message , \"APPAGENT\" , use_backup_engine = True ) try : response_json = json_parser ( response_string ) except : response_json = None # Restructure the response if response_json : summary = dict () summary [ \"example\" ] = {} for key in [ \"Observation\" , \"Thought\" , \"ControlLabel\" , \"ControlText\" , \"Function\" , \"Args\" , \"Status\" , \"Plan\" , \"Comment\" , ]: summary [ \"example\" ][ key ] = response_json . get ( key , \"\" ) summary [ \"Tips\" ] = response_json . get ( \"Tips\" , \"\" ) return summary , cost","title":"get_summary"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience.summarizer.ExperienceSummarizer.get_summary_list","text":"Get the summary list. Parameters: logs ( list ) \u2013 The logs. return: The summary list and the total cost. Source code in experience/summarizer.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def get_summary_list ( self , logs : list ) -> Tuple [ list , float ]: \"\"\" Get the summary list. :param logs: The logs. return: The summary list and the total cost. \"\"\" summaries = [] total_cost = 0.0 for log_partition in logs : prompt = self . build_prompt ( log_partition ) summary , cost = self . get_summary ( prompt ) summary [ \"request\" ] = log_partition . get ( \"subtask\" ) summary [ \"Sub-task\" ] = log_partition . get ( \"subtask\" ) summary [ \"app_list\" ] = [ log_partition . get ( \"application\" )] summaries . append ( summary ) total_cost += cost return summaries , total_cost","title":"get_summary_list"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience.summarizer.ExperienceSummarizer.read_logs","text":"Read the log. Parameters: log_path ( str ) \u2013 The path of the log file. Source code in experience/summarizer.py 119 120 121 122 123 124 125 126 @staticmethod def read_logs ( log_path : str ) -> list : \"\"\" Read the log. :param log_path: The path of the log file. \"\"\" replay_loader = ExperienceLogLoader ( log_path ) return replay_loader . subtask_partition","title":"read_logs"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#experience-retriever","text":"The ExperienceRetriever class is located in the ufo/rag/retriever.py file. The ExperienceRetriever class provides the following methods to retrieve the experience: Bases: Retriever Class to create experience retrievers. Create a new ExperienceRetriever. Parameters: db_path \u2013 The path to the database. Source code in rag/retriever.py 138 139 140 141 142 143 def __init__ ( self , db_path ) -> None : \"\"\" Create a new ExperienceRetriever. :param db_path: The path to the database. \"\"\" self . indexer = self . get_indexer ( db_path )","title":"Experience Retriever"},{"location":"advanced_usage/reinforce_appagent/experience_learning/#rag.retriever.ExperienceRetriever.get_indexer","text":"Create an experience indexer. Parameters: db_path ( str ) \u2013 The path to the database. Source code in rag/retriever.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def get_indexer ( self , db_path : str ): \"\"\" Create an experience indexer. :param db_path: The path to the database. \"\"\" try : db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) return db except Exception as e : print_with_color ( \"Warning: Failed to load experience indexer from {path} , error: {error} .\" . format ( path = db_path , error = e ), \"yellow\" , ) return None","title":"get_indexer"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/","text":"Learning from Bing Search UFO provides the capability to reinforce the AppAgent by searching for information on Bing to obtain up-to-date knowledge for niche tasks or applications which beyond the AppAgent 's knowledge. Mechanism Upon receiving a request, the AppAgent constructs a Bing search query based on the request and retrieves the search results from Bing. The AppAgent then extracts the relevant information from the top-k search results from Bing and generates a plan based on the retrieved information. Activate the Learning from Bing Search Step 1: Obtain Bing API Key To use the Bing search, you need to obtain a Bing API key. You can follow the instructions on the Microsoft Azure Bing Search API to get the API key. Step 2: Configure the AppAgent Configure the following parameters to allow UFO to use online Bing search for the decision-making process: Configuration Option Description Type Default Value RAG_ONLINE_SEARCH Whether to use the Bing search Boolean False BING_API_KEY The Bing search API key String \"\" RAG_ONLINE_SEARCH_TOPK The topk for the online search Integer 5 RAG_ONLINE_RETRIEVED_TOPK The topk for the online retrieved searched results Integer 1 Reference Bases: Retriever Class to create online retrievers. Create a new OfflineDocRetriever. :query: The query to create an indexer for. :top_k: The number of documents to retrieve. Source code in rag/retriever.py 173 174 175 176 177 178 179 180 def __init__ ( self , query : str , top_k : int ) -> None : \"\"\" Create a new OfflineDocRetriever. :query: The query to create an indexer for. :top_k: The number of documents to retrieve. \"\"\" self . query = query self . indexer = self . get_indexer ( top_k ) get_indexer ( top_k ) Create an online search indexer. Parameters: top_k ( int ) \u2013 The number of documents to retrieve. Returns: \u2013 The created indexer. Source code in rag/retriever.py 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def get_indexer ( self , top_k : int ): \"\"\" Create an online search indexer. :param top_k: The number of documents to retrieve. :return: The created indexer. \"\"\" bing_retriever = web_search . BingSearchWeb () result_list = bing_retriever . search ( self . query , top_k = top_k ) documents = bing_retriever . create_documents ( result_list ) if len ( documents ) == 0 : return None try : indexer = bing_retriever . create_indexer ( documents ) print_with_color ( \"Online indexer created successfully for {num} searched results.\" . format ( num = len ( documents ) ), \"cyan\" , ) except Exception as e : print_with_color ( \"Warning: Failed to create online indexer, error: {error} .\" . format ( error = e ), \"yellow\" , ) return None return indexer","title":"Learning from Bing Search"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/#learning-from-bing-search","text":"UFO provides the capability to reinforce the AppAgent by searching for information on Bing to obtain up-to-date knowledge for niche tasks or applications which beyond the AppAgent 's knowledge.","title":"Learning from Bing Search"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/#mechanism","text":"Upon receiving a request, the AppAgent constructs a Bing search query based on the request and retrieves the search results from Bing. The AppAgent then extracts the relevant information from the top-k search results from Bing and generates a plan based on the retrieved information.","title":"Mechanism"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/#activate-the-learning-from-bing-search","text":"","title":"Activate the Learning from Bing Search"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/#step-1-obtain-bing-api-key","text":"To use the Bing search, you need to obtain a Bing API key. You can follow the instructions on the Microsoft Azure Bing Search API to get the API key.","title":"Step 1: Obtain Bing API Key"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/#step-2-configure-the-appagent","text":"Configure the following parameters to allow UFO to use online Bing search for the decision-making process: Configuration Option Description Type Default Value RAG_ONLINE_SEARCH Whether to use the Bing search Boolean False BING_API_KEY The Bing search API key String \"\" RAG_ONLINE_SEARCH_TOPK The topk for the online search Integer 5 RAG_ONLINE_RETRIEVED_TOPK The topk for the online retrieved searched results Integer 1","title":"Step 2: Configure the AppAgent"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/#reference","text":"Bases: Retriever Class to create online retrievers. Create a new OfflineDocRetriever. :query: The query to create an indexer for. :top_k: The number of documents to retrieve. Source code in rag/retriever.py 173 174 175 176 177 178 179 180 def __init__ ( self , query : str , top_k : int ) -> None : \"\"\" Create a new OfflineDocRetriever. :query: The query to create an indexer for. :top_k: The number of documents to retrieve. \"\"\" self . query = query self . indexer = self . get_indexer ( top_k )","title":"Reference"},{"location":"advanced_usage/reinforce_appagent/learning_from_bing_search/#rag.retriever.OnlineDocRetriever.get_indexer","text":"Create an online search indexer. Parameters: top_k ( int ) \u2013 The number of documents to retrieve. Returns: \u2013 The created indexer. Source code in rag/retriever.py 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def get_indexer ( self , top_k : int ): \"\"\" Create an online search indexer. :param top_k: The number of documents to retrieve. :return: The created indexer. \"\"\" bing_retriever = web_search . BingSearchWeb () result_list = bing_retriever . search ( self . query , top_k = top_k ) documents = bing_retriever . create_documents ( result_list ) if len ( documents ) == 0 : return None try : indexer = bing_retriever . create_indexer ( documents ) print_with_color ( \"Online indexer created successfully for {num} searched results.\" . format ( num = len ( documents ) ), \"cyan\" , ) except Exception as e : print_with_color ( \"Warning: Failed to create online indexer, error: {error} .\" . format ( error = e ), \"yellow\" , ) return None return indexer","title":"get_indexer"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/","text":"Here is the polished document for your Python code project: Learning from User Demonstration For complex tasks, users can demonstrate the task using Step Recorder to record the action trajectories. UFO can learn from these user demonstrations to improve the AppAgent's performance. Mechanism UFO use the Step Recorder tool to record the task and action trajectories. The recorded demonstration is saved as a zip file. The DemonstrationSummarizer class extracts and summarizes the demonstration. The summarized demonstration is saved in the DEMONSTRATION_SAVED_PATH as specified in the config_dev.yaml file. When the AppAgent encounters a similar task, the DemonstrationRetriever class retrieves the saved demonstration from the demonstration database and generates a plan based on the retrieved demonstration. Info You can find how to record the task and action trajectories using the Step Recorder tool in the User Demonstration Provision document. You can find a demo video of learning from user demonstrations: Activating Learning from User Demonstrations Step 1: User Demonstration Please follow the steps in the User Demonstration Provision document to provide user demonstrations. Step 2: Configure the AppAgent Configure the following parameters to allow UFO to use RAG from user demonstrations: Configuration Option Description Type Default Value RAG_DEMONSTRATION Whether to use RAG from user demonstrations Boolean False RAG_DEMONSTRATION_RETRIEVED_TOPK The top K documents to retrieve offline Integer 5 RAG_DEMONSTRATION_COMPLETION_N The number of completion choices for the demonstration result Integer 3 Reference Demonstration Summarizer The DemonstrationSummarizer class is located in the record_processor/summarizer/summarizer.py file. The DemonstrationSummarizer class provides methods to summarize the demonstration: The DemonstrationSummarizer class is the summarizer for the demonstration learning. It summarizes the demonstration record to a list of summaries, and save the summaries to the YAML file and the vector database. A sample of the summary is as follows: { \"example\": { \"Observation\": \"Word.exe is opened.\", \"Thought\": \"The user is trying to create a new file.\", \"ControlLabel\": \"1\", \"ControlText\": \"Sample Control Text\", \"Function\": \"CreateFile\", \"Args\": \"filename='new_file.txt'\", \"Status\": \"Success\", \"Plan\": \"Create a new file named 'new_file.txt'.\", \"Comment\": \"The user successfully created a new file.\" }, \"Tips\": \"You can use the 'CreateFile' function to create a new file.\" } Initialize the DemonstrationSummarizer. Parameters: is_visual ( bool ) \u2013 Whether the request is for visual model. prompt_template ( str ) \u2013 The path of the prompt template. demonstration_prompt_template ( str ) \u2013 The path of the example prompt template for demonstration. api_prompt_template ( str ) \u2013 The path of the api prompt template. Source code in summarizer/summarizer.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def __init__ ( self , is_visual : bool , prompt_template : str , demonstration_prompt_template : str , api_prompt_template : str , completion_num : int = 1 , ): \"\"\" Initialize the DemonstrationSummarizer. :param is_visual: Whether the request is for visual model. :param prompt_template: The path of the prompt template. :param demonstration_prompt_template: The path of the example prompt template for demonstration. :param api_prompt_template: The path of the api prompt template. \"\"\" self . is_visual = is_visual self . prompt_template = prompt_template self . demonstration_prompt_template = demonstration_prompt_template self . api_prompt_template = api_prompt_template self . completion_num = completion_num __build_prompt ( demo_record ) Build the prompt by the user demonstration record. Parameters: demo_record ( DemonstrationRecord ) \u2013 The user demonstration record. return: The prompt. Source code in summarizer/summarizer.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def __build_prompt ( self , demo_record : DemonstrationRecord ) -> list : \"\"\" Build the prompt by the user demonstration record. :param demo_record: The user demonstration record. return: The prompt. \"\"\" demonstration_prompter = DemonstrationPrompter ( self . is_visual , self . prompt_template , self . demonstration_prompt_template , self . api_prompt_template , ) demonstration_system_prompt = ( demonstration_prompter . system_prompt_construction () ) demonstration_user_prompt = demonstration_prompter . user_content_construction ( demo_record ) demonstration_prompt = demonstration_prompter . prompt_construction ( demonstration_system_prompt , demonstration_user_prompt ) return demonstration_prompt __parse_response ( response_string ) Parse the response string to a dict of summary. Parameters: response_string ( str ) \u2013 The response string. return: The summary dict. Source code in summarizer/summarizer.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def __parse_response ( self , response_string : str ) -> dict : \"\"\" Parse the response string to a dict of summary. :param response_string: The response string. return: The summary dict. \"\"\" try : response_json = json_parser ( response_string ) except : response_json = None # Restructure the response, in case any of the keys are missing, set them to empty string. if response_json : summary = dict () summary [ \"example\" ] = {} for key in [ \"Observation\" , \"Thought\" , \"ControlLabel\" , \"ControlText\" , \"Function\" , \"Args\" , \"Status\" , \"Plan\" , \"Comment\" , ]: summary [ \"example\" ][ key ] = response_json . get ( key , \"\" ) summary [ \"Tips\" ] = response_json . get ( \"Tips\" , \"\" ) return summary create_or_update_vector_db ( summaries , db_path ) staticmethod Create or update the vector database. Parameters: summaries ( list ) \u2013 The summaries. db_path ( str ) \u2013 The path of the vector database. Source code in summarizer/summarizer.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 @staticmethod def create_or_update_vector_db ( summaries : list , db_path : str ): \"\"\" Create or update the vector database. :param summaries: The summaries. :param db_path: The path of the vector database. \"\"\" document_list = [] for summary in summaries : request = summary [ \"request\" ] document_list . append ( Document ( page_content = request , metadata = summary )) db = FAISS . from_documents ( document_list , get_hugginface_embedding ()) # Check if the db exists, if not, create a new one. if os . path . exists ( db_path ): prev_db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) db . merge_from ( prev_db ) db . save_local ( db_path ) print ( f \"Updated vector DB successfully: { db_path } \" ) create_or_update_yaml ( summaries , yaml_path ) staticmethod Create or update the YAML file. Parameters: summaries ( list ) \u2013 The summaries. yaml_path ( str ) \u2013 The path of the YAML file. Source code in summarizer/summarizer.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @staticmethod def create_or_update_yaml ( summaries : list , yaml_path : str ): \"\"\" Create or update the YAML file. :param summaries: The summaries. :param yaml_path: The path of the YAML file. \"\"\" # Check if the file exists, if not, create a new one if not os . path . exists ( yaml_path ): with open ( yaml_path , \"w\" ): pass print ( f \"Created new YAML file: { yaml_path } \" ) # Read existing data from the YAML file with open ( yaml_path , \"r\" ) as file : existing_data = yaml . safe_load ( file ) # Initialize index and existing_data if file is empty index = len ( existing_data ) if existing_data else 0 existing_data = existing_data or {} # Update data with new summaries for i , summary in enumerate ( summaries ): example = { f \"example { index + i } \" : summary } existing_data . update ( example ) # Write updated data back to the YAML file with open ( yaml_path , \"w\" ) as file : yaml . safe_dump ( existing_data , file , default_flow_style = False , sort_keys = False ) print ( f \"Updated existing YAML file successfully: { yaml_path } \" ) get_summary_list ( record ) Get the summary list for a record Parameters: record ( DemonstrationRecord ) \u2013 The demonstration record. return: The summary list for the user defined completion number and the cost Source code in summarizer/summarizer.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_summary_list ( self , record : DemonstrationRecord ) -> Tuple [ list , float ]: \"\"\" Get the summary list for a record :param record: The demonstration record. return: The summary list for the user defined completion number and the cost \"\"\" prompt = self . __build_prompt ( record ) response_string_list , cost = get_completions ( prompt , \"APPAGENT\" , use_backup_engine = True , n = self . completion_num ) summaries = [] for response_string in response_string_list : summary = self . __parse_response ( response_string ) if summary : summary [ \"request\" ] = record . get_request () summary [ \"app_list\" ] = record . get_applications () summaries . append ( summary ) return summaries , cost Demonstration Retriever The DemonstrationRetriever class is located in the rag/retriever.py file. The DemonstrationRetriever class provides methods to retrieve the demonstration: Bases: Retriever Class to create demonstration retrievers. Create a new DemonstrationRetriever. :db_path: The path to the database. Source code in rag/retriever.py 219 220 221 222 223 224 def __init__ ( self , db_path ) -> None : \"\"\" Create a new DemonstrationRetriever. :db_path: The path to the database. \"\"\" self . indexer = self . get_indexer ( db_path ) get_indexer ( db_path ) Create a demonstration indexer. :db_path: The path to the database. Source code in rag/retriever.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def get_indexer ( self , db_path : str ): \"\"\" Create a demonstration indexer. :db_path: The path to the database. \"\"\" try : db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) return db except Exception as e : print_with_color ( \"Warning: Failed to load experience indexer from {path} , error: {error} .\" . format ( path = db_path , error = e ), \"yellow\" , ) return None","title":"Learning from User Demonstration"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#learning-from-user-demonstration","text":"For complex tasks, users can demonstrate the task using Step Recorder to record the action trajectories. UFO can learn from these user demonstrations to improve the AppAgent's performance.","title":"Learning from User Demonstration"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#mechanism","text":"UFO use the Step Recorder tool to record the task and action trajectories. The recorded demonstration is saved as a zip file. The DemonstrationSummarizer class extracts and summarizes the demonstration. The summarized demonstration is saved in the DEMONSTRATION_SAVED_PATH as specified in the config_dev.yaml file. When the AppAgent encounters a similar task, the DemonstrationRetriever class retrieves the saved demonstration from the demonstration database and generates a plan based on the retrieved demonstration. Info You can find how to record the task and action trajectories using the Step Recorder tool in the User Demonstration Provision document. You can find a demo video of learning from user demonstrations:","title":"Mechanism"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#activating-learning-from-user-demonstrations","text":"","title":"Activating Learning from User Demonstrations"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#step-1-user-demonstration","text":"Please follow the steps in the User Demonstration Provision document to provide user demonstrations.","title":"Step 1: User Demonstration"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#step-2-configure-the-appagent","text":"Configure the following parameters to allow UFO to use RAG from user demonstrations: Configuration Option Description Type Default Value RAG_DEMONSTRATION Whether to use RAG from user demonstrations Boolean False RAG_DEMONSTRATION_RETRIEVED_TOPK The top K documents to retrieve offline Integer 5 RAG_DEMONSTRATION_COMPLETION_N The number of completion choices for the demonstration result Integer 3","title":"Step 2: Configure the AppAgent"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#reference","text":"","title":"Reference"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#demonstration-summarizer","text":"The DemonstrationSummarizer class is located in the record_processor/summarizer/summarizer.py file. The DemonstrationSummarizer class provides methods to summarize the demonstration: The DemonstrationSummarizer class is the summarizer for the demonstration learning. It summarizes the demonstration record to a list of summaries, and save the summaries to the YAML file and the vector database. A sample of the summary is as follows: { \"example\": { \"Observation\": \"Word.exe is opened.\", \"Thought\": \"The user is trying to create a new file.\", \"ControlLabel\": \"1\", \"ControlText\": \"Sample Control Text\", \"Function\": \"CreateFile\", \"Args\": \"filename='new_file.txt'\", \"Status\": \"Success\", \"Plan\": \"Create a new file named 'new_file.txt'.\", \"Comment\": \"The user successfully created a new file.\" }, \"Tips\": \"You can use the 'CreateFile' function to create a new file.\" } Initialize the DemonstrationSummarizer. Parameters: is_visual ( bool ) \u2013 Whether the request is for visual model. prompt_template ( str ) \u2013 The path of the prompt template. demonstration_prompt_template ( str ) \u2013 The path of the example prompt template for demonstration. api_prompt_template ( str ) \u2013 The path of the api prompt template. Source code in summarizer/summarizer.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def __init__ ( self , is_visual : bool , prompt_template : str , demonstration_prompt_template : str , api_prompt_template : str , completion_num : int = 1 , ): \"\"\" Initialize the DemonstrationSummarizer. :param is_visual: Whether the request is for visual model. :param prompt_template: The path of the prompt template. :param demonstration_prompt_template: The path of the example prompt template for demonstration. :param api_prompt_template: The path of the api prompt template. \"\"\" self . is_visual = is_visual self . prompt_template = prompt_template self . demonstration_prompt_template = demonstration_prompt_template self . api_prompt_template = api_prompt_template self . completion_num = completion_num","title":"Demonstration Summarizer"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#summarizer.summarizer.DemonstrationSummarizer.__build_prompt","text":"Build the prompt by the user demonstration record. Parameters: demo_record ( DemonstrationRecord ) \u2013 The user demonstration record. return: The prompt. Source code in summarizer/summarizer.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def __build_prompt ( self , demo_record : DemonstrationRecord ) -> list : \"\"\" Build the prompt by the user demonstration record. :param demo_record: The user demonstration record. return: The prompt. \"\"\" demonstration_prompter = DemonstrationPrompter ( self . is_visual , self . prompt_template , self . demonstration_prompt_template , self . api_prompt_template , ) demonstration_system_prompt = ( demonstration_prompter . system_prompt_construction () ) demonstration_user_prompt = demonstration_prompter . user_content_construction ( demo_record ) demonstration_prompt = demonstration_prompter . prompt_construction ( demonstration_system_prompt , demonstration_user_prompt ) return demonstration_prompt","title":"__build_prompt"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#summarizer.summarizer.DemonstrationSummarizer.__parse_response","text":"Parse the response string to a dict of summary. Parameters: response_string ( str ) \u2013 The response string. return: The summary dict. Source code in summarizer/summarizer.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def __parse_response ( self , response_string : str ) -> dict : \"\"\" Parse the response string to a dict of summary. :param response_string: The response string. return: The summary dict. \"\"\" try : response_json = json_parser ( response_string ) except : response_json = None # Restructure the response, in case any of the keys are missing, set them to empty string. if response_json : summary = dict () summary [ \"example\" ] = {} for key in [ \"Observation\" , \"Thought\" , \"ControlLabel\" , \"ControlText\" , \"Function\" , \"Args\" , \"Status\" , \"Plan\" , \"Comment\" , ]: summary [ \"example\" ][ key ] = response_json . get ( key , \"\" ) summary [ \"Tips\" ] = response_json . get ( \"Tips\" , \"\" ) return summary","title":"__parse_response"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#summarizer.summarizer.DemonstrationSummarizer.create_or_update_vector_db","text":"Create or update the vector database. Parameters: summaries ( list ) \u2013 The summaries. db_path ( str ) \u2013 The path of the vector database. Source code in summarizer/summarizer.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 @staticmethod def create_or_update_vector_db ( summaries : list , db_path : str ): \"\"\" Create or update the vector database. :param summaries: The summaries. :param db_path: The path of the vector database. \"\"\" document_list = [] for summary in summaries : request = summary [ \"request\" ] document_list . append ( Document ( page_content = request , metadata = summary )) db = FAISS . from_documents ( document_list , get_hugginface_embedding ()) # Check if the db exists, if not, create a new one. if os . path . exists ( db_path ): prev_db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) db . merge_from ( prev_db ) db . save_local ( db_path ) print ( f \"Updated vector DB successfully: { db_path } \" )","title":"create_or_update_vector_db"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#summarizer.summarizer.DemonstrationSummarizer.create_or_update_yaml","text":"Create or update the YAML file. Parameters: summaries ( list ) \u2013 The summaries. yaml_path ( str ) \u2013 The path of the YAML file. Source code in summarizer/summarizer.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @staticmethod def create_or_update_yaml ( summaries : list , yaml_path : str ): \"\"\" Create or update the YAML file. :param summaries: The summaries. :param yaml_path: The path of the YAML file. \"\"\" # Check if the file exists, if not, create a new one if not os . path . exists ( yaml_path ): with open ( yaml_path , \"w\" ): pass print ( f \"Created new YAML file: { yaml_path } \" ) # Read existing data from the YAML file with open ( yaml_path , \"r\" ) as file : existing_data = yaml . safe_load ( file ) # Initialize index and existing_data if file is empty index = len ( existing_data ) if existing_data else 0 existing_data = existing_data or {} # Update data with new summaries for i , summary in enumerate ( summaries ): example = { f \"example { index + i } \" : summary } existing_data . update ( example ) # Write updated data back to the YAML file with open ( yaml_path , \"w\" ) as file : yaml . safe_dump ( existing_data , file , default_flow_style = False , sort_keys = False ) print ( f \"Updated existing YAML file successfully: { yaml_path } \" )","title":"create_or_update_yaml"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#summarizer.summarizer.DemonstrationSummarizer.get_summary_list","text":"Get the summary list for a record Parameters: record ( DemonstrationRecord ) \u2013 The demonstration record. return: The summary list for the user defined completion number and the cost Source code in summarizer/summarizer.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_summary_list ( self , record : DemonstrationRecord ) -> Tuple [ list , float ]: \"\"\" Get the summary list for a record :param record: The demonstration record. return: The summary list for the user defined completion number and the cost \"\"\" prompt = self . __build_prompt ( record ) response_string_list , cost = get_completions ( prompt , \"APPAGENT\" , use_backup_engine = True , n = self . completion_num ) summaries = [] for response_string in response_string_list : summary = self . __parse_response ( response_string ) if summary : summary [ \"request\" ] = record . get_request () summary [ \"app_list\" ] = record . get_applications () summaries . append ( summary ) return summaries , cost","title":"get_summary_list"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#demonstration-retriever","text":"The DemonstrationRetriever class is located in the rag/retriever.py file. The DemonstrationRetriever class provides methods to retrieve the demonstration: Bases: Retriever Class to create demonstration retrievers. Create a new DemonstrationRetriever. :db_path: The path to the database. Source code in rag/retriever.py 219 220 221 222 223 224 def __init__ ( self , db_path ) -> None : \"\"\" Create a new DemonstrationRetriever. :db_path: The path to the database. \"\"\" self . indexer = self . get_indexer ( db_path )","title":"Demonstration Retriever"},{"location":"advanced_usage/reinforce_appagent/learning_from_demonstration/#rag.retriever.DemonstrationRetriever.get_indexer","text":"Create a demonstration indexer. :db_path: The path to the database. Source code in rag/retriever.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def get_indexer ( self , db_path : str ): \"\"\" Create a demonstration indexer. :db_path: The path to the database. \"\"\" try : db = FAISS . load_local ( db_path , get_hugginface_embedding (), allow_dangerous_deserialization = True , ) return db except Exception as e : print_with_color ( \"Warning: Failed to load experience indexer from {path} , error: {error} .\" . format ( path = db_path , error = e ), \"yellow\" , ) return None","title":"get_indexer"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/","text":"Learning from Help Documents User or applications can provide help documents to the AppAgent to reinforce its capabilities. The AppAgent can retrieve knowledge from these documents to improve its understanding of the task, generate high-quality plans, and interact more efficiently with the application. You can find how to provide help documents to the AppAgent in the Help Document Provision section. Mechanism The help documents are provided in a format of task-solution pairs . Upon receiving a request, the AppAgent retrieves the relevant help documents by matching the request with the task descriptions in the help documents and generates a plan based on the retrieved solutions. Note Since the retrieved help documents may not be relevant to the request, the AppAgent will only take them as references to generate the plan. Activate the Learning from Help Documents Follow the steps below to activate the learning from help documents: Step 1: Provide Help Documents Please follow the steps in the Help Document Provision document to provide help documents to the AppAgent. Step 2: Configure the AppAgent Configure the following parameters in the config.yaml file to activate the learning from help documents: Configuration Option Description Type Default Value RAG_OFFLINE_DOCS Whether to use the offline RAG Boolean False RAG_OFFLINE_DOCS_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 1 Reference Bases: Retriever Class to create offline retrievers. Create a new OfflineDocRetriever. :appname: The name of the application. Source code in rag/retriever.py 83 84 85 86 87 88 89 90 def __init__ ( self , app_name : str ) -> None : \"\"\" Create a new OfflineDocRetriever. :appname: The name of the application. \"\"\" self . app_name = app_name indexer_path = self . get_offline_indexer_path () self . indexer = self . get_indexer ( indexer_path ) get_indexer ( path ) Load the retriever. Parameters: path ( str ) \u2013 The path to load the retriever from. Returns: \u2013 The loaded retriever. Source code in rag/retriever.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def get_indexer ( self , path : str ): \"\"\" Load the retriever. :param path: The path to load the retriever from. :return: The loaded retriever. \"\"\" if path : print_with_color ( \"Loading offline indexer from {path} ...\" . format ( path = path ), \"cyan\" ) else : return None try : db = FAISS . load_local ( path , get_hugginface_embedding (), allow_dangerous_deserialization = True ) return db except Exception as e : print_with_color ( \"Warning: Failed to load experience indexer from {path} , error: {error} .\" . format ( path = path , error = e ), \"yellow\" , ) return None get_offline_indexer_path () Get the path to the offline indexer. Returns: \u2013 The path to the offline indexer. Source code in rag/retriever.py 92 93 94 95 96 97 98 99 100 101 102 def get_offline_indexer_path ( self ): \"\"\" Get the path to the offline indexer. :return: The path to the offline indexer. \"\"\" offline_records = get_offline_learner_indexer_config () for key in offline_records : if key . lower () in self . app_name . lower (): return offline_records [ key ] return None","title":"Learning from Help Document"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#learning-from-help-documents","text":"User or applications can provide help documents to the AppAgent to reinforce its capabilities. The AppAgent can retrieve knowledge from these documents to improve its understanding of the task, generate high-quality plans, and interact more efficiently with the application. You can find how to provide help documents to the AppAgent in the Help Document Provision section.","title":"Learning from Help Documents"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#mechanism","text":"The help documents are provided in a format of task-solution pairs . Upon receiving a request, the AppAgent retrieves the relevant help documents by matching the request with the task descriptions in the help documents and generates a plan based on the retrieved solutions. Note Since the retrieved help documents may not be relevant to the request, the AppAgent will only take them as references to generate the plan.","title":"Mechanism"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#activate-the-learning-from-help-documents","text":"Follow the steps below to activate the learning from help documents:","title":"Activate the Learning from Help Documents"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#step-1-provide-help-documents","text":"Please follow the steps in the Help Document Provision document to provide help documents to the AppAgent.","title":"Step 1: Provide Help Documents"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#step-2-configure-the-appagent","text":"Configure the following parameters in the config.yaml file to activate the learning from help documents: Configuration Option Description Type Default Value RAG_OFFLINE_DOCS Whether to use the offline RAG Boolean False RAG_OFFLINE_DOCS_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 1","title":"Step 2: Configure the AppAgent"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#reference","text":"Bases: Retriever Class to create offline retrievers. Create a new OfflineDocRetriever. :appname: The name of the application. Source code in rag/retriever.py 83 84 85 86 87 88 89 90 def __init__ ( self , app_name : str ) -> None : \"\"\" Create a new OfflineDocRetriever. :appname: The name of the application. \"\"\" self . app_name = app_name indexer_path = self . get_offline_indexer_path () self . indexer = self . get_indexer ( indexer_path )","title":"Reference"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#rag.retriever.OfflineDocRetriever.get_indexer","text":"Load the retriever. Parameters: path ( str ) \u2013 The path to load the retriever from. Returns: \u2013 The loaded retriever. Source code in rag/retriever.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def get_indexer ( self , path : str ): \"\"\" Load the retriever. :param path: The path to load the retriever from. :return: The loaded retriever. \"\"\" if path : print_with_color ( \"Loading offline indexer from {path} ...\" . format ( path = path ), \"cyan\" ) else : return None try : db = FAISS . load_local ( path , get_hugginface_embedding (), allow_dangerous_deserialization = True ) return db except Exception as e : print_with_color ( \"Warning: Failed to load experience indexer from {path} , error: {error} .\" . format ( path = path , error = e ), \"yellow\" , ) return None","title":"get_indexer"},{"location":"advanced_usage/reinforce_appagent/learning_from_help_document/#rag.retriever.OfflineDocRetriever.get_offline_indexer_path","text":"Get the path to the offline indexer. Returns: \u2013 The path to the offline indexer. Source code in rag/retriever.py 92 93 94 95 96 97 98 99 100 101 102 def get_offline_indexer_path ( self ): \"\"\" Get the path to the offline indexer. :return: The path to the offline indexer. \"\"\" offline_records = get_offline_learner_indexer_config () for key in offline_records : if key . lower () in self . app_name . lower (): return offline_records [ key ] return None","title":"get_offline_indexer_path"},{"location":"advanced_usage/reinforce_appagent/overview/","text":"Reinforcing AppAgent UFO provides versatile mechanisms to reinforce the AppAgent's capabilities through RAG (Retrieval-Augmented Generation) and other techniques. These enhance the AppAgent's understanding of the task, improving the quality of the generated plans, and increasing the efficiency of the AppAgent's interactions with the application. We currently support the following reinforcement methods: Reinforcement Method Description Learning from Help Documents Reinforce the AppAgent by retrieving knowledge from help documents. Learning from Bing Search Reinforce the AppAgent by searching for information on Bing to obtain up-to-date knowledge. Learning from Self-Experience Reinforce the AppAgent by learning from its own successful experiences. Learning from User Demonstrations Reinforce the AppAgent by learning from action trajectories demonstrated by users. Knowledge Provision UFO provides the knowledge to the AppAgent through a context_provision method defined in the AppAgent class: def context_provision(self, request: str = \"\") -> None: \"\"\" Provision the context for the app agent. :param request: The Bing search query. \"\"\" # Load the offline document indexer for the app agent if available. if configs[\"RAG_OFFLINE_DOCS\"]: utils.print_with_color( \"Loading offline help document indexer for {app}...\".format( app=self._process_name ), \"magenta\", ) self.build_offline_docs_retriever() # Load the online search indexer for the app agent if available. if configs[\"RAG_ONLINE_SEARCH\"] and request: utils.print_with_color(\"Creating a Bing search indexer...\", \"magenta\") self.build_online_search_retriever( request, configs[\"RAG_ONLINE_SEARCH_TOPK\"] ) # Load the experience indexer for the app agent if available. if configs[\"RAG_EXPERIENCE\"]: utils.print_with_color(\"Creating an experience indexer...\", \"magenta\") experience_path = configs[\"EXPERIENCE_SAVED_PATH\"] db_path = os.path.join(experience_path, \"experience_db\") self.build_experience_retriever(db_path) # Load the demonstration indexer for the app agent if available. if configs[\"RAG_DEMONSTRATION\"]: utils.print_with_color(\"Creating an demonstration indexer...\", \"magenta\") demonstration_path = configs[\"DEMONSTRATION_SAVED_PATH\"] db_path = os.path.join(demonstration_path, \"demonstration_db\") self.build_human_demonstration_retriever(db_path) The context_provision method loads the offline document indexer, online search indexer, experience indexer, and demonstration indexer for the AppAgent based on the configuration settings in the config_dev.yaml file. Reference UFO employs the Retriever class located in the ufo/rag/retriever.py file to retrieve knowledge from various sources. The Retriever class provides the following methods to retrieve knowledge: Bases: ABC Class to retrieve documents. Create a new Retriever. Source code in rag/retriever.py 42 43 44 45 46 47 48 49 def __init__ ( self ) -> None : \"\"\" Create a new Retriever. \"\"\" self . indexer = self . get_indexer () pass get_indexer () abstractmethod Get the indexer. Returns: \u2013 The indexer. Source code in rag/retriever.py 51 52 53 54 55 56 57 @abstractmethod def get_indexer ( self ): \"\"\" Get the indexer. :return: The indexer. \"\"\" pass retrieve ( query , top_k , filter = None ) Retrieve the document from the given query. :filter: The filter to apply to the retrieved documents. Parameters: query ( str ) \u2013 The query to retrieve the document from. top_k ( int ) \u2013 The number of documents to retrieve. Returns: \u2013 The document from the given query. Source code in rag/retriever.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def retrieve ( self , query : str , top_k : int , filter = None ): \"\"\" Retrieve the document from the given query. :param query: The query to retrieve the document from. :param top_k: The number of documents to retrieve. :filter: The filter to apply to the retrieved documents. :return: The document from the given query. \"\"\" if not self . indexer : return [] results = self . indexer . similarity_search ( query , top_k , filter = filter ) if not results : return [] else : return results","title":"Overview"},{"location":"advanced_usage/reinforce_appagent/overview/#reinforcing-appagent","text":"UFO provides versatile mechanisms to reinforce the AppAgent's capabilities through RAG (Retrieval-Augmented Generation) and other techniques. These enhance the AppAgent's understanding of the task, improving the quality of the generated plans, and increasing the efficiency of the AppAgent's interactions with the application. We currently support the following reinforcement methods: Reinforcement Method Description Learning from Help Documents Reinforce the AppAgent by retrieving knowledge from help documents. Learning from Bing Search Reinforce the AppAgent by searching for information on Bing to obtain up-to-date knowledge. Learning from Self-Experience Reinforce the AppAgent by learning from its own successful experiences. Learning from User Demonstrations Reinforce the AppAgent by learning from action trajectories demonstrated by users.","title":"Reinforcing AppAgent"},{"location":"advanced_usage/reinforce_appagent/overview/#knowledge-provision","text":"UFO provides the knowledge to the AppAgent through a context_provision method defined in the AppAgent class: def context_provision(self, request: str = \"\") -> None: \"\"\" Provision the context for the app agent. :param request: The Bing search query. \"\"\" # Load the offline document indexer for the app agent if available. if configs[\"RAG_OFFLINE_DOCS\"]: utils.print_with_color( \"Loading offline help document indexer for {app}...\".format( app=self._process_name ), \"magenta\", ) self.build_offline_docs_retriever() # Load the online search indexer for the app agent if available. if configs[\"RAG_ONLINE_SEARCH\"] and request: utils.print_with_color(\"Creating a Bing search indexer...\", \"magenta\") self.build_online_search_retriever( request, configs[\"RAG_ONLINE_SEARCH_TOPK\"] ) # Load the experience indexer for the app agent if available. if configs[\"RAG_EXPERIENCE\"]: utils.print_with_color(\"Creating an experience indexer...\", \"magenta\") experience_path = configs[\"EXPERIENCE_SAVED_PATH\"] db_path = os.path.join(experience_path, \"experience_db\") self.build_experience_retriever(db_path) # Load the demonstration indexer for the app agent if available. if configs[\"RAG_DEMONSTRATION\"]: utils.print_with_color(\"Creating an demonstration indexer...\", \"magenta\") demonstration_path = configs[\"DEMONSTRATION_SAVED_PATH\"] db_path = os.path.join(demonstration_path, \"demonstration_db\") self.build_human_demonstration_retriever(db_path) The context_provision method loads the offline document indexer, online search indexer, experience indexer, and demonstration indexer for the AppAgent based on the configuration settings in the config_dev.yaml file.","title":"Knowledge Provision"},{"location":"advanced_usage/reinforce_appagent/overview/#reference","text":"UFO employs the Retriever class located in the ufo/rag/retriever.py file to retrieve knowledge from various sources. The Retriever class provides the following methods to retrieve knowledge: Bases: ABC Class to retrieve documents. Create a new Retriever. Source code in rag/retriever.py 42 43 44 45 46 47 48 49 def __init__ ( self ) -> None : \"\"\" Create a new Retriever. \"\"\" self . indexer = self . get_indexer () pass","title":"Reference"},{"location":"advanced_usage/reinforce_appagent/overview/#rag.retriever.Retriever.get_indexer","text":"Get the indexer. Returns: \u2013 The indexer. Source code in rag/retriever.py 51 52 53 54 55 56 57 @abstractmethod def get_indexer ( self ): \"\"\" Get the indexer. :return: The indexer. \"\"\" pass","title":"get_indexer"},{"location":"advanced_usage/reinforce_appagent/overview/#rag.retriever.Retriever.retrieve","text":"Retrieve the document from the given query. :filter: The filter to apply to the retrieved documents. Parameters: query ( str ) \u2013 The query to retrieve the document from. top_k ( int ) \u2013 The number of documents to retrieve. Returns: \u2013 The document from the given query. Source code in rag/retriever.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def retrieve ( self , query : str , top_k : int , filter = None ): \"\"\" Retrieve the document from the given query. :param query: The query to retrieve the document from. :param top_k: The number of documents to retrieve. :filter: The filter to apply to the retrieved documents. :return: The document from the given query. \"\"\" if not self . indexer : return [] results = self . indexer . similarity_search ( query , top_k , filter = filter ) if not results : return [] else : return results","title":"retrieve"},{"location":"agents/app_agent/","text":"AppAgent \ud83d\udc7e An AppAgent is responsible for iteratively executing actions on the selected applications until the task is successfully concluded within a specific application. The AppAgent is created by the HostAgent to fulfill a sub-task within a Round . The AppAgent is responsible for executing the necessary actions within the application to fulfill the user's request. The AppAgent has the following features: ReAct with the Application - The AppAgent recursively interacts with the application in a workflow of observation->thought->action, leveraging the multi-modal capabilities of Visual Language Models (VLMs) to comprehend the application UI and fulfill the user's request. Comprehension Enhancement - The AppAgent is enhanced by Retrieval Augmented Generation (RAG) from heterogeneous sources, including external knowledge bases, and demonstration libraries, making the agent an application \"expert\". Versatile Skill Set - The AppAgent is equipped with a diverse set of skills to support comprehensive automation, such as mouse, keyboard, native APIs, and \"Copilot\". Tip You can find the how to enhance the AppAgent with external knowledge bases and demonstration libraries in the Reinforcing AppAgent documentation. We show the framework of the AppAgent in the following diagram: AppAgent Input To interact with the application, the AppAgent receives the following inputs: Input Description Type User Request The user's request in natural language. String Sub-Task The sub-task description to be executed by the AppAgent , assigned by the HostAgent . String Current Application The name of the application to be interacted with. String Control Information Index, name and control type of available controls in the application. List of Dictionaries Application Screenshots Screenshots of the application, including a clean screenshot, an annotated screenshot with labeled controls, and a screenshot with a rectangle around the selected control at the previous step (optional). List of Strings Previous Sub-Tasks The previous sub-tasks and their completion status. List of Strings Previous Plan The previous plan for the following steps. List of Strings HostAgent Message The message from the HostAgent for the completion of the sub-task. String Retrived Information The retrieved information from external knowledge bases or demonstration libraries. String Blackboard The shared memory space for storing and sharing information among the agents. Dictionary Below is an example of the annotated application screenshot with labeled controls. This follow the Set-of-Mark paradigm. By processing these inputs, the AppAgent determines the necessary actions to fulfill the user's request within the application. Tip Whether to concatenate the clean screenshot and annotated screenshot can be configured in the CONCAT_SCREENSHOT field in the config_dev.yaml file. Tip Whether to include the screenshot with a rectangle around the selected control at the previous step can be configured in the INCLUDE_LAST_SCREENSHOT field in the config_dev.yaml file. AppAgent Output With the inputs provided, the AppAgent generates the following outputs: Output Description Type Observation The observation of the current application screenshots. String Thought The logical reasoning process of the AppAgent . String ControlLabel The index of the selected control to interact with. String ControlText The name of the selected control to interact with. String Function The function to be executed on the selected control. String Args The arguments required for the function execution. List of Strings Status The status of the agent, mapped to the AgentState . String Plan The plan for the following steps after the current action. List of Strings Comment Additional comments or information provided to the user. String SaveScreenshot The flag to save the screenshot of the application to the blackboard for future reference. Boolean Below is an example of the AppAgent output: { \"Observation\": \"Application screenshot\", \"Thought\": \"Logical reasoning process\", \"ControlLabel\": \"Control index\", \"ControlText\": \"Control name\", \"Function\": \"Function name\", \"Args\": [\"arg1\", \"arg2\"], \"Status\": \"AgentState\", \"Plan\": [\"Step 1\", \"Step 2\"], \"Comment\": \"Additional comments\", \"SaveScreenshot\": true } Info The AppAgent output is formatted as a JSON object by LLMs and can be parsed by the json.loads method in Python. AppAgent State The AppAgent state is managed by a state machine that determines the next action to be executed based on the current state, as defined in the ufo/agents/states/app_agent_states.py module. The states include: State Description CONTINUE Main execution loop; evaluates which subtasks are ready to launch or resume. ASSIGN Selects an available application process and spawns the corresponding AppAgent . PENDING Waits for user input to resolve ambiguity or gather additional task parameters. FINISH All subtasks complete; cleans up agent instances and finalizes session state. FAIL Enters recovery or abort mode upon irrecoverable failure. The state machine diagram for the AppAgent is shown below: The AppAgent progresses through these states to execute the necessary actions within the application and fulfill the sub-task assigned by the HostAgent . Knowledge Enhancement The AppAgent is enhanced by Retrieval Augmented Generation (RAG) from heterogeneous sources, including external knowledge bases and demonstration libraries. The AppAgent leverages this knowledge to enhance its comprehension of the application and learn from demonstrations to improve its performance. Learning from Help Documents User can provide help documents to the AppAgent to enhance its comprehension of the application and improve its performance in the config.yaml file. Tip Please find details configuration in the documentation . Tip You may also refer to the here for how to provide help documents to the AppAgent . In the AppAgent , it calls the build_offline_docs_retriever to build a help document retriever, and uses the retrived_documents_prompt_helper to contruct the prompt for the AppAgent . Learning from Bing Search Since help documents may not cover all the information or the information may be outdated, the AppAgent can also leverage Bing search to retrieve the latest information. You can activate Bing search and configure the search engine in the config.yaml file. Tip Please find details configuration in the documentation . Tip You may also refer to the here for the implementation of Bing search in the AppAgent . In the AppAgent , it calls the build_online_search_retriever to build a Bing search retriever, and uses the retrived_documents_prompt_helper to contruct the prompt for the AppAgent . Learning from Self-Demonstrations You may save successful action trajectories in the AppAgent to learn from self-demonstrations and improve its performance. After the completion of a session , the AppAgent will ask the user whether to save the action trajectories for future reference. You may configure the use of self-demonstrations in the config.yaml file. Tip You can find details of the configuration in the documentation . Tip You may also refer to the here for the implementation of self-demonstrations in the AppAgent . In the AppAgent , it calls the build_experience_retriever to build a self-demonstration retriever, and uses the rag_experience_retrieve to retrieve the demonstration for the AppAgent . Learning from Human Demonstrations In addition to self-demonstrations, you can also provide human demonstrations to the AppAgent to enhance its performance by using the Step Recorder tool built in the Windows OS. The AppAgent will learn from the human demonstrations to improve its performance and achieve better personalization. The use of human demonstrations can be configured in the config.yaml file. Tip You can find details of the configuration in the documentation . Tip You may also refer to the here for the implementation of human demonstrations in the AppAgent . In the AppAgent , it calls the build_human_demonstration_retriever to build a human demonstration retriever, and uses the rag_experience_retrieve to retrieve the demonstration for the AppAgent . Skill Set for Automation The AppAgent is equipped with a versatile skill set to support comprehensive automation within the application by calling the create_puppeteer_interface method. The skills include: Skill Description UI Automation Mimicking user interactions with the application UI controls using the UI Automation and Win32 API. Native API Accessing the application's native API to execute specific functions and actions. In-App Agent Leveraging the in-app agent to interact with the application's internal functions and features. By utilizing these skills, the AppAgent can efficiently interact with the application and fulfill the user's request. You can find more details in the Automator documentation and the code in the ufo/automator module. Reference Bases: BasicAgent The AppAgent class that manages the interaction with the application. Initialize the AppAgent. :name: The name of the agent. Parameters: process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The root name of the app. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. skip_prompter ( bool , default: False ) \u2013 The flag indicating whether to skip the prompter initialization. mode ( str , default: 'normal' ) \u2013 The mode of the agent. Source code in agents/agent/app_agent.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def __init__ ( self , name : str , process_name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , skip_prompter : bool = False , mode : str = \"normal\" , ) -> None : \"\"\" Initialize the AppAgent. :name: The name of the agent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param skip_prompter: The flag indicating whether to skip the prompter initialization. :param mode: The mode of the agent. \"\"\" super () . __init__ ( name = name ) if not skip_prompter : self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_root_name ) self . _process_name = process_name self . _app_root_name = app_root_name self . offline_doc_retriever = None self . online_doc_retriever = None self . experience_retriever = None self . human_demonstration_retriever = None self . Puppeteer = self . create_puppeteer_interface () self . _mode = mode control_detection_backend = configs . get ( \"CONTROL_BACKEND\" , [ \"uia\" ]) if \"omniparser\" in control_detection_backend : omniparser_endpoint = configs . get ( \"OMNIPARSER\" , {}) . get ( \"ENDPOINT\" , \"\" ) omniparser_service = OmniParser ( endpoint = omniparser_endpoint ) self . grounding_service : Optional [ BasicGrounding ] = OmniparserGrounding ( service = omniparser_service ) else : self . grounding_service : Optional [ BasicGrounding ] = None self . set_state ( self . default_state ) default_state property Get the default state. mode property Get the mode of the session. status_manager property Get the status manager. build_experience_retriever ( db_path ) Build the experience retriever. Parameters: db_path ( str ) \u2013 The path to the experience database. Returns: None \u2013 The experience retriever. Source code in agents/agent/app_agent.py 448 449 450 451 452 453 454 455 456 def build_experience_retriever ( self , db_path : str ) -> None : \"\"\" Build the experience retriever. :param db_path: The path to the experience database. :return: The experience retriever. \"\"\" self . experience_retriever = self . retriever_factory . create_retriever ( \"experience\" , db_path ) build_human_demonstration_retriever ( db_path ) Build the human demonstration retriever. Parameters: db_path ( str ) \u2013 The path to the human demonstration database. Returns: None \u2013 The human demonstration retriever. Source code in agents/agent/app_agent.py 458 459 460 461 462 463 464 465 466 def build_human_demonstration_retriever ( self , db_path : str ) -> None : \"\"\" Build the human demonstration retriever. :param db_path: The path to the human demonstration database. :return: The human demonstration retriever. \"\"\" self . human_demonstration_retriever = self . retriever_factory . create_retriever ( \"demonstration\" , db_path ) build_offline_docs_retriever () Build the offline docs retriever. Source code in agents/agent/app_agent.py 430 431 432 433 434 435 436 def build_offline_docs_retriever ( self ) -> None : \"\"\" Build the offline docs retriever. \"\"\" self . offline_doc_retriever = self . retriever_factory . create_retriever ( \"offline\" , self . _app_root_name ) build_online_search_retriever ( request , top_k ) Build the online search retriever. Parameters: request ( str ) \u2013 The request for online Bing search. top_k ( int ) \u2013 The number of documents to retrieve. Source code in agents/agent/app_agent.py 438 439 440 441 442 443 444 445 446 def build_online_search_retriever ( self , request : str , top_k : int ) -> None : \"\"\" Build the online search retriever. :param request: The request for online Bing search. :param top_k: The number of documents to retrieve. \"\"\" self . online_doc_retriever = self . retriever_factory . create_retriever ( \"online\" , request , top_k ) context_provision ( request = '' ) Provision the context for the app agent. Parameters: request ( str , default: '' ) \u2013 The request sent to the Bing search retriever. Source code in agents/agent/app_agent.py 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 def context_provision ( self , request : str = \"\" ) -> None : \"\"\" Provision the context for the app agent. :param request: The request sent to the Bing search retriever. \"\"\" # Load the offline document indexer for the app agent if available. if configs [ \"RAG_OFFLINE_DOCS\" ]: utils . print_with_color ( \"Loading offline help document indexer for {app} ...\" . format ( app = self . _process_name ), \"magenta\" , ) self . build_offline_docs_retriever () # Load the online search indexer for the app agent if available. if configs [ \"RAG_ONLINE_SEARCH\" ] and request : utils . print_with_color ( \"Creating a Bing search indexer...\" , \"magenta\" ) self . build_online_search_retriever ( request , configs [ \"RAG_ONLINE_SEARCH_TOPK\" ] ) # Load the experience indexer for the app agent if available. if configs [ \"RAG_EXPERIENCE\" ]: utils . print_with_color ( \"Creating an experience indexer...\" , \"magenta\" ) experience_path = configs [ \"EXPERIENCE_SAVED_PATH\" ] db_path = os . path . join ( experience_path , \"experience_db\" ) self . build_experience_retriever ( db_path ) # Load the demonstration indexer for the app agent if available. if configs [ \"RAG_DEMONSTRATION\" ]: utils . print_with_color ( \"Creating an demonstration indexer...\" , \"magenta\" ) demonstration_path = configs [ \"DEMONSTRATION_SAVED_PATH\" ] db_path = os . path . join ( demonstration_path , \"demonstration_db\" ) self . build_human_demonstration_retriever ( db_path ) create_puppeteer_interface () Create the Puppeteer interface to automate the app. Returns: AppPuppeteer \u2013 The Puppeteer interface. Source code in agents/agent/app_agent.py 394 395 396 397 398 399 def create_puppeteer_interface ( self ) -> puppeteer . AppPuppeteer : \"\"\" Create the Puppeteer interface to automate the app. :return: The Puppeteer interface. \"\"\" return puppeteer . AppPuppeteer ( self . _process_name , self . _app_root_name ) demonstration_prompt_helper ( request ) Get the examples and tips for the AppAgent using the demonstration retriever. Parameters: request \u2013 The request for the AppAgent. Returns: Tuple [ List [ Dict [ str , Any ]]] \u2013 The examples and tips for the AppAgent. Source code in agents/agent/app_agent.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 def demonstration_prompt_helper ( self , request ) -> Tuple [ List [ Dict [ str , Any ]]]: \"\"\" Get the examples and tips for the AppAgent using the demonstration retriever. :param request: The request for the AppAgent. :return: The examples and tips for the AppAgent. \"\"\" # Get the examples and tips for the AppAgent using the experience and demonstration retrievers. if configs [ \"RAG_EXPERIENCE\" ]: experience_results = self . rag_experience_retrieve ( request , configs [ \"RAG_EXPERIENCE_RETRIEVED_TOPK\" ] ) else : experience_results = [] if configs [ \"RAG_DEMONSTRATION\" ]: demonstration_results = self . rag_demonstration_retrieve ( request , configs [ \"RAG_DEMONSTRATION_RETRIEVED_TOPK\" ] ) else : demonstration_results = [] return experience_results , demonstration_results external_knowledge_prompt_helper ( request , offline_top_k , online_top_k ) Retrieve the external knowledge and construct the prompt. Parameters: request ( str ) \u2013 The request. offline_top_k ( int ) \u2013 The number of offline documents to retrieve. online_top_k ( int ) \u2013 The number of online documents to retrieve. Returns: Tuple [ str , str ] \u2013 The prompt message for the external_knowledge. Source code in agents/agent/app_agent.py 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def external_knowledge_prompt_helper ( self , request : str , offline_top_k : int , online_top_k : int ) -> Tuple [ str , str ]: \"\"\" Retrieve the external knowledge and construct the prompt. :param request: The request. :param offline_top_k: The number of offline documents to retrieve. :param online_top_k: The number of online documents to retrieve. :return: The prompt message for the external_knowledge. \"\"\" # Retrieve offline documents and construct the prompt if self . offline_doc_retriever : offline_docs = self . offline_doc_retriever . retrieve ( request , offline_top_k , filter = None , ) format_string = \"[Similar Requests]: {question} \\n Step: {answer} \\n \" offline_docs_prompt = self . prompter . retrived_documents_prompt_helper ( \"[Help Documents]\" , \"\" , [ format_string . format ( question = doc . metadata . get ( \"title\" , \"\" ), answer = doc . metadata . get ( \"text\" , \"\" ), ) for doc in offline_docs ], ) else : offline_docs_prompt = \"\" # Retrieve online documents and construct the prompt if self . online_doc_retriever : online_search_docs = self . online_doc_retriever . retrieve ( request , online_top_k , filter = None ) online_docs_prompt = self . prompter . retrived_documents_prompt_helper ( \"Online Search Results\" , \"Search Result\" , [ doc . page_content for doc in online_search_docs ], ) else : online_docs_prompt = \"\" return offline_docs_prompt , online_docs_prompt get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_root_name ) Get the prompt for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. app_root_name ( str ) \u2013 The root name of the app. Returns: AppAgentPrompter \u2013 The prompter instance. Source code in agents/agent/app_agent.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , app_root_name : str , ) -> AppAgentPrompter : \"\"\" Get the prompt for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param app_root_name: The root name of the app. :return: The prompter instance. \"\"\" return AppAgentPrompter ( is_visual , main_prompt , example_prompt , api_prompt , app_root_name ) message_constructor ( dynamic_examples , dynamic_knowledge , image_list , control_info , prev_subtask , plan , request , subtask , current_application , host_message , blackboard_prompt , last_success_actions , include_last_screenshot ) Construct the prompt message for the AppAgent. Parameters: dynamic_examples ( str ) \u2013 The dynamic examples retrieved from the self-demonstration and human demonstration. dynamic_knowledge ( str ) \u2013 The dynamic knowledge retrieved from the external knowledge base. image_list ( List ) \u2013 The list of screenshot images. control_info ( str ) \u2013 The control information. plan ( List [ str ] ) \u2013 The plan list. request ( str ) \u2013 The overall user request. subtask ( str ) \u2013 The subtask for the current AppAgent to process. current_application ( str ) \u2013 The current application name. host_message ( List [ str ] ) \u2013 The message from the HostAgent. blackboard_prompt ( List [ Dict [ str , str ]] ) \u2013 The prompt message from the blackboard. last_success_actions ( List [ Dict [ str , Any ]] ) \u2013 The list of successful actions in the last step. include_last_screenshot ( bool ) \u2013 The flag indicating whether to include the last screenshot. Returns: List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]] \u2013 The prompt message. Source code in agents/agent/app_agent.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def message_constructor ( self , dynamic_examples : str , dynamic_knowledge : str , image_list : List , control_info : str , prev_subtask : List [ Dict [ str , str ]], plan : List [ str ], request : str , subtask : str , current_application : str , host_message : List [ str ], blackboard_prompt : List [ Dict [ str , str ]], last_success_actions : List [ Dict [ str , Any ]], include_last_screenshot : bool , ) -> List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]]: \"\"\" Construct the prompt message for the AppAgent. :param dynamic_examples: The dynamic examples retrieved from the self-demonstration and human demonstration. :param dynamic_knowledge: The dynamic knowledge retrieved from the external knowledge base. :param image_list: The list of screenshot images. :param control_info: The control information. :param plan: The plan list. :param request: The overall user request. :param subtask: The subtask for the current AppAgent to process. :param current_application: The current application name. :param host_message: The message from the HostAgent. :param blackboard_prompt: The prompt message from the blackboard. :param last_success_actions: The list of successful actions in the last step. :param include_last_screenshot: The flag indicating whether to include the last screenshot. :return: The prompt message. \"\"\" appagent_prompt_system_message = self . prompter . system_prompt_construction ( dynamic_examples ) appagent_prompt_user_message = self . prompter . user_content_construction ( image_list = image_list , control_item = control_info , prev_subtask = prev_subtask , prev_plan = plan , user_request = request , subtask = subtask , current_application = current_application , host_message = host_message , retrieved_docs = dynamic_knowledge , last_success_actions = last_success_actions , include_last_screenshot = include_last_screenshot , ) if blackboard_prompt : appagent_prompt_user_message = ( blackboard_prompt + appagent_prompt_user_message ) appagent_prompt_message = self . prompter . prompt_construction ( appagent_prompt_system_message , appagent_prompt_user_message ) return appagent_prompt_message print_response ( response_dict , print_action = True ) Print the response. Parameters: response_dict ( Dict [ str , Any ] ) \u2013 The response dictionary to print. print_action ( bool , default: True ) \u2013 The flag indicating whether to print the action. Source code in agents/agent/app_agent.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def print_response ( self , response_dict : Dict [ str , Any ], print_action : bool = True ) -> None : \"\"\" Print the response. :param response_dict: The response dictionary to print. :param print_action: The flag indicating whether to print the action. \"\"\" control_text = response_dict . get ( \"ControlText\" ) control_label = response_dict . get ( \"ControlLabel\" ) if not control_text and not control_label : control_text = \"[No control selected.]\" control_label = \"[No control label selected.]\" observation = response_dict . get ( \"Observation\" ) thought = response_dict . get ( \"Thought\" ) plan = response_dict . get ( \"Plan\" ) status = response_dict . get ( \"Status\" ) comment = response_dict . get ( \"Comment\" ) function_call = response_dict . get ( \"Function\" ) args = utils . revise_line_breaks ( response_dict . get ( \"Args\" )) # Generate the function call string action = self . Puppeteer . get_command_string ( function_call , args ) utils . print_with_color ( \"Observations\ud83d\udc40: {observation} \" . format ( observation = observation ), \"cyan\" ) utils . print_with_color ( \"Thoughts\ud83d\udca1: {thought} \" . format ( thought = thought ), \"green\" ) if print_action : utils . print_with_color ( \"Selected item\ud83d\udd79\ufe0f: {control_text} , Label: {label} \" . format ( control_text = control_text , label = control_label ), \"yellow\" , ) utils . print_with_color ( \"Action applied\u2692\ufe0f: {action} \" . format ( action = action ), \"blue\" ) utils . print_with_color ( \"Status\ud83d\udcca: {status} \" . format ( status = status ), \"blue\" ) utils . print_with_color ( \"Next Plan\ud83d\udcda: {plan} \" . format ( plan = \" \\n \" . join ( plan )), \"cyan\" ) utils . print_with_color ( \"Comment\ud83d\udcac: {comment} \" . format ( comment = comment ), \"green\" ) screenshot_saving = response_dict . get ( \"SaveScreenshot\" , {}) if screenshot_saving . get ( \"save\" , False ): utils . print_with_color ( \"Notice: The current screenshot\ud83d\udcf8 is saved to the blackboard.\" , \"yellow\" , ) utils . print_with_color ( \"Saving reason: {reason} \" . format ( reason = screenshot_saving . get ( \"reason\" ) ), \"yellow\" , ) process ( context ) Process the agent. Parameters: context ( Context ) \u2013 The context. Source code in agents/agent/app_agent.py 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 def process ( self , context : Context ) -> None : \"\"\" Process the agent. :param context: The context. \"\"\" if configs . get ( \"ACTION_SEQUENCE\" , False ): self . processor = AppAgentActionSequenceProcessor ( agent = self , context = context , ground_service = self . grounding_service ) else : self . processor = AppAgentProcessor ( agent = self , context = context , ground_service = self . grounding_service ) self . processor . process () self . status = self . processor . status process_comfirmation () Process the user confirmation. Returns: bool \u2013 The decision. Source code in agents/agent/app_agent.py 401 402 403 404 405 406 407 408 409 410 411 412 413 414 def process_comfirmation ( self ) -> bool : \"\"\" Process the user confirmation. :return: The decision. \"\"\" action = self . processor . actions control_text = self . processor . control_text decision = interactor . sensitive_step_asker ( action , control_text ) if not decision : utils . print_with_color ( \"The user has canceled the action.\" , \"red\" ) return decision rag_demonstration_retrieve ( request , demonstration_top_k ) Retrieving demonstration examples for the user request. Parameters: request ( str ) \u2013 The user request. demonstration_top_k ( int ) \u2013 The number of documents to retrieve. Returns: str \u2013 The retrieved examples and tips string. Source code in agents/agent/app_agent.py 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 def rag_demonstration_retrieve ( self , request : str , demonstration_top_k : int ) -> str : \"\"\" Retrieving demonstration examples for the user request. :param request: The user request. :param demonstration_top_k: The number of documents to retrieve. :return: The retrieved examples and tips string. \"\"\" retrieved_docs = [] # Retrieve demonstration examples. demonstration_docs = self . human_demonstration_retriever . retrieve ( request , demonstration_top_k ) if demonstration_docs : for doc in demonstration_docs : example_request = doc . metadata . get ( \"request\" , \"\" ) response = doc . metadata . get ( \"example\" , {}) subtask = doc . metadata . get ( \"Sub-task\" , \"\" ) tips = doc . metadata . get ( \"Tips\" , \"\" ) retrieved_docs . append ( { \"Request\" : example_request , \"Response\" : response , \"Sub-task\" : subtask , \"Tips\" : tips , } ) return retrieved_docs else : return [] rag_experience_retrieve ( request , experience_top_k ) Retrieving experience examples for the user request. Parameters: request ( str ) \u2013 The user request. experience_top_k ( int ) \u2013 The number of documents to retrieve. Returns: List [ Dict [ str , Any ]] \u2013 The retrieved examples and tips dictionary. Source code in agents/agent/app_agent.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def rag_experience_retrieve ( self , request : str , experience_top_k : int ) -> List [ Dict [ str , Any ]]: \"\"\" Retrieving experience examples for the user request. :param request: The user request. :param experience_top_k: The number of documents to retrieve. :return: The retrieved examples and tips dictionary. \"\"\" retrieved_docs = [] # Retrieve experience examples. Only retrieve the examples that are related to the current application. experience_docs = self . experience_retriever . retrieve ( request , experience_top_k , filter = lambda x : self . _app_root_name . lower () in [ app . lower () for app in x [ \"app_list\" ]], ) if experience_docs : for doc in experience_docs : example_request = doc . metadata . get ( \"request\" , \"\" ) response = doc . metadata . get ( \"example\" , {}) tips = doc . metadata . get ( \"Tips\" , \"\" ) subtask = doc . metadata . get ( \"Sub-task\" , \"\" ) retrieved_docs . append ( { \"Request\" : example_request , \"Response\" : response , \"Sub-task\" : subtask , \"Tips\" : tips , } ) return retrieved_docs","title":"AppAgent"},{"location":"agents/app_agent/#appagent","text":"An AppAgent is responsible for iteratively executing actions on the selected applications until the task is successfully concluded within a specific application. The AppAgent is created by the HostAgent to fulfill a sub-task within a Round . The AppAgent is responsible for executing the necessary actions within the application to fulfill the user's request. The AppAgent has the following features: ReAct with the Application - The AppAgent recursively interacts with the application in a workflow of observation->thought->action, leveraging the multi-modal capabilities of Visual Language Models (VLMs) to comprehend the application UI and fulfill the user's request. Comprehension Enhancement - The AppAgent is enhanced by Retrieval Augmented Generation (RAG) from heterogeneous sources, including external knowledge bases, and demonstration libraries, making the agent an application \"expert\". Versatile Skill Set - The AppAgent is equipped with a diverse set of skills to support comprehensive automation, such as mouse, keyboard, native APIs, and \"Copilot\". Tip You can find the how to enhance the AppAgent with external knowledge bases and demonstration libraries in the Reinforcing AppAgent documentation. We show the framework of the AppAgent in the following diagram:","title":"AppAgent \ud83d\udc7e"},{"location":"agents/app_agent/#appagent-input","text":"To interact with the application, the AppAgent receives the following inputs: Input Description Type User Request The user's request in natural language. String Sub-Task The sub-task description to be executed by the AppAgent , assigned by the HostAgent . String Current Application The name of the application to be interacted with. String Control Information Index, name and control type of available controls in the application. List of Dictionaries Application Screenshots Screenshots of the application, including a clean screenshot, an annotated screenshot with labeled controls, and a screenshot with a rectangle around the selected control at the previous step (optional). List of Strings Previous Sub-Tasks The previous sub-tasks and their completion status. List of Strings Previous Plan The previous plan for the following steps. List of Strings HostAgent Message The message from the HostAgent for the completion of the sub-task. String Retrived Information The retrieved information from external knowledge bases or demonstration libraries. String Blackboard The shared memory space for storing and sharing information among the agents. Dictionary Below is an example of the annotated application screenshot with labeled controls. This follow the Set-of-Mark paradigm.","title":"AppAgent Input"},{"location":"agents/app_agent/#appagent-output","text":"With the inputs provided, the AppAgent generates the following outputs: Output Description Type Observation The observation of the current application screenshots. String Thought The logical reasoning process of the AppAgent . String ControlLabel The index of the selected control to interact with. String ControlText The name of the selected control to interact with. String Function The function to be executed on the selected control. String Args The arguments required for the function execution. List of Strings Status The status of the agent, mapped to the AgentState . String Plan The plan for the following steps after the current action. List of Strings Comment Additional comments or information provided to the user. String SaveScreenshot The flag to save the screenshot of the application to the blackboard for future reference. Boolean Below is an example of the AppAgent output: { \"Observation\": \"Application screenshot\", \"Thought\": \"Logical reasoning process\", \"ControlLabel\": \"Control index\", \"ControlText\": \"Control name\", \"Function\": \"Function name\", \"Args\": [\"arg1\", \"arg2\"], \"Status\": \"AgentState\", \"Plan\": [\"Step 1\", \"Step 2\"], \"Comment\": \"Additional comments\", \"SaveScreenshot\": true } Info The AppAgent output is formatted as a JSON object by LLMs and can be parsed by the json.loads method in Python.","title":"AppAgent Output"},{"location":"agents/app_agent/#appagent-state","text":"The AppAgent state is managed by a state machine that determines the next action to be executed based on the current state, as defined in the ufo/agents/states/app_agent_states.py module. The states include: State Description CONTINUE Main execution loop; evaluates which subtasks are ready to launch or resume. ASSIGN Selects an available application process and spawns the corresponding AppAgent . PENDING Waits for user input to resolve ambiguity or gather additional task parameters. FINISH All subtasks complete; cleans up agent instances and finalizes session state. FAIL Enters recovery or abort mode upon irrecoverable failure. The state machine diagram for the AppAgent is shown below:","title":"AppAgent State"},{"location":"agents/app_agent/#knowledge-enhancement","text":"The AppAgent is enhanced by Retrieval Augmented Generation (RAG) from heterogeneous sources, including external knowledge bases and demonstration libraries. The AppAgent leverages this knowledge to enhance its comprehension of the application and learn from demonstrations to improve its performance.","title":"Knowledge Enhancement"},{"location":"agents/app_agent/#learning-from-help-documents","text":"User can provide help documents to the AppAgent to enhance its comprehension of the application and improve its performance in the config.yaml file. Tip Please find details configuration in the documentation . Tip You may also refer to the here for how to provide help documents to the AppAgent . In the AppAgent , it calls the build_offline_docs_retriever to build a help document retriever, and uses the retrived_documents_prompt_helper to contruct the prompt for the AppAgent .","title":"Learning from Help Documents"},{"location":"agents/app_agent/#learning-from-bing-search","text":"Since help documents may not cover all the information or the information may be outdated, the AppAgent can also leverage Bing search to retrieve the latest information. You can activate Bing search and configure the search engine in the config.yaml file. Tip Please find details configuration in the documentation . Tip You may also refer to the here for the implementation of Bing search in the AppAgent . In the AppAgent , it calls the build_online_search_retriever to build a Bing search retriever, and uses the retrived_documents_prompt_helper to contruct the prompt for the AppAgent .","title":"Learning from Bing Search"},{"location":"agents/app_agent/#learning-from-self-demonstrations","text":"You may save successful action trajectories in the AppAgent to learn from self-demonstrations and improve its performance. After the completion of a session , the AppAgent will ask the user whether to save the action trajectories for future reference. You may configure the use of self-demonstrations in the config.yaml file. Tip You can find details of the configuration in the documentation . Tip You may also refer to the here for the implementation of self-demonstrations in the AppAgent . In the AppAgent , it calls the build_experience_retriever to build a self-demonstration retriever, and uses the rag_experience_retrieve to retrieve the demonstration for the AppAgent .","title":"Learning from Self-Demonstrations"},{"location":"agents/app_agent/#learning-from-human-demonstrations","text":"In addition to self-demonstrations, you can also provide human demonstrations to the AppAgent to enhance its performance by using the Step Recorder tool built in the Windows OS. The AppAgent will learn from the human demonstrations to improve its performance and achieve better personalization. The use of human demonstrations can be configured in the config.yaml file. Tip You can find details of the configuration in the documentation . Tip You may also refer to the here for the implementation of human demonstrations in the AppAgent . In the AppAgent , it calls the build_human_demonstration_retriever to build a human demonstration retriever, and uses the rag_experience_retrieve to retrieve the demonstration for the AppAgent .","title":"Learning from Human Demonstrations"},{"location":"agents/app_agent/#skill-set-for-automation","text":"The AppAgent is equipped with a versatile skill set to support comprehensive automation within the application by calling the create_puppeteer_interface method. The skills include: Skill Description UI Automation Mimicking user interactions with the application UI controls using the UI Automation and Win32 API. Native API Accessing the application's native API to execute specific functions and actions. In-App Agent Leveraging the in-app agent to interact with the application's internal functions and features. By utilizing these skills, the AppAgent can efficiently interact with the application and fulfill the user's request. You can find more details in the Automator documentation and the code in the ufo/automator module.","title":"Skill Set for Automation"},{"location":"agents/app_agent/#reference","text":"Bases: BasicAgent The AppAgent class that manages the interaction with the application. Initialize the AppAgent. :name: The name of the agent. Parameters: process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The root name of the app. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. skip_prompter ( bool , default: False ) \u2013 The flag indicating whether to skip the prompter initialization. mode ( str , default: 'normal' ) \u2013 The mode of the agent. Source code in agents/agent/app_agent.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def __init__ ( self , name : str , process_name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , skip_prompter : bool = False , mode : str = \"normal\" , ) -> None : \"\"\" Initialize the AppAgent. :name: The name of the agent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param skip_prompter: The flag indicating whether to skip the prompter initialization. :param mode: The mode of the agent. \"\"\" super () . __init__ ( name = name ) if not skip_prompter : self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_root_name ) self . _process_name = process_name self . _app_root_name = app_root_name self . offline_doc_retriever = None self . online_doc_retriever = None self . experience_retriever = None self . human_demonstration_retriever = None self . Puppeteer = self . create_puppeteer_interface () self . _mode = mode control_detection_backend = configs . get ( \"CONTROL_BACKEND\" , [ \"uia\" ]) if \"omniparser\" in control_detection_backend : omniparser_endpoint = configs . get ( \"OMNIPARSER\" , {}) . get ( \"ENDPOINT\" , \"\" ) omniparser_service = OmniParser ( endpoint = omniparser_endpoint ) self . grounding_service : Optional [ BasicGrounding ] = OmniparserGrounding ( service = omniparser_service ) else : self . grounding_service : Optional [ BasicGrounding ] = None self . set_state ( self . default_state )","title":"Reference"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.default_state","text":"Get the default state.","title":"default_state"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.mode","text":"Get the mode of the session.","title":"mode"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.status_manager","text":"Get the status manager.","title":"status_manager"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.build_experience_retriever","text":"Build the experience retriever. Parameters: db_path ( str ) \u2013 The path to the experience database. Returns: None \u2013 The experience retriever. Source code in agents/agent/app_agent.py 448 449 450 451 452 453 454 455 456 def build_experience_retriever ( self , db_path : str ) -> None : \"\"\" Build the experience retriever. :param db_path: The path to the experience database. :return: The experience retriever. \"\"\" self . experience_retriever = self . retriever_factory . create_retriever ( \"experience\" , db_path )","title":"build_experience_retriever"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.build_human_demonstration_retriever","text":"Build the human demonstration retriever. Parameters: db_path ( str ) \u2013 The path to the human demonstration database. Returns: None \u2013 The human demonstration retriever. Source code in agents/agent/app_agent.py 458 459 460 461 462 463 464 465 466 def build_human_demonstration_retriever ( self , db_path : str ) -> None : \"\"\" Build the human demonstration retriever. :param db_path: The path to the human demonstration database. :return: The human demonstration retriever. \"\"\" self . human_demonstration_retriever = self . retriever_factory . create_retriever ( \"demonstration\" , db_path )","title":"build_human_demonstration_retriever"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.build_offline_docs_retriever","text":"Build the offline docs retriever. Source code in agents/agent/app_agent.py 430 431 432 433 434 435 436 def build_offline_docs_retriever ( self ) -> None : \"\"\" Build the offline docs retriever. \"\"\" self . offline_doc_retriever = self . retriever_factory . create_retriever ( \"offline\" , self . _app_root_name )","title":"build_offline_docs_retriever"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.build_online_search_retriever","text":"Build the online search retriever. Parameters: request ( str ) \u2013 The request for online Bing search. top_k ( int ) \u2013 The number of documents to retrieve. Source code in agents/agent/app_agent.py 438 439 440 441 442 443 444 445 446 def build_online_search_retriever ( self , request : str , top_k : int ) -> None : \"\"\" Build the online search retriever. :param request: The request for online Bing search. :param top_k: The number of documents to retrieve. \"\"\" self . online_doc_retriever = self . retriever_factory . create_retriever ( \"online\" , request , top_k )","title":"build_online_search_retriever"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.context_provision","text":"Provision the context for the app agent. Parameters: request ( str , default: '' ) \u2013 The request sent to the Bing search retriever. Source code in agents/agent/app_agent.py 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 def context_provision ( self , request : str = \"\" ) -> None : \"\"\" Provision the context for the app agent. :param request: The request sent to the Bing search retriever. \"\"\" # Load the offline document indexer for the app agent if available. if configs [ \"RAG_OFFLINE_DOCS\" ]: utils . print_with_color ( \"Loading offline help document indexer for {app} ...\" . format ( app = self . _process_name ), \"magenta\" , ) self . build_offline_docs_retriever () # Load the online search indexer for the app agent if available. if configs [ \"RAG_ONLINE_SEARCH\" ] and request : utils . print_with_color ( \"Creating a Bing search indexer...\" , \"magenta\" ) self . build_online_search_retriever ( request , configs [ \"RAG_ONLINE_SEARCH_TOPK\" ] ) # Load the experience indexer for the app agent if available. if configs [ \"RAG_EXPERIENCE\" ]: utils . print_with_color ( \"Creating an experience indexer...\" , \"magenta\" ) experience_path = configs [ \"EXPERIENCE_SAVED_PATH\" ] db_path = os . path . join ( experience_path , \"experience_db\" ) self . build_experience_retriever ( db_path ) # Load the demonstration indexer for the app agent if available. if configs [ \"RAG_DEMONSTRATION\" ]: utils . print_with_color ( \"Creating an demonstration indexer...\" , \"magenta\" ) demonstration_path = configs [ \"DEMONSTRATION_SAVED_PATH\" ] db_path = os . path . join ( demonstration_path , \"demonstration_db\" ) self . build_human_demonstration_retriever ( db_path )","title":"context_provision"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.create_puppeteer_interface","text":"Create the Puppeteer interface to automate the app. Returns: AppPuppeteer \u2013 The Puppeteer interface. Source code in agents/agent/app_agent.py 394 395 396 397 398 399 def create_puppeteer_interface ( self ) -> puppeteer . AppPuppeteer : \"\"\" Create the Puppeteer interface to automate the app. :return: The Puppeteer interface. \"\"\" return puppeteer . AppPuppeteer ( self . _process_name , self . _app_root_name )","title":"create_puppeteer_interface"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.demonstration_prompt_helper","text":"Get the examples and tips for the AppAgent using the demonstration retriever. Parameters: request \u2013 The request for the AppAgent. Returns: Tuple [ List [ Dict [ str , Any ]]] \u2013 The examples and tips for the AppAgent. Source code in agents/agent/app_agent.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 def demonstration_prompt_helper ( self , request ) -> Tuple [ List [ Dict [ str , Any ]]]: \"\"\" Get the examples and tips for the AppAgent using the demonstration retriever. :param request: The request for the AppAgent. :return: The examples and tips for the AppAgent. \"\"\" # Get the examples and tips for the AppAgent using the experience and demonstration retrievers. if configs [ \"RAG_EXPERIENCE\" ]: experience_results = self . rag_experience_retrieve ( request , configs [ \"RAG_EXPERIENCE_RETRIEVED_TOPK\" ] ) else : experience_results = [] if configs [ \"RAG_DEMONSTRATION\" ]: demonstration_results = self . rag_demonstration_retrieve ( request , configs [ \"RAG_DEMONSTRATION_RETRIEVED_TOPK\" ] ) else : demonstration_results = [] return experience_results , demonstration_results","title":"demonstration_prompt_helper"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.external_knowledge_prompt_helper","text":"Retrieve the external knowledge and construct the prompt. Parameters: request ( str ) \u2013 The request. offline_top_k ( int ) \u2013 The number of offline documents to retrieve. online_top_k ( int ) \u2013 The number of online documents to retrieve. Returns: Tuple [ str , str ] \u2013 The prompt message for the external_knowledge. Source code in agents/agent/app_agent.py 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 def external_knowledge_prompt_helper ( self , request : str , offline_top_k : int , online_top_k : int ) -> Tuple [ str , str ]: \"\"\" Retrieve the external knowledge and construct the prompt. :param request: The request. :param offline_top_k: The number of offline documents to retrieve. :param online_top_k: The number of online documents to retrieve. :return: The prompt message for the external_knowledge. \"\"\" # Retrieve offline documents and construct the prompt if self . offline_doc_retriever : offline_docs = self . offline_doc_retriever . retrieve ( request , offline_top_k , filter = None , ) format_string = \"[Similar Requests]: {question} \\n Step: {answer} \\n \" offline_docs_prompt = self . prompter . retrived_documents_prompt_helper ( \"[Help Documents]\" , \"\" , [ format_string . format ( question = doc . metadata . get ( \"title\" , \"\" ), answer = doc . metadata . get ( \"text\" , \"\" ), ) for doc in offline_docs ], ) else : offline_docs_prompt = \"\" # Retrieve online documents and construct the prompt if self . online_doc_retriever : online_search_docs = self . online_doc_retriever . retrieve ( request , online_top_k , filter = None ) online_docs_prompt = self . prompter . retrived_documents_prompt_helper ( \"Online Search Results\" , \"Search Result\" , [ doc . page_content for doc in online_search_docs ], ) else : online_docs_prompt = \"\" return offline_docs_prompt , online_docs_prompt","title":"external_knowledge_prompt_helper"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.get_prompter","text":"Get the prompt for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. app_root_name ( str ) \u2013 The root name of the app. Returns: AppAgentPrompter \u2013 The prompter instance. Source code in agents/agent/app_agent.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , app_root_name : str , ) -> AppAgentPrompter : \"\"\" Get the prompt for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param app_root_name: The root name of the app. :return: The prompter instance. \"\"\" return AppAgentPrompter ( is_visual , main_prompt , example_prompt , api_prompt , app_root_name )","title":"get_prompter"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.message_constructor","text":"Construct the prompt message for the AppAgent. Parameters: dynamic_examples ( str ) \u2013 The dynamic examples retrieved from the self-demonstration and human demonstration. dynamic_knowledge ( str ) \u2013 The dynamic knowledge retrieved from the external knowledge base. image_list ( List ) \u2013 The list of screenshot images. control_info ( str ) \u2013 The control information. plan ( List [ str ] ) \u2013 The plan list. request ( str ) \u2013 The overall user request. subtask ( str ) \u2013 The subtask for the current AppAgent to process. current_application ( str ) \u2013 The current application name. host_message ( List [ str ] ) \u2013 The message from the HostAgent. blackboard_prompt ( List [ Dict [ str , str ]] ) \u2013 The prompt message from the blackboard. last_success_actions ( List [ Dict [ str , Any ]] ) \u2013 The list of successful actions in the last step. include_last_screenshot ( bool ) \u2013 The flag indicating whether to include the last screenshot. Returns: List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]] \u2013 The prompt message. Source code in agents/agent/app_agent.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def message_constructor ( self , dynamic_examples : str , dynamic_knowledge : str , image_list : List , control_info : str , prev_subtask : List [ Dict [ str , str ]], plan : List [ str ], request : str , subtask : str , current_application : str , host_message : List [ str ], blackboard_prompt : List [ Dict [ str , str ]], last_success_actions : List [ Dict [ str , Any ]], include_last_screenshot : bool , ) -> List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]]: \"\"\" Construct the prompt message for the AppAgent. :param dynamic_examples: The dynamic examples retrieved from the self-demonstration and human demonstration. :param dynamic_knowledge: The dynamic knowledge retrieved from the external knowledge base. :param image_list: The list of screenshot images. :param control_info: The control information. :param plan: The plan list. :param request: The overall user request. :param subtask: The subtask for the current AppAgent to process. :param current_application: The current application name. :param host_message: The message from the HostAgent. :param blackboard_prompt: The prompt message from the blackboard. :param last_success_actions: The list of successful actions in the last step. :param include_last_screenshot: The flag indicating whether to include the last screenshot. :return: The prompt message. \"\"\" appagent_prompt_system_message = self . prompter . system_prompt_construction ( dynamic_examples ) appagent_prompt_user_message = self . prompter . user_content_construction ( image_list = image_list , control_item = control_info , prev_subtask = prev_subtask , prev_plan = plan , user_request = request , subtask = subtask , current_application = current_application , host_message = host_message , retrieved_docs = dynamic_knowledge , last_success_actions = last_success_actions , include_last_screenshot = include_last_screenshot , ) if blackboard_prompt : appagent_prompt_user_message = ( blackboard_prompt + appagent_prompt_user_message ) appagent_prompt_message = self . prompter . prompt_construction ( appagent_prompt_system_message , appagent_prompt_user_message ) return appagent_prompt_message","title":"message_constructor"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.print_response","text":"Print the response. Parameters: response_dict ( Dict [ str , Any ] ) \u2013 The response dictionary to print. print_action ( bool , default: True ) \u2013 The flag indicating whether to print the action. Source code in agents/agent/app_agent.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def print_response ( self , response_dict : Dict [ str , Any ], print_action : bool = True ) -> None : \"\"\" Print the response. :param response_dict: The response dictionary to print. :param print_action: The flag indicating whether to print the action. \"\"\" control_text = response_dict . get ( \"ControlText\" ) control_label = response_dict . get ( \"ControlLabel\" ) if not control_text and not control_label : control_text = \"[No control selected.]\" control_label = \"[No control label selected.]\" observation = response_dict . get ( \"Observation\" ) thought = response_dict . get ( \"Thought\" ) plan = response_dict . get ( \"Plan\" ) status = response_dict . get ( \"Status\" ) comment = response_dict . get ( \"Comment\" ) function_call = response_dict . get ( \"Function\" ) args = utils . revise_line_breaks ( response_dict . get ( \"Args\" )) # Generate the function call string action = self . Puppeteer . get_command_string ( function_call , args ) utils . print_with_color ( \"Observations\ud83d\udc40: {observation} \" . format ( observation = observation ), \"cyan\" ) utils . print_with_color ( \"Thoughts\ud83d\udca1: {thought} \" . format ( thought = thought ), \"green\" ) if print_action : utils . print_with_color ( \"Selected item\ud83d\udd79\ufe0f: {control_text} , Label: {label} \" . format ( control_text = control_text , label = control_label ), \"yellow\" , ) utils . print_with_color ( \"Action applied\u2692\ufe0f: {action} \" . format ( action = action ), \"blue\" ) utils . print_with_color ( \"Status\ud83d\udcca: {status} \" . format ( status = status ), \"blue\" ) utils . print_with_color ( \"Next Plan\ud83d\udcda: {plan} \" . format ( plan = \" \\n \" . join ( plan )), \"cyan\" ) utils . print_with_color ( \"Comment\ud83d\udcac: {comment} \" . format ( comment = comment ), \"green\" ) screenshot_saving = response_dict . get ( \"SaveScreenshot\" , {}) if screenshot_saving . get ( \"save\" , False ): utils . print_with_color ( \"Notice: The current screenshot\ud83d\udcf8 is saved to the blackboard.\" , \"yellow\" , ) utils . print_with_color ( \"Saving reason: {reason} \" . format ( reason = screenshot_saving . get ( \"reason\" ) ), \"yellow\" , )","title":"print_response"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.process","text":"Process the agent. Parameters: context ( Context ) \u2013 The context. Source code in agents/agent/app_agent.py 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 def process ( self , context : Context ) -> None : \"\"\" Process the agent. :param context: The context. \"\"\" if configs . get ( \"ACTION_SEQUENCE\" , False ): self . processor = AppAgentActionSequenceProcessor ( agent = self , context = context , ground_service = self . grounding_service ) else : self . processor = AppAgentProcessor ( agent = self , context = context , ground_service = self . grounding_service ) self . processor . process () self . status = self . processor . status","title":"process"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.process_comfirmation","text":"Process the user confirmation. Returns: bool \u2013 The decision. Source code in agents/agent/app_agent.py 401 402 403 404 405 406 407 408 409 410 411 412 413 414 def process_comfirmation ( self ) -> bool : \"\"\" Process the user confirmation. :return: The decision. \"\"\" action = self . processor . actions control_text = self . processor . control_text decision = interactor . sensitive_step_asker ( action , control_text ) if not decision : utils . print_with_color ( \"The user has canceled the action.\" , \"red\" ) return decision","title":"process_comfirmation"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.rag_demonstration_retrieve","text":"Retrieving demonstration examples for the user request. Parameters: request ( str ) \u2013 The user request. demonstration_top_k ( int ) \u2013 The number of documents to retrieve. Returns: str \u2013 The retrieved examples and tips string. Source code in agents/agent/app_agent.py 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 def rag_demonstration_retrieve ( self , request : str , demonstration_top_k : int ) -> str : \"\"\" Retrieving demonstration examples for the user request. :param request: The user request. :param demonstration_top_k: The number of documents to retrieve. :return: The retrieved examples and tips string. \"\"\" retrieved_docs = [] # Retrieve demonstration examples. demonstration_docs = self . human_demonstration_retriever . retrieve ( request , demonstration_top_k ) if demonstration_docs : for doc in demonstration_docs : example_request = doc . metadata . get ( \"request\" , \"\" ) response = doc . metadata . get ( \"example\" , {}) subtask = doc . metadata . get ( \"Sub-task\" , \"\" ) tips = doc . metadata . get ( \"Tips\" , \"\" ) retrieved_docs . append ( { \"Request\" : example_request , \"Response\" : response , \"Sub-task\" : subtask , \"Tips\" : tips , } ) return retrieved_docs else : return []","title":"rag_demonstration_retrieve"},{"location":"agents/app_agent/#agents.agent.app_agent.AppAgent.rag_experience_retrieve","text":"Retrieving experience examples for the user request. Parameters: request ( str ) \u2013 The user request. experience_top_k ( int ) \u2013 The number of documents to retrieve. Returns: List [ Dict [ str , Any ]] \u2013 The retrieved examples and tips dictionary. Source code in agents/agent/app_agent.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def rag_experience_retrieve ( self , request : str , experience_top_k : int ) -> List [ Dict [ str , Any ]]: \"\"\" Retrieving experience examples for the user request. :param request: The user request. :param experience_top_k: The number of documents to retrieve. :return: The retrieved examples and tips dictionary. \"\"\" retrieved_docs = [] # Retrieve experience examples. Only retrieve the examples that are related to the current application. experience_docs = self . experience_retriever . retrieve ( request , experience_top_k , filter = lambda x : self . _app_root_name . lower () in [ app . lower () for app in x [ \"app_list\" ]], ) if experience_docs : for doc in experience_docs : example_request = doc . metadata . get ( \"request\" , \"\" ) response = doc . metadata . get ( \"example\" , {}) tips = doc . metadata . get ( \"Tips\" , \"\" ) subtask = doc . metadata . get ( \"Sub-task\" , \"\" ) retrieved_docs . append ( { \"Request\" : example_request , \"Response\" : response , \"Sub-task\" : subtask , \"Tips\" : tips , } ) return retrieved_docs","title":"rag_experience_retrieve"},{"location":"agents/evaluation_agent/","text":"EvaluationAgent \ud83e\uddd0 The objective of the EvaluationAgent is to evaluate whether a Session or Round has been successfully completed. The EvaluationAgent assesses the performance of the HostAgent and AppAgent in fulfilling the request. You can configure whether to enable the EvaluationAgent in the config_dev.yaml file and the detailed documentation can be found here . Note The EvaluationAgent is fully LLM-driven and conducts evaluations based on the action trajectories and screenshots. It may not by 100% accurate since LLM may make mistakes. We illustrate the evaluation process in the following figure: Configuration To enable the EvaluationAgent , you can configure the following parameters in the config_dev.yaml file to evaluate the task completion status at different levels: Configuration Option Description Type Default Value EVA_SESSION Whether to include the session in the evaluation. Boolean True EVA_ROUND Whether to include the round in the evaluation. Boolean False EVA_ALL_SCREENSHOTS Whether to include all the screenshots in the evaluation. Boolean True Evaluation Inputs The EvaluationAgent takes the following inputs for evaluation: Input Description Type User Request The user's request to be evaluated. String APIs Description The description of the APIs used in the execution. List of Strings Action Trajectories The action trajectories executed by the HostAgent and AppAgent . List of Strings Screenshots The screenshots captured during the execution. List of Images For more details on how to construct the inputs, please refer to the EvaluationAgentPrompter class in ufo/prompter/eva_prompter.py . Tip You can configure whether to use all screenshots or only the first and last screenshot for evaluation in the EVA_ALL_SCREENSHOTS of the config_dev.yaml file. Evaluation Outputs The EvaluationAgent generates the following outputs after evaluation: Output Description Type reason The detailed reason for your judgment, by observing the screenshot differences and the . String sub_scores The sub-score of the evaluation in decomposing the evaluation into multiple sub-goals. List of Dictionaries complete The completion status of the evaluation, can be yes , no , or unsure . String Below is an example of the evaluation output: { \"reason\": \"The agent successfully completed the task of sending 'hello' to Zac on Microsoft Teams. The initial screenshot shows the Microsoft Teams application with the chat window of Chaoyun Zhang open. The agent then focused on the chat window, input the message 'hello', and clicked the Send button. The final screenshot confirms that the message 'hello' was sent to Zac.\", \"sub_scores\": { \"correct application focus\": \"yes\", \"correct message input\": \"yes\", \"message sent successfully\": \"yes\" }, \"complete\": \"yes\"} Info The log of the evaluation results will be saved in the logs/{task_name}/evaluation.log file. The EvaluationAgent employs the CoT mechanism to first decompose the evaluation into multiple sub-goals and then evaluate each sub-goal separately. The sub-scores are then aggregated to determine the overall completion status of the evaluation. Reference Bases: BasicAgent The agent for evaluation. Initialize the FollowAgent. :agent_type: The type of the agent. :is_visual: The flag indicating whether the agent is visual or not. Source code in agents/agent/evaluation_agent.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self , name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the FollowAgent. :agent_type: The type of the agent. :is_visual: The flag indicating whether the agent is visual or not. \"\"\" super () . __init__ ( name = name ) self . _app_root_name = app_root_name self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_root_name , ) status_manager property Get the status manager. evaluate ( request , log_path , eva_all_screenshots = True ) Evaluate the task completion. Parameters: log_path ( str ) \u2013 The path to the log file. Returns: Tuple [ Dict [ str , str ], float ] \u2013 The evaluation result and the cost of LLM. Source code in agents/agent/evaluation_agent.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def evaluate ( self , request : str , log_path : str , eva_all_screenshots : bool = True ) -> Tuple [ Dict [ str , str ], float ]: \"\"\" Evaluate the task completion. :param log_path: The path to the log file. :return: The evaluation result and the cost of LLM. \"\"\" message = self . message_constructor ( log_path = log_path , request = request , eva_all_screenshots = eva_all_screenshots ) result , cost = self . get_response ( message = message , namescope = \"eva\" , use_backup_engine = True ) result = json_parser ( result ) return result , cost get_prompter ( is_visual , prompt_template , example_prompt_template , api_prompt_template , root_name = None ) Get the prompter for the agent. Source code in agents/agent/evaluation_agent.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_prompter ( self , is_visual , prompt_template : str , example_prompt_template : str , api_prompt_template : str , root_name : Optional [ str ] = None , ) -> EvaluationAgentPrompter : \"\"\" Get the prompter for the agent. \"\"\" return EvaluationAgentPrompter ( is_visual = is_visual , prompt_template = prompt_template , example_prompt_template = example_prompt_template , api_prompt_template = api_prompt_template , root_name = root_name , ) message_constructor ( log_path , request , eva_all_screenshots = True ) Construct the message. Parameters: log_path ( str ) \u2013 The path to the log file. request ( str ) \u2013 The request. eva_all_screenshots ( bool , default: True ) \u2013 The flag indicating whether to evaluate all screenshots. Returns: Dict [ str , Any ] \u2013 The message. Source code in agents/agent/evaluation_agent.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def message_constructor ( self , log_path : str , request : str , eva_all_screenshots : bool = True ) -> Dict [ str , Any ]: \"\"\" Construct the message. :param log_path: The path to the log file. :param request: The request. :param eva_all_screenshots: The flag indicating whether to evaluate all screenshots. :return: The message. \"\"\" evaagent_prompt_system_message = self . prompter . system_prompt_construction () evaagent_prompt_user_message = self . prompter . user_content_construction ( log_path = log_path , request = request , eva_all_screenshots = eva_all_screenshots ) evaagent_prompt_message = self . prompter . prompt_construction ( evaagent_prompt_system_message , evaagent_prompt_user_message ) return evaagent_prompt_message print_response ( response_dict ) Print the response of the evaluation. Parameters: response_dict ( Dict [ str , Any ] ) \u2013 The response dictionary. Source code in agents/agent/evaluation_agent.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def print_response ( self , response_dict : Dict [ str , Any ]) -> None : \"\"\" Print the response of the evaluation. :param response_dict: The response dictionary. \"\"\" emoji_map = { \"yes\" : \"\u2705\" , \"no\" : \"\u274c\" , \"maybe\" : \"\u2753\" , } complete = emoji_map . get ( response_dict . get ( \"complete\" ), response_dict . get ( \"complete\" ) ) sub_scores = response_dict . get ( \"sub_scores\" , {}) reason = response_dict . get ( \"reason\" , \"\" ) print_with_color ( f \"Evaluation result\ud83e\uddd0:\" , \"magenta\" ) print_with_color ( f \"[Sub-scores\ud83d\udcca:]\" , \"green\" ) for score , evaluation in sub_scores . items (): print_with_color ( f \" { score } : { emoji_map . get ( evaluation , evaluation ) } \" , \"green\" ) print_with_color ( \"[Task is complete\ud83d\udcaf:] {complete} \" . format ( complete = complete ), \"cyan\" ) print_with_color ( f \"[Reason\ud83e\udd14:] { reason } \" . format ( reason = reason ), \"blue\" ) process_comfirmation () Comfirmation, currently do nothing. Source code in agents/agent/evaluation_agent.py 119 120 121 122 123 def process_comfirmation ( self ) -> None : \"\"\" Comfirmation, currently do nothing. \"\"\" pass","title":"EvaluationAgent"},{"location":"agents/evaluation_agent/#evaluationagent","text":"The objective of the EvaluationAgent is to evaluate whether a Session or Round has been successfully completed. The EvaluationAgent assesses the performance of the HostAgent and AppAgent in fulfilling the request. You can configure whether to enable the EvaluationAgent in the config_dev.yaml file and the detailed documentation can be found here . Note The EvaluationAgent is fully LLM-driven and conducts evaluations based on the action trajectories and screenshots. It may not by 100% accurate since LLM may make mistakes. We illustrate the evaluation process in the following figure:","title":"EvaluationAgent \ud83e\uddd0"},{"location":"agents/evaluation_agent/#configuration","text":"To enable the EvaluationAgent , you can configure the following parameters in the config_dev.yaml file to evaluate the task completion status at different levels: Configuration Option Description Type Default Value EVA_SESSION Whether to include the session in the evaluation. Boolean True EVA_ROUND Whether to include the round in the evaluation. Boolean False EVA_ALL_SCREENSHOTS Whether to include all the screenshots in the evaluation. Boolean True","title":"Configuration"},{"location":"agents/evaluation_agent/#evaluation-inputs","text":"The EvaluationAgent takes the following inputs for evaluation: Input Description Type User Request The user's request to be evaluated. String APIs Description The description of the APIs used in the execution. List of Strings Action Trajectories The action trajectories executed by the HostAgent and AppAgent . List of Strings Screenshots The screenshots captured during the execution. List of Images For more details on how to construct the inputs, please refer to the EvaluationAgentPrompter class in ufo/prompter/eva_prompter.py . Tip You can configure whether to use all screenshots or only the first and last screenshot for evaluation in the EVA_ALL_SCREENSHOTS of the config_dev.yaml file.","title":"Evaluation Inputs"},{"location":"agents/evaluation_agent/#evaluation-outputs","text":"The EvaluationAgent generates the following outputs after evaluation: Output Description Type reason The detailed reason for your judgment, by observing the screenshot differences and the . String sub_scores The sub-score of the evaluation in decomposing the evaluation into multiple sub-goals. List of Dictionaries complete The completion status of the evaluation, can be yes , no , or unsure . String Below is an example of the evaluation output: { \"reason\": \"The agent successfully completed the task of sending 'hello' to Zac on Microsoft Teams. The initial screenshot shows the Microsoft Teams application with the chat window of Chaoyun Zhang open. The agent then focused on the chat window, input the message 'hello', and clicked the Send button. The final screenshot confirms that the message 'hello' was sent to Zac.\", \"sub_scores\": { \"correct application focus\": \"yes\", \"correct message input\": \"yes\", \"message sent successfully\": \"yes\" }, \"complete\": \"yes\"} Info The log of the evaluation results will be saved in the logs/{task_name}/evaluation.log file. The EvaluationAgent employs the CoT mechanism to first decompose the evaluation into multiple sub-goals and then evaluate each sub-goal separately. The sub-scores are then aggregated to determine the overall completion status of the evaluation.","title":"Evaluation Outputs"},{"location":"agents/evaluation_agent/#reference","text":"Bases: BasicAgent The agent for evaluation. Initialize the FollowAgent. :agent_type: The type of the agent. :is_visual: The flag indicating whether the agent is visual or not. Source code in agents/agent/evaluation_agent.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self , name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the FollowAgent. :agent_type: The type of the agent. :is_visual: The flag indicating whether the agent is visual or not. \"\"\" super () . __init__ ( name = name ) self . _app_root_name = app_root_name self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_root_name , )","title":"Reference"},{"location":"agents/evaluation_agent/#agents.agent.evaluation_agent.EvaluationAgent.status_manager","text":"Get the status manager.","title":"status_manager"},{"location":"agents/evaluation_agent/#agents.agent.evaluation_agent.EvaluationAgent.evaluate","text":"Evaluate the task completion. Parameters: log_path ( str ) \u2013 The path to the log file. Returns: Tuple [ Dict [ str , str ], float ] \u2013 The evaluation result and the cost of LLM. Source code in agents/agent/evaluation_agent.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def evaluate ( self , request : str , log_path : str , eva_all_screenshots : bool = True ) -> Tuple [ Dict [ str , str ], float ]: \"\"\" Evaluate the task completion. :param log_path: The path to the log file. :return: The evaluation result and the cost of LLM. \"\"\" message = self . message_constructor ( log_path = log_path , request = request , eva_all_screenshots = eva_all_screenshots ) result , cost = self . get_response ( message = message , namescope = \"eva\" , use_backup_engine = True ) result = json_parser ( result ) return result , cost","title":"evaluate"},{"location":"agents/evaluation_agent/#agents.agent.evaluation_agent.EvaluationAgent.get_prompter","text":"Get the prompter for the agent. Source code in agents/agent/evaluation_agent.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_prompter ( self , is_visual , prompt_template : str , example_prompt_template : str , api_prompt_template : str , root_name : Optional [ str ] = None , ) -> EvaluationAgentPrompter : \"\"\" Get the prompter for the agent. \"\"\" return EvaluationAgentPrompter ( is_visual = is_visual , prompt_template = prompt_template , example_prompt_template = example_prompt_template , api_prompt_template = api_prompt_template , root_name = root_name , )","title":"get_prompter"},{"location":"agents/evaluation_agent/#agents.agent.evaluation_agent.EvaluationAgent.message_constructor","text":"Construct the message. Parameters: log_path ( str ) \u2013 The path to the log file. request ( str ) \u2013 The request. eva_all_screenshots ( bool , default: True ) \u2013 The flag indicating whether to evaluate all screenshots. Returns: Dict [ str , Any ] \u2013 The message. Source code in agents/agent/evaluation_agent.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def message_constructor ( self , log_path : str , request : str , eva_all_screenshots : bool = True ) -> Dict [ str , Any ]: \"\"\" Construct the message. :param log_path: The path to the log file. :param request: The request. :param eva_all_screenshots: The flag indicating whether to evaluate all screenshots. :return: The message. \"\"\" evaagent_prompt_system_message = self . prompter . system_prompt_construction () evaagent_prompt_user_message = self . prompter . user_content_construction ( log_path = log_path , request = request , eva_all_screenshots = eva_all_screenshots ) evaagent_prompt_message = self . prompter . prompt_construction ( evaagent_prompt_system_message , evaagent_prompt_user_message ) return evaagent_prompt_message","title":"message_constructor"},{"location":"agents/evaluation_agent/#agents.agent.evaluation_agent.EvaluationAgent.print_response","text":"Print the response of the evaluation. Parameters: response_dict ( Dict [ str , Any ] ) \u2013 The response dictionary. Source code in agents/agent/evaluation_agent.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def print_response ( self , response_dict : Dict [ str , Any ]) -> None : \"\"\" Print the response of the evaluation. :param response_dict: The response dictionary. \"\"\" emoji_map = { \"yes\" : \"\u2705\" , \"no\" : \"\u274c\" , \"maybe\" : \"\u2753\" , } complete = emoji_map . get ( response_dict . get ( \"complete\" ), response_dict . get ( \"complete\" ) ) sub_scores = response_dict . get ( \"sub_scores\" , {}) reason = response_dict . get ( \"reason\" , \"\" ) print_with_color ( f \"Evaluation result\ud83e\uddd0:\" , \"magenta\" ) print_with_color ( f \"[Sub-scores\ud83d\udcca:]\" , \"green\" ) for score , evaluation in sub_scores . items (): print_with_color ( f \" { score } : { emoji_map . get ( evaluation , evaluation ) } \" , \"green\" ) print_with_color ( \"[Task is complete\ud83d\udcaf:] {complete} \" . format ( complete = complete ), \"cyan\" ) print_with_color ( f \"[Reason\ud83e\udd14:] { reason } \" . format ( reason = reason ), \"blue\" )","title":"print_response"},{"location":"agents/evaluation_agent/#agents.agent.evaluation_agent.EvaluationAgent.process_comfirmation","text":"Comfirmation, currently do nothing. Source code in agents/agent/evaluation_agent.py 119 120 121 122 123 def process_comfirmation ( self ) -> None : \"\"\" Comfirmation, currently do nothing. \"\"\" pass","title":"process_comfirmation"},{"location":"agents/follower_agent/","text":"Follower Agent \ud83d\udeb6\ud83c\udffd\u200d\u2642\ufe0f The FollowerAgent is inherited from the AppAgent and is responsible for following the user's instructions to perform specific tasks within the application. The FollowerAgent is designed to execute a series of actions based on the user's guidance. It is particularly useful for software testing, when clear instructions are provided to validate the application's behavior. Different from the AppAgent The FollowerAgent shares most of the functionalities with the AppAgent , but it is designed to follow the step-by-step instructions provided by the user, instead of does its own reasoning to determine the next action. Usage The FollowerAgent is available in follower mode. You can find more details in the documentation . It also uses differnt Session and Processor to handle the user's instructions. The step-wise instructions are provided by the user in the in a json file, which is then parsed by the FollowerAgent to execute the actions. An example of the json file is shown below: { \"task\": \"Type in a bold text of 'Test For Fun'\", \"steps\": [ \"1.type in 'Test For Fun'\", \"2.select the text of 'Test For Fun'\", \"3.click on the bold\" ], \"object\": \"draft.docx\" } Reference Bases: AppAgent The FollowerAgent class the manager of a FollowedAgent that follows the step-by-step instructions for action execution within an application. It is a subclass of the AppAgent, which completes the action execution within the application. Initialize the FollowAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The root name of the app. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. app_info_prompt ( str ) \u2013 The app information prompt file path. Source code in agents/agent/follower_agent.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def __init__ ( self , name : str , process_name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , app_info_prompt : str , ): \"\"\" Initialize the FollowAgent. :param name: The name of the agent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param app_info_prompt: The app information prompt file path. \"\"\" super () . __init__ ( name = name , process_name = process_name , app_root_name = app_root_name , is_visual = is_visual , main_prompt = main_prompt , example_prompt = example_prompt , api_prompt = api_prompt , skip_prompter = True , ) self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_info_prompt , app_root_name , ) get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_info_prompt , app_root_name = '' ) Get the prompter for the follower agent. Parameters: is_visual ( str ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. app_info_prompt ( str ) \u2013 The app information prompt file path. app_root_name ( str , default: '' ) \u2013 The root name of the app. Returns: FollowerAgentPrompter \u2013 The prompter instance. Source code in agents/agent/follower_agent.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def get_prompter ( self , is_visual : str , main_prompt : str , example_prompt : str , api_prompt : str , app_info_prompt : str , app_root_name : str = \"\" , ) -> FollowerAgentPrompter : \"\"\" Get the prompter for the follower agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param app_info_prompt: The app information prompt file path. :param app_root_name: The root name of the app. :return: The prompter instance. \"\"\" return FollowerAgentPrompter ( is_visual , main_prompt , example_prompt , api_prompt , app_info_prompt , app_root_name , ) message_constructor ( dynamic_examples , dynamic_knowledge , image_list , control_info , prev_subtask , plan , request , subtask , host_message , current_state , state_diff , blackboard_prompt , include_last_screenshot ) Construct the prompt message for the FollowAgent. Parameters: dynamic_examples ( str ) \u2013 The dynamic examples retrieved from the self-demonstration and human demonstration. dynamic_knowledge ( str ) \u2013 The dynamic knowledge retrieved from the self-demonstration and human demonstration. image_list ( List [ str ] ) \u2013 The list of screenshot images. control_info ( str ) \u2013 The control information. prev_subtask ( List [ str ] ) \u2013 The previous subtask. plan ( List [ str ] ) \u2013 The plan. request ( str ) \u2013 The request. subtask ( str ) \u2013 The subtask. host_message ( List [ str ] ) \u2013 The host message. current_state ( Dict [ str , str ] ) \u2013 The current state of the app. state_diff ( Dict [ str , str ] ) \u2013 The state difference between the current state and the previous state. blackboard_prompt ( List [ Dict [ str , str ]] ) \u2013 The blackboard prompt. include_last_screenshot ( bool ) \u2013 The flag indicating whether the last screenshot should be included. Returns: List [ Dict [ str , str ]] \u2013 The prompt message. Source code in agents/agent/follower_agent.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def message_constructor ( self , dynamic_examples : str , dynamic_knowledge : str , image_list : List [ str ], control_info : str , prev_subtask : List [ str ], plan : List [ str ], request : str , subtask : str , host_message : List [ str ], current_state : Dict [ str , str ], state_diff : Dict [ str , str ], blackboard_prompt : List [ Dict [ str , str ]], include_last_screenshot : bool , ) -> List [ Dict [ str , str ]]: \"\"\" Construct the prompt message for the FollowAgent. :param dynamic_examples: The dynamic examples retrieved from the self-demonstration and human demonstration. :param dynamic_knowledge: The dynamic knowledge retrieved from the self-demonstration and human demonstration. :param image_list: The list of screenshot images. :param control_info: The control information. :param prev_subtask: The previous subtask. :param plan: The plan. :param request: The request. :param subtask: The subtask. :param host_message: The host message. :param current_state: The current state of the app. :param state_diff: The state difference between the current state and the previous state. :param blackboard_prompt: The blackboard prompt. :param include_last_screenshot: The flag indicating whether the last screenshot should be included. :return: The prompt message. \"\"\" followagent_prompt_system_message = self . prompter . system_prompt_construction ( dynamic_examples ) followagent_prompt_user_message = self . prompter . user_content_construction ( image_list = image_list , control_item = control_info , prev_subtask = prev_subtask , prev_plan = plan , user_request = request , subtask = subtask , current_application = self . _process_name , host_message = host_message , retrieved_docs = dynamic_knowledge , current_state = current_state , state_diff = state_diff , include_last_screenshot = include_last_screenshot , ) followagent_prompt_message = self . prompter . prompt_construction ( followagent_prompt_system_message , followagent_prompt_user_message ) return followagent_prompt_message","title":"FollowerAgent"},{"location":"agents/follower_agent/#follower-agent","text":"The FollowerAgent is inherited from the AppAgent and is responsible for following the user's instructions to perform specific tasks within the application. The FollowerAgent is designed to execute a series of actions based on the user's guidance. It is particularly useful for software testing, when clear instructions are provided to validate the application's behavior.","title":"Follower Agent \ud83d\udeb6\ud83c\udffd\u200d\u2642\ufe0f"},{"location":"agents/follower_agent/#different-from-the-appagent","text":"The FollowerAgent shares most of the functionalities with the AppAgent , but it is designed to follow the step-by-step instructions provided by the user, instead of does its own reasoning to determine the next action.","title":"Different from the AppAgent"},{"location":"agents/follower_agent/#usage","text":"The FollowerAgent is available in follower mode. You can find more details in the documentation . It also uses differnt Session and Processor to handle the user's instructions. The step-wise instructions are provided by the user in the in a json file, which is then parsed by the FollowerAgent to execute the actions. An example of the json file is shown below: { \"task\": \"Type in a bold text of 'Test For Fun'\", \"steps\": [ \"1.type in 'Test For Fun'\", \"2.select the text of 'Test For Fun'\", \"3.click on the bold\" ], \"object\": \"draft.docx\" }","title":"Usage"},{"location":"agents/follower_agent/#reference","text":"Bases: AppAgent The FollowerAgent class the manager of a FollowedAgent that follows the step-by-step instructions for action execution within an application. It is a subclass of the AppAgent, which completes the action execution within the application. Initialize the FollowAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The root name of the app. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. app_info_prompt ( str ) \u2013 The app information prompt file path. Source code in agents/agent/follower_agent.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def __init__ ( self , name : str , process_name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , app_info_prompt : str , ): \"\"\" Initialize the FollowAgent. :param name: The name of the agent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param app_info_prompt: The app information prompt file path. \"\"\" super () . __init__ ( name = name , process_name = process_name , app_root_name = app_root_name , is_visual = is_visual , main_prompt = main_prompt , example_prompt = example_prompt , api_prompt = api_prompt , skip_prompter = True , ) self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt , app_info_prompt , app_root_name , )","title":"Reference"},{"location":"agents/follower_agent/#agents.agent.follower_agent.FollowerAgent.get_prompter","text":"Get the prompter for the follower agent. Parameters: is_visual ( str ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. app_info_prompt ( str ) \u2013 The app information prompt file path. app_root_name ( str , default: '' ) \u2013 The root name of the app. Returns: FollowerAgentPrompter \u2013 The prompter instance. Source code in agents/agent/follower_agent.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def get_prompter ( self , is_visual : str , main_prompt : str , example_prompt : str , api_prompt : str , app_info_prompt : str , app_root_name : str = \"\" , ) -> FollowerAgentPrompter : \"\"\" Get the prompter for the follower agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :param app_info_prompt: The app information prompt file path. :param app_root_name: The root name of the app. :return: The prompter instance. \"\"\" return FollowerAgentPrompter ( is_visual , main_prompt , example_prompt , api_prompt , app_info_prompt , app_root_name , )","title":"get_prompter"},{"location":"agents/follower_agent/#agents.agent.follower_agent.FollowerAgent.message_constructor","text":"Construct the prompt message for the FollowAgent. Parameters: dynamic_examples ( str ) \u2013 The dynamic examples retrieved from the self-demonstration and human demonstration. dynamic_knowledge ( str ) \u2013 The dynamic knowledge retrieved from the self-demonstration and human demonstration. image_list ( List [ str ] ) \u2013 The list of screenshot images. control_info ( str ) \u2013 The control information. prev_subtask ( List [ str ] ) \u2013 The previous subtask. plan ( List [ str ] ) \u2013 The plan. request ( str ) \u2013 The request. subtask ( str ) \u2013 The subtask. host_message ( List [ str ] ) \u2013 The host message. current_state ( Dict [ str , str ] ) \u2013 The current state of the app. state_diff ( Dict [ str , str ] ) \u2013 The state difference between the current state and the previous state. blackboard_prompt ( List [ Dict [ str , str ]] ) \u2013 The blackboard prompt. include_last_screenshot ( bool ) \u2013 The flag indicating whether the last screenshot should be included. Returns: List [ Dict [ str , str ]] \u2013 The prompt message. Source code in agents/agent/follower_agent.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def message_constructor ( self , dynamic_examples : str , dynamic_knowledge : str , image_list : List [ str ], control_info : str , prev_subtask : List [ str ], plan : List [ str ], request : str , subtask : str , host_message : List [ str ], current_state : Dict [ str , str ], state_diff : Dict [ str , str ], blackboard_prompt : List [ Dict [ str , str ]], include_last_screenshot : bool , ) -> List [ Dict [ str , str ]]: \"\"\" Construct the prompt message for the FollowAgent. :param dynamic_examples: The dynamic examples retrieved from the self-demonstration and human demonstration. :param dynamic_knowledge: The dynamic knowledge retrieved from the self-demonstration and human demonstration. :param image_list: The list of screenshot images. :param control_info: The control information. :param prev_subtask: The previous subtask. :param plan: The plan. :param request: The request. :param subtask: The subtask. :param host_message: The host message. :param current_state: The current state of the app. :param state_diff: The state difference between the current state and the previous state. :param blackboard_prompt: The blackboard prompt. :param include_last_screenshot: The flag indicating whether the last screenshot should be included. :return: The prompt message. \"\"\" followagent_prompt_system_message = self . prompter . system_prompt_construction ( dynamic_examples ) followagent_prompt_user_message = self . prompter . user_content_construction ( image_list = image_list , control_item = control_info , prev_subtask = prev_subtask , prev_plan = plan , user_request = request , subtask = subtask , current_application = self . _process_name , host_message = host_message , retrieved_docs = dynamic_knowledge , current_state = current_state , state_diff = state_diff , include_last_screenshot = include_last_screenshot , ) followagent_prompt_message = self . prompter . prompt_construction ( followagent_prompt_system_message , followagent_prompt_user_message ) return followagent_prompt_message","title":"message_constructor"},{"location":"agents/host_agent/","text":"HostAgent \ud83e\udd16 The HostAgent assumes three primary responsibilities: Task Decomposition. Given a user's natural language input, HostAgent identifies the underlying task goal and decomposes it into a dependency-ordered subtask graph. Application Lifecycle Management. For each subtask, HostAgent inspects system process metadata (via UIA APIs) to determine whether the target application is running. If not, it launches the program and registers it with the runtime. AppAgent Instantiation. HostAgent spawns the corresponding AppAgent for each active application, providing it with task context, memory references, and relevant toolchains (e.g., APIs, documentation). Task Scheduling and Control. The global execution plan is serialized into a finite state machine (FSM), allowing HostAgent to enforce execution order, detect failures, and resolve dependencies across agents. Shared State Communication. HostAgent reads from and writes to a global blackboard, enabling inter-agent communication and system-level observability for debugging and replay. Below is a diagram illustrating the HostAgent architecture and its interactions with other components: The HostAgent activates its Processor to process the user's request and decompose it into sub-tasks. Each sub-task is then assigned to an AppAgent for execution. The HostAgent monitors the progress of the AppAgents and ensures the successful completion of the user's request. HostAgent Input The HostAgent receives the following inputs: Input Description Type User Request The user's request in natural language. String Application Information Information about the existing active applications. List of Strings Desktop Screenshots Screenshots of the desktop to provide context to the HostAgent . Image Previous Sub-Tasks The previous sub-tasks and their completion status. List of Strings Previous Plan The previous plan for the following sub-tasks. List of Strings Blackboard The shared memory space for storing and sharing information among the agents. Dictionary By processing these inputs, the HostAgent determines the appropriate application to fulfill the user's request and orchestrates the AppAgents to execute the necessary actions. HostAgent Output With the inputs provided, the HostAgent generates the following outputs: Output Description Type Observation The observation of current desktop screenshots. String Thought The logical reasoning process of the HostAgent . String Current Sub-Task The current sub-task to be executed by the AppAgent . String Message The message to be sent to the AppAgent for the completion of the sub-task. String ControlLabel The index of the selected application to execute the sub-task. String ControlText The name of the selected application to execute the sub-task. String Plan The plan for the following sub-tasks after the current sub-task. List of Strings Status The status of the agent, mapped to the AgentState . String Comment Additional comments or information provided to the user. String Questions The questions to be asked to the user for additional information. List of Strings Bash The bash command to be executed by the HostAgent . It can be used to open applications or execute system commands. String Below is an example of the HostAgent output: { \"Observation\": \"Desktop screenshot\", \"Thought\": \"Logical reasoning process\", \"Current Sub-Task\": \"Sub-task description\", \"Message\": \"Message to AppAgent\", \"ControlLabel\": \"Application index\", \"ControlText\": \"Application name\", \"Plan\": [\"Sub-task 1\", \"Sub-task 2\"], \"Status\": \"AgentState\", \"Comment\": \"Additional comments\", \"Questions\": [\"Question 1\", \"Question 2\"], \"Bash\": \"Bash command\" } Info The HostAgent output is formatted as a JSON object by LLMs and can be parsed by the json.loads method in Python. HostAgent State The HostAgent progresses through different states, as defined in the ufo/agents/states/host_agent_states.py module. The states include: State Description CONTINUE Default state for action planning and execution. PENDING Invoked for safety-critical actions (e.g., destructive operations); requires user confirmation. FINISH Task completed; execution ends. FAIL Irrecoverable failure detected (e.g., application crash, permission error). The state machine diagram for the HostAgent is shown below: The HostAgent transitions between these states based on the user's request, the application information, and the progress of the AppAgents in executing the sub-tasks. Task Decomposition Upon receiving the user's request, the HostAgent decomposes it into sub-tasks and assigns each sub-task to an AppAgent for execution. The HostAgent determines the appropriate application to fulfill the user's request based on the application information and the user's request. It then orchestrates the AppAgents to execute the necessary actions to complete the sub-tasks. We show the task decomposition process in the following figure: Creating and Registering AppAgents When the HostAgent determines the need for a new AppAgent to fulfill a sub-task, it creates an instance of the AppAgent and registers it with the HostAgent , by calling the create_subagent method: def create_subagent( self, agent_type: str, agent_name: str, process_name: str, app_root_name: str, is_visual: bool, main_prompt: str, example_prompt: str, api_prompt: str, *args, **kwargs, ) -> BasicAgent: \"\"\" Create an SubAgent hosted by the HostAgent. :param agent_type: The type of the agent to create. :param agent_name: The name of the SubAgent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :return: The created SubAgent. \"\"\" app_agent = self.agent_factory.create_agent( agent_type, agent_name, process_name, app_root_name, is_visual, main_prompt, example_prompt, api_prompt, *args, **kwargs, ) self.appagent_dict[agent_name] = app_agent app_agent.host = self self._active_appagent = app_agent return app_agent The HostAgent then assigns the sub-task to the AppAgent for execution and monitors its progress. Reference Bases: BasicAgent The HostAgent class the manager of AppAgents. Initialize the HostAgent. :name: The name of the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. Source code in agents/agent/host_agent.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def __init__ ( self , name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ) -> None : \"\"\" Initialize the HostAgent. :name: The name of the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. \"\"\" super () . __init__ ( name = name ) self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) self . offline_doc_retriever = None self . online_doc_retriever = None self . experience_retriever = None self . human_demonstration_retriever = None self . agent_factory = AgentFactory () self . appagent_dict = {} self . _active_appagent = None self . _blackboard = Blackboard () self . set_state ( self . default_state ) self . Puppeteer = self . create_puppeteer_interface () blackboard property Get the blackboard. default_state property Get the default state. status_manager property Get the status manager. sub_agent_amount property Get the amount of sub agents. Returns: int \u2013 The amount of sub agents. create_app_agent ( application_window_name , application_root_name , request , mode ) Create the app agent for the host agent. Parameters: application_window_name ( str ) \u2013 The name of the application window. application_root_name ( str ) \u2013 The name of the application root. request ( str ) \u2013 The user request. mode ( str ) \u2013 The mode of the session. Returns: AppAgent \u2013 The app agent. Source code in agents/agent/host_agent.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 def create_app_agent ( self , application_window_name : str , application_root_name : str , request : str , mode : str , ) -> AppAgent : \"\"\" Create the app agent for the host agent. :param application_window_name: The name of the application window. :param application_root_name: The name of the application root. :param request: The user request. :param mode: The mode of the session. :return: The app agent. \"\"\" if configs . get ( \"ACTION_SEQUENCE\" , False ): example_prompt = configs [ \"APPAGENT_EXAMPLE_PROMPT_AS\" ] else : example_prompt = configs [ \"APPAGENT_EXAMPLE_PROMPT\" ] if mode in [ \"normal\" , \"batch_normal\" , \"follower\" ]: agent_name = ( \"AppAgent/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) if mode == \"normal\" else \"BatchAgent/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) ) app_agent : AppAgent = self . create_subagent ( agent_type = \"app\" , agent_name = agent_name , process_name = application_window_name , app_root_name = application_root_name , is_visual = configs [ \"APP_AGENT\" ][ \"VISUAL_MODE\" ], main_prompt = configs [ \"APPAGENT_PROMPT\" ], example_prompt = example_prompt , api_prompt = configs [ \"API_PROMPT\" ], mode = mode , ) elif mode in [ \"normal_operator\" , \"batch_normal_operator\" ]: agent_name = ( \"OpenAIOperator/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) if mode == \"normal_operator\" else \"BatchOpenAIOperator/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) ) app_agent : OpenAIOperatorAgent = self . create_subagent ( \"operator\" , agent_name = agent_name , process_name = application_window_name , app_root_name = application_root_name , ) else : raise ValueError ( f \"The { mode } mode is not supported.\" ) # Create the COM receiver for the app agent. if configs . get ( \"USE_APIS\" , False ): app_agent . Puppeteer . receiver_manager . create_api_receiver ( application_root_name , application_window_name ) # Provision the context for the app agent, including the all retrievers. app_agent . context_provision ( request ) return app_agent create_puppeteer_interface () Create the Puppeteer interface to automate the app. Returns: AppPuppeteer \u2013 The Puppeteer interface. Source code in agents/agent/host_agent.py 209 210 211 212 213 214 def create_puppeteer_interface ( self ) -> puppeteer . AppPuppeteer : \"\"\" Create the Puppeteer interface to automate the app. :return: The Puppeteer interface. \"\"\" return puppeteer . AppPuppeteer ( \"\" , \"\" ) create_subagent ( agent_type , agent_name , process_name , app_root_name , * args , ** kwargs ) Create an SubAgent hosted by the HostAgent. Parameters: agent_type ( str ) \u2013 The type of the agent to create. agent_name ( str ) \u2013 The name of the SubAgent. process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The root name of the app. Returns: BasicAgent \u2013 The created SubAgent. Source code in agents/agent/host_agent.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def create_subagent ( self , agent_type : str , agent_name : str , process_name : str , app_root_name : str , * args , ** kwargs , ) -> BasicAgent : \"\"\" Create an SubAgent hosted by the HostAgent. :param agent_type: The type of the agent to create. :param agent_name: The name of the SubAgent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :return: The created SubAgent. \"\"\" app_agent = self . agent_factory . create_agent ( agent_type , agent_name , process_name , app_root_name , # is_visual, # main_prompt, # example_prompt, # api_prompt, * args , ** kwargs , ) self . appagent_dict [ agent_name ] = app_agent app_agent . host = self self . _active_appagent = app_agent return app_agent get_active_appagent () Get the active app agent. Returns: AppAgent \u2013 The active app agent. Source code in agents/agent/host_agent.py 146 147 148 149 150 151 def get_active_appagent ( self ) -> AppAgent : \"\"\" Get the active app agent. :return: The active app agent. \"\"\" return self . _active_appagent get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) Get the prompt for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. Returns: HostAgentPrompter \u2013 The prompter instance. Source code in agents/agent/host_agent.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ) -> HostAgentPrompter : \"\"\" Get the prompt for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :return: The prompter instance. \"\"\" return HostAgentPrompter ( is_visual , main_prompt , example_prompt , api_prompt ) message_constructor ( image_list , os_info , plan , prev_subtask , request , blackboard_prompt ) Construct the message. Parameters: image_list ( List [ str ] ) \u2013 The list of screenshot images. os_info ( str ) \u2013 The OS information. prev_subtask ( List [ Dict [ str , str ]] ) \u2013 The previous subtask. plan ( List [ str ] ) \u2013 The plan. request ( str ) \u2013 The request. Returns: List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]] \u2013 The message. Source code in agents/agent/host_agent.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 def message_constructor ( self , image_list : List [ str ], os_info : str , plan : List [ str ], prev_subtask : List [ Dict [ str , str ]], request : str , blackboard_prompt : List [ Dict [ str , str ]], ) -> List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]]: \"\"\" Construct the message. :param image_list: The list of screenshot images. :param os_info: The OS information. :param prev_subtask: The previous subtask. :param plan: The plan. :param request: The request. :return: The message. \"\"\" hostagent_prompt_system_message = self . prompter . system_prompt_construction () hostagent_prompt_user_message = self . prompter . user_content_construction ( image_list = image_list , control_item = os_info , prev_subtask = prev_subtask , prev_plan = plan , user_request = request , ) if blackboard_prompt : hostagent_prompt_user_message = ( blackboard_prompt + hostagent_prompt_user_message ) hostagent_prompt_message = self . prompter . prompt_construction ( hostagent_prompt_system_message , hostagent_prompt_user_message ) return hostagent_prompt_message print_response ( response_dict ) Print the response. Parameters: response_dict ( Dict ) \u2013 The response dictionary to print. Source code in agents/agent/host_agent.py 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def print_response ( self , response_dict : Dict ) -> None : \"\"\" Print the response. :param response_dict: The response dictionary to print. \"\"\" application = response_dict . get ( \"ControlText\" ) if not application : application = \"[The required application needs to be opened.]\" observation = response_dict . get ( \"Observation\" ) thought = response_dict . get ( \"Thought\" ) bash_command = response_dict . get ( \"Bash\" , None ) subtask = response_dict . get ( \"CurrentSubtask\" ) # Convert the message from a list to a string. message = list ( response_dict . get ( \"Message\" , \"\" )) message = \" \\n \" . join ( message ) # Concatenate the subtask with the plan and convert the plan from a list to a string. plan = list ( response_dict . get ( \"Plan\" )) plan = [ subtask ] + plan plan = \" \\n \" . join ([ f \"( { i + 1 } ) \" + str ( item ) for i , item in enumerate ( plan )]) status = response_dict . get ( \"Status\" ) comment = response_dict . get ( \"Comment\" ) utils . print_with_color ( \"Observations\ud83d\udc40: {observation} \" . format ( observation = observation ), \"cyan\" ) utils . print_with_color ( \"Thoughts\ud83d\udca1: {thought} \" . format ( thought = thought ), \"green\" ) if bash_command : utils . print_with_color ( \"Running Bash Command\ud83d\udd27: {bash} \" . format ( bash = bash_command ), \"yellow\" ) utils . print_with_color ( \"Plans\ud83d\udcda: {plan} \" . format ( plan = plan ), \"cyan\" , ) utils . print_with_color ( \"Next Selected application\ud83d\udcf2: {application} \" . format ( application = application ), \"yellow\" , ) utils . print_with_color ( \"Messages to AppAgent\ud83d\udce9: {message} \" . format ( message = message ), \"cyan\" ) utils . print_with_color ( \"Status\ud83d\udcca: {status} \" . format ( status = status ), \"blue\" ) utils . print_with_color ( \"Comment\ud83d\udcac: {comment} \" . format ( comment = comment ), \"green\" ) process ( context ) Process the agent. Parameters: context ( Context ) \u2013 The context. Source code in agents/agent/host_agent.py 198 199 200 201 202 203 204 205 206 207 def process ( self , context : Context ) -> None : \"\"\" Process the agent. :param context: The context. \"\"\" self . processor = HostAgentProcessor ( agent = self , context = context ) self . processor . process () # Sync the status with the processor. self . status = self . processor . status process_comfirmation () TODO: Process the confirmation. Source code in agents/agent/host_agent.py 294 295 296 297 298 def process_comfirmation ( self ) -> None : \"\"\" TODO: Process the confirmation. \"\"\" pass","title":"HostAgent"},{"location":"agents/host_agent/#hostagent","text":"The HostAgent assumes three primary responsibilities: Task Decomposition. Given a user's natural language input, HostAgent identifies the underlying task goal and decomposes it into a dependency-ordered subtask graph. Application Lifecycle Management. For each subtask, HostAgent inspects system process metadata (via UIA APIs) to determine whether the target application is running. If not, it launches the program and registers it with the runtime. AppAgent Instantiation. HostAgent spawns the corresponding AppAgent for each active application, providing it with task context, memory references, and relevant toolchains (e.g., APIs, documentation). Task Scheduling and Control. The global execution plan is serialized into a finite state machine (FSM), allowing HostAgent to enforce execution order, detect failures, and resolve dependencies across agents. Shared State Communication. HostAgent reads from and writes to a global blackboard, enabling inter-agent communication and system-level observability for debugging and replay. Below is a diagram illustrating the HostAgent architecture and its interactions with other components:","title":"HostAgent \ud83e\udd16"},{"location":"agents/host_agent/#hostagent-input","text":"The HostAgent receives the following inputs: Input Description Type User Request The user's request in natural language. String Application Information Information about the existing active applications. List of Strings Desktop Screenshots Screenshots of the desktop to provide context to the HostAgent . Image Previous Sub-Tasks The previous sub-tasks and their completion status. List of Strings Previous Plan The previous plan for the following sub-tasks. List of Strings Blackboard The shared memory space for storing and sharing information among the agents. Dictionary By processing these inputs, the HostAgent determines the appropriate application to fulfill the user's request and orchestrates the AppAgents to execute the necessary actions.","title":"HostAgent Input"},{"location":"agents/host_agent/#hostagent-output","text":"With the inputs provided, the HostAgent generates the following outputs: Output Description Type Observation The observation of current desktop screenshots. String Thought The logical reasoning process of the HostAgent . String Current Sub-Task The current sub-task to be executed by the AppAgent . String Message The message to be sent to the AppAgent for the completion of the sub-task. String ControlLabel The index of the selected application to execute the sub-task. String ControlText The name of the selected application to execute the sub-task. String Plan The plan for the following sub-tasks after the current sub-task. List of Strings Status The status of the agent, mapped to the AgentState . String Comment Additional comments or information provided to the user. String Questions The questions to be asked to the user for additional information. List of Strings Bash The bash command to be executed by the HostAgent . It can be used to open applications or execute system commands. String Below is an example of the HostAgent output: { \"Observation\": \"Desktop screenshot\", \"Thought\": \"Logical reasoning process\", \"Current Sub-Task\": \"Sub-task description\", \"Message\": \"Message to AppAgent\", \"ControlLabel\": \"Application index\", \"ControlText\": \"Application name\", \"Plan\": [\"Sub-task 1\", \"Sub-task 2\"], \"Status\": \"AgentState\", \"Comment\": \"Additional comments\", \"Questions\": [\"Question 1\", \"Question 2\"], \"Bash\": \"Bash command\" } Info The HostAgent output is formatted as a JSON object by LLMs and can be parsed by the json.loads method in Python.","title":"HostAgent Output"},{"location":"agents/host_agent/#hostagent-state","text":"The HostAgent progresses through different states, as defined in the ufo/agents/states/host_agent_states.py module. The states include: State Description CONTINUE Default state for action planning and execution. PENDING Invoked for safety-critical actions (e.g., destructive operations); requires user confirmation. FINISH Task completed; execution ends. FAIL Irrecoverable failure detected (e.g., application crash, permission error). The state machine diagram for the HostAgent is shown below:","title":"HostAgent State"},{"location":"agents/host_agent/#task-decomposition","text":"Upon receiving the user's request, the HostAgent decomposes it into sub-tasks and assigns each sub-task to an AppAgent for execution. The HostAgent determines the appropriate application to fulfill the user's request based on the application information and the user's request. It then orchestrates the AppAgents to execute the necessary actions to complete the sub-tasks. We show the task decomposition process in the following figure:","title":"Task Decomposition"},{"location":"agents/host_agent/#creating-and-registering-appagents","text":"When the HostAgent determines the need for a new AppAgent to fulfill a sub-task, it creates an instance of the AppAgent and registers it with the HostAgent , by calling the create_subagent method: def create_subagent( self, agent_type: str, agent_name: str, process_name: str, app_root_name: str, is_visual: bool, main_prompt: str, example_prompt: str, api_prompt: str, *args, **kwargs, ) -> BasicAgent: \"\"\" Create an SubAgent hosted by the HostAgent. :param agent_type: The type of the agent to create. :param agent_name: The name of the SubAgent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :return: The created SubAgent. \"\"\" app_agent = self.agent_factory.create_agent( agent_type, agent_name, process_name, app_root_name, is_visual, main_prompt, example_prompt, api_prompt, *args, **kwargs, ) self.appagent_dict[agent_name] = app_agent app_agent.host = self self._active_appagent = app_agent return app_agent The HostAgent then assigns the sub-task to the AppAgent for execution and monitors its progress.","title":"Creating and Registering AppAgents"},{"location":"agents/host_agent/#reference","text":"Bases: BasicAgent The HostAgent class the manager of AppAgents. Initialize the HostAgent. :name: The name of the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. Source code in agents/agent/host_agent.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def __init__ ( self , name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ) -> None : \"\"\" Initialize the HostAgent. :name: The name of the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. \"\"\" super () . __init__ ( name = name ) self . prompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) self . offline_doc_retriever = None self . online_doc_retriever = None self . experience_retriever = None self . human_demonstration_retriever = None self . agent_factory = AgentFactory () self . appagent_dict = {} self . _active_appagent = None self . _blackboard = Blackboard () self . set_state ( self . default_state ) self . Puppeteer = self . create_puppeteer_interface ()","title":"Reference"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.blackboard","text":"Get the blackboard.","title":"blackboard"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.default_state","text":"Get the default state.","title":"default_state"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.status_manager","text":"Get the status manager.","title":"status_manager"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.sub_agent_amount","text":"Get the amount of sub agents. Returns: int \u2013 The amount of sub agents.","title":"sub_agent_amount"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.create_app_agent","text":"Create the app agent for the host agent. Parameters: application_window_name ( str ) \u2013 The name of the application window. application_root_name ( str ) \u2013 The name of the application root. request ( str ) \u2013 The user request. mode ( str ) \u2013 The mode of the session. Returns: AppAgent \u2013 The app agent. Source code in agents/agent/host_agent.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 def create_app_agent ( self , application_window_name : str , application_root_name : str , request : str , mode : str , ) -> AppAgent : \"\"\" Create the app agent for the host agent. :param application_window_name: The name of the application window. :param application_root_name: The name of the application root. :param request: The user request. :param mode: The mode of the session. :return: The app agent. \"\"\" if configs . get ( \"ACTION_SEQUENCE\" , False ): example_prompt = configs [ \"APPAGENT_EXAMPLE_PROMPT_AS\" ] else : example_prompt = configs [ \"APPAGENT_EXAMPLE_PROMPT\" ] if mode in [ \"normal\" , \"batch_normal\" , \"follower\" ]: agent_name = ( \"AppAgent/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) if mode == \"normal\" else \"BatchAgent/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) ) app_agent : AppAgent = self . create_subagent ( agent_type = \"app\" , agent_name = agent_name , process_name = application_window_name , app_root_name = application_root_name , is_visual = configs [ \"APP_AGENT\" ][ \"VISUAL_MODE\" ], main_prompt = configs [ \"APPAGENT_PROMPT\" ], example_prompt = example_prompt , api_prompt = configs [ \"API_PROMPT\" ], mode = mode , ) elif mode in [ \"normal_operator\" , \"batch_normal_operator\" ]: agent_name = ( \"OpenAIOperator/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) if mode == \"normal_operator\" else \"BatchOpenAIOperator/ {root} / {process} \" . format ( root = application_root_name , process = application_window_name ) ) app_agent : OpenAIOperatorAgent = self . create_subagent ( \"operator\" , agent_name = agent_name , process_name = application_window_name , app_root_name = application_root_name , ) else : raise ValueError ( f \"The { mode } mode is not supported.\" ) # Create the COM receiver for the app agent. if configs . get ( \"USE_APIS\" , False ): app_agent . Puppeteer . receiver_manager . create_api_receiver ( application_root_name , application_window_name ) # Provision the context for the app agent, including the all retrievers. app_agent . context_provision ( request ) return app_agent","title":"create_app_agent"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.create_puppeteer_interface","text":"Create the Puppeteer interface to automate the app. Returns: AppPuppeteer \u2013 The Puppeteer interface. Source code in agents/agent/host_agent.py 209 210 211 212 213 214 def create_puppeteer_interface ( self ) -> puppeteer . AppPuppeteer : \"\"\" Create the Puppeteer interface to automate the app. :return: The Puppeteer interface. \"\"\" return puppeteer . AppPuppeteer ( \"\" , \"\" )","title":"create_puppeteer_interface"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.create_subagent","text":"Create an SubAgent hosted by the HostAgent. Parameters: agent_type ( str ) \u2013 The type of the agent to create. agent_name ( str ) \u2013 The name of the SubAgent. process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The root name of the app. Returns: BasicAgent \u2013 The created SubAgent. Source code in agents/agent/host_agent.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def create_subagent ( self , agent_type : str , agent_name : str , process_name : str , app_root_name : str , * args , ** kwargs , ) -> BasicAgent : \"\"\" Create an SubAgent hosted by the HostAgent. :param agent_type: The type of the agent to create. :param agent_name: The name of the SubAgent. :param process_name: The process name of the app. :param app_root_name: The root name of the app. :return: The created SubAgent. \"\"\" app_agent = self . agent_factory . create_agent ( agent_type , agent_name , process_name , app_root_name , # is_visual, # main_prompt, # example_prompt, # api_prompt, * args , ** kwargs , ) self . appagent_dict [ agent_name ] = app_agent app_agent . host = self self . _active_appagent = app_agent return app_agent","title":"create_subagent"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.get_active_appagent","text":"Get the active app agent. Returns: AppAgent \u2013 The active app agent. Source code in agents/agent/host_agent.py 146 147 148 149 150 151 def get_active_appagent ( self ) -> AppAgent : \"\"\" Get the active app agent. :return: The active app agent. \"\"\" return self . _active_appagent","title":"get_active_appagent"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.get_prompter","text":"Get the prompt for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt file path. example_prompt ( str ) \u2013 The example prompt file path. api_prompt ( str ) \u2013 The API prompt file path. Returns: HostAgentPrompter \u2013 The prompter instance. Source code in agents/agent/host_agent.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ) -> HostAgentPrompter : \"\"\" Get the prompt for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt file path. :param example_prompt: The example prompt file path. :param api_prompt: The API prompt file path. :return: The prompter instance. \"\"\" return HostAgentPrompter ( is_visual , main_prompt , example_prompt , api_prompt )","title":"get_prompter"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.message_constructor","text":"Construct the message. Parameters: image_list ( List [ str ] ) \u2013 The list of screenshot images. os_info ( str ) \u2013 The OS information. prev_subtask ( List [ Dict [ str , str ]] ) \u2013 The previous subtask. plan ( List [ str ] ) \u2013 The plan. request ( str ) \u2013 The request. Returns: List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]] \u2013 The message. Source code in agents/agent/host_agent.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 def message_constructor ( self , image_list : List [ str ], os_info : str , plan : List [ str ], prev_subtask : List [ Dict [ str , str ]], request : str , blackboard_prompt : List [ Dict [ str , str ]], ) -> List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]]: \"\"\" Construct the message. :param image_list: The list of screenshot images. :param os_info: The OS information. :param prev_subtask: The previous subtask. :param plan: The plan. :param request: The request. :return: The message. \"\"\" hostagent_prompt_system_message = self . prompter . system_prompt_construction () hostagent_prompt_user_message = self . prompter . user_content_construction ( image_list = image_list , control_item = os_info , prev_subtask = prev_subtask , prev_plan = plan , user_request = request , ) if blackboard_prompt : hostagent_prompt_user_message = ( blackboard_prompt + hostagent_prompt_user_message ) hostagent_prompt_message = self . prompter . prompt_construction ( hostagent_prompt_system_message , hostagent_prompt_user_message ) return hostagent_prompt_message","title":"message_constructor"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.print_response","text":"Print the response. Parameters: response_dict ( Dict ) \u2013 The response dictionary to print. Source code in agents/agent/host_agent.py 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def print_response ( self , response_dict : Dict ) -> None : \"\"\" Print the response. :param response_dict: The response dictionary to print. \"\"\" application = response_dict . get ( \"ControlText\" ) if not application : application = \"[The required application needs to be opened.]\" observation = response_dict . get ( \"Observation\" ) thought = response_dict . get ( \"Thought\" ) bash_command = response_dict . get ( \"Bash\" , None ) subtask = response_dict . get ( \"CurrentSubtask\" ) # Convert the message from a list to a string. message = list ( response_dict . get ( \"Message\" , \"\" )) message = \" \\n \" . join ( message ) # Concatenate the subtask with the plan and convert the plan from a list to a string. plan = list ( response_dict . get ( \"Plan\" )) plan = [ subtask ] + plan plan = \" \\n \" . join ([ f \"( { i + 1 } ) \" + str ( item ) for i , item in enumerate ( plan )]) status = response_dict . get ( \"Status\" ) comment = response_dict . get ( \"Comment\" ) utils . print_with_color ( \"Observations\ud83d\udc40: {observation} \" . format ( observation = observation ), \"cyan\" ) utils . print_with_color ( \"Thoughts\ud83d\udca1: {thought} \" . format ( thought = thought ), \"green\" ) if bash_command : utils . print_with_color ( \"Running Bash Command\ud83d\udd27: {bash} \" . format ( bash = bash_command ), \"yellow\" ) utils . print_with_color ( \"Plans\ud83d\udcda: {plan} \" . format ( plan = plan ), \"cyan\" , ) utils . print_with_color ( \"Next Selected application\ud83d\udcf2: {application} \" . format ( application = application ), \"yellow\" , ) utils . print_with_color ( \"Messages to AppAgent\ud83d\udce9: {message} \" . format ( message = message ), \"cyan\" ) utils . print_with_color ( \"Status\ud83d\udcca: {status} \" . format ( status = status ), \"blue\" ) utils . print_with_color ( \"Comment\ud83d\udcac: {comment} \" . format ( comment = comment ), \"green\" )","title":"print_response"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.process","text":"Process the agent. Parameters: context ( Context ) \u2013 The context. Source code in agents/agent/host_agent.py 198 199 200 201 202 203 204 205 206 207 def process ( self , context : Context ) -> None : \"\"\" Process the agent. :param context: The context. \"\"\" self . processor = HostAgentProcessor ( agent = self , context = context ) self . processor . process () # Sync the status with the processor. self . status = self . processor . status","title":"process"},{"location":"agents/host_agent/#agents.agent.host_agent.HostAgent.process_comfirmation","text":"TODO: Process the confirmation. Source code in agents/agent/host_agent.py 294 295 296 297 298 def process_comfirmation ( self ) -> None : \"\"\" TODO: Process the confirmation. \"\"\" pass","title":"process_comfirmation"},{"location":"agents/overview/","text":"Agents In UFO, there are four types of agents: HostAgent , AppAgent , FollowerAgent , and EvaluationAgent . Each agent has a specific role in the UFO system and is responsible for different aspects of the user interaction process: Agent Description HostAgent Decomposes the user request into sub-tasks and selects the appropriate application to fulfill the request. AppAgent Executes actions on the selected application. FollowerAgent Follows the user's instructions to complete the task. EvaluationAgent Evaluates the completeness of a session or a round. In the normal workflow, only the HostAgent and AppAgent are involved in the user interaction process. The FollowerAgent and EvaluationAgent are used for specific tasks. Please see below the orchestration of the agents in UFO: Main Components An agent in UFO is composed of the following main components to fulfill its role in the UFO system: Component Description State Represents the current state of the agent and determines the next action and agent to handle the request. Memory Stores information about the user request, application state, and other relevant data. Blackboard Stores information shared between agents. Prompter Generates prompts for the language model based on the user request and application state. Processor Processes the workflow of the agent, including handling user requests, executing actions, and memory management. Reference Below is the reference for the Agent class in UFO. All agents in UFO inherit from the Agent class and implement necessary methods to fulfill their roles in the UFO system. Bases: ABC The BasicAgent class is the abstract class for the agent. Initialize the BasicAgent. Parameters: name ( str ) \u2013 The name of the agent. Source code in agents/agent/basic.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , name : str ) -> None : \"\"\" Initialize the BasicAgent. :param name: The name of the agent. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = self . status_manager . CONTINUE . value self . _register_self () self . retriever_factory = retriever . RetrieverFactory () self . _memory = Memory () self . _host = None self . _processor : Optional [ BaseProcessor ] = None self . _state = None self . Puppeteer : puppeteer . AppPuppeteer = None blackboard property Get the blackboard. Returns: Blackboard \u2013 The blackboard. default_state property Get the default state of the agent. Returns: AgentState \u2013 The default state of the agent. host property writable Get the host of the agent. Returns: HostAgent \u2013 The host of the agent. memory property writable Get the memory of the agent. Returns: Memory \u2013 The memory of the agent. name property Get the name of the agent. Returns: str \u2013 The name of the agent. processor property writable Get the processor. Returns: BaseProcessor \u2013 The processor. state property Get the state of the agent. Returns: AgentState \u2013 The state of the agent. status property writable Get the status of the agent. Returns: str \u2013 The status of the agent. status_manager property Get the status manager. Returns: AgentStatus \u2013 The status manager. step property writable Get the step of the agent. Returns: int \u2013 The step of the agent. add_memory ( memory_item ) Update the memory of the agent. Parameters: memory_item ( MemoryItem ) \u2013 The memory item to add. Source code in agents/agent/basic.py 204 205 206 207 208 209 def add_memory ( self , memory_item : MemoryItem ) -> None : \"\"\" Update the memory of the agent. :param memory_item: The memory item to add. \"\"\" self . _memory . add_memory_item ( memory_item ) build_experience_retriever () Build the experience retriever. Source code in agents/agent/basic.py 349 350 351 352 353 def build_experience_retriever ( self ) -> None : \"\"\" Build the experience retriever. \"\"\" pass build_human_demonstration_retriever () Build the human demonstration retriever. Source code in agents/agent/basic.py 355 356 357 358 359 def build_human_demonstration_retriever ( self ) -> None : \"\"\" Build the human demonstration retriever. \"\"\" pass build_offline_docs_retriever () Build the offline docs retriever. Source code in agents/agent/basic.py 337 338 339 340 341 def build_offline_docs_retriever ( self ) -> None : \"\"\" Build the offline docs retriever. \"\"\" pass build_online_search_retriever () Build the online search retriever. Source code in agents/agent/basic.py 343 344 345 346 347 def build_online_search_retriever ( self ) -> None : \"\"\" Build the online search retriever. \"\"\" pass clear_memory () Clear the memory of the agent. Source code in agents/agent/basic.py 218 219 220 221 222 def clear_memory ( self ) -> None : \"\"\" Clear the memory of the agent. \"\"\" self . _memory . clear () create_puppeteer_interface () Create the puppeteer interface. Source code in agents/agent/basic.py 256 257 258 259 260 def create_puppeteer_interface ( self ) -> puppeteer . AppPuppeteer : \"\"\" Create the puppeteer interface. \"\"\" pass delete_memory ( step ) Delete the memory of the agent. Parameters: step ( int ) \u2013 The step of the memory item to delete. Source code in agents/agent/basic.py 211 212 213 214 215 216 def delete_memory ( self , step : int ) -> None : \"\"\" Delete the memory of the agent. :param step: The step of the memory item to delete. \"\"\" self . _memory . delete_memory_item ( step ) get_cls ( name ) classmethod Retrieves an agent class from the registry. Parameters: name ( str ) \u2013 The name of the agent class. Returns: Type ['BasicAgent'] \u2013 The agent class. Source code in agents/agent/basic.py 376 377 378 379 380 381 382 383 @classmethod def get_cls ( cls , name : str ) -> Type [ \"BasicAgent\" ]: \"\"\" Retrieves an agent class from the registry. :param name: The name of the agent class. :return: The agent class. \"\"\" return AgentRegistry () . get_cls ( name ) get_prompter () abstractmethod Get the prompt for the agent. Returns: str \u2013 The prompt. Source code in agents/agent/basic.py 132 133 134 135 136 137 138 @abstractmethod def get_prompter ( self ) -> str : \"\"\" Get the prompt for the agent. :return: The prompt. \"\"\" pass get_response ( message , namescope , use_backup_engine , configs = configs ) classmethod Get the response for the prompt. Parameters: message ( List [ dict ] ) \u2013 The message for LLMs. namescope ( str ) \u2013 The namescope for the LLMs. use_backup_engine ( bool ) \u2013 Whether to use the backup engine. configs \u2013 The configurations. Returns: str \u2013 The response. Source code in agents/agent/basic.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 @classmethod def get_response ( cls , message : List [ dict ], namescope : str , use_backup_engine : bool , configs = configs , ) -> str : \"\"\" Get the response for the prompt. :param message: The message for LLMs. :param namescope: The namescope for the LLMs. :param use_backup_engine: Whether to use the backup engine. :param configs: The configurations. :return: The response. \"\"\" response_string , cost = llm_call . get_completion ( message , namescope , use_backup_engine = use_backup_engine , configs = configs ) return response_string , cost handle ( context ) Handle the agent. Parameters: context ( Context ) \u2013 The context for the agent. Source code in agents/agent/basic.py 243 244 245 246 247 248 def handle ( self , context : Context ) -> None : \"\"\" Handle the agent. :param context: The context for the agent. \"\"\" self . state . handle ( self , context ) message_constructor () abstractmethod Construct the message. Returns: List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]] \u2013 The message. Source code in agents/agent/basic.py 140 141 142 143 144 145 146 @abstractmethod def message_constructor ( self ) -> List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]]: \"\"\" Construct the message. :return: The message. \"\"\" pass print_response () Print the response. Source code in agents/agent/basic.py 361 362 363 364 365 def print_response ( self ) -> None : \"\"\" Print the response. \"\"\" pass process ( context ) Process the agent. Source code in agents/agent/basic.py 250 251 252 253 254 def process ( self , context : Context ) -> None : \"\"\" Process the agent. \"\"\" pass process_asker ( ask_user = True ) Ask for the process. Parameters: ask_user ( bool , default: True ) \u2013 Whether to ask the user for the questions. Source code in agents/agent/basic.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 def process_asker ( self , ask_user : bool = True ) -> None : \"\"\" Ask for the process. :param ask_user: Whether to ask the user for the questions. \"\"\" _ask_message = \"Could you please answer the following questions to help me understand your needs and complete the task?\" _none_answer_message = \"The answer for the question is not available, please proceed with your own knowledge or experience, or leave it as a placeholder. Do not ask the same question again.\" if self . processor : question_list = self . processor . question_list if ask_user : utils . print_with_color ( _ask_message , \"yellow\" , ) for index , question in enumerate ( question_list ): if ask_user : answer = question_asker ( question , index + 1 ) if not answer . strip (): continue qa_pair = { \"question\" : question , \"answer\" : answer } utils . append_string_to_file ( configs [ \"QA_PAIR_FILE\" ], json . dumps ( qa_pair ) ) else : qa_pair = { \"question\" : question , \"answer\" : _none_answer_message , } self . blackboard . add_questions ( qa_pair ) process_comfirmation () abstractmethod Confirm the process. Source code in agents/agent/basic.py 306 307 308 309 310 311 @abstractmethod def process_comfirmation ( self ) -> None : \"\"\" Confirm the process. \"\"\" pass process_resume () Resume the process. Source code in agents/agent/basic.py 262 263 264 265 266 267 def process_resume ( self ) -> None : \"\"\" Resume the process. \"\"\" if self . processor : self . processor . resume () reflection () TODO: Reflect on the action. Source code in agents/agent/basic.py 224 225 226 227 228 229 def reflection ( self ) -> None : \"\"\" TODO: Reflect on the action. \"\"\" pass response_to_dict ( response ) staticmethod Convert the response to a dictionary. Parameters: response ( str ) \u2013 The response. Returns: Dict [ str , str ] \u2013 The dictionary. Source code in agents/agent/basic.py 169 170 171 172 173 174 175 176 @staticmethod def response_to_dict ( response : str ) -> Dict [ str , str ]: \"\"\" Convert the response to a dictionary. :param response: The response. :return: The dictionary. \"\"\" return utils . json_parser ( response ) set_memory_from_list_of_dicts ( data ) Set the memory from the list of dictionaries. Parameters: data ( List [ Dict [ str , str ]] ) \u2013 The list of dictionaries. Source code in agents/agent/basic.py 194 195 196 197 198 199 200 201 202 def set_memory_from_list_of_dicts ( self , data : List [ Dict [ str , str ]]) -> None : \"\"\" Set the memory from the list of dictionaries. :param data: The list of dictionaries. \"\"\" assert isinstance ( data , list ), \"The data should be a list of dictionaries.\" self . _memory . from_list_of_dicts ( data ) set_state ( state ) Set the state of the agent. Parameters: state ( AgentState ) \u2013 The state of the agent. Source code in agents/agent/basic.py 231 232 233 234 235 236 237 238 239 240 241 def set_state ( self , state : AgentState ) -> None : \"\"\" Set the state of the agent. :param state: The state of the agent. \"\"\" assert issubclass ( type ( self ), state . agent_class () ), f \"The state is only for agent type of { state . agent_class () } , but the current agent is { type ( self ) } .\" self . _state = state","title":"Overview"},{"location":"agents/overview/#agents","text":"In UFO, there are four types of agents: HostAgent , AppAgent , FollowerAgent , and EvaluationAgent . Each agent has a specific role in the UFO system and is responsible for different aspects of the user interaction process: Agent Description HostAgent Decomposes the user request into sub-tasks and selects the appropriate application to fulfill the request. AppAgent Executes actions on the selected application. FollowerAgent Follows the user's instructions to complete the task. EvaluationAgent Evaluates the completeness of a session or a round. In the normal workflow, only the HostAgent and AppAgent are involved in the user interaction process. The FollowerAgent and EvaluationAgent are used for specific tasks. Please see below the orchestration of the agents in UFO:","title":"Agents"},{"location":"agents/overview/#main-components","text":"An agent in UFO is composed of the following main components to fulfill its role in the UFO system: Component Description State Represents the current state of the agent and determines the next action and agent to handle the request. Memory Stores information about the user request, application state, and other relevant data. Blackboard Stores information shared between agents. Prompter Generates prompts for the language model based on the user request and application state. Processor Processes the workflow of the agent, including handling user requests, executing actions, and memory management.","title":"Main Components"},{"location":"agents/overview/#reference","text":"Below is the reference for the Agent class in UFO. All agents in UFO inherit from the Agent class and implement necessary methods to fulfill their roles in the UFO system. Bases: ABC The BasicAgent class is the abstract class for the agent. Initialize the BasicAgent. Parameters: name ( str ) \u2013 The name of the agent. Source code in agents/agent/basic.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , name : str ) -> None : \"\"\" Initialize the BasicAgent. :param name: The name of the agent. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = self . status_manager . CONTINUE . value self . _register_self () self . retriever_factory = retriever . RetrieverFactory () self . _memory = Memory () self . _host = None self . _processor : Optional [ BaseProcessor ] = None self . _state = None self . Puppeteer : puppeteer . AppPuppeteer = None","title":"Reference"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.blackboard","text":"Get the blackboard. Returns: Blackboard \u2013 The blackboard.","title":"blackboard"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.default_state","text":"Get the default state of the agent. Returns: AgentState \u2013 The default state of the agent.","title":"default_state"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.host","text":"Get the host of the agent. Returns: HostAgent \u2013 The host of the agent.","title":"host"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.memory","text":"Get the memory of the agent. Returns: Memory \u2013 The memory of the agent.","title":"memory"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.name","text":"Get the name of the agent. Returns: str \u2013 The name of the agent.","title":"name"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.processor","text":"Get the processor. Returns: BaseProcessor \u2013 The processor.","title":"processor"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.state","text":"Get the state of the agent. Returns: AgentState \u2013 The state of the agent.","title":"state"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.status","text":"Get the status of the agent. Returns: str \u2013 The status of the agent.","title":"status"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.status_manager","text":"Get the status manager. Returns: AgentStatus \u2013 The status manager.","title":"status_manager"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.step","text":"Get the step of the agent. Returns: int \u2013 The step of the agent.","title":"step"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.add_memory","text":"Update the memory of the agent. Parameters: memory_item ( MemoryItem ) \u2013 The memory item to add. Source code in agents/agent/basic.py 204 205 206 207 208 209 def add_memory ( self , memory_item : MemoryItem ) -> None : \"\"\" Update the memory of the agent. :param memory_item: The memory item to add. \"\"\" self . _memory . add_memory_item ( memory_item )","title":"add_memory"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.build_experience_retriever","text":"Build the experience retriever. Source code in agents/agent/basic.py 349 350 351 352 353 def build_experience_retriever ( self ) -> None : \"\"\" Build the experience retriever. \"\"\" pass","title":"build_experience_retriever"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.build_human_demonstration_retriever","text":"Build the human demonstration retriever. Source code in agents/agent/basic.py 355 356 357 358 359 def build_human_demonstration_retriever ( self ) -> None : \"\"\" Build the human demonstration retriever. \"\"\" pass","title":"build_human_demonstration_retriever"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.build_offline_docs_retriever","text":"Build the offline docs retriever. Source code in agents/agent/basic.py 337 338 339 340 341 def build_offline_docs_retriever ( self ) -> None : \"\"\" Build the offline docs retriever. \"\"\" pass","title":"build_offline_docs_retriever"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.build_online_search_retriever","text":"Build the online search retriever. Source code in agents/agent/basic.py 343 344 345 346 347 def build_online_search_retriever ( self ) -> None : \"\"\" Build the online search retriever. \"\"\" pass","title":"build_online_search_retriever"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.clear_memory","text":"Clear the memory of the agent. Source code in agents/agent/basic.py 218 219 220 221 222 def clear_memory ( self ) -> None : \"\"\" Clear the memory of the agent. \"\"\" self . _memory . clear ()","title":"clear_memory"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.create_puppeteer_interface","text":"Create the puppeteer interface. Source code in agents/agent/basic.py 256 257 258 259 260 def create_puppeteer_interface ( self ) -> puppeteer . AppPuppeteer : \"\"\" Create the puppeteer interface. \"\"\" pass","title":"create_puppeteer_interface"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.delete_memory","text":"Delete the memory of the agent. Parameters: step ( int ) \u2013 The step of the memory item to delete. Source code in agents/agent/basic.py 211 212 213 214 215 216 def delete_memory ( self , step : int ) -> None : \"\"\" Delete the memory of the agent. :param step: The step of the memory item to delete. \"\"\" self . _memory . delete_memory_item ( step )","title":"delete_memory"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.get_cls","text":"Retrieves an agent class from the registry. Parameters: name ( str ) \u2013 The name of the agent class. Returns: Type ['BasicAgent'] \u2013 The agent class. Source code in agents/agent/basic.py 376 377 378 379 380 381 382 383 @classmethod def get_cls ( cls , name : str ) -> Type [ \"BasicAgent\" ]: \"\"\" Retrieves an agent class from the registry. :param name: The name of the agent class. :return: The agent class. \"\"\" return AgentRegistry () . get_cls ( name )","title":"get_cls"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.get_prompter","text":"Get the prompt for the agent. Returns: str \u2013 The prompt. Source code in agents/agent/basic.py 132 133 134 135 136 137 138 @abstractmethod def get_prompter ( self ) -> str : \"\"\" Get the prompt for the agent. :return: The prompt. \"\"\" pass","title":"get_prompter"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.get_response","text":"Get the response for the prompt. Parameters: message ( List [ dict ] ) \u2013 The message for LLMs. namescope ( str ) \u2013 The namescope for the LLMs. use_backup_engine ( bool ) \u2013 Whether to use the backup engine. configs \u2013 The configurations. Returns: str \u2013 The response. Source code in agents/agent/basic.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 @classmethod def get_response ( cls , message : List [ dict ], namescope : str , use_backup_engine : bool , configs = configs , ) -> str : \"\"\" Get the response for the prompt. :param message: The message for LLMs. :param namescope: The namescope for the LLMs. :param use_backup_engine: Whether to use the backup engine. :param configs: The configurations. :return: The response. \"\"\" response_string , cost = llm_call . get_completion ( message , namescope , use_backup_engine = use_backup_engine , configs = configs ) return response_string , cost","title":"get_response"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.handle","text":"Handle the agent. Parameters: context ( Context ) \u2013 The context for the agent. Source code in agents/agent/basic.py 243 244 245 246 247 248 def handle ( self , context : Context ) -> None : \"\"\" Handle the agent. :param context: The context for the agent. \"\"\" self . state . handle ( self , context )","title":"handle"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.message_constructor","text":"Construct the message. Returns: List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]] \u2013 The message. Source code in agents/agent/basic.py 140 141 142 143 144 145 146 @abstractmethod def message_constructor ( self ) -> List [ Dict [ str , Union [ str , List [ Dict [ str , str ]]]]]: \"\"\" Construct the message. :return: The message. \"\"\" pass","title":"message_constructor"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.print_response","text":"Print the response. Source code in agents/agent/basic.py 361 362 363 364 365 def print_response ( self ) -> None : \"\"\" Print the response. \"\"\" pass","title":"print_response"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.process","text":"Process the agent. Source code in agents/agent/basic.py 250 251 252 253 254 def process ( self , context : Context ) -> None : \"\"\" Process the agent. \"\"\" pass","title":"process"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.process_asker","text":"Ask for the process. Parameters: ask_user ( bool , default: True ) \u2013 Whether to ask the user for the questions. Source code in agents/agent/basic.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 def process_asker ( self , ask_user : bool = True ) -> None : \"\"\" Ask for the process. :param ask_user: Whether to ask the user for the questions. \"\"\" _ask_message = \"Could you please answer the following questions to help me understand your needs and complete the task?\" _none_answer_message = \"The answer for the question is not available, please proceed with your own knowledge or experience, or leave it as a placeholder. Do not ask the same question again.\" if self . processor : question_list = self . processor . question_list if ask_user : utils . print_with_color ( _ask_message , \"yellow\" , ) for index , question in enumerate ( question_list ): if ask_user : answer = question_asker ( question , index + 1 ) if not answer . strip (): continue qa_pair = { \"question\" : question , \"answer\" : answer } utils . append_string_to_file ( configs [ \"QA_PAIR_FILE\" ], json . dumps ( qa_pair ) ) else : qa_pair = { \"question\" : question , \"answer\" : _none_answer_message , } self . blackboard . add_questions ( qa_pair )","title":"process_asker"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.process_comfirmation","text":"Confirm the process. Source code in agents/agent/basic.py 306 307 308 309 310 311 @abstractmethod def process_comfirmation ( self ) -> None : \"\"\" Confirm the process. \"\"\" pass","title":"process_comfirmation"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.process_resume","text":"Resume the process. Source code in agents/agent/basic.py 262 263 264 265 266 267 def process_resume ( self ) -> None : \"\"\" Resume the process. \"\"\" if self . processor : self . processor . resume ()","title":"process_resume"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.reflection","text":"TODO: Reflect on the action. Source code in agents/agent/basic.py 224 225 226 227 228 229 def reflection ( self ) -> None : \"\"\" TODO: Reflect on the action. \"\"\" pass","title":"reflection"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.response_to_dict","text":"Convert the response to a dictionary. Parameters: response ( str ) \u2013 The response. Returns: Dict [ str , str ] \u2013 The dictionary. Source code in agents/agent/basic.py 169 170 171 172 173 174 175 176 @staticmethod def response_to_dict ( response : str ) -> Dict [ str , str ]: \"\"\" Convert the response to a dictionary. :param response: The response. :return: The dictionary. \"\"\" return utils . json_parser ( response )","title":"response_to_dict"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.set_memory_from_list_of_dicts","text":"Set the memory from the list of dictionaries. Parameters: data ( List [ Dict [ str , str ]] ) \u2013 The list of dictionaries. Source code in agents/agent/basic.py 194 195 196 197 198 199 200 201 202 def set_memory_from_list_of_dicts ( self , data : List [ Dict [ str , str ]]) -> None : \"\"\" Set the memory from the list of dictionaries. :param data: The list of dictionaries. \"\"\" assert isinstance ( data , list ), \"The data should be a list of dictionaries.\" self . _memory . from_list_of_dicts ( data )","title":"set_memory_from_list_of_dicts"},{"location":"agents/overview/#agents.agent.basic.BasicAgent.set_state","text":"Set the state of the agent. Parameters: state ( AgentState ) \u2013 The state of the agent. Source code in agents/agent/basic.py 231 232 233 234 235 236 237 238 239 240 241 def set_state ( self , state : AgentState ) -> None : \"\"\" Set the state of the agent. :param state: The state of the agent. \"\"\" assert issubclass ( type ( self ), state . agent_class () ), f \"The state is only for agent type of { state . agent_class () } , but the current agent is { type ( self ) } .\" self . _state = state","title":"set_state"},{"location":"agents/design/blackboard/","text":"Agent Blackboard The Blackboard is a shared memory space that is visible to all agents in the UFO framework. It stores information required for agents to interact with the user and applications at every step. The Blackboard is a key component of the UFO framework, enabling agents to share information and collaborate to fulfill user requests. The Blackboard is implemented as a class in the ufo/agents/memory/blackboard.py file. Components The Blackboard consists of the following data components: Component Description questions A list of questions that UFO asks the user, along with their corresponding answers. requests A list of historical user requests received in previous Round . trajectories A list of step-wise trajectories that record the agent's actions and decisions at each step. screenshots A list of screenshots taken by the agent when it believes the current state is important for future reference. Tip The keys stored in the trajectories are configured as HISTORY_KEYS in the config_dev.yaml file. You can customize the keys based on your requirements and the agent's logic. Tip Whether to save the screenshots is determined by the AppAgent . You can enable or disable screenshot capture by setting the SCREENSHOT_TO_MEMORY flag in the config_dev.yaml file. Blackboard to Prompt Data in the Blackboard is based on the MemoryItem class. It has a method blackboard_to_prompt that converts the information stored in the Blackboard to a string prompt. Agents call this method to construct the prompt for the LLM's inference. The blackboard_to_prompt method is defined as follows: def blackboard_to_prompt(self) -> List[str]: \"\"\" Convert the blackboard to a prompt. :return: The prompt. \"\"\" prefix = [ { \"type\": \"text\", \"text\": \"[Blackboard:]\", } ] blackboard_prompt = ( prefix + self.texts_to_prompt(self.questions, \"[Questions & Answers:]\") + self.texts_to_prompt(self.requests, \"[Request History:]\") + self.texts_to_prompt(self.trajectories, \"[Step Trajectories Completed Previously:]\") + self.screenshots_to_prompt() ) return blackboard_prompt Reference Class for the blackboard, which stores the data and images which are visible to all the agents. Initialize the blackboard. Source code in agents/memory/blackboard.py 41 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self ) -> None : \"\"\" Initialize the blackboard. \"\"\" self . _questions : Memory = Memory () self . _requests : Memory = Memory () self . _trajectories : Memory = Memory () self . _screenshots : Memory = Memory () if configs . get ( \"USE_CUSTOMIZATION\" , False ): self . load_questions ( configs . get ( \"QA_PAIR_FILE\" , \"\" ), configs . get ( \"QA_PAIR_NUM\" , - 1 ) ) questions property Get the data from the blackboard. Returns: Memory \u2013 The questions from the blackboard. requests property Get the data from the blackboard. Returns: Memory \u2013 The requests from the blackboard. screenshots property Get the images from the blackboard. Returns: Memory \u2013 The images from the blackboard. trajectories property Get the data from the blackboard. Returns: Memory \u2013 The trajectories from the blackboard. add_data ( data , memory ) Add the data to the a memory in the blackboard. Parameters: data ( Union [ MemoryItem , Dict [ str , str ], str ] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. memory ( Memory ) \u2013 The memory to add the data to. Source code in agents/memory/blackboard.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def add_data ( self , data : Union [ MemoryItem , Dict [ str , str ], str ], memory : Memory ) -> None : \"\"\" Add the data to the a memory in the blackboard. :param data: The data to be added. It can be a dictionary or a MemoryItem or a string. :param memory: The memory to add the data to. \"\"\" if isinstance ( data , dict ): data_memory = MemoryItem () data_memory . add_values_from_dict ( data ) memory . add_memory_item ( data_memory ) elif isinstance ( data , MemoryItem ): memory . add_memory_item ( data ) elif isinstance ( data , str ): data_memory = MemoryItem () data_memory . add_values_from_dict ({ \"text\" : data }) memory . add_memory_item ( data_memory ) else : print ( f \"Warning: Unsupported data type: { type ( data ) } when adding data.\" ) add_image ( screenshot_path = '' , metadata = None ) Add the image to the blackboard. Parameters: screenshot_path ( str , default: '' ) \u2013 The path of the image. metadata ( Optional [ Dict [ str , str ]] , default: None ) \u2013 The metadata of the image. Source code in agents/memory/blackboard.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def add_image ( self , screenshot_path : str = \"\" , metadata : Optional [ Dict [ str , str ]] = None , ) -> None : \"\"\" Add the image to the blackboard. :param screenshot_path: The path of the image. :param metadata: The metadata of the image. \"\"\" if os . path . exists ( screenshot_path ): screenshot_str = PhotographerFacade () . encode_image_from_path ( screenshot_path ) else : print ( f \"Screenshot path { screenshot_path } does not exist.\" ) screenshot_str = \"\" image_memory_item = ImageMemoryItem () image_memory_item . add_values_from_dict ( { ImageMemoryItemNames . METADATA : metadata . get ( ImageMemoryItemNames . METADATA ), ImageMemoryItemNames . IMAGE_PATH : screenshot_path , ImageMemoryItemNames . IMAGE_STR : screenshot_str , } ) self . screenshots . add_memory_item ( image_memory_item ) add_questions ( questions ) Add the data to the blackboard. Parameters: questions ( Union [ MemoryItem , Dict [ str , str ]] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. Source code in agents/memory/blackboard.py 109 110 111 112 113 114 115 def add_questions ( self , questions : Union [ MemoryItem , Dict [ str , str ]]) -> None : \"\"\" Add the data to the blackboard. :param questions: The data to be added. It can be a dictionary or a MemoryItem or a string. \"\"\" self . add_data ( questions , self . questions ) add_requests ( requests ) Add the data to the blackboard. Parameters: requests ( Union [ MemoryItem , Dict [ str , str ]] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. Source code in agents/memory/blackboard.py 117 118 119 120 121 122 123 def add_requests ( self , requests : Union [ MemoryItem , Dict [ str , str ]]) -> None : \"\"\" Add the data to the blackboard. :param requests: The data to be added. It can be a dictionary or a MemoryItem or a string. \"\"\" self . add_data ( requests , self . requests ) add_trajectories ( trajectories ) Add the data to the blackboard. Parameters: trajectories ( Union [ MemoryItem , Dict [ str , str ]] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. Source code in agents/memory/blackboard.py 125 126 127 128 129 130 131 def add_trajectories ( self , trajectories : Union [ MemoryItem , Dict [ str , str ]]) -> None : \"\"\" Add the data to the blackboard. :param trajectories: The data to be added. It can be a dictionary or a MemoryItem or a string. \"\"\" self . add_data ( trajectories , self . trajectories ) blackboard_from_dict ( blackboard_dict ) Convert the dictionary to the blackboard. Parameters: blackboard_dict ( Dict [ str , List [ Dict [ str , str ]]] ) \u2013 The dictionary. Source code in agents/memory/blackboard.py 264 265 266 267 268 269 270 271 272 273 274 def blackboard_from_dict ( self , blackboard_dict : Dict [ str , List [ Dict [ str , str ]]] ) -> None : \"\"\" Convert the dictionary to the blackboard. :param blackboard_dict: The dictionary. \"\"\" self . questions . from_list_of_dicts ( blackboard_dict . get ( \"questions\" , [])) self . requests . from_list_of_dicts ( blackboard_dict . get ( \"requests\" , [])) self . trajectories . from_list_of_dicts ( blackboard_dict . get ( \"trajectories\" , [])) self . screenshots . from_list_of_dicts ( blackboard_dict . get ( \"screenshots\" , [])) blackboard_to_dict () Convert the blackboard to a dictionary. Returns: Dict [ str , List [ Dict [ str , str ]]] \u2013 The blackboard in the dictionary format. Source code in agents/memory/blackboard.py 243 244 245 246 247 248 249 250 251 252 253 254 255 def blackboard_to_dict ( self ) -> Dict [ str , List [ Dict [ str , str ]]]: \"\"\" Convert the blackboard to a dictionary. :return: The blackboard in the dictionary format. \"\"\" blackboard_dict = { \"questions\" : self . questions . to_list_of_dicts (), \"requests\" : self . requests . to_list_of_dicts (), \"trajectories\" : self . trajectories . to_list_of_dicts (), \"screenshots\" : self . screenshots . to_list_of_dicts (), } return blackboard_dict blackboard_to_json () Convert the blackboard to a JSON string. Returns: str \u2013 The JSON string. Source code in agents/memory/blackboard.py 257 258 259 260 261 262 def blackboard_to_json ( self ) -> str : \"\"\" Convert the blackboard to a JSON string. :return: The JSON string. \"\"\" return json . dumps ( self . blackboard_to_dict ()) blackboard_to_prompt () Convert the blackboard to a prompt. Returns: List [ str ] \u2013 The prompt. Source code in agents/memory/blackboard.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 def blackboard_to_prompt ( self ) -> List [ str ]: \"\"\" Convert the blackboard to a prompt. :return: The prompt. \"\"\" prefix = [ { \"type\" : \"text\" , \"text\" : \"[Blackboard:]\" , } ] blackboard_prompt = ( prefix + self . texts_to_prompt ( self . questions , \"[Questions & Answers:]\" ) + self . texts_to_prompt ( self . requests , \"[Request History:]\" ) + self . texts_to_prompt ( self . trajectories , \"[Step Trajectories Completed Previously:]\" ) + self . screenshots_to_prompt () ) return blackboard_prompt clear () Clear the blackboard. Source code in agents/memory/blackboard.py 312 313 314 315 316 317 318 319 def clear ( self ) -> None : \"\"\" Clear the blackboard. \"\"\" self . questions . clear () self . requests . clear () self . trajectories . clear () self . screenshots . clear () is_empty () Check if the blackboard is empty. Returns: bool \u2013 True if the blackboard is empty, False otherwise. Source code in agents/memory/blackboard.py 300 301 302 303 304 305 306 307 308 309 310 def is_empty ( self ) -> bool : \"\"\" Check if the blackboard is empty. :return: True if the blackboard is empty, False otherwise. \"\"\" return ( self . questions . is_empty () and self . requests . is_empty () and self . trajectories . is_empty () and self . screenshots . is_empty () ) load_questions ( file_path , last_k =- 1 ) Load the data from a file. Parameters: file_path ( str ) \u2013 The path of the file. last_k \u2013 The number of lines to read from the end of the file. If -1, read all lines. Source code in agents/memory/blackboard.py 194 195 196 197 198 199 200 201 202 def load_questions ( self , file_path : str , last_k =- 1 ) -> None : \"\"\" Load the data from a file. :param file_path: The path of the file. :param last_k: The number of lines to read from the end of the file. If -1, read all lines. \"\"\" qa_list = self . read_json_file ( file_path , last_k ) for qa in qa_list : self . add_questions ( qa ) questions_to_json () Convert the data to a dictionary. Returns: str \u2013 The data in the dictionary format. Source code in agents/memory/blackboard.py 166 167 168 169 170 171 def questions_to_json ( self ) -> str : \"\"\" Convert the data to a dictionary. :return: The data in the dictionary format. \"\"\" return self . questions . to_json () read_json_file ( file_path , last_k =- 1 ) staticmethod Read the json file. Parameters: file_path ( str ) \u2013 The path of the file. last_k \u2013 The number of lines to read from the end of the file. If -1, read all lines. Returns: Dict [ str , str ] \u2013 The data in the file. Source code in agents/memory/blackboard.py 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 @staticmethod def read_json_file ( file_path : str , last_k =- 1 ) -> Dict [ str , str ]: \"\"\" Read the json file. :param file_path: The path of the file. :param last_k: The number of lines to read from the end of the file. If -1, read all lines. :return: The data in the file. \"\"\" data_list = [] # Check if the file exists if os . path . exists ( file_path ): # Open the file and read the lines with open ( file_path , \"r\" , encoding = \"utf-8\" ) as file : lines = file . readlines () # If last_k is not -1, only read the last k lines if last_k != - 1 : lines = lines [ - last_k :] # Parse the lines as JSON for line in lines : try : data = json . loads ( line . strip ()) data_list . append ( data ) except json . JSONDecodeError : print ( f \"Warning: Unable to parse line as JSON: { line } \" ) return data_list requests_to_json () Convert the data to a dictionary. Returns: str \u2013 The data in the dictionary format. Source code in agents/memory/blackboard.py 173 174 175 176 177 178 def requests_to_json ( self ) -> str : \"\"\" Convert the data to a dictionary. :return: The data in the dictionary format. \"\"\" return self . requests . to_json () screenshots_to_json () Convert the images to a dictionary. Returns: str \u2013 The images in the dictionary format. Source code in agents/memory/blackboard.py 187 188 189 190 191 192 def screenshots_to_json ( self ) -> str : \"\"\" Convert the images to a dictionary. :return: The images in the dictionary format. \"\"\" return self . screenshots . to_json () screenshots_to_prompt () Convert the images to a prompt. Returns: List [ str ] \u2013 The prompt. Source code in agents/memory/blackboard.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def screenshots_to_prompt ( self ) -> List [ str ]: \"\"\" Convert the images to a prompt. :return: The prompt. \"\"\" user_content = [] for screenshot_dict in self . screenshots . list_content : user_content . append ( { \"type\" : \"text\" , \"text\" : json . dumps ( screenshot_dict . get ( ImageMemoryItemNames . METADATA , \"\" ) ), } ) user_content . append ( { \"type\" : \"image_url\" , \"image_url\" : { \"url\" : screenshot_dict . get ( ImageMemoryItemNames . IMAGE_STR , \"\" ) }, } ) return user_content texts_to_prompt ( memory , prefix ) Convert the data to a prompt. Returns: List [ str ] \u2013 The prompt. Source code in agents/memory/blackboard.py 204 205 206 207 208 209 210 211 212 213 214 def texts_to_prompt ( self , memory : Memory , prefix : str ) -> List [ str ]: \"\"\" Convert the data to a prompt. :return: The prompt. \"\"\" user_content = [ { \"type\" : \"text\" , \"text\" : f \" { prefix } \\n { json . dumps ( memory . list_content ) } \" } ] return user_content trajectories_to_json () Convert the data to a dictionary. Returns: str \u2013 The data in the dictionary format. Source code in agents/memory/blackboard.py 180 181 182 183 184 185 def trajectories_to_json ( self ) -> str : \"\"\" Convert the data to a dictionary. :return: The data in the dictionary format. \"\"\" return self . trajectories . to_json () Note You can customize the class to tailor the Blackboard to your requirements.","title":"Blackboard"},{"location":"agents/design/blackboard/#agent-blackboard","text":"The Blackboard is a shared memory space that is visible to all agents in the UFO framework. It stores information required for agents to interact with the user and applications at every step. The Blackboard is a key component of the UFO framework, enabling agents to share information and collaborate to fulfill user requests. The Blackboard is implemented as a class in the ufo/agents/memory/blackboard.py file.","title":"Agent Blackboard"},{"location":"agents/design/blackboard/#components","text":"The Blackboard consists of the following data components: Component Description questions A list of questions that UFO asks the user, along with their corresponding answers. requests A list of historical user requests received in previous Round . trajectories A list of step-wise trajectories that record the agent's actions and decisions at each step. screenshots A list of screenshots taken by the agent when it believes the current state is important for future reference. Tip The keys stored in the trajectories are configured as HISTORY_KEYS in the config_dev.yaml file. You can customize the keys based on your requirements and the agent's logic. Tip Whether to save the screenshots is determined by the AppAgent . You can enable or disable screenshot capture by setting the SCREENSHOT_TO_MEMORY flag in the config_dev.yaml file.","title":"Components"},{"location":"agents/design/blackboard/#blackboard-to-prompt","text":"Data in the Blackboard is based on the MemoryItem class. It has a method blackboard_to_prompt that converts the information stored in the Blackboard to a string prompt. Agents call this method to construct the prompt for the LLM's inference. The blackboard_to_prompt method is defined as follows: def blackboard_to_prompt(self) -> List[str]: \"\"\" Convert the blackboard to a prompt. :return: The prompt. \"\"\" prefix = [ { \"type\": \"text\", \"text\": \"[Blackboard:]\", } ] blackboard_prompt = ( prefix + self.texts_to_prompt(self.questions, \"[Questions & Answers:]\") + self.texts_to_prompt(self.requests, \"[Request History:]\") + self.texts_to_prompt(self.trajectories, \"[Step Trajectories Completed Previously:]\") + self.screenshots_to_prompt() ) return blackboard_prompt","title":"Blackboard to Prompt"},{"location":"agents/design/blackboard/#reference","text":"Class for the blackboard, which stores the data and images which are visible to all the agents. Initialize the blackboard. Source code in agents/memory/blackboard.py 41 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self ) -> None : \"\"\" Initialize the blackboard. \"\"\" self . _questions : Memory = Memory () self . _requests : Memory = Memory () self . _trajectories : Memory = Memory () self . _screenshots : Memory = Memory () if configs . get ( \"USE_CUSTOMIZATION\" , False ): self . load_questions ( configs . get ( \"QA_PAIR_FILE\" , \"\" ), configs . get ( \"QA_PAIR_NUM\" , - 1 ) )","title":"Reference"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.questions","text":"Get the data from the blackboard. Returns: Memory \u2013 The questions from the blackboard.","title":"questions"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.requests","text":"Get the data from the blackboard. Returns: Memory \u2013 The requests from the blackboard.","title":"requests"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.screenshots","text":"Get the images from the blackboard. Returns: Memory \u2013 The images from the blackboard.","title":"screenshots"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.trajectories","text":"Get the data from the blackboard. Returns: Memory \u2013 The trajectories from the blackboard.","title":"trajectories"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.add_data","text":"Add the data to the a memory in the blackboard. Parameters: data ( Union [ MemoryItem , Dict [ str , str ], str ] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. memory ( Memory ) \u2013 The memory to add the data to. Source code in agents/memory/blackboard.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def add_data ( self , data : Union [ MemoryItem , Dict [ str , str ], str ], memory : Memory ) -> None : \"\"\" Add the data to the a memory in the blackboard. :param data: The data to be added. It can be a dictionary or a MemoryItem or a string. :param memory: The memory to add the data to. \"\"\" if isinstance ( data , dict ): data_memory = MemoryItem () data_memory . add_values_from_dict ( data ) memory . add_memory_item ( data_memory ) elif isinstance ( data , MemoryItem ): memory . add_memory_item ( data ) elif isinstance ( data , str ): data_memory = MemoryItem () data_memory . add_values_from_dict ({ \"text\" : data }) memory . add_memory_item ( data_memory ) else : print ( f \"Warning: Unsupported data type: { type ( data ) } when adding data.\" )","title":"add_data"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.add_image","text":"Add the image to the blackboard. Parameters: screenshot_path ( str , default: '' ) \u2013 The path of the image. metadata ( Optional [ Dict [ str , str ]] , default: None ) \u2013 The metadata of the image. Source code in agents/memory/blackboard.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def add_image ( self , screenshot_path : str = \"\" , metadata : Optional [ Dict [ str , str ]] = None , ) -> None : \"\"\" Add the image to the blackboard. :param screenshot_path: The path of the image. :param metadata: The metadata of the image. \"\"\" if os . path . exists ( screenshot_path ): screenshot_str = PhotographerFacade () . encode_image_from_path ( screenshot_path ) else : print ( f \"Screenshot path { screenshot_path } does not exist.\" ) screenshot_str = \"\" image_memory_item = ImageMemoryItem () image_memory_item . add_values_from_dict ( { ImageMemoryItemNames . METADATA : metadata . get ( ImageMemoryItemNames . METADATA ), ImageMemoryItemNames . IMAGE_PATH : screenshot_path , ImageMemoryItemNames . IMAGE_STR : screenshot_str , } ) self . screenshots . add_memory_item ( image_memory_item )","title":"add_image"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.add_questions","text":"Add the data to the blackboard. Parameters: questions ( Union [ MemoryItem , Dict [ str , str ]] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. Source code in agents/memory/blackboard.py 109 110 111 112 113 114 115 def add_questions ( self , questions : Union [ MemoryItem , Dict [ str , str ]]) -> None : \"\"\" Add the data to the blackboard. :param questions: The data to be added. It can be a dictionary or a MemoryItem or a string. \"\"\" self . add_data ( questions , self . questions )","title":"add_questions"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.add_requests","text":"Add the data to the blackboard. Parameters: requests ( Union [ MemoryItem , Dict [ str , str ]] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. Source code in agents/memory/blackboard.py 117 118 119 120 121 122 123 def add_requests ( self , requests : Union [ MemoryItem , Dict [ str , str ]]) -> None : \"\"\" Add the data to the blackboard. :param requests: The data to be added. It can be a dictionary or a MemoryItem or a string. \"\"\" self . add_data ( requests , self . requests )","title":"add_requests"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.add_trajectories","text":"Add the data to the blackboard. Parameters: trajectories ( Union [ MemoryItem , Dict [ str , str ]] ) \u2013 The data to be added. It can be a dictionary or a MemoryItem or a string. Source code in agents/memory/blackboard.py 125 126 127 128 129 130 131 def add_trajectories ( self , trajectories : Union [ MemoryItem , Dict [ str , str ]]) -> None : \"\"\" Add the data to the blackboard. :param trajectories: The data to be added. It can be a dictionary or a MemoryItem or a string. \"\"\" self . add_data ( trajectories , self . trajectories )","title":"add_trajectories"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.blackboard_from_dict","text":"Convert the dictionary to the blackboard. Parameters: blackboard_dict ( Dict [ str , List [ Dict [ str , str ]]] ) \u2013 The dictionary. Source code in agents/memory/blackboard.py 264 265 266 267 268 269 270 271 272 273 274 def blackboard_from_dict ( self , blackboard_dict : Dict [ str , List [ Dict [ str , str ]]] ) -> None : \"\"\" Convert the dictionary to the blackboard. :param blackboard_dict: The dictionary. \"\"\" self . questions . from_list_of_dicts ( blackboard_dict . get ( \"questions\" , [])) self . requests . from_list_of_dicts ( blackboard_dict . get ( \"requests\" , [])) self . trajectories . from_list_of_dicts ( blackboard_dict . get ( \"trajectories\" , [])) self . screenshots . from_list_of_dicts ( blackboard_dict . get ( \"screenshots\" , []))","title":"blackboard_from_dict"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.blackboard_to_dict","text":"Convert the blackboard to a dictionary. Returns: Dict [ str , List [ Dict [ str , str ]]] \u2013 The blackboard in the dictionary format. Source code in agents/memory/blackboard.py 243 244 245 246 247 248 249 250 251 252 253 254 255 def blackboard_to_dict ( self ) -> Dict [ str , List [ Dict [ str , str ]]]: \"\"\" Convert the blackboard to a dictionary. :return: The blackboard in the dictionary format. \"\"\" blackboard_dict = { \"questions\" : self . questions . to_list_of_dicts (), \"requests\" : self . requests . to_list_of_dicts (), \"trajectories\" : self . trajectories . to_list_of_dicts (), \"screenshots\" : self . screenshots . to_list_of_dicts (), } return blackboard_dict","title":"blackboard_to_dict"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.blackboard_to_json","text":"Convert the blackboard to a JSON string. Returns: str \u2013 The JSON string. Source code in agents/memory/blackboard.py 257 258 259 260 261 262 def blackboard_to_json ( self ) -> str : \"\"\" Convert the blackboard to a JSON string. :return: The JSON string. \"\"\" return json . dumps ( self . blackboard_to_dict ())","title":"blackboard_to_json"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.blackboard_to_prompt","text":"Convert the blackboard to a prompt. Returns: List [ str ] \u2013 The prompt. Source code in agents/memory/blackboard.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 def blackboard_to_prompt ( self ) -> List [ str ]: \"\"\" Convert the blackboard to a prompt. :return: The prompt. \"\"\" prefix = [ { \"type\" : \"text\" , \"text\" : \"[Blackboard:]\" , } ] blackboard_prompt = ( prefix + self . texts_to_prompt ( self . questions , \"[Questions & Answers:]\" ) + self . texts_to_prompt ( self . requests , \"[Request History:]\" ) + self . texts_to_prompt ( self . trajectories , \"[Step Trajectories Completed Previously:]\" ) + self . screenshots_to_prompt () ) return blackboard_prompt","title":"blackboard_to_prompt"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.clear","text":"Clear the blackboard. Source code in agents/memory/blackboard.py 312 313 314 315 316 317 318 319 def clear ( self ) -> None : \"\"\" Clear the blackboard. \"\"\" self . questions . clear () self . requests . clear () self . trajectories . clear () self . screenshots . clear ()","title":"clear"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.is_empty","text":"Check if the blackboard is empty. Returns: bool \u2013 True if the blackboard is empty, False otherwise. Source code in agents/memory/blackboard.py 300 301 302 303 304 305 306 307 308 309 310 def is_empty ( self ) -> bool : \"\"\" Check if the blackboard is empty. :return: True if the blackboard is empty, False otherwise. \"\"\" return ( self . questions . is_empty () and self . requests . is_empty () and self . trajectories . is_empty () and self . screenshots . is_empty () )","title":"is_empty"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.load_questions","text":"Load the data from a file. Parameters: file_path ( str ) \u2013 The path of the file. last_k \u2013 The number of lines to read from the end of the file. If -1, read all lines. Source code in agents/memory/blackboard.py 194 195 196 197 198 199 200 201 202 def load_questions ( self , file_path : str , last_k =- 1 ) -> None : \"\"\" Load the data from a file. :param file_path: The path of the file. :param last_k: The number of lines to read from the end of the file. If -1, read all lines. \"\"\" qa_list = self . read_json_file ( file_path , last_k ) for qa in qa_list : self . add_questions ( qa )","title":"load_questions"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.questions_to_json","text":"Convert the data to a dictionary. Returns: str \u2013 The data in the dictionary format. Source code in agents/memory/blackboard.py 166 167 168 169 170 171 def questions_to_json ( self ) -> str : \"\"\" Convert the data to a dictionary. :return: The data in the dictionary format. \"\"\" return self . questions . to_json ()","title":"questions_to_json"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.read_json_file","text":"Read the json file. Parameters: file_path ( str ) \u2013 The path of the file. last_k \u2013 The number of lines to read from the end of the file. If -1, read all lines. Returns: Dict [ str , str ] \u2013 The data in the file. Source code in agents/memory/blackboard.py 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 @staticmethod def read_json_file ( file_path : str , last_k =- 1 ) -> Dict [ str , str ]: \"\"\" Read the json file. :param file_path: The path of the file. :param last_k: The number of lines to read from the end of the file. If -1, read all lines. :return: The data in the file. \"\"\" data_list = [] # Check if the file exists if os . path . exists ( file_path ): # Open the file and read the lines with open ( file_path , \"r\" , encoding = \"utf-8\" ) as file : lines = file . readlines () # If last_k is not -1, only read the last k lines if last_k != - 1 : lines = lines [ - last_k :] # Parse the lines as JSON for line in lines : try : data = json . loads ( line . strip ()) data_list . append ( data ) except json . JSONDecodeError : print ( f \"Warning: Unable to parse line as JSON: { line } \" ) return data_list","title":"read_json_file"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.requests_to_json","text":"Convert the data to a dictionary. Returns: str \u2013 The data in the dictionary format. Source code in agents/memory/blackboard.py 173 174 175 176 177 178 def requests_to_json ( self ) -> str : \"\"\" Convert the data to a dictionary. :return: The data in the dictionary format. \"\"\" return self . requests . to_json ()","title":"requests_to_json"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.screenshots_to_json","text":"Convert the images to a dictionary. Returns: str \u2013 The images in the dictionary format. Source code in agents/memory/blackboard.py 187 188 189 190 191 192 def screenshots_to_json ( self ) -> str : \"\"\" Convert the images to a dictionary. :return: The images in the dictionary format. \"\"\" return self . screenshots . to_json ()","title":"screenshots_to_json"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.screenshots_to_prompt","text":"Convert the images to a prompt. Returns: List [ str ] \u2013 The prompt. Source code in agents/memory/blackboard.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def screenshots_to_prompt ( self ) -> List [ str ]: \"\"\" Convert the images to a prompt. :return: The prompt. \"\"\" user_content = [] for screenshot_dict in self . screenshots . list_content : user_content . append ( { \"type\" : \"text\" , \"text\" : json . dumps ( screenshot_dict . get ( ImageMemoryItemNames . METADATA , \"\" ) ), } ) user_content . append ( { \"type\" : \"image_url\" , \"image_url\" : { \"url\" : screenshot_dict . get ( ImageMemoryItemNames . IMAGE_STR , \"\" ) }, } ) return user_content","title":"screenshots_to_prompt"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.texts_to_prompt","text":"Convert the data to a prompt. Returns: List [ str ] \u2013 The prompt. Source code in agents/memory/blackboard.py 204 205 206 207 208 209 210 211 212 213 214 def texts_to_prompt ( self , memory : Memory , prefix : str ) -> List [ str ]: \"\"\" Convert the data to a prompt. :return: The prompt. \"\"\" user_content = [ { \"type\" : \"text\" , \"text\" : f \" { prefix } \\n { json . dumps ( memory . list_content ) } \" } ] return user_content","title":"texts_to_prompt"},{"location":"agents/design/blackboard/#agents.memory.blackboard.Blackboard.trajectories_to_json","text":"Convert the data to a dictionary. Returns: str \u2013 The data in the dictionary format. Source code in agents/memory/blackboard.py 180 181 182 183 184 185 def trajectories_to_json ( self ) -> str : \"\"\" Convert the data to a dictionary. :return: The data in the dictionary format. \"\"\" return self . trajectories . to_json () Note You can customize the class to tailor the Blackboard to your requirements.","title":"trajectories_to_json"},{"location":"agents/design/memory/","text":"Agent Memory The Memory manages the memory of the agent and stores the information required for the agent to interact with the user and applications at every step. Parts of elements in the Memory will be visible to the agent for decision-making. MemoryItem A MemoryItem is a dataclass that represents a single step in the agent's memory. The fields of a MemoryItem is flexible and can be customized based on the requirements of the agent. The MemoryItem class is defined as follows: This data class represents a memory item of an agent at one step. attributes property Get the attributes of the memory item. Returns: List [ str ] \u2013 The attributes. add_values_from_dict ( values ) Add fields to the memory item. Parameters: values ( Dict [ str , Any ] ) \u2013 The values of the fields. Source code in agents/memory/memory.py 66 67 68 69 70 71 72 def add_values_from_dict ( self , values : Dict [ str , Any ]) -> None : \"\"\" Add fields to the memory item. :param values: The values of the fields. \"\"\" for key , value in values . items (): self . set_value ( key , value ) filter ( keys = []) Fetch the memory item. Parameters: keys ( List [ str ] , default: [] ) \u2013 The keys to fetch. Returns: None \u2013 The filtered memory item. Source code in agents/memory/memory.py 46 47 48 49 50 51 52 53 def filter ( self , keys : List [ str ] = []) -> None : \"\"\" Fetch the memory item. :param keys: The keys to fetch. :return: The filtered memory item. \"\"\" return { key : value for key , value in self . to_dict () . items () if key in keys } from_dict ( data ) Convert the dictionary to a MemoryItem. Parameters: data ( Dict [ str , str ] ) \u2013 The dictionary. Source code in agents/memory/memory.py 31 32 33 34 35 36 37 def from_dict ( self , data : Dict [ str , str ]) -> None : \"\"\" Convert the dictionary to a MemoryItem. :param data: The dictionary. \"\"\" for key , value in data . items (): self . set_value ( key , value ) get_value ( key ) Get the value of the field. Parameters: key ( str ) \u2013 The key of the field. Returns: Optional [ str ] \u2013 The value of the field. Source code in agents/memory/memory.py 74 75 76 77 78 79 80 81 def get_value ( self , key : str ) -> Optional [ str ]: \"\"\" Get the value of the field. :param key: The key of the field. :return: The value of the field. \"\"\" return getattr ( self , key , None ) get_values ( keys ) Get the values of the fields. Parameters: keys ( List [ str ] ) \u2013 The keys of the fields. Returns: dict \u2013 The values of the fields. Source code in agents/memory/memory.py 83 84 85 86 87 88 89 def get_values ( self , keys : List [ str ]) -> dict : \"\"\" Get the values of the fields. :param keys: The keys of the fields. :return: The values of the fields. \"\"\" return { key : self . get_value ( key ) for key in keys } set_value ( key , value ) Add a field to the memory item. Parameters: key ( str ) \u2013 The key of the field. value ( str ) \u2013 The value of the field. Source code in agents/memory/memory.py 55 56 57 58 59 60 61 62 63 64 def set_value ( self , key : str , value : str ) -> None : \"\"\" Add a field to the memory item. :param key: The key of the field. :param value: The value of the field. \"\"\" setattr ( self , key , value ) if key not in self . _memory_attributes : self . _memory_attributes . append ( key ) to_dict () Convert the MemoryItem to a dictionary. Returns: Dict [ str , str ] \u2013 The dictionary. Source code in agents/memory/memory.py 19 20 21 22 23 24 25 26 27 28 29 def to_dict ( self ) -> Dict [ str , str ]: \"\"\" Convert the MemoryItem to a dictionary. :return: The dictionary. \"\"\" return { key : value for key , value in self . __dict__ . items () if key in self . _memory_attributes } to_json () Convert the memory item to a JSON string. Returns: str \u2013 The JSON string. Source code in agents/memory/memory.py 39 40 41 42 43 44 def to_json ( self ) -> str : \"\"\" Convert the memory item to a JSON string. :return: The JSON string. \"\"\" return json . dumps ( self . to_dict ()) Info At each step, an instance of MemoryItem is created and stored in the Memory to record the information of the agent's interaction with the user and applications. Memory The Memory class is responsible for managing the memory of the agent. It stores a list of MemoryItem instances that represent the agent's memory at each step. The Memory class is defined as follows: This data class represents a memory of an agent. content property Get the content of the memory. Returns: List [ MemoryItem ] \u2013 The content of the memory. length property Get the length of the memory. Returns: int \u2013 The length of the memory. list_content property List the content of the memory. Returns: List [ Dict [ str , str ]] \u2013 The content of the memory. add_memory_item ( memory_item ) Add a memory item to the memory. Parameters: memory_item ( MemoryItem ) \u2013 The memory item to add. Source code in agents/memory/memory.py 131 132 133 134 135 136 def add_memory_item ( self , memory_item : MemoryItem ) -> None : \"\"\" Add a memory item to the memory. :param memory_item: The memory item to add. \"\"\" self . _content . append ( memory_item ) clear () Clear the memory. Source code in agents/memory/memory.py 138 139 140 141 142 def clear ( self ) -> None : \"\"\" Clear the memory. \"\"\" self . _content = [] delete_memory_item ( step ) Delete a memory item from the memory. Parameters: step ( int ) \u2013 The step of the memory item to delete. Source code in agents/memory/memory.py 152 153 154 155 156 157 def delete_memory_item ( self , step : int ) -> None : \"\"\" Delete a memory item from the memory. :param step: The step of the memory item to delete. \"\"\" self . _content = [ item for item in self . _content if item . step != step ] filter_memory_from_keys ( keys ) Filter the memory from the keys. If an item does not have the key, the key will be ignored. Parameters: keys ( List [ str ] ) \u2013 The keys to filter. Returns: List [ Dict [ str , str ]] \u2013 The filtered memory. Source code in agents/memory/memory.py 123 124 125 126 127 128 129 def filter_memory_from_keys ( self , keys : List [ str ]) -> List [ Dict [ str , str ]]: \"\"\" Filter the memory from the keys. If an item does not have the key, the key will be ignored. :param keys: The keys to filter. :return: The filtered memory. \"\"\" return [ item . filter ( keys ) for item in self . _content ] filter_memory_from_steps ( steps ) Filter the memory from the steps. Parameters: steps ( List [ int ] ) \u2013 The steps to filter. Returns: List [ Dict [ str , str ]] \u2013 The filtered memory. Source code in agents/memory/memory.py 115 116 117 118 119 120 121 def filter_memory_from_steps ( self , steps : List [ int ]) -> List [ Dict [ str , str ]]: \"\"\" Filter the memory from the steps. :param steps: The steps to filter. :return: The filtered memory. \"\"\" return [ item . to_dict () for item in self . _content if item . step in steps ] from_list_of_dicts ( data ) Convert the list of dictionaries to the memory. Parameters: data ( List [ Dict [ str , str ]] ) \u2013 The list of dictionaries. Source code in agents/memory/memory.py 176 177 178 179 180 181 182 183 184 185 def from_list_of_dicts ( self , data : List [ Dict [ str , str ]]) -> None : \"\"\" Convert the list of dictionaries to the memory. :param data: The list of dictionaries. \"\"\" self . _content = [] for item in data : memory_item = MemoryItem () memory_item . from_dict ( item ) self . _content . append ( memory_item ) get_latest_item () Get the latest memory item. Returns: MemoryItem \u2013 The latest memory item. Source code in agents/memory/memory.py 187 188 189 190 191 192 193 194 def get_latest_item ( self ) -> MemoryItem : \"\"\" Get the latest memory item. :return: The latest memory item. \"\"\" if self . length == 0 : return None return self . _content [ - 1 ] is_empty () Check if the memory is empty. Returns: bool \u2013 The boolean value indicating if the memory is empty. Source code in agents/memory/memory.py 212 213 214 215 216 217 def is_empty ( self ) -> bool : \"\"\" Check if the memory is empty. :return: The boolean value indicating if the memory is empty. \"\"\" return self . length == 0 load ( content ) Load the data from the memory. Parameters: content ( List [ MemoryItem ] ) \u2013 The content to load. Source code in agents/memory/memory.py 108 109 110 111 112 113 def load ( self , content : List [ MemoryItem ]) -> None : \"\"\" Load the data from the memory. :param content: The content to load. \"\"\" self . _content = content to_json () Convert the memory to a JSON string. Returns: str \u2013 The JSON string. Source code in agents/memory/memory.py 159 160 161 162 163 164 165 166 167 def to_json ( self ) -> str : \"\"\" Convert the memory to a JSON string. :return: The JSON string. \"\"\" return json . dumps ( [ item . to_dict () for item in self . _content if item is not None ] ) to_list_of_dicts () Convert the memory to a list of dictionaries. Returns: List [ Dict [ str , str ]] \u2013 The list of dictionaries. Source code in agents/memory/memory.py 169 170 171 172 173 174 def to_list_of_dicts ( self ) -> List [ Dict [ str , str ]]: \"\"\" Convert the memory to a list of dictionaries. :return: The list of dictionaries. \"\"\" return [ item . to_dict () for item in self . _content ] Info Each agent has its own Memory instance to store their information. Info Not all information in the Memory are provided to the agent for decision-making. The agent can access parts of the memory based on the requirements of the agent's logic.","title":"Memory"},{"location":"agents/design/memory/#agent-memory","text":"The Memory manages the memory of the agent and stores the information required for the agent to interact with the user and applications at every step. Parts of elements in the Memory will be visible to the agent for decision-making.","title":"Agent Memory"},{"location":"agents/design/memory/#memoryitem","text":"A MemoryItem is a dataclass that represents a single step in the agent's memory. The fields of a MemoryItem is flexible and can be customized based on the requirements of the agent. The MemoryItem class is defined as follows: This data class represents a memory item of an agent at one step.","title":"MemoryItem"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.attributes","text":"Get the attributes of the memory item. Returns: List [ str ] \u2013 The attributes.","title":"attributes"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.add_values_from_dict","text":"Add fields to the memory item. Parameters: values ( Dict [ str , Any ] ) \u2013 The values of the fields. Source code in agents/memory/memory.py 66 67 68 69 70 71 72 def add_values_from_dict ( self , values : Dict [ str , Any ]) -> None : \"\"\" Add fields to the memory item. :param values: The values of the fields. \"\"\" for key , value in values . items (): self . set_value ( key , value )","title":"add_values_from_dict"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.filter","text":"Fetch the memory item. Parameters: keys ( List [ str ] , default: [] ) \u2013 The keys to fetch. Returns: None \u2013 The filtered memory item. Source code in agents/memory/memory.py 46 47 48 49 50 51 52 53 def filter ( self , keys : List [ str ] = []) -> None : \"\"\" Fetch the memory item. :param keys: The keys to fetch. :return: The filtered memory item. \"\"\" return { key : value for key , value in self . to_dict () . items () if key in keys }","title":"filter"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.from_dict","text":"Convert the dictionary to a MemoryItem. Parameters: data ( Dict [ str , str ] ) \u2013 The dictionary. Source code in agents/memory/memory.py 31 32 33 34 35 36 37 def from_dict ( self , data : Dict [ str , str ]) -> None : \"\"\" Convert the dictionary to a MemoryItem. :param data: The dictionary. \"\"\" for key , value in data . items (): self . set_value ( key , value )","title":"from_dict"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.get_value","text":"Get the value of the field. Parameters: key ( str ) \u2013 The key of the field. Returns: Optional [ str ] \u2013 The value of the field. Source code in agents/memory/memory.py 74 75 76 77 78 79 80 81 def get_value ( self , key : str ) -> Optional [ str ]: \"\"\" Get the value of the field. :param key: The key of the field. :return: The value of the field. \"\"\" return getattr ( self , key , None )","title":"get_value"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.get_values","text":"Get the values of the fields. Parameters: keys ( List [ str ] ) \u2013 The keys of the fields. Returns: dict \u2013 The values of the fields. Source code in agents/memory/memory.py 83 84 85 86 87 88 89 def get_values ( self , keys : List [ str ]) -> dict : \"\"\" Get the values of the fields. :param keys: The keys of the fields. :return: The values of the fields. \"\"\" return { key : self . get_value ( key ) for key in keys }","title":"get_values"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.set_value","text":"Add a field to the memory item. Parameters: key ( str ) \u2013 The key of the field. value ( str ) \u2013 The value of the field. Source code in agents/memory/memory.py 55 56 57 58 59 60 61 62 63 64 def set_value ( self , key : str , value : str ) -> None : \"\"\" Add a field to the memory item. :param key: The key of the field. :param value: The value of the field. \"\"\" setattr ( self , key , value ) if key not in self . _memory_attributes : self . _memory_attributes . append ( key )","title":"set_value"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.to_dict","text":"Convert the MemoryItem to a dictionary. Returns: Dict [ str , str ] \u2013 The dictionary. Source code in agents/memory/memory.py 19 20 21 22 23 24 25 26 27 28 29 def to_dict ( self ) -> Dict [ str , str ]: \"\"\" Convert the MemoryItem to a dictionary. :return: The dictionary. \"\"\" return { key : value for key , value in self . __dict__ . items () if key in self . _memory_attributes }","title":"to_dict"},{"location":"agents/design/memory/#agents.memory.memory.MemoryItem.to_json","text":"Convert the memory item to a JSON string. Returns: str \u2013 The JSON string. Source code in agents/memory/memory.py 39 40 41 42 43 44 def to_json ( self ) -> str : \"\"\" Convert the memory item to a JSON string. :return: The JSON string. \"\"\" return json . dumps ( self . to_dict ()) Info At each step, an instance of MemoryItem is created and stored in the Memory to record the information of the agent's interaction with the user and applications.","title":"to_json"},{"location":"agents/design/memory/#memory","text":"The Memory class is responsible for managing the memory of the agent. It stores a list of MemoryItem instances that represent the agent's memory at each step. The Memory class is defined as follows: This data class represents a memory of an agent.","title":"Memory"},{"location":"agents/design/memory/#agents.memory.memory.Memory.content","text":"Get the content of the memory. Returns: List [ MemoryItem ] \u2013 The content of the memory.","title":"content"},{"location":"agents/design/memory/#agents.memory.memory.Memory.length","text":"Get the length of the memory. Returns: int \u2013 The length of the memory.","title":"length"},{"location":"agents/design/memory/#agents.memory.memory.Memory.list_content","text":"List the content of the memory. Returns: List [ Dict [ str , str ]] \u2013 The content of the memory.","title":"list_content"},{"location":"agents/design/memory/#agents.memory.memory.Memory.add_memory_item","text":"Add a memory item to the memory. Parameters: memory_item ( MemoryItem ) \u2013 The memory item to add. Source code in agents/memory/memory.py 131 132 133 134 135 136 def add_memory_item ( self , memory_item : MemoryItem ) -> None : \"\"\" Add a memory item to the memory. :param memory_item: The memory item to add. \"\"\" self . _content . append ( memory_item )","title":"add_memory_item"},{"location":"agents/design/memory/#agents.memory.memory.Memory.clear","text":"Clear the memory. Source code in agents/memory/memory.py 138 139 140 141 142 def clear ( self ) -> None : \"\"\" Clear the memory. \"\"\" self . _content = []","title":"clear"},{"location":"agents/design/memory/#agents.memory.memory.Memory.delete_memory_item","text":"Delete a memory item from the memory. Parameters: step ( int ) \u2013 The step of the memory item to delete. Source code in agents/memory/memory.py 152 153 154 155 156 157 def delete_memory_item ( self , step : int ) -> None : \"\"\" Delete a memory item from the memory. :param step: The step of the memory item to delete. \"\"\" self . _content = [ item for item in self . _content if item . step != step ]","title":"delete_memory_item"},{"location":"agents/design/memory/#agents.memory.memory.Memory.filter_memory_from_keys","text":"Filter the memory from the keys. If an item does not have the key, the key will be ignored. Parameters: keys ( List [ str ] ) \u2013 The keys to filter. Returns: List [ Dict [ str , str ]] \u2013 The filtered memory. Source code in agents/memory/memory.py 123 124 125 126 127 128 129 def filter_memory_from_keys ( self , keys : List [ str ]) -> List [ Dict [ str , str ]]: \"\"\" Filter the memory from the keys. If an item does not have the key, the key will be ignored. :param keys: The keys to filter. :return: The filtered memory. \"\"\" return [ item . filter ( keys ) for item in self . _content ]","title":"filter_memory_from_keys"},{"location":"agents/design/memory/#agents.memory.memory.Memory.filter_memory_from_steps","text":"Filter the memory from the steps. Parameters: steps ( List [ int ] ) \u2013 The steps to filter. Returns: List [ Dict [ str , str ]] \u2013 The filtered memory. Source code in agents/memory/memory.py 115 116 117 118 119 120 121 def filter_memory_from_steps ( self , steps : List [ int ]) -> List [ Dict [ str , str ]]: \"\"\" Filter the memory from the steps. :param steps: The steps to filter. :return: The filtered memory. \"\"\" return [ item . to_dict () for item in self . _content if item . step in steps ]","title":"filter_memory_from_steps"},{"location":"agents/design/memory/#agents.memory.memory.Memory.from_list_of_dicts","text":"Convert the list of dictionaries to the memory. Parameters: data ( List [ Dict [ str , str ]] ) \u2013 The list of dictionaries. Source code in agents/memory/memory.py 176 177 178 179 180 181 182 183 184 185 def from_list_of_dicts ( self , data : List [ Dict [ str , str ]]) -> None : \"\"\" Convert the list of dictionaries to the memory. :param data: The list of dictionaries. \"\"\" self . _content = [] for item in data : memory_item = MemoryItem () memory_item . from_dict ( item ) self . _content . append ( memory_item )","title":"from_list_of_dicts"},{"location":"agents/design/memory/#agents.memory.memory.Memory.get_latest_item","text":"Get the latest memory item. Returns: MemoryItem \u2013 The latest memory item. Source code in agents/memory/memory.py 187 188 189 190 191 192 193 194 def get_latest_item ( self ) -> MemoryItem : \"\"\" Get the latest memory item. :return: The latest memory item. \"\"\" if self . length == 0 : return None return self . _content [ - 1 ]","title":"get_latest_item"},{"location":"agents/design/memory/#agents.memory.memory.Memory.is_empty","text":"Check if the memory is empty. Returns: bool \u2013 The boolean value indicating if the memory is empty. Source code in agents/memory/memory.py 212 213 214 215 216 217 def is_empty ( self ) -> bool : \"\"\" Check if the memory is empty. :return: The boolean value indicating if the memory is empty. \"\"\" return self . length == 0","title":"is_empty"},{"location":"agents/design/memory/#agents.memory.memory.Memory.load","text":"Load the data from the memory. Parameters: content ( List [ MemoryItem ] ) \u2013 The content to load. Source code in agents/memory/memory.py 108 109 110 111 112 113 def load ( self , content : List [ MemoryItem ]) -> None : \"\"\" Load the data from the memory. :param content: The content to load. \"\"\" self . _content = content","title":"load"},{"location":"agents/design/memory/#agents.memory.memory.Memory.to_json","text":"Convert the memory to a JSON string. Returns: str \u2013 The JSON string. Source code in agents/memory/memory.py 159 160 161 162 163 164 165 166 167 def to_json ( self ) -> str : \"\"\" Convert the memory to a JSON string. :return: The JSON string. \"\"\" return json . dumps ( [ item . to_dict () for item in self . _content if item is not None ] )","title":"to_json"},{"location":"agents/design/memory/#agents.memory.memory.Memory.to_list_of_dicts","text":"Convert the memory to a list of dictionaries. Returns: List [ Dict [ str , str ]] \u2013 The list of dictionaries. Source code in agents/memory/memory.py 169 170 171 172 173 174 def to_list_of_dicts ( self ) -> List [ Dict [ str , str ]]: \"\"\" Convert the memory to a list of dictionaries. :return: The list of dictionaries. \"\"\" return [ item . to_dict () for item in self . _content ] Info Each agent has its own Memory instance to store their information. Info Not all information in the Memory are provided to the agent for decision-making. The agent can access parts of the memory based on the requirements of the agent's logic.","title":"to_list_of_dicts"},{"location":"agents/design/processor/","text":"Agents Processor The Processor is a key component of the agent to process the core logic of the agent to process the user's request. The Processor is implemented as a class in the ufo/agents/processors folder. Each agent has its own Processor class withing the folder. Core Process Once called, an agent follows a series of steps to process the user's request defined in the Processor class by calling the process method. The workflow of the process is as follows: Step Description Function 1 Print the step information. print_step_info 2 Capture the screenshot of the application. capture_screenshot 3 Get the control information of the application. get_control_info 4 Get the prompt message for the LLM. get_prompt_message 5 Generate the response from the LLM. get_response 6 Update the cost of the step. update_cost 7 Parse the response from the LLM. parse_response 8 Execute the action based on the response. execute_action 9 Update the memory and blackboard. update_memory 10 Update the status of the agent. update_status At each step, the Processor processes the user's request by invoking the corresponding method sequentially to execute the necessary actions. The process may be paused. It can be resumed, based on the agent's logic and the user's request using the resume method. Reference Below is the basic structure of the Processor class: Bases: ABC The base processor for the session. A session consists of multiple rounds of conversation with the user, completing a task. At each round, the HostAgent and AppAgent interact with the user and the application with the processor. Each processor is responsible for processing the user request and updating the HostAgent and AppAgent at a single step in a round. Initialize the processor. Parameters: context ( Context ) \u2013 The context of the session. agent ( BasicAgent ) \u2013 The agent who executes the processor. Source code in agents/processors/basic.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , agent : BasicAgent , context : Context ) -> None : \"\"\" Initialize the processor. :param context: The context of the session. :param agent: The agent who executes the processor. \"\"\" self . _context = context self . _agent = agent self . photographer = PhotographerFacade () self . control_inspector = ControlInspectorFacade ( BACKEND ) self . _prompt_message = None self . _status = None self . _response = None self . _cost = 0 self . _control_label = None self . _control_text = None self . _response_json = {} self . _memory_data = MemoryItem () self . _question_list = [] self . _agent_status_manager = self . agent . status_manager self . _is_resumed = False self . _plan = None self . _total_time_cost = 0 self . _time_cost = {} self . _exeception_traceback = {} self . _actions = ActionSequence () actions property writable Get the actions. Returns: ActionSequence \u2013 The actions. agent property Get the agent. Returns: BasicAgent \u2013 The agent. app_root property writable Get the application root. Returns: str \u2013 The application root. application_process_name property writable Get the application process name. Returns: str \u2013 The application process name. application_window property writable Get the active window. Returns: UIAWrapper \u2013 The active window. context property Get the context. Returns: Context \u2013 The context. control_label property writable Get the control label. Returns: str \u2013 The control label. control_reannotate property writable Get the control reannotation. Returns: List [ str ] \u2013 The control reannotation. control_text property writable Get the active application. Returns: str \u2013 The active application. cost property writable Get the cost of the processor. Returns: float \u2013 The cost of the processor. host_message property writable Get the host message. Returns: List [ str ] \u2013 The host message. log_path property Get the log path. Returns: str \u2013 The log path. logger property Get the logger. Returns: str \u2013 The logger. name property Get the name of the processor. Returns: str \u2013 The name of the processor. plan property writable Get the plan of the agent. Returns: str \u2013 The plan. prev_plan property Get the previous plan. Returns: List [ str ] \u2013 The previous plan of the agent. previous_subtasks property writable Get the previous subtasks. Returns: List [ str ] \u2013 The previous subtasks. question_list property writable Get the question list. Returns: List [ str ] \u2013 The question list. request property Get the request. Returns: str \u2013 The request. request_logger property Get the request logger. Returns: str \u2013 The request logger. round_cost property writable Get the round cost. Returns: float \u2013 The round cost. round_num property Get the round number. Returns: int \u2013 The round number. round_step property writable Get the round step. Returns: int \u2013 The round step. round_subtask_amount property Get the round subtask amount. Returns: int \u2013 The round subtask amount. session_cost property writable Get the session cost. Returns: float \u2013 The session cost. session_step property writable Get the session step. Returns: int \u2013 The session step. status property writable Get the status of the processor. Returns: str \u2013 The status of the processor. subtask property writable Get the subtask. Returns: str \u2013 The subtask. ui_tree_path property Get the UI tree path. Returns: str \u2013 The UI tree path. add_to_memory ( data_dict ) Add the data to the memory. Parameters: data_dict ( Dict [ str , Any ] ) \u2013 The data dictionary to be added to the memory. Source code in agents/processors/basic.py 293 294 295 296 297 298 def add_to_memory ( self , data_dict : Dict [ str , Any ]) -> None : \"\"\" Add the data to the memory. :param data_dict: The data dictionary to be added to the memory. \"\"\" self . _memory_data . add_values_from_dict ( data_dict ) capture_screenshot () abstractmethod Capture the screenshot. Source code in agents/processors/basic.py 231 232 233 234 235 236 @abstractmethod def capture_screenshot ( self ) -> None : \"\"\" Capture the screenshot. \"\"\" pass exception_capture ( func ) classmethod Decorator to capture the exception of the method. Parameters: func \u2013 The method to be decorated. Returns: \u2013 The decorated method. Source code in agents/processors/basic.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 @classmethod def exception_capture ( cls , func ): \"\"\" Decorator to capture the exception of the method. :param func: The method to be decorated. :return: The decorated method. \"\"\" @wraps ( func ) def wrapper ( self , * args , ** kwargs ): try : func ( self , * args , ** kwargs ) except Exception as e : self . _exeception_traceback [ func . __name__ ] = { \"type\" : str ( type ( e ) . __name__ ), \"message\" : str ( e ), \"traceback\" : traceback . format_exc (), } utils . print_with_color ( f \"Error Occurs at { func . __name__ } \" , \"red\" ) utils . print_with_color ( self . _exeception_traceback [ func . __name__ ][ \"traceback\" ], \"red\" ) if self . _response is not None : utils . print_with_color ( \"Response: \" , \"red\" ) utils . print_with_color ( self . _response , \"red\" ) self . _status = self . _agent_status_manager . ERROR . value self . sync_memory () self . add_to_memory ({ \"error\" : self . _exeception_traceback }) self . add_to_memory ({ \"Status\" : self . _status }) self . log_save () raise StopIteration ( \"Error occurred during step.\" ) return wrapper execute_action () abstractmethod Execute the action. Source code in agents/processors/basic.py 266 267 268 269 270 271 @abstractmethod def execute_action ( self ) -> None : \"\"\" Execute the action. \"\"\" pass get_control_info () abstractmethod Get the control information. Source code in agents/processors/basic.py 238 239 240 241 242 243 @abstractmethod def get_control_info ( self ) -> None : \"\"\" Get the control information. \"\"\" pass get_prompt_message () abstractmethod Get the prompt message. Source code in agents/processors/basic.py 245 246 247 248 249 250 @abstractmethod def get_prompt_message ( self ) -> None : \"\"\" Get the prompt message. \"\"\" pass get_response () abstractmethod Get the response from the LLM. Source code in agents/processors/basic.py 252 253 254 255 256 257 @abstractmethod def get_response ( self ) -> None : \"\"\" Get the response from the LLM. \"\"\" pass is_application_closed () Check if the application is closed. Returns: bool \u2013 The boolean value indicating if the application is closed. Source code in agents/processors/basic.py 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 def is_application_closed ( self ) -> bool : \"\"\" Check if the application is closed. :return: The boolean value indicating if the application is closed. \"\"\" if self . application_window is None : return True try : self . application_window . is_enabled () return False except : return True is_confirm () Check if the process is confirm. Returns: bool \u2013 The boolean value indicating if the process is confirm. Source code in agents/processors/basic.py 732 733 734 735 736 737 738 739 740 def is_confirm ( self ) -> bool : \"\"\" Check if the process is confirm. :return: The boolean value indicating if the process is confirm. \"\"\" self . agent . status = self . status return self . status == self . _agent_status_manager . CONFIRM . value is_error () Check if the process is in error. Returns: bool \u2013 The boolean value indicating if the process is in error. Source code in agents/processors/basic.py 700 701 702 703 704 705 706 707 def is_error ( self ) -> bool : \"\"\" Check if the process is in error. :return: The boolean value indicating if the process is in error. \"\"\" self . agent . status = self . status return self . status == self . _agent_status_manager . ERROR . value is_paused () Check if the process is paused. Returns: bool \u2013 The boolean value indicating if the process is paused. Source code in agents/processors/basic.py 709 710 711 712 713 714 715 716 717 718 719 720 def is_paused ( self ) -> bool : \"\"\" Check if the process is paused. :return: The boolean value indicating if the process is paused. \"\"\" self . agent . status = self . status return ( self . status == self . _agent_status_manager . PENDING . value or self . status == self . _agent_status_manager . CONFIRM . value ) is_pending () Check if the process is pending. Returns: bool \u2013 The boolean value indicating if the process is pending. Source code in agents/processors/basic.py 722 723 724 725 726 727 728 729 730 def is_pending ( self ) -> bool : \"\"\" Check if the process is pending. :return: The boolean value indicating if the process is pending. \"\"\" self . agent . status = self . status return self . status == self . _agent_status_manager . PENDING . value log ( response_json ) Set the result of the session, and log the result. result: The result of the session. response_json: The response json. return: The response json. Source code in agents/processors/basic.py 758 759 760 761 762 763 764 765 766 def log ( self , response_json : Dict [ str , Any ]) -> None : \"\"\" Set the result of the session, and log the result. result: The result of the session. response_json: The response json. return: The response json. \"\"\" self . logger . info ( json . dumps ( response_json )) log_save () Save the log. Source code in agents/processors/basic.py 300 301 302 303 304 305 306 307 308 def log_save ( self ) -> None : \"\"\" Save the log. \"\"\" self . _memory_data . add_values_from_dict ( { \"total_time_cost\" : self . _total_time_cost } ) self . log ( self . _memory_data . to_dict ()) method_timer ( func ) classmethod Decorator to calculate the time cost of the method. Parameters: func \u2013 The method to be decorated. Returns: \u2013 The decorated method. Source code in agents/processors/basic.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 @classmethod def method_timer ( cls , func ): \"\"\" Decorator to calculate the time cost of the method. :param func: The method to be decorated. :return: The decorated method. \"\"\" @wraps ( func ) def wrapper ( self , * args , ** kwargs ): start_time = time . time () result = func ( self , * args , ** kwargs ) end_time = time . time () self . _time_cost [ func . __name__ ] = end_time - start_time return result return wrapper parse_response () abstractmethod Parse the response. Source code in agents/processors/basic.py 259 260 261 262 263 264 @abstractmethod def parse_response ( self ) -> None : \"\"\" Parse the response. \"\"\" pass print_step_info () abstractmethod Print the step information. Source code in agents/processors/basic.py 224 225 226 227 228 229 @abstractmethod def print_step_info ( self ) -> None : \"\"\" Print the step information. \"\"\" pass process () Process a single step in a round. The process includes the following steps: 1. Print the step information. 2. Capture the screenshot. 3. Get the control information. 4. Get the prompt message. 5. Get the response. 6. Update the cost. 7. Parse the response. 8. Execute the action. 9. Update the memory. 10. Update the step and status. 11. Save the log. Source code in agents/processors/basic.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def process ( self ) -> None : \"\"\" Process a single step in a round. The process includes the following steps: 1. Print the step information. 2. Capture the screenshot. 3. Get the control information. 4. Get the prompt message. 5. Get the response. 6. Update the cost. 7. Parse the response. 8. Execute the action. 9. Update the memory. 10. Update the step and status. 11. Save the log. \"\"\" start_time = time . time () try : # Step 1: Print the step information. self . print_step_info () # Step 2: Capture the screenshot. self . capture_screenshot () # Step 3: Get the control information. self . get_control_info () # Step 4: Get the prompt message. self . get_prompt_message () # Step 5: Get the response. self . get_response () # Step 6: Update the context. self . update_cost () # Step 7: Parse the response, if there is no error. self . parse_response () if self . is_pending () or self . is_paused (): # If the session is pending, update the step and memory, and return. if self . is_pending (): self . update_status () self . update_memory () return # Step 8: Execute the action. self . execute_action () # Step 9: Update the memory. self . update_memory () # Step 10: Update the status. self . update_status () self . _total_time_cost = time . time () - start_time # Step 11: Save the log. self . log_save () except StopIteration : # Error was handled and logged in the exception capture decorator. # Simply return here to stop the process early. return resume () Resume the process of action execution after the session is paused. Source code in agents/processors/basic.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def resume ( self ) -> None : \"\"\" Resume the process of action execution after the session is paused. \"\"\" self . _is_resumed = True try : # Step 1: Execute the action. self . execute_action () # Step 2: Update the memory. self . update_memory () # Step 3: Update the status. self . update_status () except StopIteration : # Error was handled and logged in the exception capture decorator. # Simply return here to stop the process early. pass finally : self . _is_resumed = False string2list ( string ) staticmethod Convert a string to a list of string if the input is a string. Parameters: string ( Any ) \u2013 The string. Returns: List [ str ] \u2013 The list. Source code in agents/processors/basic.py 776 777 778 779 780 781 782 783 784 785 786 @staticmethod def string2list ( string : Any ) -> List [ str ]: \"\"\" Convert a string to a list of string if the input is a string. :param string: The string. :return: The list. \"\"\" if isinstance ( string , str ): return [ string ] else : return string sync_memory () abstractmethod Sync the memory of the Agent. Source code in agents/processors/basic.py 217 218 219 220 221 222 @abstractmethod def sync_memory ( self ) -> None : \"\"\" Sync the memory of the Agent. \"\"\" pass update_cost () Update the cost. Source code in agents/processors/basic.py 318 319 320 321 322 323 324 def update_cost ( self ) -> None : \"\"\" Update the cost. \"\"\" self . round_cost += self . cost self . session_cost += self . cost update_memory () abstractmethod Update the memory of the Agent. Source code in agents/processors/basic.py 273 274 275 276 277 278 @abstractmethod def update_memory ( self ) -> None : \"\"\" Update the memory of the Agent. \"\"\" pass update_status () Update the status of the session. Source code in agents/processors/basic.py 280 281 282 283 284 285 286 287 288 289 290 291 def update_status ( self ) -> None : \"\"\" Update the status of the session. \"\"\" self . agent . step += 1 self . agent . status = self . status if self . status != self . _agent_status_manager . FINISH . value : time . sleep ( configs [ \"SLEEP_TIME\" ]) self . round_step += 1 self . session_step += 1","title":"Processor"},{"location":"agents/design/processor/#agents-processor","text":"The Processor is a key component of the agent to process the core logic of the agent to process the user's request. The Processor is implemented as a class in the ufo/agents/processors folder. Each agent has its own Processor class withing the folder.","title":"Agents Processor"},{"location":"agents/design/processor/#core-process","text":"Once called, an agent follows a series of steps to process the user's request defined in the Processor class by calling the process method. The workflow of the process is as follows: Step Description Function 1 Print the step information. print_step_info 2 Capture the screenshot of the application. capture_screenshot 3 Get the control information of the application. get_control_info 4 Get the prompt message for the LLM. get_prompt_message 5 Generate the response from the LLM. get_response 6 Update the cost of the step. update_cost 7 Parse the response from the LLM. parse_response 8 Execute the action based on the response. execute_action 9 Update the memory and blackboard. update_memory 10 Update the status of the agent. update_status At each step, the Processor processes the user's request by invoking the corresponding method sequentially to execute the necessary actions. The process may be paused. It can be resumed, based on the agent's logic and the user's request using the resume method.","title":"Core Process"},{"location":"agents/design/processor/#reference","text":"Below is the basic structure of the Processor class: Bases: ABC The base processor for the session. A session consists of multiple rounds of conversation with the user, completing a task. At each round, the HostAgent and AppAgent interact with the user and the application with the processor. Each processor is responsible for processing the user request and updating the HostAgent and AppAgent at a single step in a round. Initialize the processor. Parameters: context ( Context ) \u2013 The context of the session. agent ( BasicAgent ) \u2013 The agent who executes the processor. Source code in agents/processors/basic.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , agent : BasicAgent , context : Context ) -> None : \"\"\" Initialize the processor. :param context: The context of the session. :param agent: The agent who executes the processor. \"\"\" self . _context = context self . _agent = agent self . photographer = PhotographerFacade () self . control_inspector = ControlInspectorFacade ( BACKEND ) self . _prompt_message = None self . _status = None self . _response = None self . _cost = 0 self . _control_label = None self . _control_text = None self . _response_json = {} self . _memory_data = MemoryItem () self . _question_list = [] self . _agent_status_manager = self . agent . status_manager self . _is_resumed = False self . _plan = None self . _total_time_cost = 0 self . _time_cost = {} self . _exeception_traceback = {} self . _actions = ActionSequence ()","title":"Reference"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.actions","text":"Get the actions. Returns: ActionSequence \u2013 The actions.","title":"actions"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.agent","text":"Get the agent. Returns: BasicAgent \u2013 The agent.","title":"agent"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.app_root","text":"Get the application root. Returns: str \u2013 The application root.","title":"app_root"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.application_process_name","text":"Get the application process name. Returns: str \u2013 The application process name.","title":"application_process_name"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.application_window","text":"Get the active window. Returns: UIAWrapper \u2013 The active window.","title":"application_window"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.context","text":"Get the context. Returns: Context \u2013 The context.","title":"context"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.control_label","text":"Get the control label. Returns: str \u2013 The control label.","title":"control_label"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.control_reannotate","text":"Get the control reannotation. Returns: List [ str ] \u2013 The control reannotation.","title":"control_reannotate"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.control_text","text":"Get the active application. Returns: str \u2013 The active application.","title":"control_text"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.cost","text":"Get the cost of the processor. Returns: float \u2013 The cost of the processor.","title":"cost"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.host_message","text":"Get the host message. Returns: List [ str ] \u2013 The host message.","title":"host_message"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.log_path","text":"Get the log path. Returns: str \u2013 The log path.","title":"log_path"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.logger","text":"Get the logger. Returns: str \u2013 The logger.","title":"logger"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.name","text":"Get the name of the processor. Returns: str \u2013 The name of the processor.","title":"name"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.plan","text":"Get the plan of the agent. Returns: str \u2013 The plan.","title":"plan"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.prev_plan","text":"Get the previous plan. Returns: List [ str ] \u2013 The previous plan of the agent.","title":"prev_plan"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.previous_subtasks","text":"Get the previous subtasks. Returns: List [ str ] \u2013 The previous subtasks.","title":"previous_subtasks"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.question_list","text":"Get the question list. Returns: List [ str ] \u2013 The question list.","title":"question_list"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.request","text":"Get the request. Returns: str \u2013 The request.","title":"request"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.request_logger","text":"Get the request logger. Returns: str \u2013 The request logger.","title":"request_logger"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.round_cost","text":"Get the round cost. Returns: float \u2013 The round cost.","title":"round_cost"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.round_num","text":"Get the round number. Returns: int \u2013 The round number.","title":"round_num"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.round_step","text":"Get the round step. Returns: int \u2013 The round step.","title":"round_step"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.round_subtask_amount","text":"Get the round subtask amount. Returns: int \u2013 The round subtask amount.","title":"round_subtask_amount"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.session_cost","text":"Get the session cost. Returns: float \u2013 The session cost.","title":"session_cost"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.session_step","text":"Get the session step. Returns: int \u2013 The session step.","title":"session_step"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.status","text":"Get the status of the processor. Returns: str \u2013 The status of the processor.","title":"status"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.subtask","text":"Get the subtask. Returns: str \u2013 The subtask.","title":"subtask"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.ui_tree_path","text":"Get the UI tree path. Returns: str \u2013 The UI tree path.","title":"ui_tree_path"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.add_to_memory","text":"Add the data to the memory. Parameters: data_dict ( Dict [ str , Any ] ) \u2013 The data dictionary to be added to the memory. Source code in agents/processors/basic.py 293 294 295 296 297 298 def add_to_memory ( self , data_dict : Dict [ str , Any ]) -> None : \"\"\" Add the data to the memory. :param data_dict: The data dictionary to be added to the memory. \"\"\" self . _memory_data . add_values_from_dict ( data_dict )","title":"add_to_memory"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.capture_screenshot","text":"Capture the screenshot. Source code in agents/processors/basic.py 231 232 233 234 235 236 @abstractmethod def capture_screenshot ( self ) -> None : \"\"\" Capture the screenshot. \"\"\" pass","title":"capture_screenshot"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.exception_capture","text":"Decorator to capture the exception of the method. Parameters: func \u2013 The method to be decorated. Returns: \u2013 The decorated method. Source code in agents/processors/basic.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 @classmethod def exception_capture ( cls , func ): \"\"\" Decorator to capture the exception of the method. :param func: The method to be decorated. :return: The decorated method. \"\"\" @wraps ( func ) def wrapper ( self , * args , ** kwargs ): try : func ( self , * args , ** kwargs ) except Exception as e : self . _exeception_traceback [ func . __name__ ] = { \"type\" : str ( type ( e ) . __name__ ), \"message\" : str ( e ), \"traceback\" : traceback . format_exc (), } utils . print_with_color ( f \"Error Occurs at { func . __name__ } \" , \"red\" ) utils . print_with_color ( self . _exeception_traceback [ func . __name__ ][ \"traceback\" ], \"red\" ) if self . _response is not None : utils . print_with_color ( \"Response: \" , \"red\" ) utils . print_with_color ( self . _response , \"red\" ) self . _status = self . _agent_status_manager . ERROR . value self . sync_memory () self . add_to_memory ({ \"error\" : self . _exeception_traceback }) self . add_to_memory ({ \"Status\" : self . _status }) self . log_save () raise StopIteration ( \"Error occurred during step.\" ) return wrapper","title":"exception_capture"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.execute_action","text":"Execute the action. Source code in agents/processors/basic.py 266 267 268 269 270 271 @abstractmethod def execute_action ( self ) -> None : \"\"\" Execute the action. \"\"\" pass","title":"execute_action"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.get_control_info","text":"Get the control information. Source code in agents/processors/basic.py 238 239 240 241 242 243 @abstractmethod def get_control_info ( self ) -> None : \"\"\" Get the control information. \"\"\" pass","title":"get_control_info"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.get_prompt_message","text":"Get the prompt message. Source code in agents/processors/basic.py 245 246 247 248 249 250 @abstractmethod def get_prompt_message ( self ) -> None : \"\"\" Get the prompt message. \"\"\" pass","title":"get_prompt_message"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.get_response","text":"Get the response from the LLM. Source code in agents/processors/basic.py 252 253 254 255 256 257 @abstractmethod def get_response ( self ) -> None : \"\"\" Get the response from the LLM. \"\"\" pass","title":"get_response"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.is_application_closed","text":"Check if the application is closed. Returns: bool \u2013 The boolean value indicating if the application is closed. Source code in agents/processors/basic.py 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 def is_application_closed ( self ) -> bool : \"\"\" Check if the application is closed. :return: The boolean value indicating if the application is closed. \"\"\" if self . application_window is None : return True try : self . application_window . is_enabled () return False except : return True","title":"is_application_closed"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.is_confirm","text":"Check if the process is confirm. Returns: bool \u2013 The boolean value indicating if the process is confirm. Source code in agents/processors/basic.py 732 733 734 735 736 737 738 739 740 def is_confirm ( self ) -> bool : \"\"\" Check if the process is confirm. :return: The boolean value indicating if the process is confirm. \"\"\" self . agent . status = self . status return self . status == self . _agent_status_manager . CONFIRM . value","title":"is_confirm"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.is_error","text":"Check if the process is in error. Returns: bool \u2013 The boolean value indicating if the process is in error. Source code in agents/processors/basic.py 700 701 702 703 704 705 706 707 def is_error ( self ) -> bool : \"\"\" Check if the process is in error. :return: The boolean value indicating if the process is in error. \"\"\" self . agent . status = self . status return self . status == self . _agent_status_manager . ERROR . value","title":"is_error"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.is_paused","text":"Check if the process is paused. Returns: bool \u2013 The boolean value indicating if the process is paused. Source code in agents/processors/basic.py 709 710 711 712 713 714 715 716 717 718 719 720 def is_paused ( self ) -> bool : \"\"\" Check if the process is paused. :return: The boolean value indicating if the process is paused. \"\"\" self . agent . status = self . status return ( self . status == self . _agent_status_manager . PENDING . value or self . status == self . _agent_status_manager . CONFIRM . value )","title":"is_paused"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.is_pending","text":"Check if the process is pending. Returns: bool \u2013 The boolean value indicating if the process is pending. Source code in agents/processors/basic.py 722 723 724 725 726 727 728 729 730 def is_pending ( self ) -> bool : \"\"\" Check if the process is pending. :return: The boolean value indicating if the process is pending. \"\"\" self . agent . status = self . status return self . status == self . _agent_status_manager . PENDING . value","title":"is_pending"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.log","text":"Set the result of the session, and log the result. result: The result of the session. response_json: The response json. return: The response json. Source code in agents/processors/basic.py 758 759 760 761 762 763 764 765 766 def log ( self , response_json : Dict [ str , Any ]) -> None : \"\"\" Set the result of the session, and log the result. result: The result of the session. response_json: The response json. return: The response json. \"\"\" self . logger . info ( json . dumps ( response_json ))","title":"log"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.log_save","text":"Save the log. Source code in agents/processors/basic.py 300 301 302 303 304 305 306 307 308 def log_save ( self ) -> None : \"\"\" Save the log. \"\"\" self . _memory_data . add_values_from_dict ( { \"total_time_cost\" : self . _total_time_cost } ) self . log ( self . _memory_data . to_dict ())","title":"log_save"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.method_timer","text":"Decorator to calculate the time cost of the method. Parameters: func \u2013 The method to be decorated. Returns: \u2013 The decorated method. Source code in agents/processors/basic.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 @classmethod def method_timer ( cls , func ): \"\"\" Decorator to calculate the time cost of the method. :param func: The method to be decorated. :return: The decorated method. \"\"\" @wraps ( func ) def wrapper ( self , * args , ** kwargs ): start_time = time . time () result = func ( self , * args , ** kwargs ) end_time = time . time () self . _time_cost [ func . __name__ ] = end_time - start_time return result return wrapper","title":"method_timer"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.parse_response","text":"Parse the response. Source code in agents/processors/basic.py 259 260 261 262 263 264 @abstractmethod def parse_response ( self ) -> None : \"\"\" Parse the response. \"\"\" pass","title":"parse_response"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.print_step_info","text":"Print the step information. Source code in agents/processors/basic.py 224 225 226 227 228 229 @abstractmethod def print_step_info ( self ) -> None : \"\"\" Print the step information. \"\"\" pass","title":"print_step_info"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.process","text":"Process a single step in a round. The process includes the following steps: 1. Print the step information. 2. Capture the screenshot. 3. Get the control information. 4. Get the prompt message. 5. Get the response. 6. Update the cost. 7. Parse the response. 8. Execute the action. 9. Update the memory. 10. Update the step and status. 11. Save the log. Source code in agents/processors/basic.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def process ( self ) -> None : \"\"\" Process a single step in a round. The process includes the following steps: 1. Print the step information. 2. Capture the screenshot. 3. Get the control information. 4. Get the prompt message. 5. Get the response. 6. Update the cost. 7. Parse the response. 8. Execute the action. 9. Update the memory. 10. Update the step and status. 11. Save the log. \"\"\" start_time = time . time () try : # Step 1: Print the step information. self . print_step_info () # Step 2: Capture the screenshot. self . capture_screenshot () # Step 3: Get the control information. self . get_control_info () # Step 4: Get the prompt message. self . get_prompt_message () # Step 5: Get the response. self . get_response () # Step 6: Update the context. self . update_cost () # Step 7: Parse the response, if there is no error. self . parse_response () if self . is_pending () or self . is_paused (): # If the session is pending, update the step and memory, and return. if self . is_pending (): self . update_status () self . update_memory () return # Step 8: Execute the action. self . execute_action () # Step 9: Update the memory. self . update_memory () # Step 10: Update the status. self . update_status () self . _total_time_cost = time . time () - start_time # Step 11: Save the log. self . log_save () except StopIteration : # Error was handled and logged in the exception capture decorator. # Simply return here to stop the process early. return","title":"process"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.resume","text":"Resume the process of action execution after the session is paused. Source code in agents/processors/basic.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def resume ( self ) -> None : \"\"\" Resume the process of action execution after the session is paused. \"\"\" self . _is_resumed = True try : # Step 1: Execute the action. self . execute_action () # Step 2: Update the memory. self . update_memory () # Step 3: Update the status. self . update_status () except StopIteration : # Error was handled and logged in the exception capture decorator. # Simply return here to stop the process early. pass finally : self . _is_resumed = False","title":"resume"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.string2list","text":"Convert a string to a list of string if the input is a string. Parameters: string ( Any ) \u2013 The string. Returns: List [ str ] \u2013 The list. Source code in agents/processors/basic.py 776 777 778 779 780 781 782 783 784 785 786 @staticmethod def string2list ( string : Any ) -> List [ str ]: \"\"\" Convert a string to a list of string if the input is a string. :param string: The string. :return: The list. \"\"\" if isinstance ( string , str ): return [ string ] else : return string","title":"string2list"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.sync_memory","text":"Sync the memory of the Agent. Source code in agents/processors/basic.py 217 218 219 220 221 222 @abstractmethod def sync_memory ( self ) -> None : \"\"\" Sync the memory of the Agent. \"\"\" pass","title":"sync_memory"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.update_cost","text":"Update the cost. Source code in agents/processors/basic.py 318 319 320 321 322 323 324 def update_cost ( self ) -> None : \"\"\" Update the cost. \"\"\" self . round_cost += self . cost self . session_cost += self . cost","title":"update_cost"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.update_memory","text":"Update the memory of the Agent. Source code in agents/processors/basic.py 273 274 275 276 277 278 @abstractmethod def update_memory ( self ) -> None : \"\"\" Update the memory of the Agent. \"\"\" pass","title":"update_memory"},{"location":"agents/design/processor/#agents.processors.basic.BaseProcessor.update_status","text":"Update the status of the session. Source code in agents/processors/basic.py 280 281 282 283 284 285 286 287 288 289 290 291 def update_status ( self ) -> None : \"\"\" Update the status of the session. \"\"\" self . agent . step += 1 self . agent . status = self . status if self . status != self . _agent_status_manager . FINISH . value : time . sleep ( configs [ \"SLEEP_TIME\" ]) self . round_step += 1 self . session_step += 1","title":"update_status"},{"location":"agents/design/prompter/","text":"Agent Prompter The Prompter is a key component of the UFO framework, responsible for constructing prompts for the LLM to generate responses. The Prompter is implemented in the ufo/prompts folder. Each agent has its own Prompter class that defines the structure of the prompt and the information to be fed to the LLM. Components A prompt fed to the LLM usually a list of dictionaries, where each dictionary contains the following keys: Key Description role The role of the text in the prompt, can be system , user , or assistant . content The content of the text for the specific role. Tip You may find the official documentation helpful for constructing the prompt. In the __init__ method of the Prompter class, you can define the template of the prompt for each component, and the final prompt message is constructed by combining the templates of each component using the prompt_construction method. System Prompt The system prompt use the template configured in the config_dev.yaml file for each agent. It usually contains the instructions for the agent's role, action, tips, reponse format, etc. You need use the system_prompt_construction method to construct the system prompt. Prompts on the API instructions, and demonstration examples are also included in the system prompt, which are constructed by the api_prompt_helper and examples_prompt_helper methods respectively. Below is the sub-components of the system prompt: Component Description Method apis The API instructions for the agent. api_prompt_helper examples The demonstration examples for the agent. examples_prompt_helper User Prompt The user prompt is constructed based on the information from the agent's observation, external knowledge, and Blackboard . You can use the user_prompt_construction method to construct the user prompt. Below is the sub-components of the user prompt: Component Description Method observation The observation of the agent. user_content_construction retrieved_docs The knowledge retrieved from the external knowledge base. retrived_documents_prompt_helper blackboard The information stored in the Blackboard . blackboard_to_prompt Reference You can find the implementation of the Prompter in the ufo/prompts folder. Below is the basic structure of the Prompter class: Bases: ABC The BasicPrompter class is the abstract class for the prompter. Initialize the BasicPrompter. Parameters: is_visual ( bool ) \u2013 Whether the request is for visual model. prompt_template ( str ) \u2013 The path of the prompt template. example_prompt_template ( str ) \u2013 The path of the example prompt template. Source code in prompter/basic.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , is_visual : bool , prompt_template : str , example_prompt_template : str ): \"\"\" Initialize the BasicPrompter. :param is_visual: Whether the request is for visual model. :param prompt_template: The path of the prompt template. :param example_prompt_template: The path of the example prompt template. \"\"\" self . is_visual = is_visual if prompt_template : self . prompt_template = self . load_prompt_template ( prompt_template , is_visual ) else : self . prompt_template = \"\" if example_prompt_template : self . example_prompt_template = self . load_prompt_template ( example_prompt_template , is_visual ) else : self . example_prompt_template = \"\" api_prompt_helper () A helper function to construct the API list and descriptions for the prompt. Source code in prompter/basic.py 139 140 141 142 143 144 def api_prompt_helper ( self ) -> str : \"\"\" A helper function to construct the API list and descriptions for the prompt. \"\"\" pass examples_prompt_helper () A helper function to construct the examples prompt for in-context learning. Source code in prompter/basic.py 132 133 134 135 136 137 def examples_prompt_helper ( self ) -> str : \"\"\" A helper function to construct the examples prompt for in-context learning. \"\"\" pass load_prompt_template ( template_path , is_visual = None ) staticmethod Load the prompt template. Returns: Dict [ str , str ] \u2013 The prompt template. Source code in prompter/basic.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 @staticmethod def load_prompt_template ( template_path : str , is_visual = None ) -> Dict [ str , str ]: \"\"\" Load the prompt template. :return: The prompt template. \"\"\" if is_visual == None : path = template_path else : path = template_path . format ( mode = \"visual\" if is_visual == True else \"nonvisual\" ) if not path : return {} if os . path . exists ( path ): try : prompt = yaml . safe_load ( open ( path , \"r\" , encoding = \"utf-8\" )) except yaml . YAMLError as exc : print_with_color ( f \"Error loading prompt template: { exc } \" , \"yellow\" ) else : raise FileNotFoundError ( f \"Prompt template not found at { path } \" ) return prompt prompt_construction ( system_prompt , user_content ) staticmethod Construct the prompt for summarizing the experience into an example. Parameters: user_content ( List [ Dict [ str , str ]] ) \u2013 The user content. return: The prompt for summarizing the experience into an example. Source code in prompter/basic.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 @staticmethod def prompt_construction ( system_prompt : str , user_content : List [ Dict [ str , str ]] ) -> List : \"\"\" Construct the prompt for summarizing the experience into an example. :param user_content: The user content. return: The prompt for summarizing the experience into an example. \"\"\" system_message = { \"role\" : \"system\" , \"content\" : system_prompt } user_message = { \"role\" : \"user\" , \"content\" : user_content } prompt_message = [ system_message , user_message ] return prompt_message retrived_documents_prompt_helper ( header , separator , documents ) staticmethod Construct the prompt for retrieved documents. Parameters: header ( str ) \u2013 The header of the prompt. separator ( str ) \u2013 The separator of the prompt. documents ( List [ str ] ) \u2013 The retrieved documents. return: The prompt for retrieved documents. Source code in prompter/basic.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @staticmethod def retrived_documents_prompt_helper ( header : str , separator : str , documents : List [ str ] ) -> str : \"\"\" Construct the prompt for retrieved documents. :param header: The header of the prompt. :param separator: The separator of the prompt. :param documents: The retrieved documents. return: The prompt for retrieved documents. \"\"\" if header : prompt = \" \\n < {header} :> \\n \" . format ( header = header ) else : prompt = \"\" for i , document in enumerate ( documents ): if separator : prompt += \"[ {separator} {i} :]\" . format ( separator = separator , i = i + 1 ) prompt += \" \\n \" prompt += document prompt += \" \\n\\n \" return prompt system_prompt_construction () abstractmethod Construct the system prompt for LLM. Source code in prompter/basic.py 108 109 110 111 112 113 114 @abstractmethod def system_prompt_construction ( self ) -> str : \"\"\" Construct the system prompt for LLM. \"\"\" pass user_content_construction () abstractmethod Construct the full user content for LLM, including the user prompt and images. Source code in prompter/basic.py 124 125 126 127 128 129 130 @abstractmethod def user_content_construction ( self ) -> str : \"\"\" Construct the full user content for LLM, including the user prompt and images. \"\"\" pass user_prompt_construction () abstractmethod Construct the textual user prompt for LLM based on the user field in the prompt template. Source code in prompter/basic.py 116 117 118 119 120 121 122 @abstractmethod def user_prompt_construction ( self ) -> str : \"\"\" Construct the textual user prompt for LLM based on the `user` field in the prompt template. \"\"\" pass Tip You can customize the Prompter class to tailor the prompt to your requirements.","title":"Prompter"},{"location":"agents/design/prompter/#agent-prompter","text":"The Prompter is a key component of the UFO framework, responsible for constructing prompts for the LLM to generate responses. The Prompter is implemented in the ufo/prompts folder. Each agent has its own Prompter class that defines the structure of the prompt and the information to be fed to the LLM.","title":"Agent Prompter"},{"location":"agents/design/prompter/#components","text":"A prompt fed to the LLM usually a list of dictionaries, where each dictionary contains the following keys: Key Description role The role of the text in the prompt, can be system , user , or assistant . content The content of the text for the specific role. Tip You may find the official documentation helpful for constructing the prompt. In the __init__ method of the Prompter class, you can define the template of the prompt for each component, and the final prompt message is constructed by combining the templates of each component using the prompt_construction method.","title":"Components"},{"location":"agents/design/prompter/#system-prompt","text":"The system prompt use the template configured in the config_dev.yaml file for each agent. It usually contains the instructions for the agent's role, action, tips, reponse format, etc. You need use the system_prompt_construction method to construct the system prompt. Prompts on the API instructions, and demonstration examples are also included in the system prompt, which are constructed by the api_prompt_helper and examples_prompt_helper methods respectively. Below is the sub-components of the system prompt: Component Description Method apis The API instructions for the agent. api_prompt_helper examples The demonstration examples for the agent. examples_prompt_helper","title":"System Prompt"},{"location":"agents/design/prompter/#user-prompt","text":"The user prompt is constructed based on the information from the agent's observation, external knowledge, and Blackboard . You can use the user_prompt_construction method to construct the user prompt. Below is the sub-components of the user prompt: Component Description Method observation The observation of the agent. user_content_construction retrieved_docs The knowledge retrieved from the external knowledge base. retrived_documents_prompt_helper blackboard The information stored in the Blackboard . blackboard_to_prompt","title":"User Prompt"},{"location":"agents/design/prompter/#reference","text":"You can find the implementation of the Prompter in the ufo/prompts folder. Below is the basic structure of the Prompter class: Bases: ABC The BasicPrompter class is the abstract class for the prompter. Initialize the BasicPrompter. Parameters: is_visual ( bool ) \u2013 Whether the request is for visual model. prompt_template ( str ) \u2013 The path of the prompt template. example_prompt_template ( str ) \u2013 The path of the example prompt template. Source code in prompter/basic.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , is_visual : bool , prompt_template : str , example_prompt_template : str ): \"\"\" Initialize the BasicPrompter. :param is_visual: Whether the request is for visual model. :param prompt_template: The path of the prompt template. :param example_prompt_template: The path of the example prompt template. \"\"\" self . is_visual = is_visual if prompt_template : self . prompt_template = self . load_prompt_template ( prompt_template , is_visual ) else : self . prompt_template = \"\" if example_prompt_template : self . example_prompt_template = self . load_prompt_template ( example_prompt_template , is_visual ) else : self . example_prompt_template = \"\"","title":"Reference"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.api_prompt_helper","text":"A helper function to construct the API list and descriptions for the prompt. Source code in prompter/basic.py 139 140 141 142 143 144 def api_prompt_helper ( self ) -> str : \"\"\" A helper function to construct the API list and descriptions for the prompt. \"\"\" pass","title":"api_prompt_helper"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.examples_prompt_helper","text":"A helper function to construct the examples prompt for in-context learning. Source code in prompter/basic.py 132 133 134 135 136 137 def examples_prompt_helper ( self ) -> str : \"\"\" A helper function to construct the examples prompt for in-context learning. \"\"\" pass","title":"examples_prompt_helper"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.load_prompt_template","text":"Load the prompt template. Returns: Dict [ str , str ] \u2013 The prompt template. Source code in prompter/basic.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 @staticmethod def load_prompt_template ( template_path : str , is_visual = None ) -> Dict [ str , str ]: \"\"\" Load the prompt template. :return: The prompt template. \"\"\" if is_visual == None : path = template_path else : path = template_path . format ( mode = \"visual\" if is_visual == True else \"nonvisual\" ) if not path : return {} if os . path . exists ( path ): try : prompt = yaml . safe_load ( open ( path , \"r\" , encoding = \"utf-8\" )) except yaml . YAMLError as exc : print_with_color ( f \"Error loading prompt template: { exc } \" , \"yellow\" ) else : raise FileNotFoundError ( f \"Prompt template not found at { path } \" ) return prompt","title":"load_prompt_template"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.prompt_construction","text":"Construct the prompt for summarizing the experience into an example. Parameters: user_content ( List [ Dict [ str , str ]] ) \u2013 The user content. return: The prompt for summarizing the experience into an example. Source code in prompter/basic.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 @staticmethod def prompt_construction ( system_prompt : str , user_content : List [ Dict [ str , str ]] ) -> List : \"\"\" Construct the prompt for summarizing the experience into an example. :param user_content: The user content. return: The prompt for summarizing the experience into an example. \"\"\" system_message = { \"role\" : \"system\" , \"content\" : system_prompt } user_message = { \"role\" : \"user\" , \"content\" : user_content } prompt_message = [ system_message , user_message ] return prompt_message","title":"prompt_construction"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.retrived_documents_prompt_helper","text":"Construct the prompt for retrieved documents. Parameters: header ( str ) \u2013 The header of the prompt. separator ( str ) \u2013 The separator of the prompt. documents ( List [ str ] ) \u2013 The retrieved documents. return: The prompt for retrieved documents. Source code in prompter/basic.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 @staticmethod def retrived_documents_prompt_helper ( header : str , separator : str , documents : List [ str ] ) -> str : \"\"\" Construct the prompt for retrieved documents. :param header: The header of the prompt. :param separator: The separator of the prompt. :param documents: The retrieved documents. return: The prompt for retrieved documents. \"\"\" if header : prompt = \" \\n < {header} :> \\n \" . format ( header = header ) else : prompt = \"\" for i , document in enumerate ( documents ): if separator : prompt += \"[ {separator} {i} :]\" . format ( separator = separator , i = i + 1 ) prompt += \" \\n \" prompt += document prompt += \" \\n\\n \" return prompt","title":"retrived_documents_prompt_helper"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.system_prompt_construction","text":"Construct the system prompt for LLM. Source code in prompter/basic.py 108 109 110 111 112 113 114 @abstractmethod def system_prompt_construction ( self ) -> str : \"\"\" Construct the system prompt for LLM. \"\"\" pass","title":"system_prompt_construction"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.user_content_construction","text":"Construct the full user content for LLM, including the user prompt and images. Source code in prompter/basic.py 124 125 126 127 128 129 130 @abstractmethod def user_content_construction ( self ) -> str : \"\"\" Construct the full user content for LLM, including the user prompt and images. \"\"\" pass","title":"user_content_construction"},{"location":"agents/design/prompter/#prompter.basic.BasicPrompter.user_prompt_construction","text":"Construct the textual user prompt for LLM based on the user field in the prompt template. Source code in prompter/basic.py 116 117 118 119 120 121 122 @abstractmethod def user_prompt_construction ( self ) -> str : \"\"\" Construct the textual user prompt for LLM based on the `user` field in the prompt template. \"\"\" pass Tip You can customize the Prompter class to tailor the prompt to your requirements.","title":"user_prompt_construction"},{"location":"agents/design/state/","text":"Agent State The State class is a fundamental component of the UFO agent framework. It represents the current state of the agent and determines the next action and agent to handle the request. Each agent has a specific set of states that define the agent's behavior and workflow. AgentStatus The set of states for an agent is defined in the AgentStatus class: class AgentStatus(Enum): \"\"\" The status class for the agent. \"\"\" ERROR = \"ERROR\" FINISH = \"FINISH\" CONTINUE = \"CONTINUE\" FAIL = \"FAIL\" PENDING = \"PENDING\" CONFIRM = \"CONFIRM\" SCREENSHOT = \"SCREENSHOT\" Each agent implements its own set of AgentStatus to define the states of the agent. AgentStateManager The class AgentStateManager manages the state mapping from a string to the corresponding state class. Each state class is registered with the AgentStateManager using the register decorator to associate the state class with a specific agent, e.g., @AgentStateManager.register class SomeAgentState(AgentState): \"\"\" The state class for the some agent. \"\"\" Tip You can find examples on how to register the state class for the AppAgent in the ufo/agents/states/app_agent_state.py file. Below is the basic structure of the AgentStateManager class: class AgentStateManager(ABC, metaclass=SingletonABCMeta): \"\"\" A abstract class to manage the states of the agent. \"\"\" _state_mapping: Dict[str, Type[AgentState]] = {} def __init__(self): \"\"\" Initialize the state manager. \"\"\" self._state_instance_mapping: Dict[str, AgentState] = {} def get_state(self, status: str) -> AgentState: \"\"\" Get the state for the status. :param status: The status string. :return: The state object. \"\"\" # Lazy load the state class if status not in self._state_instance_mapping: state_class = self._state_mapping.get(status) if state_class: self._state_instance_mapping[status] = state_class() else: self._state_instance_mapping[status] = self.none_state state = self._state_instance_mapping.get(status, self.none_state) return state def add_state(self, status: str, state: AgentState) -> None: \"\"\" Add a new state to the state mapping. :param status: The status string. :param state: The state object. \"\"\" self.state_map[status] = state @property def state_map(self) -> Dict[str, AgentState]: \"\"\" The state mapping of status to state. :return: The state mapping. \"\"\" return self._state_instance_mapping @classmethod def register(cls, state_class: Type[AgentState]) -> Type[AgentState]: \"\"\" Decorator to register the state class to the state manager. :param state_class: The state class to be registered. :return: The state class. \"\"\" cls._state_mapping[state_class.name()] = state_class return state_class @property @abstractmethod def none_state(self) -> AgentState: \"\"\" The none state of the state manager. \"\"\" pass AgentState Each state class inherits from the AgentState class and must implement the method of handle to process the action in the state. In addition, the next_state and next_agent methods are used to determine the next state and agent to handle the transition. Please find below the reference for the State class in UFO. Bases: ABC The abstract class for the agent state. agent_class () abstractmethod classmethod The class of the agent. Returns: Type [ BasicAgent ] \u2013 The class of the agent. Source code in agents/states/basic.py 165 166 167 168 169 170 171 172 @classmethod @abstractmethod def agent_class ( cls ) -> Type [ BasicAgent ]: \"\"\" The class of the agent. :return: The class of the agent. \"\"\" pass handle ( agent , context = None ) abstractmethod Handle the agent for the current step. Parameters: agent ( BasicAgent ) \u2013 The agent to handle. context ( Optional ['Context'] , default: None ) \u2013 The context for the agent and session. Source code in agents/states/basic.py 122 123 124 125 126 127 128 129 @abstractmethod def handle ( self , agent : BasicAgent , context : Optional [ \"Context\" ] = None ) -> None : \"\"\" Handle the agent for the current step. :param agent: The agent to handle. :param context: The context for the agent and session. \"\"\" pass is_round_end () abstractmethod Check if the round ends. Returns: bool \u2013 True if the round ends, False otherwise. Source code in agents/states/basic.py 149 150 151 152 153 154 155 @abstractmethod def is_round_end ( self ) -> bool : \"\"\" Check if the round ends. :return: True if the round ends, False otherwise. \"\"\" pass is_subtask_end () abstractmethod Check if the subtask ends. Returns: bool \u2013 True if the subtask ends, False otherwise. Source code in agents/states/basic.py 157 158 159 160 161 162 163 @abstractmethod def is_subtask_end ( self ) -> bool : \"\"\" Check if the subtask ends. :return: True if the subtask ends, False otherwise. \"\"\" pass name () abstractmethod classmethod The class name of the state. Returns: str \u2013 The class name of the state. Source code in agents/states/basic.py 174 175 176 177 178 179 180 181 @classmethod @abstractmethod def name ( cls ) -> str : \"\"\" The class name of the state. :return: The class name of the state. \"\"\" return \"\" next_agent ( agent ) abstractmethod Get the agent for the next step. Parameters: agent ( BasicAgent ) \u2013 The agent for the current step. Returns: BasicAgent \u2013 The agent for the next step. Source code in agents/states/basic.py 131 132 133 134 135 136 137 138 @abstractmethod def next_agent ( self , agent : BasicAgent ) -> BasicAgent : \"\"\" Get the agent for the next step. :param agent: The agent for the current step. :return: The agent for the next step. \"\"\" return agent next_state ( agent ) abstractmethod Get the state for the next step. Parameters: agent ( BasicAgent ) \u2013 The agent for the current step. Returns: AgentState \u2013 The state for the next step. Source code in agents/states/basic.py 140 141 142 143 144 145 146 147 @abstractmethod def next_state ( self , agent : BasicAgent ) -> AgentState : \"\"\" Get the state for the next step. :param agent: The agent for the current step. :return: The state for the next step. \"\"\" pass Tip The state machine diagrams for the HostAgent and AppAgent are shown in their respective documents. Tip A Round calls the handle , next_state , and next_agent methods of the current state to process the user request and determine the next state and agent to handle the request, and orchestrates the agents to execute the necessary actions.","title":"State"},{"location":"agents/design/state/#agent-state","text":"The State class is a fundamental component of the UFO agent framework. It represents the current state of the agent and determines the next action and agent to handle the request. Each agent has a specific set of states that define the agent's behavior and workflow.","title":"Agent State"},{"location":"agents/design/state/#agentstatus","text":"The set of states for an agent is defined in the AgentStatus class: class AgentStatus(Enum): \"\"\" The status class for the agent. \"\"\" ERROR = \"ERROR\" FINISH = \"FINISH\" CONTINUE = \"CONTINUE\" FAIL = \"FAIL\" PENDING = \"PENDING\" CONFIRM = \"CONFIRM\" SCREENSHOT = \"SCREENSHOT\" Each agent implements its own set of AgentStatus to define the states of the agent.","title":"AgentStatus"},{"location":"agents/design/state/#agentstatemanager","text":"The class AgentStateManager manages the state mapping from a string to the corresponding state class. Each state class is registered with the AgentStateManager using the register decorator to associate the state class with a specific agent, e.g., @AgentStateManager.register class SomeAgentState(AgentState): \"\"\" The state class for the some agent. \"\"\" Tip You can find examples on how to register the state class for the AppAgent in the ufo/agents/states/app_agent_state.py file. Below is the basic structure of the AgentStateManager class: class AgentStateManager(ABC, metaclass=SingletonABCMeta): \"\"\" A abstract class to manage the states of the agent. \"\"\" _state_mapping: Dict[str, Type[AgentState]] = {} def __init__(self): \"\"\" Initialize the state manager. \"\"\" self._state_instance_mapping: Dict[str, AgentState] = {} def get_state(self, status: str) -> AgentState: \"\"\" Get the state for the status. :param status: The status string. :return: The state object. \"\"\" # Lazy load the state class if status not in self._state_instance_mapping: state_class = self._state_mapping.get(status) if state_class: self._state_instance_mapping[status] = state_class() else: self._state_instance_mapping[status] = self.none_state state = self._state_instance_mapping.get(status, self.none_state) return state def add_state(self, status: str, state: AgentState) -> None: \"\"\" Add a new state to the state mapping. :param status: The status string. :param state: The state object. \"\"\" self.state_map[status] = state @property def state_map(self) -> Dict[str, AgentState]: \"\"\" The state mapping of status to state. :return: The state mapping. \"\"\" return self._state_instance_mapping @classmethod def register(cls, state_class: Type[AgentState]) -> Type[AgentState]: \"\"\" Decorator to register the state class to the state manager. :param state_class: The state class to be registered. :return: The state class. \"\"\" cls._state_mapping[state_class.name()] = state_class return state_class @property @abstractmethod def none_state(self) -> AgentState: \"\"\" The none state of the state manager. \"\"\" pass","title":"AgentStateManager"},{"location":"agents/design/state/#agentstate","text":"Each state class inherits from the AgentState class and must implement the method of handle to process the action in the state. In addition, the next_state and next_agent methods are used to determine the next state and agent to handle the transition. Please find below the reference for the State class in UFO. Bases: ABC The abstract class for the agent state.","title":"AgentState"},{"location":"agents/design/state/#agents.states.basic.AgentState.agent_class","text":"The class of the agent. Returns: Type [ BasicAgent ] \u2013 The class of the agent. Source code in agents/states/basic.py 165 166 167 168 169 170 171 172 @classmethod @abstractmethod def agent_class ( cls ) -> Type [ BasicAgent ]: \"\"\" The class of the agent. :return: The class of the agent. \"\"\" pass","title":"agent_class"},{"location":"agents/design/state/#agents.states.basic.AgentState.handle","text":"Handle the agent for the current step. Parameters: agent ( BasicAgent ) \u2013 The agent to handle. context ( Optional ['Context'] , default: None ) \u2013 The context for the agent and session. Source code in agents/states/basic.py 122 123 124 125 126 127 128 129 @abstractmethod def handle ( self , agent : BasicAgent , context : Optional [ \"Context\" ] = None ) -> None : \"\"\" Handle the agent for the current step. :param agent: The agent to handle. :param context: The context for the agent and session. \"\"\" pass","title":"handle"},{"location":"agents/design/state/#agents.states.basic.AgentState.is_round_end","text":"Check if the round ends. Returns: bool \u2013 True if the round ends, False otherwise. Source code in agents/states/basic.py 149 150 151 152 153 154 155 @abstractmethod def is_round_end ( self ) -> bool : \"\"\" Check if the round ends. :return: True if the round ends, False otherwise. \"\"\" pass","title":"is_round_end"},{"location":"agents/design/state/#agents.states.basic.AgentState.is_subtask_end","text":"Check if the subtask ends. Returns: bool \u2013 True if the subtask ends, False otherwise. Source code in agents/states/basic.py 157 158 159 160 161 162 163 @abstractmethod def is_subtask_end ( self ) -> bool : \"\"\" Check if the subtask ends. :return: True if the subtask ends, False otherwise. \"\"\" pass","title":"is_subtask_end"},{"location":"agents/design/state/#agents.states.basic.AgentState.name","text":"The class name of the state. Returns: str \u2013 The class name of the state. Source code in agents/states/basic.py 174 175 176 177 178 179 180 181 @classmethod @abstractmethod def name ( cls ) -> str : \"\"\" The class name of the state. :return: The class name of the state. \"\"\" return \"\"","title":"name"},{"location":"agents/design/state/#agents.states.basic.AgentState.next_agent","text":"Get the agent for the next step. Parameters: agent ( BasicAgent ) \u2013 The agent for the current step. Returns: BasicAgent \u2013 The agent for the next step. Source code in agents/states/basic.py 131 132 133 134 135 136 137 138 @abstractmethod def next_agent ( self , agent : BasicAgent ) -> BasicAgent : \"\"\" Get the agent for the next step. :param agent: The agent for the current step. :return: The agent for the next step. \"\"\" return agent","title":"next_agent"},{"location":"agents/design/state/#agents.states.basic.AgentState.next_state","text":"Get the state for the next step. Parameters: agent ( BasicAgent ) \u2013 The agent for the current step. Returns: AgentState \u2013 The state for the next step. Source code in agents/states/basic.py 140 141 142 143 144 145 146 147 @abstractmethod def next_state ( self , agent : BasicAgent ) -> AgentState : \"\"\" Get the state for the next step. :param agent: The agent for the current step. :return: The state for the next step. \"\"\" pass Tip The state machine diagrams for the HostAgent and AppAgent are shown in their respective documents. Tip A Round calls the handle , next_state , and next_agent methods of the current state to process the user request and determine the next state and agent to handle the request, and orchestrates the agents to execute the necessary actions.","title":"next_state"},{"location":"automator/ai_tool_automator/","text":"AI Tool Automator The AI Tool Automator is a component of the UFO framework that enables the agent to interact with AI tools based on large language models (LLMs). The AI Tool Automator is designed to facilitate the integration of LLM-based AI tools into the UFO framework, enabling the agent to leverage the capabilities of these tools to perform complex tasks. Note UFO can also call in-app AI tools, such as Copilot , to assist with the automation process. This is achieved by using either UI Automation or API to interact with the in-app AI tool. These in-app AI tools differ from the AI Tool Automator, which is designed to interact with external AI tools based on LLMs that are not integrated into the application. Configuration The AI Tool Automator shares the same prompt configuration options as the UI Automator: Configuration Option Description Type Default Value API_PROMPT The prompt for the UI automation API. String \"ufo/prompts/share/base/api.yaml\" Receiver The AI Tool Automator shares the same receiver structure as the UI Automator. Please refer to the UI Automator Receiver section for more details. Command The command of the AI Tool Automator shares the same structure as the UI Automator. Please refer to the UI Automator Command section for more details. The list of available commands in the AI Tool Automator is shown below: Command Name Function Name Description AnnotationCommand annotation Annotate the control items on the screenshot. SummaryCommand summary Summarize the observation of the current application window.","title":"AI Tool"},{"location":"automator/ai_tool_automator/#ai-tool-automator","text":"The AI Tool Automator is a component of the UFO framework that enables the agent to interact with AI tools based on large language models (LLMs). The AI Tool Automator is designed to facilitate the integration of LLM-based AI tools into the UFO framework, enabling the agent to leverage the capabilities of these tools to perform complex tasks. Note UFO can also call in-app AI tools, such as Copilot , to assist with the automation process. This is achieved by using either UI Automation or API to interact with the in-app AI tool. These in-app AI tools differ from the AI Tool Automator, which is designed to interact with external AI tools based on LLMs that are not integrated into the application.","title":"AI Tool Automator"},{"location":"automator/ai_tool_automator/#configuration","text":"The AI Tool Automator shares the same prompt configuration options as the UI Automator: Configuration Option Description Type Default Value API_PROMPT The prompt for the UI automation API. String \"ufo/prompts/share/base/api.yaml\"","title":"Configuration"},{"location":"automator/ai_tool_automator/#receiver","text":"The AI Tool Automator shares the same receiver structure as the UI Automator. Please refer to the UI Automator Receiver section for more details.","title":"Receiver"},{"location":"automator/ai_tool_automator/#command","text":"The command of the AI Tool Automator shares the same structure as the UI Automator. Please refer to the UI Automator Command section for more details. The list of available commands in the AI Tool Automator is shown below: Command Name Function Name Description AnnotationCommand annotation Annotate the control items on the screenshot. SummaryCommand summary Summarize the observation of the current application window.","title":"Command"},{"location":"automator/bash_automator/","text":"Bash Automator UFO allows the HostAgent to execute bash commands on the host machine. The bash commands can be used to open applications or execute system commands. The Bash Automator is implemented in the ufo/automator/app_apis/shell module. Note Only HostAgent is currently supported by the Bash Automator. Receiver The Web Automator receiver is the ShellReceiver class defined in the ufo/automator/app_apis/shell/shell_client.py file. Bases: ReceiverBasic The base class for Web COM client using crawl4ai. Initialize the shell client. Source code in automator/app_apis/shell/shell_client.py 19 20 21 22 def __init__ ( self ) -> None : \"\"\" Initialize the shell client. \"\"\" run_shell ( params ) Run the command. Parameters: params ( Dict [ str , Any ] ) \u2013 The parameters of the command. Returns: Any \u2013 The result content. Source code in automator/app_apis/shell/shell_client.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def run_shell ( self , params : Dict [ str , Any ]) -> Any : \"\"\" Run the command. :param params: The parameters of the command. :return: The result content. \"\"\" bash_command = params . get ( \"command\" ) powershell_path = 'C: \\\\ Windows \\\\ System32 \\\\ WindowsPowerShell \\\\ v1.0 \\\\ powershell.exe' process = subprocess . Popen ( bash_command , # command to run stdout = subprocess . PIPE , # capture stdout stderr = subprocess . PIPE , # capture stderr shell = True , text = True , executable = powershell_path , ) return \"\" Command We now only support one command in the Bash Automator to execute a bash command on the host machine. @ShellReceiver.register class RunShellCommand(ShellCommand): \"\"\" The command to run the crawler with various options. \"\"\" def execute(self): \"\"\" Execute the command to run the crawler. :return: The result content. \"\"\" return self.receiver.run_shell(params=self.params) @classmethod def name(cls) -> str: \"\"\" The name of the command. \"\"\" return \"run_shell\" Below is the list of available commands in the Web Automator that are currently supported by UFO: Command Name Function Name Description RunShellCommand run_shell Get the content of a web page into a markdown format.","title":"Bash Automator"},{"location":"automator/bash_automator/#bash-automator","text":"UFO allows the HostAgent to execute bash commands on the host machine. The bash commands can be used to open applications or execute system commands. The Bash Automator is implemented in the ufo/automator/app_apis/shell module. Note Only HostAgent is currently supported by the Bash Automator.","title":"Bash Automator"},{"location":"automator/bash_automator/#receiver","text":"The Web Automator receiver is the ShellReceiver class defined in the ufo/automator/app_apis/shell/shell_client.py file. Bases: ReceiverBasic The base class for Web COM client using crawl4ai. Initialize the shell client. Source code in automator/app_apis/shell/shell_client.py 19 20 21 22 def __init__ ( self ) -> None : \"\"\" Initialize the shell client. \"\"\"","title":"Receiver"},{"location":"automator/bash_automator/#automator.app_apis.shell.shell_client.ShellReceiver.run_shell","text":"Run the command. Parameters: params ( Dict [ str , Any ] ) \u2013 The parameters of the command. Returns: Any \u2013 The result content. Source code in automator/app_apis/shell/shell_client.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def run_shell ( self , params : Dict [ str , Any ]) -> Any : \"\"\" Run the command. :param params: The parameters of the command. :return: The result content. \"\"\" bash_command = params . get ( \"command\" ) powershell_path = 'C: \\\\ Windows \\\\ System32 \\\\ WindowsPowerShell \\\\ v1.0 \\\\ powershell.exe' process = subprocess . Popen ( bash_command , # command to run stdout = subprocess . PIPE , # capture stdout stderr = subprocess . PIPE , # capture stderr shell = True , text = True , executable = powershell_path , ) return \"\"","title":"run_shell"},{"location":"automator/bash_automator/#command","text":"We now only support one command in the Bash Automator to execute a bash command on the host machine. @ShellReceiver.register class RunShellCommand(ShellCommand): \"\"\" The command to run the crawler with various options. \"\"\" def execute(self): \"\"\" Execute the command to run the crawler. :return: The result content. \"\"\" return self.receiver.run_shell(params=self.params) @classmethod def name(cls) -> str: \"\"\" The name of the command. \"\"\" return \"run_shell\" Below is the list of available commands in the Web Automator that are currently supported by UFO: Command Name Function Name Description RunShellCommand run_shell Get the content of a web page into a markdown format.","title":"Command"},{"location":"automator/overview/","text":"Application Puppeteer The Puppeteer is a tool that allows UFO to automate and take actions on applications. Currently, UFO supports two types of actions: GUI and API . Each application has a shared GUI action interface to operate with mouse and keyboard events, and a private API action interface to operate with the application's native API. We illustrate the Puppeteer architecture in the figure below: The state machine diagram for the HostAgent is shown below: Note UFO can also call in-app AI tools, such as Copilot , to assist with the automation process. This is achieved by using either GUI or API to interact with the in-app AI tool. UI Automator - This action type is used to interact with the application's UI controls, such as buttons, text boxes, and menus. UFO uses the UIA or Win32 APIs to interact with the application's UI controls. API - This action type is used to interact with the application's native API. Users and app developers can create their own API actions to interact with specific applications. Web - This action type is used to interact with web applications. UFO uses the crawl4ai library to extract information from web pages. Bash - This action type is used to interact with the command line interface (CLI) of an application. AI Tool - This action type is used to interact with the LLM-based AI tools. Action Design Patterns Actions in UFO are implemented using the command design pattern, which encapsulates a receiver, a command, and an invoker. The receiver is the object that performs the action, the command is the object that encapsulates the action, and the invoker is the object that triggers the action. The basic classes for implementing actions in UFO are as follows: Role Class Description Receiver ufo.automator.basic.ReceiverBasic The base class for all receivers in UFO. Receivers are objects that perform actions on applications. Command ufo.automator.basic.CommandBasic The base class for all commands in UFO. Commands are objects that encapsulate actions to be performed by receivers. Invoker ufo.automator.puppeteer.AppPuppeteer The base class for the invoker in UFO. Invokers are objects that trigger commands to be executed by receivers. The advantage of using the command design pattern in the agent framework is that it allows for the decoupling of the sender and receiver of the action. This decoupling enables the agent to execute actions on different objects without knowing the details of the object or the action being performed, making the agent more flexible and extensible for new actions. Receiver The Receiver is a central component in the Automator application that performs actions on the application. It provides functionalities to interact with the application and execute the action. All available actions are registered in the with the ReceiverManager class. You can find the reference for a basic Receiver class below: Bases: ABC The abstract receiver interface. command_registry property Get the command registry. supported_command_names property Get the command name list. register ( command_class ) classmethod Decorator to register the state class to the state manager. Parameters: command_class ( Type [ CommandBasic ] ) \u2013 The state class to be registered. Returns: Type [ CommandBasic ] \u2013 The state class. Source code in automator/basic.py 46 47 48 49 50 51 52 53 54 @classmethod def register ( cls , command_class : Type [ CommandBasic ]) -> Type [ CommandBasic ]: \"\"\" Decorator to register the state class to the state manager. :param command_class: The state class to be registered. :return: The state class. \"\"\" cls . _command_registry [ command_class . name ()] = command_class return command_class register_command ( command_name , command ) Add to the command registry. Parameters: command_name ( str ) \u2013 The command name. command ( CommandBasic ) \u2013 The command. Source code in automator/basic.py 24 25 26 27 28 29 30 31 def register_command ( self , command_name : str , command : CommandBasic ) -> None : \"\"\" Add to the command registry. :param command_name: The command name. :param command: The command. \"\"\" self . command_registry [ command_name ] = command self_command_mapping () Get the command-receiver mapping. Source code in automator/basic.py 40 41 42 43 44 def self_command_mapping ( self ) -> Dict [ str , CommandBasic ]: \"\"\" Get the command-receiver mapping. \"\"\" return { command_name : self for command_name in self . supported_command_names } Command The Command is a specific action that the Receiver can perform on the application. It encapsulates the function and parameters required to execute the action. The Command class is a base class for all commands in the Automator application. You can find the reference for a basic Command class below: Bases: ABC The abstract command interface. Initialize the command. Parameters: receiver ( ReceiverBasic ) \u2013 The receiver of the command. Source code in automator/basic.py 67 68 69 70 71 72 73 def __init__ ( self , receiver : ReceiverBasic , params : Dict = None ) -> None : \"\"\" Initialize the command. :param receiver: The receiver of the command. \"\"\" self . receiver = receiver self . params = params if params is not None else {} execute () abstractmethod Execute the command. Source code in automator/basic.py 75 76 77 78 79 80 @abstractmethod def execute ( self ): \"\"\" Execute the command. \"\"\" pass redo () Redo the command. Source code in automator/basic.py 88 89 90 91 92 def redo ( self ): \"\"\" Redo the command. \"\"\" self . execute () undo () Undo the command. Source code in automator/basic.py 82 83 84 85 86 def undo ( self ): \"\"\" Undo the command. \"\"\" pass Note Each command must register with a specific Receiver to be executed using the register_command decorator. For example: @ReceiverExample.register class CommandExample(CommandBasic): ... Invoker (AppPuppeteer) The AppPuppeteer plays the role of the invoker in the Automator application. It triggers the commands to be executed by the receivers. The AppPuppeteer equips the AppAgent with the capability to interact with the application's UI controls. It provides functionalities to translate action strings into specific actions and execute them. All available actions are registered in the Puppeteer with the ReceiverManager class. You can find the implementation of the AppPuppeteer class in the ufo/automator/puppeteer.py file, and its reference is shown below. The class for the app puppeteer to automate the app in the Windows environment. Initialize the app puppeteer. Parameters: process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The app root name, e.g., WINWORD.EXE. Source code in automator/puppeteer.py 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , process_name : str , app_root_name : str ) -> None : \"\"\" Initialize the app puppeteer. :param process_name: The process name of the app. :param app_root_name: The app root name, e.g., WINWORD.EXE. \"\"\" self . _process_name = process_name self . _app_root_name = app_root_name self . command_queue : Deque [ CommandBasic ] = deque () self . receiver_manager = ReceiverManager () full_path property Get the full path of the process. Only works for COM receiver. Returns: str \u2013 The full path of the process. add_command ( command_name , params , * args , ** kwargs ) Add the command to the command queue. Parameters: command_name ( str ) \u2013 The command name. params ( Dict [ str , Any ] ) \u2013 The arguments. Source code in automator/puppeteer.py 94 95 96 97 98 99 100 101 102 103 def add_command ( self , command_name : str , params : Dict [ str , Any ], * args , ** kwargs ) -> None : \"\"\" Add the command to the command queue. :param command_name: The command name. :param params: The arguments. \"\"\" command = self . create_command ( command_name , params , * args , ** kwargs ) self . command_queue . append ( command ) close () Close the app. Only works for COM receiver. Source code in automator/puppeteer.py 145 146 147 148 149 150 151 def close ( self ) -> None : \"\"\" Close the app. Only works for COM receiver. \"\"\" com_receiver = self . receiver_manager . com_receiver if com_receiver is not None : com_receiver . close () create_command ( command_name , params , * args , ** kwargs ) Create the command. Parameters: command_name ( str ) \u2013 The command name. params ( Dict [ str , Any ] ) \u2013 The arguments for the command. Source code in automator/puppeteer.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def create_command ( self , command_name : str , params : Dict [ str , Any ], * args , ** kwargs ) -> Optional [ CommandBasic ]: \"\"\" Create the command. :param command_name: The command name. :param params: The arguments for the command. \"\"\" receiver = self . receiver_manager . get_receiver_from_command_name ( command_name ) command = receiver . command_registry . get ( command_name . lower (), None ) if receiver is None : raise ValueError ( f \"Receiver for command { command_name } is not found.\" ) if command is None : raise ValueError ( f \"Command { command_name } is not supported.\" ) return command ( receiver , params , * args , ** kwargs ) execute_all_commands () Execute all the commands in the command queue. Returns: List [ Any ] \u2013 The execution results. Source code in automator/puppeteer.py 82 83 84 85 86 87 88 89 90 91 92 def execute_all_commands ( self ) -> List [ Any ]: \"\"\" Execute all the commands in the command queue. :return: The execution results. \"\"\" results = [] while self . command_queue : command = self . command_queue . popleft () results . append ( command . execute ()) return results execute_command ( command_name , params , * args , ** kwargs ) Execute the command. Parameters: command_name ( str ) \u2013 The command name. params ( Dict [ str , Any ] ) \u2013 The arguments. Returns: str \u2013 The execution result. Source code in automator/puppeteer.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def execute_command ( self , command_name : str , params : Dict [ str , Any ], * args , ** kwargs ) -> str : \"\"\" Execute the command. :param command_name: The command name. :param params: The arguments. :return: The execution result. \"\"\" command = self . create_command ( command_name , params , * args , ** kwargs ) return command . execute () get_command_queue_length () Get the length of the command queue. Returns: int \u2013 The length of the command queue. Source code in automator/puppeteer.py 105 106 107 108 109 110 def get_command_queue_length ( self ) -> int : \"\"\" Get the length of the command queue. :return: The length of the command queue. \"\"\" return len ( self . command_queue ) get_command_string ( command_name , params ) staticmethod Generate a function call string. Parameters: command_name ( str ) \u2013 The function name. params ( Dict [ str , str ] ) \u2013 The arguments as a dictionary. Returns: str \u2013 The function call string. Source code in automator/puppeteer.py 153 154 155 156 157 158 159 160 161 162 163 164 165 @staticmethod def get_command_string ( command_name : str , params : Dict [ str , str ]) -> str : \"\"\" Generate a function call string. :param command_name: The function name. :param params: The arguments as a dictionary. :return: The function call string. \"\"\" # Format the arguments args_str = \", \" . join ( f \" { k } = { v !r} \" for k , v in params . items ()) # Return the function call string return f \" { command_name } ( { args_str } )\" get_command_types ( command_name ) Get the command types. Parameters: command_name ( str ) \u2013 The command name. Returns: str \u2013 The command types. Source code in automator/puppeteer.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_command_types ( self , command_name : str ) -> str : \"\"\" Get the command types. :param command_name: The command name. :return: The command types. \"\"\" try : receiver = self . receiver_manager . get_receiver_from_command_name ( command_name ) return receiver . type_name except : return \"\" save () Save the current state of the app. Only works for COM receiver. Source code in automator/puppeteer.py 124 125 126 127 128 129 130 def save ( self ) -> None : \"\"\" Save the current state of the app. Only works for COM receiver. \"\"\" com_receiver = self . receiver_manager . com_receiver if com_receiver is not None : com_receiver . save () save_to_xml ( file_path ) Save the current state of the app to XML. Only works for COM receiver. Parameters: file_path ( str ) \u2013 The file path to save the XML. Source code in automator/puppeteer.py 132 133 134 135 136 137 138 139 140 141 142 143 def save_to_xml ( self , file_path : str ) -> None : \"\"\" Save the current state of the app to XML. Only works for COM receiver. :param file_path: The file path to save the XML. \"\"\" com_receiver = self . receiver_manager . com_receiver dir_path = os . path . dirname ( file_path ) if not os . path . exists ( dir_path ): os . makedirs ( dir_path ) if com_receiver is not None : com_receiver . save_to_xml ( file_path ) Receiver Manager The ReceiverManager manages all the receivers and commands in the Automator application. It provides functionalities to register and retrieve receivers and commands. It is a complementary component to the AppPuppeteer . The class for the receiver manager. Initialize the receiver manager. Source code in automator/puppeteer.py 175 176 177 178 179 180 181 182 183 def __init__ ( self ): \"\"\" Initialize the receiver manager. \"\"\" self . receiver_registry = {} self . ui_control_receiver : Optional [ ControlReceiver ] = None self . _receiver_list : List [ ReceiverBasic ] = [] com_receiver property Get the COM receiver. Returns: WinCOMReceiverBasic \u2013 The COM receiver. receiver_factory_registry property Get the receiver factory registry. Returns: Dict [ str , Dict [ str , Union [ str , ReceiverFactory ]]] \u2013 The receiver factory registry. receiver_list property Get the receiver list. Returns: List [ ReceiverBasic ] \u2013 The receiver list. create_api_receiver ( app_root_name , process_name ) Get the API receiver. Parameters: app_root_name ( str ) \u2013 The app root name. process_name ( str ) \u2013 The process name. Source code in automator/puppeteer.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def create_api_receiver ( self , app_root_name : str , process_name : str ) -> None : \"\"\" Get the API receiver. :param app_root_name: The app root name. :param process_name: The process name. \"\"\" for receiver_factory_dict in self . receiver_factory_registry . values (): # Check if the receiver is API if receiver_factory_dict . get ( \"is_api\" ): receiver = receiver_factory_dict . get ( \"factory\" ) . create_receiver ( app_root_name , process_name ) if receiver is not None : self . receiver_list . append ( receiver ) self . _update_receiver_registry () create_ui_control_receiver ( control , application ) Build the UI controller. Parameters: control ( UIAWrapper ) \u2013 The control element. application ( UIAWrapper ) \u2013 The application window. Returns: ControlReceiver \u2013 The UI controller receiver. Source code in automator/puppeteer.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def create_ui_control_receiver ( self , control : UIAWrapper , application : UIAWrapper ) -> \"ControlReceiver\" : \"\"\" Build the UI controller. :param control: The control element. :param application: The application window. :return: The UI controller receiver. \"\"\" # control can be None if not application : return None factory : ReceiverFactory = self . receiver_factory_registry . get ( \"UIControl\" ) . get ( \"factory\" ) self . ui_control_receiver = factory . create_receiver ( control , application ) self . receiver_list . append ( self . ui_control_receiver ) self . _update_receiver_registry () return self . ui_control_receiver get_receiver_from_command_name ( command_name ) Get the receiver from the command name. Parameters: command_name ( str ) \u2013 The command name. Returns: ReceiverBasic \u2013 The mapped receiver. Source code in automator/puppeteer.py 235 236 237 238 239 240 241 242 243 244 def get_receiver_from_command_name ( self , command_name : str ) -> ReceiverBasic : \"\"\" Get the receiver from the command name. :param command_name: The command name. :return: The mapped receiver. \"\"\" receiver = self . receiver_registry . get ( command_name , None ) if receiver is None : raise ValueError ( f \"Receiver for command { command_name } is not found.\" ) return receiver register ( receiver_factory_class ) classmethod Decorator to register the receiver factory class to the receiver manager. Parameters: receiver_factory_class ( Type [ ReceiverFactory ] ) \u2013 The receiver factory class to be registered. Returns: ReceiverFactory \u2013 The receiver factory class instance. Source code in automator/puppeteer.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 @classmethod def register ( cls , receiver_factory_class : Type [ ReceiverFactory ]) -> ReceiverFactory : \"\"\" Decorator to register the receiver factory class to the receiver manager. :param receiver_factory_class: The receiver factory class to be registered. :return: The receiver factory class instance. \"\"\" cls . _receiver_factory_registry [ receiver_factory_class . name ()] = { \"factory\" : receiver_factory_class (), \"is_api\" : receiver_factory_class . is_api (), } return receiver_factory_class () For further details, refer to the specific documentation for each component and class in the Automator module.","title":"Overview"},{"location":"automator/overview/#application-puppeteer","text":"The Puppeteer is a tool that allows UFO to automate and take actions on applications. Currently, UFO supports two types of actions: GUI and API . Each application has a shared GUI action interface to operate with mouse and keyboard events, and a private API action interface to operate with the application's native API. We illustrate the Puppeteer architecture in the figure below: The state machine diagram for the HostAgent is shown below:","title":"Application Puppeteer"},{"location":"automator/overview/#action-design-patterns","text":"Actions in UFO are implemented using the command design pattern, which encapsulates a receiver, a command, and an invoker. The receiver is the object that performs the action, the command is the object that encapsulates the action, and the invoker is the object that triggers the action. The basic classes for implementing actions in UFO are as follows: Role Class Description Receiver ufo.automator.basic.ReceiverBasic The base class for all receivers in UFO. Receivers are objects that perform actions on applications. Command ufo.automator.basic.CommandBasic The base class for all commands in UFO. Commands are objects that encapsulate actions to be performed by receivers. Invoker ufo.automator.puppeteer.AppPuppeteer The base class for the invoker in UFO. Invokers are objects that trigger commands to be executed by receivers. The advantage of using the command design pattern in the agent framework is that it allows for the decoupling of the sender and receiver of the action. This decoupling enables the agent to execute actions on different objects without knowing the details of the object or the action being performed, making the agent more flexible and extensible for new actions.","title":"Action Design Patterns"},{"location":"automator/overview/#receiver","text":"The Receiver is a central component in the Automator application that performs actions on the application. It provides functionalities to interact with the application and execute the action. All available actions are registered in the with the ReceiverManager class. You can find the reference for a basic Receiver class below: Bases: ABC The abstract receiver interface.","title":"Receiver"},{"location":"automator/overview/#automator.basic.ReceiverBasic.command_registry","text":"Get the command registry.","title":"command_registry"},{"location":"automator/overview/#automator.basic.ReceiverBasic.supported_command_names","text":"Get the command name list.","title":"supported_command_names"},{"location":"automator/overview/#automator.basic.ReceiverBasic.register","text":"Decorator to register the state class to the state manager. Parameters: command_class ( Type [ CommandBasic ] ) \u2013 The state class to be registered. Returns: Type [ CommandBasic ] \u2013 The state class. Source code in automator/basic.py 46 47 48 49 50 51 52 53 54 @classmethod def register ( cls , command_class : Type [ CommandBasic ]) -> Type [ CommandBasic ]: \"\"\" Decorator to register the state class to the state manager. :param command_class: The state class to be registered. :return: The state class. \"\"\" cls . _command_registry [ command_class . name ()] = command_class return command_class","title":"register"},{"location":"automator/overview/#automator.basic.ReceiverBasic.register_command","text":"Add to the command registry. Parameters: command_name ( str ) \u2013 The command name. command ( CommandBasic ) \u2013 The command. Source code in automator/basic.py 24 25 26 27 28 29 30 31 def register_command ( self , command_name : str , command : CommandBasic ) -> None : \"\"\" Add to the command registry. :param command_name: The command name. :param command: The command. \"\"\" self . command_registry [ command_name ] = command","title":"register_command"},{"location":"automator/overview/#automator.basic.ReceiverBasic.self_command_mapping","text":"Get the command-receiver mapping. Source code in automator/basic.py 40 41 42 43 44 def self_command_mapping ( self ) -> Dict [ str , CommandBasic ]: \"\"\" Get the command-receiver mapping. \"\"\" return { command_name : self for command_name in self . supported_command_names }","title":"self_command_mapping"},{"location":"automator/overview/#command","text":"The Command is a specific action that the Receiver can perform on the application. It encapsulates the function and parameters required to execute the action. The Command class is a base class for all commands in the Automator application. You can find the reference for a basic Command class below: Bases: ABC The abstract command interface. Initialize the command. Parameters: receiver ( ReceiverBasic ) \u2013 The receiver of the command. Source code in automator/basic.py 67 68 69 70 71 72 73 def __init__ ( self , receiver : ReceiverBasic , params : Dict = None ) -> None : \"\"\" Initialize the command. :param receiver: The receiver of the command. \"\"\" self . receiver = receiver self . params = params if params is not None else {}","title":"Command"},{"location":"automator/overview/#automator.basic.CommandBasic.execute","text":"Execute the command. Source code in automator/basic.py 75 76 77 78 79 80 @abstractmethod def execute ( self ): \"\"\" Execute the command. \"\"\" pass","title":"execute"},{"location":"automator/overview/#automator.basic.CommandBasic.redo","text":"Redo the command. Source code in automator/basic.py 88 89 90 91 92 def redo ( self ): \"\"\" Redo the command. \"\"\" self . execute ()","title":"redo"},{"location":"automator/overview/#automator.basic.CommandBasic.undo","text":"Undo the command. Source code in automator/basic.py 82 83 84 85 86 def undo ( self ): \"\"\" Undo the command. \"\"\" pass Note Each command must register with a specific Receiver to be executed using the register_command decorator. For example: @ReceiverExample.register class CommandExample(CommandBasic): ...","title":"undo"},{"location":"automator/overview/#invoker-apppuppeteer","text":"The AppPuppeteer plays the role of the invoker in the Automator application. It triggers the commands to be executed by the receivers. The AppPuppeteer equips the AppAgent with the capability to interact with the application's UI controls. It provides functionalities to translate action strings into specific actions and execute them. All available actions are registered in the Puppeteer with the ReceiverManager class. You can find the implementation of the AppPuppeteer class in the ufo/automator/puppeteer.py file, and its reference is shown below. The class for the app puppeteer to automate the app in the Windows environment. Initialize the app puppeteer. Parameters: process_name ( str ) \u2013 The process name of the app. app_root_name ( str ) \u2013 The app root name, e.g., WINWORD.EXE. Source code in automator/puppeteer.py 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , process_name : str , app_root_name : str ) -> None : \"\"\" Initialize the app puppeteer. :param process_name: The process name of the app. :param app_root_name: The app root name, e.g., WINWORD.EXE. \"\"\" self . _process_name = process_name self . _app_root_name = app_root_name self . command_queue : Deque [ CommandBasic ] = deque () self . receiver_manager = ReceiverManager ()","title":"Invoker (AppPuppeteer)"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.full_path","text":"Get the full path of the process. Only works for COM receiver. Returns: str \u2013 The full path of the process.","title":"full_path"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.add_command","text":"Add the command to the command queue. Parameters: command_name ( str ) \u2013 The command name. params ( Dict [ str , Any ] ) \u2013 The arguments. Source code in automator/puppeteer.py 94 95 96 97 98 99 100 101 102 103 def add_command ( self , command_name : str , params : Dict [ str , Any ], * args , ** kwargs ) -> None : \"\"\" Add the command to the command queue. :param command_name: The command name. :param params: The arguments. \"\"\" command = self . create_command ( command_name , params , * args , ** kwargs ) self . command_queue . append ( command )","title":"add_command"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.close","text":"Close the app. Only works for COM receiver. Source code in automator/puppeteer.py 145 146 147 148 149 150 151 def close ( self ) -> None : \"\"\" Close the app. Only works for COM receiver. \"\"\" com_receiver = self . receiver_manager . com_receiver if com_receiver is not None : com_receiver . close ()","title":"close"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.create_command","text":"Create the command. Parameters: command_name ( str ) \u2013 The command name. params ( Dict [ str , Any ] ) \u2013 The arguments for the command. Source code in automator/puppeteer.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def create_command ( self , command_name : str , params : Dict [ str , Any ], * args , ** kwargs ) -> Optional [ CommandBasic ]: \"\"\" Create the command. :param command_name: The command name. :param params: The arguments for the command. \"\"\" receiver = self . receiver_manager . get_receiver_from_command_name ( command_name ) command = receiver . command_registry . get ( command_name . lower (), None ) if receiver is None : raise ValueError ( f \"Receiver for command { command_name } is not found.\" ) if command is None : raise ValueError ( f \"Command { command_name } is not supported.\" ) return command ( receiver , params , * args , ** kwargs )","title":"create_command"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.execute_all_commands","text":"Execute all the commands in the command queue. Returns: List [ Any ] \u2013 The execution results. Source code in automator/puppeteer.py 82 83 84 85 86 87 88 89 90 91 92 def execute_all_commands ( self ) -> List [ Any ]: \"\"\" Execute all the commands in the command queue. :return: The execution results. \"\"\" results = [] while self . command_queue : command = self . command_queue . popleft () results . append ( command . execute ()) return results","title":"execute_all_commands"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.execute_command","text":"Execute the command. Parameters: command_name ( str ) \u2013 The command name. params ( Dict [ str , Any ] ) \u2013 The arguments. Returns: str \u2013 The execution result. Source code in automator/puppeteer.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def execute_command ( self , command_name : str , params : Dict [ str , Any ], * args , ** kwargs ) -> str : \"\"\" Execute the command. :param command_name: The command name. :param params: The arguments. :return: The execution result. \"\"\" command = self . create_command ( command_name , params , * args , ** kwargs ) return command . execute ()","title":"execute_command"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.get_command_queue_length","text":"Get the length of the command queue. Returns: int \u2013 The length of the command queue. Source code in automator/puppeteer.py 105 106 107 108 109 110 def get_command_queue_length ( self ) -> int : \"\"\" Get the length of the command queue. :return: The length of the command queue. \"\"\" return len ( self . command_queue )","title":"get_command_queue_length"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.get_command_string","text":"Generate a function call string. Parameters: command_name ( str ) \u2013 The function name. params ( Dict [ str , str ] ) \u2013 The arguments as a dictionary. Returns: str \u2013 The function call string. Source code in automator/puppeteer.py 153 154 155 156 157 158 159 160 161 162 163 164 165 @staticmethod def get_command_string ( command_name : str , params : Dict [ str , str ]) -> str : \"\"\" Generate a function call string. :param command_name: The function name. :param params: The arguments as a dictionary. :return: The function call string. \"\"\" # Format the arguments args_str = \", \" . join ( f \" { k } = { v !r} \" for k , v in params . items ()) # Return the function call string return f \" { command_name } ( { args_str } )\"","title":"get_command_string"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.get_command_types","text":"Get the command types. Parameters: command_name ( str ) \u2013 The command name. Returns: str \u2013 The command types. Source code in automator/puppeteer.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_command_types ( self , command_name : str ) -> str : \"\"\" Get the command types. :param command_name: The command name. :return: The command types. \"\"\" try : receiver = self . receiver_manager . get_receiver_from_command_name ( command_name ) return receiver . type_name except : return \"\"","title":"get_command_types"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.save","text":"Save the current state of the app. Only works for COM receiver. Source code in automator/puppeteer.py 124 125 126 127 128 129 130 def save ( self ) -> None : \"\"\" Save the current state of the app. Only works for COM receiver. \"\"\" com_receiver = self . receiver_manager . com_receiver if com_receiver is not None : com_receiver . save ()","title":"save"},{"location":"automator/overview/#automator.puppeteer.AppPuppeteer.save_to_xml","text":"Save the current state of the app to XML. Only works for COM receiver. Parameters: file_path ( str ) \u2013 The file path to save the XML. Source code in automator/puppeteer.py 132 133 134 135 136 137 138 139 140 141 142 143 def save_to_xml ( self , file_path : str ) -> None : \"\"\" Save the current state of the app to XML. Only works for COM receiver. :param file_path: The file path to save the XML. \"\"\" com_receiver = self . receiver_manager . com_receiver dir_path = os . path . dirname ( file_path ) if not os . path . exists ( dir_path ): os . makedirs ( dir_path ) if com_receiver is not None : com_receiver . save_to_xml ( file_path )","title":"save_to_xml"},{"location":"automator/overview/#receiver-manager","text":"The ReceiverManager manages all the receivers and commands in the Automator application. It provides functionalities to register and retrieve receivers and commands. It is a complementary component to the AppPuppeteer . The class for the receiver manager. Initialize the receiver manager. Source code in automator/puppeteer.py 175 176 177 178 179 180 181 182 183 def __init__ ( self ): \"\"\" Initialize the receiver manager. \"\"\" self . receiver_registry = {} self . ui_control_receiver : Optional [ ControlReceiver ] = None self . _receiver_list : List [ ReceiverBasic ] = []","title":"Receiver Manager"},{"location":"automator/overview/#automator.puppeteer.ReceiverManager.com_receiver","text":"Get the COM receiver. Returns: WinCOMReceiverBasic \u2013 The COM receiver.","title":"com_receiver"},{"location":"automator/overview/#automator.puppeteer.ReceiverManager.receiver_factory_registry","text":"Get the receiver factory registry. Returns: Dict [ str , Dict [ str , Union [ str , ReceiverFactory ]]] \u2013 The receiver factory registry.","title":"receiver_factory_registry"},{"location":"automator/overview/#automator.puppeteer.ReceiverManager.receiver_list","text":"Get the receiver list. Returns: List [ ReceiverBasic ] \u2013 The receiver list.","title":"receiver_list"},{"location":"automator/overview/#automator.puppeteer.ReceiverManager.create_api_receiver","text":"Get the API receiver. Parameters: app_root_name ( str ) \u2013 The app root name. process_name ( str ) \u2013 The process name. Source code in automator/puppeteer.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def create_api_receiver ( self , app_root_name : str , process_name : str ) -> None : \"\"\" Get the API receiver. :param app_root_name: The app root name. :param process_name: The process name. \"\"\" for receiver_factory_dict in self . receiver_factory_registry . values (): # Check if the receiver is API if receiver_factory_dict . get ( \"is_api\" ): receiver = receiver_factory_dict . get ( \"factory\" ) . create_receiver ( app_root_name , process_name ) if receiver is not None : self . receiver_list . append ( receiver ) self . _update_receiver_registry ()","title":"create_api_receiver"},{"location":"automator/overview/#automator.puppeteer.ReceiverManager.create_ui_control_receiver","text":"Build the UI controller. Parameters: control ( UIAWrapper ) \u2013 The control element. application ( UIAWrapper ) \u2013 The application window. Returns: ControlReceiver \u2013 The UI controller receiver. Source code in automator/puppeteer.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def create_ui_control_receiver ( self , control : UIAWrapper , application : UIAWrapper ) -> \"ControlReceiver\" : \"\"\" Build the UI controller. :param control: The control element. :param application: The application window. :return: The UI controller receiver. \"\"\" # control can be None if not application : return None factory : ReceiverFactory = self . receiver_factory_registry . get ( \"UIControl\" ) . get ( \"factory\" ) self . ui_control_receiver = factory . create_receiver ( control , application ) self . receiver_list . append ( self . ui_control_receiver ) self . _update_receiver_registry () return self . ui_control_receiver","title":"create_ui_control_receiver"},{"location":"automator/overview/#automator.puppeteer.ReceiverManager.get_receiver_from_command_name","text":"Get the receiver from the command name. Parameters: command_name ( str ) \u2013 The command name. Returns: ReceiverBasic \u2013 The mapped receiver. Source code in automator/puppeteer.py 235 236 237 238 239 240 241 242 243 244 def get_receiver_from_command_name ( self , command_name : str ) -> ReceiverBasic : \"\"\" Get the receiver from the command name. :param command_name: The command name. :return: The mapped receiver. \"\"\" receiver = self . receiver_registry . get ( command_name , None ) if receiver is None : raise ValueError ( f \"Receiver for command { command_name } is not found.\" ) return receiver","title":"get_receiver_from_command_name"},{"location":"automator/overview/#automator.puppeteer.ReceiverManager.register","text":"Decorator to register the receiver factory class to the receiver manager. Parameters: receiver_factory_class ( Type [ ReceiverFactory ] ) \u2013 The receiver factory class to be registered. Returns: ReceiverFactory \u2013 The receiver factory class instance. Source code in automator/puppeteer.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 @classmethod def register ( cls , receiver_factory_class : Type [ ReceiverFactory ]) -> ReceiverFactory : \"\"\" Decorator to register the receiver factory class to the receiver manager. :param receiver_factory_class: The receiver factory class to be registered. :return: The receiver factory class instance. \"\"\" cls . _receiver_factory_registry [ receiver_factory_class . name ()] = { \"factory\" : receiver_factory_class (), \"is_api\" : receiver_factory_class . is_api (), } return receiver_factory_class () For further details, refer to the specific documentation for each component and class in the Automator module.","title":"register"},{"location":"automator/ui_automator/","text":"GUI Automator The GUI Automator enables to mimic the operations of mouse and keyboard on the application's UI controls. UFO uses the UIA or Win32 APIs to interact with the application's UI controls, such as buttons, edit boxes, and menus. Configuration There are several configurations that need to be set up before using the UI Automator in the config_dev.yaml file. Below is the list of configurations related to the UI Automator: Configuration Option Description Type Default Value CONTROL_BACKEND The list of backend for control action, currently supporting uia and win32 and onmiparser List [\"uia\"] CONTROL_LIST The list of widgets allowed to be selected. List [\"Button\", \"Edit\", \"TabItem\", \"Document\", \"ListItem\", \"MenuItem\", \"ScrollBar\", \"TreeItem\", \"Hyperlink\", \"ComboBox\", \"RadioButton\", \"DataItem\"] ANNOTATION_COLORS The colors assigned to different control types for annotation. Dictionary {\"Button\": \"#FFF68F\", \"Edit\": \"#A5F0B5\", \"TabItem\": \"#A5E7F0\", \"Document\": \"#FFD18A\", \"ListItem\": \"#D9C3FE\", \"MenuItem\": \"#E7FEC3\", \"ScrollBar\": \"#FEC3F8\", \"TreeItem\": \"#D6D6D6\", \"Hyperlink\": \"#91FFEB\", \"ComboBox\": \"#D8B6D4\"} API_PROMPT The prompt for the UI automation API. String \"ufo/prompts/share/base/api.yaml\" CLICK_API The API used for click action, can be click_input or click . String \"click_input\" INPUT_TEXT_API The API used for input text action, can be type_keys or set_text . String \"type_keys\" INPUT_TEXT_ENTER Whether to press enter after typing the text. Boolean False Receiver The receiver of the UI Automator is the ControlReceiver class defined in the ufo/automator/ui_control/controller/control_receiver module. It is initialized with the application's window handle and control wrapper that executes the actions. The ControlReceiver provides functionalities to interact with the application's UI controls. Below is the reference for the ControlReceiver class: Bases: ReceiverBasic The control receiver class. Initialize the control receiver. Parameters: control ( Optional [ UIAWrapper ] ) \u2013 The control element. application ( Optional [ UIAWrapper ] ) \u2013 The application element. Source code in automator/ui_control/controller.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , control : Optional [ UIAWrapper ], application : Optional [ UIAWrapper ] ) -> None : \"\"\" Initialize the control receiver. :param control: The control element. :param application: The application element. \"\"\" self . control = control self . application = application if control : self . control . set_focus () self . wait_enabled () elif application : self . application . set_focus () annotation ( params , annotation_dict ) Take a screenshot of the current application window and annotate the control item on the screenshot. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the annotation method. annotation_dict ( Dict [ str , UIAWrapper ] ) \u2013 The dictionary of the control labels. Source code in automator/ui_control/controller.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def annotation ( self , params : Dict [ str , str ], annotation_dict : Dict [ str , UIAWrapper ] ) -> List [ str ]: \"\"\" Take a screenshot of the current application window and annotate the control item on the screenshot. :param params: The arguments of the annotation method. :param annotation_dict: The dictionary of the control labels. \"\"\" selected_controls_labels = params . get ( \"control_labels\" , []) control_reannotate = [ annotation_dict [ str ( label )] for label in selected_controls_labels ] return control_reannotate atomic_execution ( method_name , params ) Atomic execution of the action on the control elements. Parameters: method_name ( str ) \u2013 The name of the method to execute. params ( Dict [ str , Any ] ) \u2013 The arguments of the method. Returns: str \u2013 The result of the action. Source code in automator/ui_control/controller.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def atomic_execution ( self , method_name : str , params : Dict [ str , Any ]) -> str : \"\"\" Atomic execution of the action on the control elements. :param method_name: The name of the method to execute. :param params: The arguments of the method. :return: The result of the action. \"\"\" import traceback try : method = getattr ( self . control , method_name ) result = method ( ** params ) except AttributeError : message = f \" { self . control } doesn't have a method named { method_name } \" print_with_color ( f \"Warning: { message } \" , \"yellow\" ) result = message except Exception as e : full_traceback = traceback . format_exc () message = f \"An error occurred: { full_traceback } \" print_with_color ( f \"Warning: { message } \" , \"yellow\" ) result = message return result click_input ( params ) Click the control element. Parameters: params ( Dict [ str , Union [ str , bool ]] ) \u2013 The arguments of the click method. Returns: str \u2013 The result of the click action. Source code in automator/ui_control/controller.py 82 83 84 85 86 87 88 89 90 91 92 93 94 def click_input ( self , params : Dict [ str , Union [ str , bool ]]) -> str : \"\"\" Click the control element. :param params: The arguments of the click method. :return: The result of the click action. \"\"\" api_name = configs . get ( \"CLICK_API\" , \"click_input\" ) if api_name == \"click\" : return self . atomic_execution ( \"click\" , params ) else : return self . atomic_execution ( \"click_input\" , params ) click_on_coordinates ( params ) Click on the coordinates of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the click on coordinates method. Returns: str \u2013 The result of the click on coordinates action. Source code in automator/ui_control/controller.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def click_on_coordinates ( self , params : Dict [ str , str ]) -> str : \"\"\" Click on the coordinates of the control element. :param params: The arguments of the click on coordinates method. :return: The result of the click on coordinates action. \"\"\" # Get the relative coordinates fraction of the application window. x = float ( params . get ( \"x\" , 0 )) y = float ( params . get ( \"y\" , 0 )) button = params . get ( \"button\" , \"left\" ) double = params . get ( \"double\" , False ) # Get the absolute coordinates of the application window. tranformed_x , tranformed_y = self . transform_point ( x , y ) # print(f\"Clicking on {tranformed_x}, {tranformed_y}\") self . application . set_focus () pyautogui . click ( tranformed_x , tranformed_y , button = button , clicks = 2 if double else 1 ) return \"\" drag_on_coordinates ( params ) Drag on the coordinates of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the drag on coordinates method. Returns: str \u2013 The result of the drag on coordinates action. Source code in automator/ui_control/controller.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 def drag_on_coordinates ( self , params : Dict [ str , str ]) -> str : \"\"\" Drag on the coordinates of the control element. :param params: The arguments of the drag on coordinates method. :return: The result of the drag on coordinates action. \"\"\" start = self . transform_point ( float ( params . get ( \"start_x\" , 0 )), float ( params . get ( \"start_y\" , 0 )) ) end = self . transform_point ( float ( params . get ( \"end_x\" , 0 )), float ( params . get ( \"end_y\" , 0 )) ) duration = float ( params . get ( \"duration\" , 1 )) button = params . get ( \"button\" , \"left\" ) key_hold = params . get ( \"key_hold\" , None ) self . application . set_focus () if key_hold : pyautogui . keyDown ( key_hold ) pyautogui . moveTo ( start [ 0 ], start [ 1 ]) pyautogui . dragTo ( end [ 0 ], end [ 1 ], button = button , duration = duration ) if key_hold : pyautogui . keyUp ( key_hold ) return \"\" key_press ( params ) Key press on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the key press method. Returns: str \u2013 The result of the key press action. Source code in automator/ui_control/controller.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 def key_press ( self , params : Dict [ str , str ]) -> str : \"\"\" Key press on the control element. :param params: The arguments of the key press method. :return: The result of the key press action. \"\"\" keys = params . get ( \"keys\" , []) for key in keys : key = key . lower () pyautogui . keyDown ( key ) for key in keys : key = key . lower () pyautogui . keyUp ( key ) keyboard_input ( params ) Keyboard input on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the keyboard input method. Returns: str \u2013 The result of the keyboard input action. Source code in automator/ui_control/controller.py 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def keyboard_input ( self , params : Dict [ str , str ]) -> str : \"\"\" Keyboard input on the control element. :param params: The arguments of the keyboard input method. :return: The result of the keyboard input action. \"\"\" control_focus = params . get ( \"control_focus\" , True ) keys = params . get ( \"keys\" , \"\" ) keys = TextTransformer . transform_text ( keys , \"all\" ) if control_focus : self . atomic_execution ( \"type_keys\" , { \"keys\" : keys }) else : self . application . type_keys ( keys = keys ) return keys mouse_move ( params ) Mouse move on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the mouse move method. Returns: str \u2013 The result of the mouse move action. Source code in automator/ui_control/controller.py 292 293 294 295 296 297 298 299 300 301 302 303 304 def mouse_move ( self , params : Dict [ str , str ]) -> str : \"\"\" Mouse move on the control element. :param params: The arguments of the mouse move method. :return: The result of the mouse move action. \"\"\" x = int ( params . get ( \"x\" , 0 )) y = int ( params . get ( \"y\" , 0 )) new_x , new_y = self . transform_point ( x , y ) pyautogui . moveTo ( new_x , new_y , duration = 0.1 ) no_action () No action on the control element. Returns: \u2013 The result of the no action. Source code in automator/ui_control/controller.py 316 317 318 319 320 321 322 def no_action ( self ): \"\"\" No action on the control element. :return: The result of the no action. \"\"\" return \"\" scroll ( params ) Scroll on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the scroll method. Returns: str \u2013 The result of the scroll action. Source code in automator/ui_control/controller.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 def scroll ( self , params : Dict [ str , str ]) -> str : \"\"\" Scroll on the control element. :param params: The arguments of the scroll method. :return: The result of the scroll action. \"\"\" x = int ( params . get ( \"x\" , 0 )) y = int ( params . get ( \"y\" , 0 )) new_x , new_y = self . transform_point ( x , y ) scroll_x = int ( params . get ( \"scroll_x\" , 0 )) scroll_y = int ( params . get ( \"scroll_y\" , 0 )) pyautogui . vscroll ( scroll_y , x = new_x , y = new_y ) pyautogui . hscroll ( scroll_x , x = new_x , y = new_y ) set_edit_text ( params ) Set the edit text of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the set edit text method. Returns: str \u2013 The result of the set edit text action. Source code in automator/ui_control/controller.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def set_edit_text ( self , params : Dict [ str , str ]) -> str : \"\"\" Set the edit text of the control element. :param params: The arguments of the set edit text method. :return: The result of the set edit text action. \"\"\" text = params . get ( \"text\" , \"\" ) inter_key_pause = configs . get ( \"INPUT_TEXT_INTER_KEY_PAUSE\" , 0.1 ) if params . get ( \"clear_current_text\" , False ): self . control . type_keys ( \"^a\" , pause = inter_key_pause ) self . control . type_keys ( \" {DELETE} \" , pause = inter_key_pause ) if configs [ \"INPUT_TEXT_API\" ] == \"set_text\" : method_name = \"set_edit_text\" args = { \"text\" : text } else : method_name = \"type_keys\" # Transform the text according to the tags. text = TextTransformer . transform_text ( text , \"all\" ) args = { \"keys\" : text , \"pause\" : inter_key_pause , \"with_spaces\" : True } try : result = self . atomic_execution ( method_name , args ) if ( method_name == \"set_text\" and args [ \"text\" ] not in self . control . window_text () ): raise Exception ( f \"Failed to use set_text: { args [ 'text' ] } \" ) if configs [ \"INPUT_TEXT_ENTER\" ] and method_name in [ \"type_keys\" , \"set_text\" ]: self . atomic_execution ( \"type_keys\" , params = { \"keys\" : \" {ENTER} \" }) return result except Exception as e : if method_name == \"set_text\" : print_with_color ( f \" { self . control } doesn't have a method named { method_name } , trying default input method\" , \"yellow\" , ) method_name = \"type_keys\" clear_text_keys = \"^a {BACKSPACE} \" text_to_type = args [ \"text\" ] keys_to_send = clear_text_keys + text_to_type method_name = \"type_keys\" args = { \"keys\" : keys_to_send , \"pause\" : inter_key_pause , \"with_spaces\" : True , } return self . atomic_execution ( method_name , args ) else : return f \"An error occurred: { e } \" summary ( params ) Visual summary of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the visual summary method. should contain a key \"text\" with the text summary. Returns: str \u2013 The result of the visual summary action. Source code in automator/ui_control/controller.py 156 157 158 159 160 161 162 163 def summary ( self , params : Dict [ str , str ]) -> str : \"\"\" Visual summary of the control element. :param params: The arguments of the visual summary method. should contain a key \"text\" with the text summary. :return: The result of the visual summary action. \"\"\" return params . get ( \"text\" ) texts () Get the text of the control element. Returns: str \u2013 The text of the control element. Source code in automator/ui_control/controller.py 253 254 255 256 257 258 def texts ( self ) -> str : \"\"\" Get the text of the control element. :return: The text of the control element. \"\"\" return self . control . texts () transform_point ( fraction_x , fraction_y ) Transform the relative coordinates to the absolute coordinates. Parameters: fraction_x ( float ) \u2013 The relative x coordinate. fraction_y ( float ) \u2013 The relative y coordinate. Returns: Tuple [ int , int ] \u2013 The absolute coordinates. Source code in automator/ui_control/controller.py 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def transform_point ( self , fraction_x : float , fraction_y : float ) -> Tuple [ int , int ]: \"\"\" Transform the relative coordinates to the absolute coordinates. :param fraction_x: The relative x coordinate. :param fraction_y: The relative y coordinate. :return: The absolute coordinates. \"\"\" application_rect : RECT = self . application . rectangle () application_x = application_rect . left application_y = application_rect . top application_width = application_rect . width () application_height = application_rect . height () x = application_x + int ( application_width * fraction_x ) y = application_y + int ( application_height * fraction_y ) return x , y transform_scaled_point_to_raw ( scaled_x , scaled_y , scaled_width , scaled_height , raw_width , raw_height ) Transform the scaled coordinates to the raw coordinates. Parameters: scaled_x ( int ) \u2013 The scaled x coordinate. scaled_y ( int ) \u2013 The scaled y coordinate. raw_width ( int ) \u2013 The raw width of the application window. raw_height ( int ) \u2013 The raw height of the application window. scaled_width ( int ) \u2013 The scaled width of the application window. scaled_height ( int ) \u2013 The scaled height of the application window. Source code in automator/ui_control/controller.py 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def transform_scaled_point_to_raw ( self , scaled_x : int , scaled_y : int , scaled_width : int , scaled_height : int , raw_width : int , raw_height : int , ) -> Tuple [ int , int ]: \"\"\" Transform the scaled coordinates to the raw coordinates. :param scaled_x: The scaled x coordinate. :param scaled_y: The scaled y coordinate. :param raw_width: The raw width of the application window. :param raw_height: The raw height of the application window. :param scaled_width: The scaled width of the application window. :param scaled_height: The scaled height of the application window. \"\"\" ratio = min ( scaled_width / raw_width , scaled_height / raw_height ) raw_x = scaled_x / ratio raw_y = scaled_y / ratio return int ( raw_x ), int ( raw_y ) transfrom_absolute_point_to_fractional ( x , y ) Transform the absolute coordinates to the relative coordinates. Parameters: x ( int ) \u2013 The absolute x coordinate on the application window. y ( int ) \u2013 The absolute y coordinate on the application window. Returns: Tuple [ int , int ] \u2013 The relative coordinates fraction. Source code in automator/ui_control/controller.py 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 def transfrom_absolute_point_to_fractional ( self , x : int , y : int ) -> Tuple [ int , int ]: \"\"\" Transform the absolute coordinates to the relative coordinates. :param x: The absolute x coordinate on the application window. :param y: The absolute y coordinate on the application window. :return: The relative coordinates fraction. \"\"\" application_rect : RECT = self . application . rectangle () # application_x = application_rect.left # application_y = application_rect.top application_width = application_rect . width () application_height = application_rect . height () fraction_x = x / application_width fraction_y = y / application_height return fraction_x , fraction_y type ( params ) Type on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the type method. Returns: str \u2013 The result of the type action. Source code in automator/ui_control/controller.py 306 307 308 309 310 311 312 313 314 def type ( self , params : Dict [ str , str ]) -> str : \"\"\" Type on the control element. :param params: The arguments of the type method. :return: The result of the type action. \"\"\" text = params . get ( \"text\" , \"\" ) pyautogui . write ( text , interval = 0.1 ) wait_enabled ( timeout = 10 , retry_interval = 0.5 ) Wait until the control is enabled. Parameters: timeout ( int , default: 10 ) \u2013 The timeout to wait. retry_interval ( int , default: 0.5 ) \u2013 The retry interval to wait. Source code in automator/ui_control/controller.py 340 341 342 343 344 345 346 347 348 349 350 351 def wait_enabled ( self , timeout : int = 10 , retry_interval : int = 0.5 ) -> None : \"\"\" Wait until the control is enabled. :param timeout: The timeout to wait. :param retry_interval: The retry interval to wait. \"\"\" while not self . control . is_enabled (): time . sleep ( retry_interval ) timeout -= retry_interval if timeout <= 0 : warnings . warn ( f \"Timeout: { self . control } is not enabled.\" ) break wait_visible ( timeout = 10 , retry_interval = 0.5 ) Wait until the window is enabled. Parameters: timeout ( int , default: 10 ) \u2013 The timeout to wait. retry_interval ( int , default: 0.5 ) \u2013 The retry interval to wait. Source code in automator/ui_control/controller.py 353 354 355 356 357 358 359 360 361 362 363 364 def wait_visible ( self , timeout : int = 10 , retry_interval : int = 0.5 ) -> None : \"\"\" Wait until the window is enabled. :param timeout: The timeout to wait. :param retry_interval: The retry interval to wait. \"\"\" while not self . control . is_visible (): time . sleep ( retry_interval ) timeout -= retry_interval if timeout <= 0 : warnings . warn ( f \"Timeout: { self . control } is not visible.\" ) break wheel_mouse_input ( params ) Wheel mouse input on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the wheel mouse input method. Returns: \u2013 The result of the wheel mouse input action. Source code in automator/ui_control/controller.py 260 261 262 263 264 265 266 267 268 269 270 271 272 def wheel_mouse_input ( self , params : Dict [ str , str ]): \"\"\" Wheel mouse input on the control element. :param params: The arguments of the wheel mouse input method. :return: The result of the wheel mouse input action. \"\"\" if self . control is not None : return self . atomic_execution ( \"wheel_mouse_input\" , params ) else : keyboard . send_keys ( \"{VK_CONTROL up}\" ) dist = int ( params . get ( \"wheel_dist\" , 0 )) return self . application . wheel_mouse_input ( wheel_dist = dist ) Command The command of the UI Automator is the ControlCommand class defined in the ufo/automator/ui_control/controller/ControlCommand module. It encapsulates the function and parameters required to execute the action. The ControlCommand class is a base class for all commands in the UI Automator application. Below is an example of a ClickInputCommand class that inherits from the ControlCommand class: @ControlReceiver.register class ClickInputCommand(ControlCommand): \"\"\" The click input command class. \"\"\" def execute(self) -> str: \"\"\" Execute the click input command. :return: The result of the click input command. \"\"\" return self.receiver.click_input(self.params) @classmethod def name(cls) -> str: \"\"\" Get the name of the atomic command. :return: The name of the atomic command. \"\"\" return \"click_input\" Note The concrete command classes must implement the execute method to execute the action and the name method to return the name of the atomic command. Note Each command must register with a specific ControlReceiver to be executed using the @ControlReceiver.register decorator. Below is the list of available commands in the UI Automator that are currently supported by UFO: Command Name Function Name Description ClickInputCommand click_input Click the control item with the mouse. ClickOnCoordinatesCommand click_on_coordinates Click on the specific fractional coordinates of the application window. DragOnCoordinatesCommand drag_on_coordinates Drag the mouse on the specific fractional coordinates of the application window. SetEditTextCommand set_edit_text Add new text to the control item. GetTextsCommand texts Get the text of the control item. WheelMouseInputCommand wheel_mouse_input Scroll the control item. KeyboardInputCommand keyboard_input Simulate the keyboard input. Tip Please refer to the ufo/prompts/share/base/api.yaml file for the detailed API documentation of the UI Automator. Tip You can customize the commands by adding new command classes to the ufo/automator/ui_control/controller/ControlCommand module.","title":"GUI Automator"},{"location":"automator/ui_automator/#gui-automator","text":"The GUI Automator enables to mimic the operations of mouse and keyboard on the application's UI controls. UFO uses the UIA or Win32 APIs to interact with the application's UI controls, such as buttons, edit boxes, and menus.","title":"GUI Automator"},{"location":"automator/ui_automator/#configuration","text":"There are several configurations that need to be set up before using the UI Automator in the config_dev.yaml file. Below is the list of configurations related to the UI Automator: Configuration Option Description Type Default Value CONTROL_BACKEND The list of backend for control action, currently supporting uia and win32 and onmiparser List [\"uia\"] CONTROL_LIST The list of widgets allowed to be selected. List [\"Button\", \"Edit\", \"TabItem\", \"Document\", \"ListItem\", \"MenuItem\", \"ScrollBar\", \"TreeItem\", \"Hyperlink\", \"ComboBox\", \"RadioButton\", \"DataItem\"] ANNOTATION_COLORS The colors assigned to different control types for annotation. Dictionary {\"Button\": \"#FFF68F\", \"Edit\": \"#A5F0B5\", \"TabItem\": \"#A5E7F0\", \"Document\": \"#FFD18A\", \"ListItem\": \"#D9C3FE\", \"MenuItem\": \"#E7FEC3\", \"ScrollBar\": \"#FEC3F8\", \"TreeItem\": \"#D6D6D6\", \"Hyperlink\": \"#91FFEB\", \"ComboBox\": \"#D8B6D4\"} API_PROMPT The prompt for the UI automation API. String \"ufo/prompts/share/base/api.yaml\" CLICK_API The API used for click action, can be click_input or click . String \"click_input\" INPUT_TEXT_API The API used for input text action, can be type_keys or set_text . String \"type_keys\" INPUT_TEXT_ENTER Whether to press enter after typing the text. Boolean False","title":"Configuration"},{"location":"automator/ui_automator/#receiver","text":"The receiver of the UI Automator is the ControlReceiver class defined in the ufo/automator/ui_control/controller/control_receiver module. It is initialized with the application's window handle and control wrapper that executes the actions. The ControlReceiver provides functionalities to interact with the application's UI controls. Below is the reference for the ControlReceiver class: Bases: ReceiverBasic The control receiver class. Initialize the control receiver. Parameters: control ( Optional [ UIAWrapper ] ) \u2013 The control element. application ( Optional [ UIAWrapper ] ) \u2013 The application element. Source code in automator/ui_control/controller.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , control : Optional [ UIAWrapper ], application : Optional [ UIAWrapper ] ) -> None : \"\"\" Initialize the control receiver. :param control: The control element. :param application: The application element. \"\"\" self . control = control self . application = application if control : self . control . set_focus () self . wait_enabled () elif application : self . application . set_focus ()","title":"Receiver"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.annotation","text":"Take a screenshot of the current application window and annotate the control item on the screenshot. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the annotation method. annotation_dict ( Dict [ str , UIAWrapper ] ) \u2013 The dictionary of the control labels. Source code in automator/ui_control/controller.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def annotation ( self , params : Dict [ str , str ], annotation_dict : Dict [ str , UIAWrapper ] ) -> List [ str ]: \"\"\" Take a screenshot of the current application window and annotate the control item on the screenshot. :param params: The arguments of the annotation method. :param annotation_dict: The dictionary of the control labels. \"\"\" selected_controls_labels = params . get ( \"control_labels\" , []) control_reannotate = [ annotation_dict [ str ( label )] for label in selected_controls_labels ] return control_reannotate","title":"annotation"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.atomic_execution","text":"Atomic execution of the action on the control elements. Parameters: method_name ( str ) \u2013 The name of the method to execute. params ( Dict [ str , Any ] ) \u2013 The arguments of the method. Returns: str \u2013 The result of the action. Source code in automator/ui_control/controller.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def atomic_execution ( self , method_name : str , params : Dict [ str , Any ]) -> str : \"\"\" Atomic execution of the action on the control elements. :param method_name: The name of the method to execute. :param params: The arguments of the method. :return: The result of the action. \"\"\" import traceback try : method = getattr ( self . control , method_name ) result = method ( ** params ) except AttributeError : message = f \" { self . control } doesn't have a method named { method_name } \" print_with_color ( f \"Warning: { message } \" , \"yellow\" ) result = message except Exception as e : full_traceback = traceback . format_exc () message = f \"An error occurred: { full_traceback } \" print_with_color ( f \"Warning: { message } \" , \"yellow\" ) result = message return result","title":"atomic_execution"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.click_input","text":"Click the control element. Parameters: params ( Dict [ str , Union [ str , bool ]] ) \u2013 The arguments of the click method. Returns: str \u2013 The result of the click action. Source code in automator/ui_control/controller.py 82 83 84 85 86 87 88 89 90 91 92 93 94 def click_input ( self , params : Dict [ str , Union [ str , bool ]]) -> str : \"\"\" Click the control element. :param params: The arguments of the click method. :return: The result of the click action. \"\"\" api_name = configs . get ( \"CLICK_API\" , \"click_input\" ) if api_name == \"click\" : return self . atomic_execution ( \"click\" , params ) else : return self . atomic_execution ( \"click_input\" , params )","title":"click_input"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.click_on_coordinates","text":"Click on the coordinates of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the click on coordinates method. Returns: str \u2013 The result of the click on coordinates action. Source code in automator/ui_control/controller.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def click_on_coordinates ( self , params : Dict [ str , str ]) -> str : \"\"\" Click on the coordinates of the control element. :param params: The arguments of the click on coordinates method. :return: The result of the click on coordinates action. \"\"\" # Get the relative coordinates fraction of the application window. x = float ( params . get ( \"x\" , 0 )) y = float ( params . get ( \"y\" , 0 )) button = params . get ( \"button\" , \"left\" ) double = params . get ( \"double\" , False ) # Get the absolute coordinates of the application window. tranformed_x , tranformed_y = self . transform_point ( x , y ) # print(f\"Clicking on {tranformed_x}, {tranformed_y}\") self . application . set_focus () pyautogui . click ( tranformed_x , tranformed_y , button = button , clicks = 2 if double else 1 ) return \"\"","title":"click_on_coordinates"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.drag_on_coordinates","text":"Drag on the coordinates of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the drag on coordinates method. Returns: str \u2013 The result of the drag on coordinates action. Source code in automator/ui_control/controller.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 def drag_on_coordinates ( self , params : Dict [ str , str ]) -> str : \"\"\" Drag on the coordinates of the control element. :param params: The arguments of the drag on coordinates method. :return: The result of the drag on coordinates action. \"\"\" start = self . transform_point ( float ( params . get ( \"start_x\" , 0 )), float ( params . get ( \"start_y\" , 0 )) ) end = self . transform_point ( float ( params . get ( \"end_x\" , 0 )), float ( params . get ( \"end_y\" , 0 )) ) duration = float ( params . get ( \"duration\" , 1 )) button = params . get ( \"button\" , \"left\" ) key_hold = params . get ( \"key_hold\" , None ) self . application . set_focus () if key_hold : pyautogui . keyDown ( key_hold ) pyautogui . moveTo ( start [ 0 ], start [ 1 ]) pyautogui . dragTo ( end [ 0 ], end [ 1 ], button = button , duration = duration ) if key_hold : pyautogui . keyUp ( key_hold ) return \"\"","title":"drag_on_coordinates"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.key_press","text":"Key press on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the key press method. Returns: str \u2013 The result of the key press action. Source code in automator/ui_control/controller.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 def key_press ( self , params : Dict [ str , str ]) -> str : \"\"\" Key press on the control element. :param params: The arguments of the key press method. :return: The result of the key press action. \"\"\" keys = params . get ( \"keys\" , []) for key in keys : key = key . lower () pyautogui . keyDown ( key ) for key in keys : key = key . lower () pyautogui . keyUp ( key )","title":"key_press"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.keyboard_input","text":"Keyboard input on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the keyboard input method. Returns: str \u2013 The result of the keyboard input action. Source code in automator/ui_control/controller.py 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def keyboard_input ( self , params : Dict [ str , str ]) -> str : \"\"\" Keyboard input on the control element. :param params: The arguments of the keyboard input method. :return: The result of the keyboard input action. \"\"\" control_focus = params . get ( \"control_focus\" , True ) keys = params . get ( \"keys\" , \"\" ) keys = TextTransformer . transform_text ( keys , \"all\" ) if control_focus : self . atomic_execution ( \"type_keys\" , { \"keys\" : keys }) else : self . application . type_keys ( keys = keys ) return keys","title":"keyboard_input"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.mouse_move","text":"Mouse move on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the mouse move method. Returns: str \u2013 The result of the mouse move action. Source code in automator/ui_control/controller.py 292 293 294 295 296 297 298 299 300 301 302 303 304 def mouse_move ( self , params : Dict [ str , str ]) -> str : \"\"\" Mouse move on the control element. :param params: The arguments of the mouse move method. :return: The result of the mouse move action. \"\"\" x = int ( params . get ( \"x\" , 0 )) y = int ( params . get ( \"y\" , 0 )) new_x , new_y = self . transform_point ( x , y ) pyautogui . moveTo ( new_x , new_y , duration = 0.1 )","title":"mouse_move"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.no_action","text":"No action on the control element. Returns: \u2013 The result of the no action. Source code in automator/ui_control/controller.py 316 317 318 319 320 321 322 def no_action ( self ): \"\"\" No action on the control element. :return: The result of the no action. \"\"\" return \"\"","title":"no_action"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.scroll","text":"Scroll on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the scroll method. Returns: str \u2013 The result of the scroll action. Source code in automator/ui_control/controller.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 def scroll ( self , params : Dict [ str , str ]) -> str : \"\"\" Scroll on the control element. :param params: The arguments of the scroll method. :return: The result of the scroll action. \"\"\" x = int ( params . get ( \"x\" , 0 )) y = int ( params . get ( \"y\" , 0 )) new_x , new_y = self . transform_point ( x , y ) scroll_x = int ( params . get ( \"scroll_x\" , 0 )) scroll_y = int ( params . get ( \"scroll_y\" , 0 )) pyautogui . vscroll ( scroll_y , x = new_x , y = new_y ) pyautogui . hscroll ( scroll_x , x = new_x , y = new_y )","title":"scroll"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.set_edit_text","text":"Set the edit text of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the set edit text method. Returns: str \u2013 The result of the set edit text action. Source code in automator/ui_control/controller.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def set_edit_text ( self , params : Dict [ str , str ]) -> str : \"\"\" Set the edit text of the control element. :param params: The arguments of the set edit text method. :return: The result of the set edit text action. \"\"\" text = params . get ( \"text\" , \"\" ) inter_key_pause = configs . get ( \"INPUT_TEXT_INTER_KEY_PAUSE\" , 0.1 ) if params . get ( \"clear_current_text\" , False ): self . control . type_keys ( \"^a\" , pause = inter_key_pause ) self . control . type_keys ( \" {DELETE} \" , pause = inter_key_pause ) if configs [ \"INPUT_TEXT_API\" ] == \"set_text\" : method_name = \"set_edit_text\" args = { \"text\" : text } else : method_name = \"type_keys\" # Transform the text according to the tags. text = TextTransformer . transform_text ( text , \"all\" ) args = { \"keys\" : text , \"pause\" : inter_key_pause , \"with_spaces\" : True } try : result = self . atomic_execution ( method_name , args ) if ( method_name == \"set_text\" and args [ \"text\" ] not in self . control . window_text () ): raise Exception ( f \"Failed to use set_text: { args [ 'text' ] } \" ) if configs [ \"INPUT_TEXT_ENTER\" ] and method_name in [ \"type_keys\" , \"set_text\" ]: self . atomic_execution ( \"type_keys\" , params = { \"keys\" : \" {ENTER} \" }) return result except Exception as e : if method_name == \"set_text\" : print_with_color ( f \" { self . control } doesn't have a method named { method_name } , trying default input method\" , \"yellow\" , ) method_name = \"type_keys\" clear_text_keys = \"^a {BACKSPACE} \" text_to_type = args [ \"text\" ] keys_to_send = clear_text_keys + text_to_type method_name = \"type_keys\" args = { \"keys\" : keys_to_send , \"pause\" : inter_key_pause , \"with_spaces\" : True , } return self . atomic_execution ( method_name , args ) else : return f \"An error occurred: { e } \"","title":"set_edit_text"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.summary","text":"Visual summary of the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the visual summary method. should contain a key \"text\" with the text summary. Returns: str \u2013 The result of the visual summary action. Source code in automator/ui_control/controller.py 156 157 158 159 160 161 162 163 def summary ( self , params : Dict [ str , str ]) -> str : \"\"\" Visual summary of the control element. :param params: The arguments of the visual summary method. should contain a key \"text\" with the text summary. :return: The result of the visual summary action. \"\"\" return params . get ( \"text\" )","title":"summary"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.texts","text":"Get the text of the control element. Returns: str \u2013 The text of the control element. Source code in automator/ui_control/controller.py 253 254 255 256 257 258 def texts ( self ) -> str : \"\"\" Get the text of the control element. :return: The text of the control element. \"\"\" return self . control . texts ()","title":"texts"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.transform_point","text":"Transform the relative coordinates to the absolute coordinates. Parameters: fraction_x ( float ) \u2013 The relative x coordinate. fraction_y ( float ) \u2013 The relative y coordinate. Returns: Tuple [ int , int ] \u2013 The absolute coordinates. Source code in automator/ui_control/controller.py 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def transform_point ( self , fraction_x : float , fraction_y : float ) -> Tuple [ int , int ]: \"\"\" Transform the relative coordinates to the absolute coordinates. :param fraction_x: The relative x coordinate. :param fraction_y: The relative y coordinate. :return: The absolute coordinates. \"\"\" application_rect : RECT = self . application . rectangle () application_x = application_rect . left application_y = application_rect . top application_width = application_rect . width () application_height = application_rect . height () x = application_x + int ( application_width * fraction_x ) y = application_y + int ( application_height * fraction_y ) return x , y","title":"transform_point"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.transform_scaled_point_to_raw","text":"Transform the scaled coordinates to the raw coordinates. Parameters: scaled_x ( int ) \u2013 The scaled x coordinate. scaled_y ( int ) \u2013 The scaled y coordinate. raw_width ( int ) \u2013 The raw width of the application window. raw_height ( int ) \u2013 The raw height of the application window. scaled_width ( int ) \u2013 The scaled width of the application window. scaled_height ( int ) \u2013 The scaled height of the application window. Source code in automator/ui_control/controller.py 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def transform_scaled_point_to_raw ( self , scaled_x : int , scaled_y : int , scaled_width : int , scaled_height : int , raw_width : int , raw_height : int , ) -> Tuple [ int , int ]: \"\"\" Transform the scaled coordinates to the raw coordinates. :param scaled_x: The scaled x coordinate. :param scaled_y: The scaled y coordinate. :param raw_width: The raw width of the application window. :param raw_height: The raw height of the application window. :param scaled_width: The scaled width of the application window. :param scaled_height: The scaled height of the application window. \"\"\" ratio = min ( scaled_width / raw_width , scaled_height / raw_height ) raw_x = scaled_x / ratio raw_y = scaled_y / ratio return int ( raw_x ), int ( raw_y )","title":"transform_scaled_point_to_raw"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.transfrom_absolute_point_to_fractional","text":"Transform the absolute coordinates to the relative coordinates. Parameters: x ( int ) \u2013 The absolute x coordinate on the application window. y ( int ) \u2013 The absolute y coordinate on the application window. Returns: Tuple [ int , int ] \u2013 The relative coordinates fraction. Source code in automator/ui_control/controller.py 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 def transfrom_absolute_point_to_fractional ( self , x : int , y : int ) -> Tuple [ int , int ]: \"\"\" Transform the absolute coordinates to the relative coordinates. :param x: The absolute x coordinate on the application window. :param y: The absolute y coordinate on the application window. :return: The relative coordinates fraction. \"\"\" application_rect : RECT = self . application . rectangle () # application_x = application_rect.left # application_y = application_rect.top application_width = application_rect . width () application_height = application_rect . height () fraction_x = x / application_width fraction_y = y / application_height return fraction_x , fraction_y","title":"transfrom_absolute_point_to_fractional"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.type","text":"Type on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the type method. Returns: str \u2013 The result of the type action. Source code in automator/ui_control/controller.py 306 307 308 309 310 311 312 313 314 def type ( self , params : Dict [ str , str ]) -> str : \"\"\" Type on the control element. :param params: The arguments of the type method. :return: The result of the type action. \"\"\" text = params . get ( \"text\" , \"\" ) pyautogui . write ( text , interval = 0.1 )","title":"type"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.wait_enabled","text":"Wait until the control is enabled. Parameters: timeout ( int , default: 10 ) \u2013 The timeout to wait. retry_interval ( int , default: 0.5 ) \u2013 The retry interval to wait. Source code in automator/ui_control/controller.py 340 341 342 343 344 345 346 347 348 349 350 351 def wait_enabled ( self , timeout : int = 10 , retry_interval : int = 0.5 ) -> None : \"\"\" Wait until the control is enabled. :param timeout: The timeout to wait. :param retry_interval: The retry interval to wait. \"\"\" while not self . control . is_enabled (): time . sleep ( retry_interval ) timeout -= retry_interval if timeout <= 0 : warnings . warn ( f \"Timeout: { self . control } is not enabled.\" ) break","title":"wait_enabled"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.wait_visible","text":"Wait until the window is enabled. Parameters: timeout ( int , default: 10 ) \u2013 The timeout to wait. retry_interval ( int , default: 0.5 ) \u2013 The retry interval to wait. Source code in automator/ui_control/controller.py 353 354 355 356 357 358 359 360 361 362 363 364 def wait_visible ( self , timeout : int = 10 , retry_interval : int = 0.5 ) -> None : \"\"\" Wait until the window is enabled. :param timeout: The timeout to wait. :param retry_interval: The retry interval to wait. \"\"\" while not self . control . is_visible (): time . sleep ( retry_interval ) timeout -= retry_interval if timeout <= 0 : warnings . warn ( f \"Timeout: { self . control } is not visible.\" ) break","title":"wait_visible"},{"location":"automator/ui_automator/#automator.ui_control.controller.ControlReceiver.wheel_mouse_input","text":"Wheel mouse input on the control element. Parameters: params ( Dict [ str , str ] ) \u2013 The arguments of the wheel mouse input method. Returns: \u2013 The result of the wheel mouse input action. Source code in automator/ui_control/controller.py 260 261 262 263 264 265 266 267 268 269 270 271 272 def wheel_mouse_input ( self , params : Dict [ str , str ]): \"\"\" Wheel mouse input on the control element. :param params: The arguments of the wheel mouse input method. :return: The result of the wheel mouse input action. \"\"\" if self . control is not None : return self . atomic_execution ( \"wheel_mouse_input\" , params ) else : keyboard . send_keys ( \"{VK_CONTROL up}\" ) dist = int ( params . get ( \"wheel_dist\" , 0 )) return self . application . wheel_mouse_input ( wheel_dist = dist )","title":"wheel_mouse_input"},{"location":"automator/ui_automator/#command","text":"The command of the UI Automator is the ControlCommand class defined in the ufo/automator/ui_control/controller/ControlCommand module. It encapsulates the function and parameters required to execute the action. The ControlCommand class is a base class for all commands in the UI Automator application. Below is an example of a ClickInputCommand class that inherits from the ControlCommand class: @ControlReceiver.register class ClickInputCommand(ControlCommand): \"\"\" The click input command class. \"\"\" def execute(self) -> str: \"\"\" Execute the click input command. :return: The result of the click input command. \"\"\" return self.receiver.click_input(self.params) @classmethod def name(cls) -> str: \"\"\" Get the name of the atomic command. :return: The name of the atomic command. \"\"\" return \"click_input\" Note The concrete command classes must implement the execute method to execute the action and the name method to return the name of the atomic command. Note Each command must register with a specific ControlReceiver to be executed using the @ControlReceiver.register decorator. Below is the list of available commands in the UI Automator that are currently supported by UFO: Command Name Function Name Description ClickInputCommand click_input Click the control item with the mouse. ClickOnCoordinatesCommand click_on_coordinates Click on the specific fractional coordinates of the application window. DragOnCoordinatesCommand drag_on_coordinates Drag the mouse on the specific fractional coordinates of the application window. SetEditTextCommand set_edit_text Add new text to the control item. GetTextsCommand texts Get the text of the control item. WheelMouseInputCommand wheel_mouse_input Scroll the control item. KeyboardInputCommand keyboard_input Simulate the keyboard input. Tip Please refer to the ufo/prompts/share/base/api.yaml file for the detailed API documentation of the UI Automator. Tip You can customize the commands by adding new command classes to the ufo/automator/ui_control/controller/ControlCommand module.","title":"Command"},{"location":"automator/web_automator/","text":"Web Automator We also support the use of the Web Automator to get the content of a web page. The Web Automator is implemented in ufo/autoamtor/app_apis/web module. Configuration There are several configurations that need to be set up before using the API Automator in the config_dev.yaml file. Below is the list of configurations related to the API Automator: Configuration Option Description Type Default Value USE_APIS Whether to allow the use of application APIs. Boolean True APP_API_PROMPT_ADDRESS The prompt address for the application API. Dict {\"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\"} Note Only msedge.exe and chrome.exe are currently supported by the Web Automator. Receiver The Web Automator receiver is the WebReceiver class defined in the ufo/automator/app_apis/web/webclient.py module: Bases: ReceiverBasic The base class for Web COM client using crawl4ai. Initialize the Web COM client. Source code in automator/app_apis/web/webclient.py 21 22 23 24 25 26 27 def __init__ ( self ) -> None : \"\"\" Initialize the Web COM client. \"\"\" self . _headers = { \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\" } web_crawler ( url , ignore_link ) Run the crawler with various options. Parameters: url ( str ) \u2013 The URL of the webpage. ignore_link ( bool ) \u2013 Whether to ignore the links. Returns: str \u2013 The result markdown content. Source code in automator/app_apis/web/webclient.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def web_crawler ( self , url : str , ignore_link : bool ) -> str : \"\"\" Run the crawler with various options. :param url: The URL of the webpage. :param ignore_link: Whether to ignore the links. :return: The result markdown content. \"\"\" try : # Get the HTML content of the webpage response = requests . get ( url , headers = self . _headers ) response . raise_for_status () html_content = response . text # Convert the HTML content to markdown h = html2text . HTML2Text () h . ignore_links = ignore_link markdown_content = h . handle ( html_content ) return markdown_content except requests . RequestException as e : print ( f \"Error fetching the URL: { e } \" ) return f \"Error fetching the URL: { e } \" Command We now only support one command in the Web Automator to get the content of a web page into a markdown format. More commands will be added in the future for the Web Automator. @WebReceiver.register class WebCrawlerCommand(WebCommand): \"\"\" The command to run the crawler with various options. \"\"\" def execute(self): \"\"\" Execute the command to run the crawler. :return: The result content. \"\"\" return self.receiver.web_crawler( url=self.params.get(\"url\"), ignore_link=self.params.get(\"ignore_link\", False), ) @classmethod def name(cls) -> str: \"\"\" The name of the command. \"\"\" return \"web_crawler\" Below is the list of available commands in the Web Automator that are currently supported by UFO: Command Name Function Name Description WebCrawlerCommand web_crawler Get the content of a web page into a markdown format. Tip Please refer to the ufo/prompts/apps/web/api.yaml file for the prompt details for the WebCrawlerCommand command.","title":"Web Automator"},{"location":"automator/web_automator/#web-automator","text":"We also support the use of the Web Automator to get the content of a web page. The Web Automator is implemented in ufo/autoamtor/app_apis/web module.","title":"Web Automator"},{"location":"automator/web_automator/#configuration","text":"There are several configurations that need to be set up before using the API Automator in the config_dev.yaml file. Below is the list of configurations related to the API Automator: Configuration Option Description Type Default Value USE_APIS Whether to allow the use of application APIs. Boolean True APP_API_PROMPT_ADDRESS The prompt address for the application API. Dict {\"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\"} Note Only msedge.exe and chrome.exe are currently supported by the Web Automator.","title":"Configuration"},{"location":"automator/web_automator/#receiver","text":"The Web Automator receiver is the WebReceiver class defined in the ufo/automator/app_apis/web/webclient.py module: Bases: ReceiverBasic The base class for Web COM client using crawl4ai. Initialize the Web COM client. Source code in automator/app_apis/web/webclient.py 21 22 23 24 25 26 27 def __init__ ( self ) -> None : \"\"\" Initialize the Web COM client. \"\"\" self . _headers = { \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\" }","title":"Receiver"},{"location":"automator/web_automator/#automator.app_apis.web.webclient.WebReceiver.web_crawler","text":"Run the crawler with various options. Parameters: url ( str ) \u2013 The URL of the webpage. ignore_link ( bool ) \u2013 Whether to ignore the links. Returns: str \u2013 The result markdown content. Source code in automator/app_apis/web/webclient.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def web_crawler ( self , url : str , ignore_link : bool ) -> str : \"\"\" Run the crawler with various options. :param url: The URL of the webpage. :param ignore_link: Whether to ignore the links. :return: The result markdown content. \"\"\" try : # Get the HTML content of the webpage response = requests . get ( url , headers = self . _headers ) response . raise_for_status () html_content = response . text # Convert the HTML content to markdown h = html2text . HTML2Text () h . ignore_links = ignore_link markdown_content = h . handle ( html_content ) return markdown_content except requests . RequestException as e : print ( f \"Error fetching the URL: { e } \" ) return f \"Error fetching the URL: { e } \"","title":"web_crawler"},{"location":"automator/web_automator/#command","text":"We now only support one command in the Web Automator to get the content of a web page into a markdown format. More commands will be added in the future for the Web Automator. @WebReceiver.register class WebCrawlerCommand(WebCommand): \"\"\" The command to run the crawler with various options. \"\"\" def execute(self): \"\"\" Execute the command to run the crawler. :return: The result content. \"\"\" return self.receiver.web_crawler( url=self.params.get(\"url\"), ignore_link=self.params.get(\"ignore_link\", False), ) @classmethod def name(cls) -> str: \"\"\" The name of the command. \"\"\" return \"web_crawler\" Below is the list of available commands in the Web Automator that are currently supported by UFO: Command Name Function Name Description WebCrawlerCommand web_crawler Get the content of a web page into a markdown format. Tip Please refer to the ufo/prompts/apps/web/api.yaml file for the prompt details for the WebCrawlerCommand command.","title":"Command"},{"location":"automator/wincom_automator/","text":"API Automator UFO currently support the use of Win32 API API automator to interact with the application's native API. We implement them in python using the pywin32 library. The API automator now supports Word and Excel applications, and we are working on extending the support to other applications. Configuration There are several configurations that need to be set up before using the API Automator in the config_dev.yaml file. Below is the list of configurations related to the API Automator: Configuration Option Description Type Default Value USE_APIS Whether to allow the use of application APIs. Boolean True APP_API_PROMPT_ADDRESS The prompt address for the application API. Dict {\"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\"} Note Only WINWORD.EXE and EXCEL.EXE are currently supported by the API Automator. Receiver The base class for the receiver of the API Automator is the WinCOMReceiverBasic class defined in the ufo/automator/app_apis/basic module. It is initialized with the application's win32 com object and provides functionalities to interact with the application's native API. Below is the reference for the WinCOMReceiverBasic class: Bases: ReceiverBasic The base class for Windows COM client. Initialize the Windows COM client. Parameters: app_root_name ( str ) \u2013 The app root name. process_name ( str ) \u2013 The process name. clsid ( str ) \u2013 The CLSID of the COM object. Source code in automator/app_apis/basic.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , app_root_name : str , process_name : str , clsid : str ) -> None : \"\"\" Initialize the Windows COM client. :param app_root_name: The app root name. :param process_name: The process name. :param clsid: The CLSID of the COM object. \"\"\" self . app_root_name = app_root_name self . process_name = process_name self . clsid = clsid self . client = win32com . client . Dispatch ( self . clsid ) self . com_object = self . get_object_from_process_name () full_path property Get the full path of the process. Returns: str \u2013 The full path of the process. app_match ( object_name_list ) Check if the process name matches the app root. Parameters: object_name_list ( List [ str ] ) \u2013 The list of object name. Returns: str \u2013 The matched object name. Source code in automator/app_apis/basic.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def app_match ( self , object_name_list : List [ str ]) -> str : \"\"\" Check if the process name matches the app root. :param object_name_list: The list of object name. :return: The matched object name. \"\"\" suffix = self . get_suffix_mapping () if self . process_name . endswith ( suffix ): clean_process_name = self . process_name [: - len ( suffix )] else : clean_process_name = self . process_name if not object_name_list : return \"\" return max ( object_name_list , key = lambda x : self . longest_common_substring_length ( clean_process_name , x ), ) close () Close the app. Source code in automator/app_apis/basic.py 110 111 112 113 114 115 116 117 def close ( self ) -> None : \"\"\" Close the app. \"\"\" try : self . com_object . Close () except : pass get_object_from_process_name () abstractmethod Get the object from the process name. Source code in automator/app_apis/basic.py 36 37 38 39 40 41 @abstractmethod def get_object_from_process_name ( self ) -> win32com . client . CDispatch : \"\"\" Get the object from the process name. \"\"\" pass get_suffix_mapping () Get the suffix mapping. Returns: Dict [ str , str ] \u2013 The suffix mapping. Source code in automator/app_apis/basic.py 43 44 45 46 47 48 49 50 51 52 53 54 55 def get_suffix_mapping ( self ) -> Dict [ str , str ]: \"\"\" Get the suffix mapping. :return: The suffix mapping. \"\"\" suffix_mapping = { \"WINWORD.EXE\" : \"docx\" , \"EXCEL.EXE\" : \"xlsx\" , \"POWERPNT.EXE\" : \"pptx\" , \"olk.exe\" : \"msg\" , } return suffix_mapping . get ( self . app_root_name , None ) longest_common_substring_length ( str1 , str2 ) staticmethod Get the longest common substring of two strings. Parameters: str1 ( str ) \u2013 The first string. str2 ( str ) \u2013 The second string. Returns: int \u2013 The length of the longest common substring. Source code in automator/app_apis/basic.py 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 @staticmethod def longest_common_substring_length ( str1 : str , str2 : str ) -> int : \"\"\" Get the longest common substring of two strings. :param str1: The first string. :param str2: The second string. :return: The length of the longest common substring. \"\"\" m = len ( str1 ) n = len ( str2 ) dp = [[ 0 ] * ( n + 1 ) for _ in range ( m + 1 )] max_length = 0 for i in range ( 1 , m + 1 ): for j in range ( 1 , n + 1 ): if str1 [ i - 1 ] == str2 [ j - 1 ]: dp [ i ][ j ] = dp [ i - 1 ][ j - 1 ] + 1 if dp [ i ][ j ] > max_length : max_length = dp [ i ][ j ] else : dp [ i ][ j ] = 0 return max_length save () Save the current state of the app. Source code in automator/app_apis/basic.py 91 92 93 94 95 96 97 98 def save ( self ) -> None : \"\"\" Save the current state of the app. \"\"\" try : self . com_object . Save () except : pass save_to_xml ( file_path ) Save the current state of the app to XML. Parameters: file_path ( str ) \u2013 The file path to save the XML. Source code in automator/app_apis/basic.py 100 101 102 103 104 105 106 107 108 def save_to_xml ( self , file_path : str ) -> None : \"\"\" Save the current state of the app to XML. :param file_path: The file path to save the XML. \"\"\" try : self . com_object . SaveAs ( file_path , self . xml_format_code ) except : pass The receiver of Word and Excel applications inherit from the WinCOMReceiverBasic class. The WordReceiver and ExcelReceiver classes are defined in the ufo/automator/app_apis/word and ufo/automator/app_apis/excel modules, respectively: Command The command of the API Automator for the Word and Excel applications in located in the client module in the ufo/automator/app_apis/{app_name} folder inheriting from the WinCOMCommand class. It encapsulates the function and parameters required to execute the action. Below is an example of a WordCommand class that inherits from the SelectTextCommand class: @WordWinCOMReceiver.register class SelectTextCommand(WinCOMCommand): \"\"\" The command to select text. \"\"\" def execute(self): \"\"\" Execute the command to select text. :return: The selected text. \"\"\" return self.receiver.select_text(self.params.get(\"text\")) @classmethod def name(cls) -> str: \"\"\" The name of the command. \"\"\" return \"select_text\" Note The concrete command classes must implement the execute method to execute the action and the name method to return the name of the atomic command. Note Each command must register with a concrete WinCOMReceiver to be executed using the register decorator. Below is the list of available commands in the API Automator that are currently supported by UFO: Word API Commands Command Name Function Name Description InsertTableCommand insert_table Insert a table to a Word document. SelectTextCommand select_text Select the text in a Word document. SelectTableCommand select_table Select a table in a Word document. Excel API Commands Command Name Function Name Description GetSheetContentCommand get_sheet_content Get the content of a sheet in the Excel app. Table2MarkdownCommand table2markdown Convert the table content in a sheet of the Excel app to markdown format. InsertExcelTableCommand insert_excel_table Insert a table to the Excel sheet. Tip Please refer to the ufo/prompts/apps/{app_name}/api.yaml file for the prompt details for the commands. Tip You can customize the commands by adding new command classes to the ufo/automator/app_apis/{app_name}/ module.","title":"API Automator"},{"location":"automator/wincom_automator/#api-automator","text":"UFO currently support the use of Win32 API API automator to interact with the application's native API. We implement them in python using the pywin32 library. The API automator now supports Word and Excel applications, and we are working on extending the support to other applications.","title":"API Automator"},{"location":"automator/wincom_automator/#configuration","text":"There are several configurations that need to be set up before using the API Automator in the config_dev.yaml file. Below is the list of configurations related to the API Automator: Configuration Option Description Type Default Value USE_APIS Whether to allow the use of application APIs. Boolean True APP_API_PROMPT_ADDRESS The prompt address for the application API. Dict {\"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\"} Note Only WINWORD.EXE and EXCEL.EXE are currently supported by the API Automator.","title":"Configuration"},{"location":"automator/wincom_automator/#receiver","text":"The base class for the receiver of the API Automator is the WinCOMReceiverBasic class defined in the ufo/automator/app_apis/basic module. It is initialized with the application's win32 com object and provides functionalities to interact with the application's native API. Below is the reference for the WinCOMReceiverBasic class: Bases: ReceiverBasic The base class for Windows COM client. Initialize the Windows COM client. Parameters: app_root_name ( str ) \u2013 The app root name. process_name ( str ) \u2013 The process name. clsid ( str ) \u2013 The CLSID of the COM object. Source code in automator/app_apis/basic.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , app_root_name : str , process_name : str , clsid : str ) -> None : \"\"\" Initialize the Windows COM client. :param app_root_name: The app root name. :param process_name: The process name. :param clsid: The CLSID of the COM object. \"\"\" self . app_root_name = app_root_name self . process_name = process_name self . clsid = clsid self . client = win32com . client . Dispatch ( self . clsid ) self . com_object = self . get_object_from_process_name ()","title":"Receiver"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.full_path","text":"Get the full path of the process. Returns: str \u2013 The full path of the process.","title":"full_path"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.app_match","text":"Check if the process name matches the app root. Parameters: object_name_list ( List [ str ] ) \u2013 The list of object name. Returns: str \u2013 The matched object name. Source code in automator/app_apis/basic.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def app_match ( self , object_name_list : List [ str ]) -> str : \"\"\" Check if the process name matches the app root. :param object_name_list: The list of object name. :return: The matched object name. \"\"\" suffix = self . get_suffix_mapping () if self . process_name . endswith ( suffix ): clean_process_name = self . process_name [: - len ( suffix )] else : clean_process_name = self . process_name if not object_name_list : return \"\" return max ( object_name_list , key = lambda x : self . longest_common_substring_length ( clean_process_name , x ), )","title":"app_match"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.close","text":"Close the app. Source code in automator/app_apis/basic.py 110 111 112 113 114 115 116 117 def close ( self ) -> None : \"\"\" Close the app. \"\"\" try : self . com_object . Close () except : pass","title":"close"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.get_object_from_process_name","text":"Get the object from the process name. Source code in automator/app_apis/basic.py 36 37 38 39 40 41 @abstractmethod def get_object_from_process_name ( self ) -> win32com . client . CDispatch : \"\"\" Get the object from the process name. \"\"\" pass","title":"get_object_from_process_name"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.get_suffix_mapping","text":"Get the suffix mapping. Returns: Dict [ str , str ] \u2013 The suffix mapping. Source code in automator/app_apis/basic.py 43 44 45 46 47 48 49 50 51 52 53 54 55 def get_suffix_mapping ( self ) -> Dict [ str , str ]: \"\"\" Get the suffix mapping. :return: The suffix mapping. \"\"\" suffix_mapping = { \"WINWORD.EXE\" : \"docx\" , \"EXCEL.EXE\" : \"xlsx\" , \"POWERPNT.EXE\" : \"pptx\" , \"olk.exe\" : \"msg\" , } return suffix_mapping . get ( self . app_root_name , None )","title":"get_suffix_mapping"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.longest_common_substring_length","text":"Get the longest common substring of two strings. Parameters: str1 ( str ) \u2013 The first string. str2 ( str ) \u2013 The second string. Returns: int \u2013 The length of the longest common substring. Source code in automator/app_apis/basic.py 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 @staticmethod def longest_common_substring_length ( str1 : str , str2 : str ) -> int : \"\"\" Get the longest common substring of two strings. :param str1: The first string. :param str2: The second string. :return: The length of the longest common substring. \"\"\" m = len ( str1 ) n = len ( str2 ) dp = [[ 0 ] * ( n + 1 ) for _ in range ( m + 1 )] max_length = 0 for i in range ( 1 , m + 1 ): for j in range ( 1 , n + 1 ): if str1 [ i - 1 ] == str2 [ j - 1 ]: dp [ i ][ j ] = dp [ i - 1 ][ j - 1 ] + 1 if dp [ i ][ j ] > max_length : max_length = dp [ i ][ j ] else : dp [ i ][ j ] = 0 return max_length","title":"longest_common_substring_length"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.save","text":"Save the current state of the app. Source code in automator/app_apis/basic.py 91 92 93 94 95 96 97 98 def save ( self ) -> None : \"\"\" Save the current state of the app. \"\"\" try : self . com_object . Save () except : pass","title":"save"},{"location":"automator/wincom_automator/#automator.app_apis.basic.WinCOMReceiverBasic.save_to_xml","text":"Save the current state of the app to XML. Parameters: file_path ( str ) \u2013 The file path to save the XML. Source code in automator/app_apis/basic.py 100 101 102 103 104 105 106 107 108 def save_to_xml ( self , file_path : str ) -> None : \"\"\" Save the current state of the app to XML. :param file_path: The file path to save the XML. \"\"\" try : self . com_object . SaveAs ( file_path , self . xml_format_code ) except : pass The receiver of Word and Excel applications inherit from the WinCOMReceiverBasic class. The WordReceiver and ExcelReceiver classes are defined in the ufo/automator/app_apis/word and ufo/automator/app_apis/excel modules, respectively:","title":"save_to_xml"},{"location":"automator/wincom_automator/#command","text":"The command of the API Automator for the Word and Excel applications in located in the client module in the ufo/automator/app_apis/{app_name} folder inheriting from the WinCOMCommand class. It encapsulates the function and parameters required to execute the action. Below is an example of a WordCommand class that inherits from the SelectTextCommand class: @WordWinCOMReceiver.register class SelectTextCommand(WinCOMCommand): \"\"\" The command to select text. \"\"\" def execute(self): \"\"\" Execute the command to select text. :return: The selected text. \"\"\" return self.receiver.select_text(self.params.get(\"text\")) @classmethod def name(cls) -> str: \"\"\" The name of the command. \"\"\" return \"select_text\" Note The concrete command classes must implement the execute method to execute the action and the name method to return the name of the atomic command. Note Each command must register with a concrete WinCOMReceiver to be executed using the register decorator. Below is the list of available commands in the API Automator that are currently supported by UFO:","title":"Command"},{"location":"automator/wincom_automator/#word-api-commands","text":"Command Name Function Name Description InsertTableCommand insert_table Insert a table to a Word document. SelectTextCommand select_text Select the text in a Word document. SelectTableCommand select_table Select a table in a Word document.","title":"Word API Commands"},{"location":"automator/wincom_automator/#excel-api-commands","text":"Command Name Function Name Description GetSheetContentCommand get_sheet_content Get the content of a sheet in the Excel app. Table2MarkdownCommand table2markdown Convert the table content in a sheet of the Excel app to markdown format. InsertExcelTableCommand insert_excel_table Insert a table to the Excel sheet. Tip Please refer to the ufo/prompts/apps/{app_name}/api.yaml file for the prompt details for the commands. Tip You can customize the commands by adding new command classes to the ufo/automator/app_apis/{app_name}/ module.","title":"Excel API Commands"},{"location":"benchmark/osworld/","text":"\ud83e\udde9 Setting up UFO with OSWorld (Windows) OSWorld is a benchmark suite designed to evaluate the performance of AI agents in real-world scenarios. We select the 49 cases from the original OSWorld benchmark that are compatible with the Windows platform, renamed as OSWorld-W. The tasks cover a wide range of functionalities and interactions that users typically perform on their computers, including Office 365 and browser. \ud83d\udcbb Deployment Guide (WSL Recommended) We strongly recommend reviewing the original WAA deployment guide beforehand. The instructions below assume you are familiar with the original setup. 1. Clone the Repository git clone https://github.com/nice-mee/WindowsAgentArena.git \ud83d\udca1 To run OSWorld cases, switch to the dedicated development branch: git checkout osworld Create a config.json file in the repo root with a placeholder key (UFO will override this): { \"OPENAI_API_KEY\": \"placeholder\" } 2. Build the Docker Image Navigate to the scripts directory and build the Docker image: cd scripts chmod +x build-container-image.sh prepare-agents.sh # (if needed) ./build-container-image.sh --build-base-image true This will generate the windowsarena/winarena:latest image using the latest codebase in src/ . 3. Integrate UFO Configure UFO via ufo/config/config.json (see UFO repo for details). Copy the entire ufo folder into the WAA container client directory: cp -r src/win-arena-container/vm/setup/mm_agents/UFO/ufo src/win-arena-container/client/ \u26a0\ufe0f Python 3.9 Compatibility Fix In ufo/llm/openai.py , swap the order of @staticmethod and @functools.lru_cache() to prevent issues due to a known Python 3.9 bug. 4. Prepare the Windows 11 Virtual Machine 4.1 Download the ISO Go to the Microsoft Evaluation Center Accept the terms and download Windows 11 Enterprise Evaluation (English, 90-day trial) (~6GB) Rename the file to setup.iso and place it in: WindowsAgentArena/src/win-arena-container/vm/image 4.2 Generate the Golden Image Snapshot Prepare the Windows VM snapshot (a fully provisioned 30GB image): cd ./scripts ./run-local.sh --mode dev --prepare-image true \u26a0\ufe0f Do not interact with the VM during preparation. It will shut down automatically when complete. The golden image will be saved in: WindowsAgentArena/src/win-arena-container/vm/storage 5. Initial Run (First Boot Setup) Launch the environment: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_custom.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Once the VM boots: Do not enter the device code (this keeps the WAA server alive indefinitely). Visit http://localhost:8006 and perform the following setup actions: Disable Windows Firewall Open Google Chrome and complete initial setup Open VLC and complete initial setup Activate Office 365 (Word, Excel, PowerPoint, etc.) with a Microsoft account (use a temporary one if needed). After setup: Stop the client Backup the golden image from the storage folder \ud83e\uddea Running Experiments Before each experiment: Replace the VM image with your prepared golden snapshot Clear any previous UFO logs Then run: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_full.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Note test_full.json : Contains all test cases where UIA is available. test_all.json : Includes all test cases, even those incompatible with UIA. Use test_full.json if you're not using OmniParser.","title":"OSWorld (Windows)"},{"location":"benchmark/osworld/#setting-up-ufo-with-osworld-windows","text":"OSWorld is a benchmark suite designed to evaluate the performance of AI agents in real-world scenarios. We select the 49 cases from the original OSWorld benchmark that are compatible with the Windows platform, renamed as OSWorld-W. The tasks cover a wide range of functionalities and interactions that users typically perform on their computers, including Office 365 and browser.","title":"\ud83e\udde9 Setting up UFO with OSWorld (Windows)"},{"location":"benchmark/osworld/#deployment-guide-wsl-recommended","text":"We strongly recommend reviewing the original WAA deployment guide beforehand. The instructions below assume you are familiar with the original setup.","title":"\ud83d\udcbb Deployment Guide (WSL Recommended)"},{"location":"benchmark/osworld/#1-clone-the-repository","text":"git clone https://github.com/nice-mee/WindowsAgentArena.git \ud83d\udca1 To run OSWorld cases, switch to the dedicated development branch: git checkout osworld Create a config.json file in the repo root with a placeholder key (UFO will override this): { \"OPENAI_API_KEY\": \"placeholder\" }","title":"1. Clone the Repository"},{"location":"benchmark/osworld/#2-build-the-docker-image","text":"Navigate to the scripts directory and build the Docker image: cd scripts chmod +x build-container-image.sh prepare-agents.sh # (if needed) ./build-container-image.sh --build-base-image true This will generate the windowsarena/winarena:latest image using the latest codebase in src/ .","title":"2. Build the Docker Image"},{"location":"benchmark/osworld/#3-integrate-ufo","text":"Configure UFO via ufo/config/config.json (see UFO repo for details). Copy the entire ufo folder into the WAA container client directory: cp -r src/win-arena-container/vm/setup/mm_agents/UFO/ufo src/win-arena-container/client/ \u26a0\ufe0f Python 3.9 Compatibility Fix In ufo/llm/openai.py , swap the order of @staticmethod and @functools.lru_cache() to prevent issues due to a known Python 3.9 bug.","title":"3. Integrate UFO"},{"location":"benchmark/osworld/#4-prepare-the-windows-11-virtual-machine","text":"","title":"4. Prepare the Windows 11 Virtual Machine"},{"location":"benchmark/osworld/#41-download-the-iso","text":"Go to the Microsoft Evaluation Center Accept the terms and download Windows 11 Enterprise Evaluation (English, 90-day trial) (~6GB) Rename the file to setup.iso and place it in: WindowsAgentArena/src/win-arena-container/vm/image","title":"4.1 Download the ISO"},{"location":"benchmark/osworld/#42-generate-the-golden-image-snapshot","text":"Prepare the Windows VM snapshot (a fully provisioned 30GB image): cd ./scripts ./run-local.sh --mode dev --prepare-image true \u26a0\ufe0f Do not interact with the VM during preparation. It will shut down automatically when complete. The golden image will be saved in: WindowsAgentArena/src/win-arena-container/vm/storage","title":"4.2 Generate the Golden Image Snapshot"},{"location":"benchmark/osworld/#5-initial-run-first-boot-setup","text":"Launch the environment: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_custom.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Once the VM boots: Do not enter the device code (this keeps the WAA server alive indefinitely). Visit http://localhost:8006 and perform the following setup actions: Disable Windows Firewall Open Google Chrome and complete initial setup Open VLC and complete initial setup Activate Office 365 (Word, Excel, PowerPoint, etc.) with a Microsoft account (use a temporary one if needed). After setup: Stop the client Backup the golden image from the storage folder","title":"5. Initial Run (First Boot Setup)"},{"location":"benchmark/osworld/#running-experiments","text":"Before each experiment: Replace the VM image with your prepared golden snapshot Clear any previous UFO logs Then run: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_full.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Note test_full.json : Contains all test cases where UIA is available. test_all.json : Includes all test cases, even those incompatible with UIA. Use test_full.json if you're not using OmniParser.","title":"\ud83e\uddea Running Experiments"},{"location":"benchmark/overview/","text":"Benchmark Overview UFO\u00b2 is rigorously benchmarked on two publicly\u2011available live\u2011task suites: Benchmark Scope Windows Agent Arena (WAA) 154 real Windows tasks across 15 applications (Office, Edge, File Explorer, VS Code, \u2026) OSWorld (Windows) 49 cross\u2011application tasks that mix Office 365, browser and system utilities The integration of these benchmarks into UFO\u00b2 is in separate repositories. Please follow the above documents for more details. Note we have revised the verification scripts of some cases to ensure the correctness of the results.","title":"Overview"},{"location":"benchmark/overview/#benchmark-overview","text":"UFO\u00b2 is rigorously benchmarked on two publicly\u2011available live\u2011task suites: Benchmark Scope Windows Agent Arena (WAA) 154 real Windows tasks across 15 applications (Office, Edge, File Explorer, VS Code, \u2026) OSWorld (Windows) 49 cross\u2011application tasks that mix Office 365, browser and system utilities The integration of these benchmarks into UFO\u00b2 is in separate repositories. Please follow the above documents for more details. Note we have revised the verification scripts of some cases to ensure the correctness of the results.","title":"Benchmark Overview"},{"location":"benchmark/windows_agent_arena/","text":"\ud83e\udde9 Setting up UFO with Windows Agent Arena (WAA) Windows Agent Arena (WAA) is a benchmark suite designed to evaluate the performance of AI agents in executing real-world tasks on Windows operating systems. It consists of 154 tasks across 15 applications, including Microsoft Office, Edge, File Explorer, and VS Code. The tasks are designed to cover a wide range of functionalities and interactions that users typically perform on their computers. This repository provides a modified version of Windows Agent Arena (WAA) \ud83e\ude9f , a scalable platform for benchmarking and evaluating multimodal desktop AI agents. This customized fork integrates with UFO , a UI-focused automation agent for Windows OS. \ud83d\udcbb Deployment Guide (WSL Recommended) We strongly recommend reviewing the original WAA deployment guide beforehand. The instructions below assume you are familiar with the original setup. 1. Clone the Repository git clone https://github.com/nice-mee/WindowsAgentArena.git \ud83d\udca1 To run OSWorld cases, switch to the dedicated development branch: git checkout 2020-qqtcg/dev Create a config.json file in the repo root with a placeholder key (UFO will override this): { \"OPENAI_API_KEY\": \"placeholder\" } 2. Build the Docker Image Navigate to the scripts directory and build the Docker image: cd scripts chmod +x build-container-image.sh prepare-agents.sh # (if needed) ./build-container-image.sh --build-base-image true This will generate the windowsarena/winarena:latest image using the latest codebase in src/ . 3. Integrate UFO Configure UFO via ufo/config/config.json (see UFO repo for details). Copy the entire ufo folder into the WAA container client directory: cp -r src/win-arena-container/vm/setup/mm_agents/UFO/ufo src/win-arena-container/client/ \u26a0\ufe0f Python 3.9 Compatibility Fix In ufo/llm/openai.py , swap the order of @staticmethod and @functools.lru_cache() to prevent issues due to a known Python 3.9 bug. 4. Prepare the Windows 11 Virtual Machine 4.1 Download the ISO Go to the Microsoft Evaluation Center Accept the terms and download Windows 11 Enterprise Evaluation (English, 90-day trial) (~6GB) Rename the file to setup.iso and place it in: WindowsAgentArena/src/win-arena-container/vm/image 4.2 Generate the Golden Image Snapshot Prepare the Windows VM snapshot (a fully provisioned 30GB image): cd ./scripts ./run-local.sh --mode dev --prepare-image true \u26a0\ufe0f Do not interact with the VM during preparation. It will shut down automatically when complete. The golden image will be saved in: WindowsAgentArena/src/win-arena-container/vm/storage 5. Initial Run (First Boot Setup) Launch the environment: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_custom.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Once the VM boots: Do not enter the device code (this keeps the WAA server alive indefinitely). Visit http://localhost:8006 and perform the following setup actions: Disable Windows Firewall Open Google Chrome and complete initial setup Open VLC and complete initial setup After setup: Stop the client Backup the golden image from the storage folder \ud83e\uddea Running Experiments Before each experiment: Replace the VM image with your prepared golden snapshot Clear any previous UFO logs Then run: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_full.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Note test_full.json : Contains all test cases where UIA is available. test_all.json : Includes all test cases, even those incompatible with UIA. Use test_full.json if you're not using OmniParser.","title":"Windows Agent Arena"},{"location":"benchmark/windows_agent_arena/#setting-up-ufo-with-windows-agent-arena-waa","text":"Windows Agent Arena (WAA) is a benchmark suite designed to evaluate the performance of AI agents in executing real-world tasks on Windows operating systems. It consists of 154 tasks across 15 applications, including Microsoft Office, Edge, File Explorer, and VS Code. The tasks are designed to cover a wide range of functionalities and interactions that users typically perform on their computers. This repository provides a modified version of Windows Agent Arena (WAA) \ud83e\ude9f , a scalable platform for benchmarking and evaluating multimodal desktop AI agents. This customized fork integrates with UFO , a UI-focused automation agent for Windows OS.","title":"\ud83e\udde9 Setting up UFO with Windows Agent Arena (WAA)"},{"location":"benchmark/windows_agent_arena/#deployment-guide-wsl-recommended","text":"We strongly recommend reviewing the original WAA deployment guide beforehand. The instructions below assume you are familiar with the original setup.","title":"\ud83d\udcbb Deployment Guide (WSL Recommended)"},{"location":"benchmark/windows_agent_arena/#1-clone-the-repository","text":"git clone https://github.com/nice-mee/WindowsAgentArena.git \ud83d\udca1 To run OSWorld cases, switch to the dedicated development branch: git checkout 2020-qqtcg/dev Create a config.json file in the repo root with a placeholder key (UFO will override this): { \"OPENAI_API_KEY\": \"placeholder\" }","title":"1. Clone the Repository"},{"location":"benchmark/windows_agent_arena/#2-build-the-docker-image","text":"Navigate to the scripts directory and build the Docker image: cd scripts chmod +x build-container-image.sh prepare-agents.sh # (if needed) ./build-container-image.sh --build-base-image true This will generate the windowsarena/winarena:latest image using the latest codebase in src/ .","title":"2. Build the Docker Image"},{"location":"benchmark/windows_agent_arena/#3-integrate-ufo","text":"Configure UFO via ufo/config/config.json (see UFO repo for details). Copy the entire ufo folder into the WAA container client directory: cp -r src/win-arena-container/vm/setup/mm_agents/UFO/ufo src/win-arena-container/client/ \u26a0\ufe0f Python 3.9 Compatibility Fix In ufo/llm/openai.py , swap the order of @staticmethod and @functools.lru_cache() to prevent issues due to a known Python 3.9 bug.","title":"3. Integrate UFO"},{"location":"benchmark/windows_agent_arena/#4-prepare-the-windows-11-virtual-machine","text":"","title":"4. Prepare the Windows 11 Virtual Machine"},{"location":"benchmark/windows_agent_arena/#41-download-the-iso","text":"Go to the Microsoft Evaluation Center Accept the terms and download Windows 11 Enterprise Evaluation (English, 90-day trial) (~6GB) Rename the file to setup.iso and place it in: WindowsAgentArena/src/win-arena-container/vm/image","title":"4.1 Download the ISO"},{"location":"benchmark/windows_agent_arena/#42-generate-the-golden-image-snapshot","text":"Prepare the Windows VM snapshot (a fully provisioned 30GB image): cd ./scripts ./run-local.sh --mode dev --prepare-image true \u26a0\ufe0f Do not interact with the VM during preparation. It will shut down automatically when complete. The golden image will be saved in: WindowsAgentArena/src/win-arena-container/vm/storage","title":"4.2 Generate the Golden Image Snapshot"},{"location":"benchmark/windows_agent_arena/#5-initial-run-first-boot-setup","text":"Launch the environment: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_custom.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Once the VM boots: Do not enter the device code (this keeps the WAA server alive indefinitely). Visit http://localhost:8006 and perform the following setup actions: Disable Windows Firewall Open Google Chrome and complete initial setup Open VLC and complete initial setup After setup: Stop the client Backup the golden image from the storage folder","title":"5. Initial Run (First Boot Setup)"},{"location":"benchmark/windows_agent_arena/#running-experiments","text":"Before each experiment: Replace the VM image with your prepared golden snapshot Clear any previous UFO logs Then run: ./run-local.sh --mode dev --json-name \"evaluation_examples_windows/test_full.json\" --agent UFO --agent-settings '{\"llm_type\": \"azure\", \"llm_endpoint\": \"https://cloudgpt-openai.azure-api.net/openai/deployments/gpt-4o-20240513/chat/completions?api-version=2024-04-01-preview\", \"llm_auth\": {\"type\": \"api-key\", \"token\": \"\"}}' Note test_full.json : Contains all test cases where UIA is available. test_all.json : Includes all test cases, even those incompatible with UIA. Use test_full.json if you're not using OmniParser.","title":"\ud83e\uddea Running Experiments"},{"location":"configurations/developer_configuration/","text":"Developer Configuration This section provides detailed information on how to configure the UFO agent for developers. The configuration file config_dev.yaml is located in the ufo/config directory and contains various settings and switches to customize the UFO agent for development purposes. System Configuration The following parameters are included in the system configuration of the UFO agent: Configuration Option Description Type Default Value CONTROL_BACKEND The list of backend for control action, currently supporting uia and win32 and onmiparser List [\"uia\"] ACTION_SEQUENCE Whether to use output multiple actions in a single step. Boolean False MAX_STEP The maximum step limit for completing the user request in a session. Integer 100 MAX_ROUND The maximum round limit for completing the user request in a session. Integer 10 SLEEP_TIME The sleep time in seconds between each step to wait for the window to be ready. Integer 5 RECTANGLE_TIME The time in seconds for the rectangle display around the selected control. Integer 1 SAFE_GUARD Whether to use the safe guard to ask for user confirmation before performing sensitive operations. Boolean True CONTROL_LIST The list of widgets allowed to be selected. List [\"Button\", \"Edit\", \"TabItem\", \"Document\", \"ListItem\", \"MenuItem\", \"ScrollBar\", \"TreeItem\", \"Hyperlink\", \"ComboBox\", \"RadioButton\", \"DataItem\"] HISTORY_KEYS The keys of the step history added to the Blackboard for agent decision-making. List [\"Step\", \"Thought\", \"ControlText\", \"Subtask\", \"Action\", \"Comment\", \"Results\", \"UserConfirm\"] ANNOTATION_COLORS The colors assigned to different control types for annotation. Dictionary {\"Button\": \"#FFF68F\", \"Edit\": \"#A5F0B5\", \"TabItem\": \"#A5E7F0\", \"Document\": \"#FFD18A\", \"ListItem\": \"#D9C3FE\", \"MenuItem\": \"#E7FEC3\", \"ScrollBar\": \"#FEC3F8\", \"TreeItem\": \"#D6D6D6\", \"Hyperlink\": \"#91FFEB\", \"ComboBox\": \"#D8B6D4\"} ANNOTATION_FONT_SIZE The font size for the annotation. Integer 22 PRINT_LOG Whether to print the log in the console. Boolean False CONCAT_SCREENSHOT Whether to concatenate the screenshots into a single image for the LLM input. Boolean False INCLUDE_LAST_SCREENSHOT Whether to include the screenshot from the last step in the observation. Boolean True LOG_LEVEL The log level for the UFO agent. String \"DEBUG\" REQUEST_TIMEOUT The call timeout in seconds for the LLM model. Integer 250 USE_APIS Whether to allow the use of application APIs. Boolean True LOG_XML Whether to log the XML file at every step. Boolean False SCREENSHOT_TO_MEMORY Whether to allow the screenshot to Blackboard for the agent's decision making. Boolean True SAVE_UI_TREE Whether to save the UI tree in the log. Boolean False SAVE_EXPERIENCE Whether to save the experience, can be \"always\" for always save, \"always_not\" for always not save, \"ask\" for asking the user to save or not. By default, it is \"always_not\" String \"always_not\" TASK_STATUS Whether to record the status of the tasks in batch execution mode. Boolean True Main Prompt Configuration Main Prompt Templates The main prompt templates include the prompts in the UFO agent for both system and user roles. Configuration Option Description Type Default Value HOSTAGENT_PROMPT The main prompt template for the HostAgent . String \"ufo/prompts/share/base/host_agent.yaml\" APPAGENT_PROMPT The main prompt template for the AppAgent . String \"ufo/prompts/share/base/app_agent.yaml\" FOLLOWERAGENT_PROMPT The main prompt template for the FollowerAgent . String \"ufo/prompts/share/base/app_agent.yaml\" EVALUATION_PROMPT The prompt template for the evaluation. String \"ufo/prompts/evaluation/evaluate.yaml\" Lite versions of the main prompt templates can be found in the ufo/prompts/share/lite directory to reduce the input size for specific token limits. Example Prompt Templates Example prompt templates are used for demonstration purposes in the UFO agent. Configuration Option Description Type Default Value HOSTAGENT_EXAMPLE_PROMPT The example prompt template for the HostAgent used for demonstration. String \"ufo/prompts/examples/{mode}/host_agent_example.yaml\" APPAGENT_EXAMPLE_PROMPT The example prompt template for the AppAgent used for demonstration. String \"ufo/prompts/examples/{mode}/app_agent_example.yaml\" Lite versions of the example prompt templates can be found in the ufo/prompts/examples/lite/{mode} directory to reduce the input size for demonstration purposes. Experience and Demonstration Learning These configuration parameters are used for experience and demonstration learning in the UFO agent. Configuration Option Description Type Default Value EXPERIENCE_PROMPT The prompt for self-experience learning. String \"ufo/prompts/experience/experience_summary.yaml\" EXPERIENCE_SAVED_PATH The path to save the experience learning data. String \"vectordb/experience/\" DEMONSTRATION_PROMPT The prompt for user demonstration learning. String \"ufo/prompts/demonstration/demonstration_summary.yaml\" DEMONSTRATION_SAVED_PATH The path to save the demonstration learning data. String \"vectordb/demonstration/\" Application API Configuration These prompt configuration parameters are used for the application and control APIs in the UFO agent. Configuration Option Description Type Default Value API_PROMPT The prompt for the UI automation API. String \"ufo/prompts/share/base/api.yaml\" APP_API_PROMPT_ADDRESS The prompt address for the application API. Dict {\"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\"} pywinauto Configuration The API configuration parameters are used for the pywinauto API in the UFO agent. Configuration Option Description Type Default Value CLICK_API The API used for click action, can be click_input or click . String \"click_input\" INPUT_TEXT_API The API used for input text action, can be type_keys or set_text . String \"type_keys\" INPUT_TEXT_ENTER Whether to press enter after typing the text. Boolean False Control Filtering The control filtering configuration parameters are used for control filtering in the agent's observation. Configuration Option Description Type Default Value CONTROL_FILTER The control filter type, can be TEXT , SEMANTIC , or ICON . List [] CONTROL_FILTER_TOP_K_PLAN The control filter effect on top k plans from the agent. Integer 2 CONTROL_FILTER_TOP_K_SEMANTIC The control filter top k for semantic similarity. Integer 15 CONTROL_FILTER_TOP_K_ICON The control filter top k for icon similarity. Integer 15 CONTROL_FILTER_MODEL_SEMANTIC_NAME The control filter model name for semantic similarity. String \"all-MiniLM-L6-v2\" CONTROL_FILTER_MODEL_ICON_NAME The control filter model name for icon similarity. String \"clip-ViT-B-32\" Customizations The customization configuration parameters are used for customizations in the UFO agent. Configuration Option Description Type Default Value ASK_QUESTION Whether to ask the user for a question. Boolean True USE_CUSTOMIZATION Whether to enable the customization. Boolean True QA_PAIR_FILE The path for the historical QA pairs. String \"customization/historical_qa.txt\" QA_PAIR_NUM The number of QA pairs for the customization. Integer 20 Evaluation The evaluation configuration parameters are used for the evaluation in the UFO agent. Configuration Option Description Type Default Value EVA_SESSION Whether to include the session in the evaluation. Boolean True EVA_ROUND Whether to include the round in the evaluation. Boolean False EVA_ALL_SCREENSHOTS Whether to include all the screenshots in the evaluation. Boolean True You can customize the configuration parameters in the config_dev.yaml file to suit your development needs and enhance the functionality of the UFO agent.","title":"Developer Configuration"},{"location":"configurations/developer_configuration/#developer-configuration","text":"This section provides detailed information on how to configure the UFO agent for developers. The configuration file config_dev.yaml is located in the ufo/config directory and contains various settings and switches to customize the UFO agent for development purposes.","title":"Developer Configuration"},{"location":"configurations/developer_configuration/#system-configuration","text":"The following parameters are included in the system configuration of the UFO agent: Configuration Option Description Type Default Value CONTROL_BACKEND The list of backend for control action, currently supporting uia and win32 and onmiparser List [\"uia\"] ACTION_SEQUENCE Whether to use output multiple actions in a single step. Boolean False MAX_STEP The maximum step limit for completing the user request in a session. Integer 100 MAX_ROUND The maximum round limit for completing the user request in a session. Integer 10 SLEEP_TIME The sleep time in seconds between each step to wait for the window to be ready. Integer 5 RECTANGLE_TIME The time in seconds for the rectangle display around the selected control. Integer 1 SAFE_GUARD Whether to use the safe guard to ask for user confirmation before performing sensitive operations. Boolean True CONTROL_LIST The list of widgets allowed to be selected. List [\"Button\", \"Edit\", \"TabItem\", \"Document\", \"ListItem\", \"MenuItem\", \"ScrollBar\", \"TreeItem\", \"Hyperlink\", \"ComboBox\", \"RadioButton\", \"DataItem\"] HISTORY_KEYS The keys of the step history added to the Blackboard for agent decision-making. List [\"Step\", \"Thought\", \"ControlText\", \"Subtask\", \"Action\", \"Comment\", \"Results\", \"UserConfirm\"] ANNOTATION_COLORS The colors assigned to different control types for annotation. Dictionary {\"Button\": \"#FFF68F\", \"Edit\": \"#A5F0B5\", \"TabItem\": \"#A5E7F0\", \"Document\": \"#FFD18A\", \"ListItem\": \"#D9C3FE\", \"MenuItem\": \"#E7FEC3\", \"ScrollBar\": \"#FEC3F8\", \"TreeItem\": \"#D6D6D6\", \"Hyperlink\": \"#91FFEB\", \"ComboBox\": \"#D8B6D4\"} ANNOTATION_FONT_SIZE The font size for the annotation. Integer 22 PRINT_LOG Whether to print the log in the console. Boolean False CONCAT_SCREENSHOT Whether to concatenate the screenshots into a single image for the LLM input. Boolean False INCLUDE_LAST_SCREENSHOT Whether to include the screenshot from the last step in the observation. Boolean True LOG_LEVEL The log level for the UFO agent. String \"DEBUG\" REQUEST_TIMEOUT The call timeout in seconds for the LLM model. Integer 250 USE_APIS Whether to allow the use of application APIs. Boolean True LOG_XML Whether to log the XML file at every step. Boolean False SCREENSHOT_TO_MEMORY Whether to allow the screenshot to Blackboard for the agent's decision making. Boolean True SAVE_UI_TREE Whether to save the UI tree in the log. Boolean False SAVE_EXPERIENCE Whether to save the experience, can be \"always\" for always save, \"always_not\" for always not save, \"ask\" for asking the user to save or not. By default, it is \"always_not\" String \"always_not\" TASK_STATUS Whether to record the status of the tasks in batch execution mode. Boolean True","title":"System Configuration"},{"location":"configurations/developer_configuration/#main-prompt-configuration","text":"","title":"Main Prompt Configuration"},{"location":"configurations/developer_configuration/#main-prompt-templates","text":"The main prompt templates include the prompts in the UFO agent for both system and user roles. Configuration Option Description Type Default Value HOSTAGENT_PROMPT The main prompt template for the HostAgent . String \"ufo/prompts/share/base/host_agent.yaml\" APPAGENT_PROMPT The main prompt template for the AppAgent . String \"ufo/prompts/share/base/app_agent.yaml\" FOLLOWERAGENT_PROMPT The main prompt template for the FollowerAgent . String \"ufo/prompts/share/base/app_agent.yaml\" EVALUATION_PROMPT The prompt template for the evaluation. String \"ufo/prompts/evaluation/evaluate.yaml\" Lite versions of the main prompt templates can be found in the ufo/prompts/share/lite directory to reduce the input size for specific token limits.","title":"Main Prompt Templates"},{"location":"configurations/developer_configuration/#example-prompt-templates","text":"Example prompt templates are used for demonstration purposes in the UFO agent. Configuration Option Description Type Default Value HOSTAGENT_EXAMPLE_PROMPT The example prompt template for the HostAgent used for demonstration. String \"ufo/prompts/examples/{mode}/host_agent_example.yaml\" APPAGENT_EXAMPLE_PROMPT The example prompt template for the AppAgent used for demonstration. String \"ufo/prompts/examples/{mode}/app_agent_example.yaml\" Lite versions of the example prompt templates can be found in the ufo/prompts/examples/lite/{mode} directory to reduce the input size for demonstration purposes.","title":"Example Prompt Templates"},{"location":"configurations/developer_configuration/#experience-and-demonstration-learning","text":"These configuration parameters are used for experience and demonstration learning in the UFO agent. Configuration Option Description Type Default Value EXPERIENCE_PROMPT The prompt for self-experience learning. String \"ufo/prompts/experience/experience_summary.yaml\" EXPERIENCE_SAVED_PATH The path to save the experience learning data. String \"vectordb/experience/\" DEMONSTRATION_PROMPT The prompt for user demonstration learning. String \"ufo/prompts/demonstration/demonstration_summary.yaml\" DEMONSTRATION_SAVED_PATH The path to save the demonstration learning data. String \"vectordb/demonstration/\"","title":"Experience and Demonstration Learning"},{"location":"configurations/developer_configuration/#application-api-configuration","text":"These prompt configuration parameters are used for the application and control APIs in the UFO agent. Configuration Option Description Type Default Value API_PROMPT The prompt for the UI automation API. String \"ufo/prompts/share/base/api.yaml\" APP_API_PROMPT_ADDRESS The prompt address for the application API. Dict {\"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\"}","title":"Application API Configuration"},{"location":"configurations/developer_configuration/#pywinauto-configuration","text":"The API configuration parameters are used for the pywinauto API in the UFO agent. Configuration Option Description Type Default Value CLICK_API The API used for click action, can be click_input or click . String \"click_input\" INPUT_TEXT_API The API used for input text action, can be type_keys or set_text . String \"type_keys\" INPUT_TEXT_ENTER Whether to press enter after typing the text. Boolean False","title":"pywinauto Configuration"},{"location":"configurations/developer_configuration/#control-filtering","text":"The control filtering configuration parameters are used for control filtering in the agent's observation. Configuration Option Description Type Default Value CONTROL_FILTER The control filter type, can be TEXT , SEMANTIC , or ICON . List [] CONTROL_FILTER_TOP_K_PLAN The control filter effect on top k plans from the agent. Integer 2 CONTROL_FILTER_TOP_K_SEMANTIC The control filter top k for semantic similarity. Integer 15 CONTROL_FILTER_TOP_K_ICON The control filter top k for icon similarity. Integer 15 CONTROL_FILTER_MODEL_SEMANTIC_NAME The control filter model name for semantic similarity. String \"all-MiniLM-L6-v2\" CONTROL_FILTER_MODEL_ICON_NAME The control filter model name for icon similarity. String \"clip-ViT-B-32\"","title":"Control Filtering"},{"location":"configurations/developer_configuration/#customizations","text":"The customization configuration parameters are used for customizations in the UFO agent. Configuration Option Description Type Default Value ASK_QUESTION Whether to ask the user for a question. Boolean True USE_CUSTOMIZATION Whether to enable the customization. Boolean True QA_PAIR_FILE The path for the historical QA pairs. String \"customization/historical_qa.txt\" QA_PAIR_NUM The number of QA pairs for the customization. Integer 20","title":"Customizations"},{"location":"configurations/developer_configuration/#evaluation","text":"The evaluation configuration parameters are used for the evaluation in the UFO agent. Configuration Option Description Type Default Value EVA_SESSION Whether to include the session in the evaluation. Boolean True EVA_ROUND Whether to include the round in the evaluation. Boolean False EVA_ALL_SCREENSHOTS Whether to include all the screenshots in the evaluation. Boolean True You can customize the configuration parameters in the config_dev.yaml file to suit your development needs and enhance the functionality of the UFO agent.","title":"Evaluation"},{"location":"configurations/pricing_configuration/","text":"Pricing Configuration We provide a configuration file pricing_config.yaml to calculate the pricing of the UFO agent using different LLM APIs. The pricing configuration file is located in the ufo/config directory. Note that the pricing configuration file is only used for reference and may not be up-to-date. Please refer to the official pricing documentation of the respective LLM API provider for the most accurate pricing information. You can also customize the pricing configuration file based on the configured model names and their respective input and output prices by adding or modifying the pricing information in the pricing_config.yaml file. Below is the default pricing configuration: # Prices in $ per 1000 tokens # Last updated: 2024-05-13 PRICES: { \"openai/gpt-4-0613\": {\"input\": 0.03, \"output\": 0.06}, \"openai/gpt-3.5-turbo-0613\": {\"input\": 0.0015, \"output\": 0.002}, \"openai/gpt-4-0125-preview\": {\"input\": 0.01, \"output\": 0.03}, \"openai/gpt-4-1106-preview\": {\"input\": 0.01, \"output\": 0.03}, \"openai/gpt-4-1106-vision-preview\": {\"input\": 0.01, \"output\": 0.03}, \"openai/gpt-4\": {\"input\": 0.03, \"output\": 0.06}, \"openai/gpt-4-32k\": {\"input\": 0.06, \"output\": 0.12}, \"openai/gpt-4-turbo\": {\"input\":0.01,\"output\": 0.03}, \"openai/gpt-4o\": {\"input\": 0.005,\"output\": 0.015}, \"openai/gpt-4o-2024-05-13\": {\"input\": 0.005, \"output\": 0.015}, \"openai/gpt-3.5-turbo-0125\": {\"input\": 0.0005, \"output\": 0.0015}, \"openai/gpt-3.5-turbo-1106\": {\"input\": 0.001, \"output\": 0.002}, \"openai/gpt-3.5-turbo-instruct\": {\"input\": 0.0015, \"output\": 0.002}, \"openai/gpt-3.5-turbo-16k-0613\": {\"input\": 0.003, \"output\": 0.004}, \"openai/whisper-1\": {\"input\": 0.006, \"output\": 0.006}, \"openai/tts-1\": {\"input\": 0.015, \"output\": 0.015}, \"openai/tts-hd-1\": {\"input\": 0.03, \"output\": 0.03}, \"openai/text-embedding-ada-002-v2\": {\"input\": 0.0001, \"output\": 0.0001}, \"openai/text-davinci:003\": {\"input\": 0.02, \"output\": 0.02}, \"openai/text-ada-001\": {\"input\": 0.0004, \"output\": 0.0004}, \"azure/gpt-35-turbo-20220309\":{\"input\": 0.0015, \"output\": 0.002}, \"azure/gpt-35-turbo-20230613\":{\"input\": 0.0015, \"output\": 0.002}, \"azure/gpt-35-turbo-16k-20230613\":{\"input\": 0.003, \"output\": 0.004}, \"azure/gpt-35-turbo-1106\":{\"input\": 0.001, \"output\": 0.002}, \"azure/gpt-4-20230321\":{\"input\": 0.03, \"output\": 0.06}, \"azure/gpt-4-32k-20230321\":{\"input\": 0.06, \"output\": 0.12}, \"azure/gpt-4-1106-preview\": {\"input\": 0.01, \"output\": 0.03}, \"azure/gpt-4-0125-preview\": {\"input\": 0.01, \"output\": 0.03}, \"azure/gpt-4-visual-preview\": {\"input\": 0.01, \"output\": 0.03}, \"azure/gpt-4-turbo-20240409\": {\"input\":0.01,\"output\": 0.03}, \"azure/gpt-4o\": {\"input\": 0.005,\"output\": 0.015}, \"azure/gpt-4o-20240513\": {\"input\": 0.005, \"output\": 0.015}, \"qwen/qwen-vl-plus\": {\"input\": 0.008, \"output\": 0.008}, \"qwen/qwen-vl-max\": {\"input\": 0.02, \"output\": 0.02}, \"gemini/gemini-1.5-flash\": {\"input\": 0.00035, \"output\": 0.00105}, \"gemini/gemini-1.5-pro\": {\"input\": 0.0035, \"output\": 0.0105}, \"gemini/gemini-1.0-pro\": {\"input\": 0.0005, \"output\": 0.0015}, } Please refer to the official pricing documentation of the respective LLM API provider for the most accurate pricing information.","title":"Model Pricing"},{"location":"configurations/pricing_configuration/#pricing-configuration","text":"We provide a configuration file pricing_config.yaml to calculate the pricing of the UFO agent using different LLM APIs. The pricing configuration file is located in the ufo/config directory. Note that the pricing configuration file is only used for reference and may not be up-to-date. Please refer to the official pricing documentation of the respective LLM API provider for the most accurate pricing information. You can also customize the pricing configuration file based on the configured model names and their respective input and output prices by adding or modifying the pricing information in the pricing_config.yaml file. Below is the default pricing configuration: # Prices in $ per 1000 tokens # Last updated: 2024-05-13 PRICES: { \"openai/gpt-4-0613\": {\"input\": 0.03, \"output\": 0.06}, \"openai/gpt-3.5-turbo-0613\": {\"input\": 0.0015, \"output\": 0.002}, \"openai/gpt-4-0125-preview\": {\"input\": 0.01, \"output\": 0.03}, \"openai/gpt-4-1106-preview\": {\"input\": 0.01, \"output\": 0.03}, \"openai/gpt-4-1106-vision-preview\": {\"input\": 0.01, \"output\": 0.03}, \"openai/gpt-4\": {\"input\": 0.03, \"output\": 0.06}, \"openai/gpt-4-32k\": {\"input\": 0.06, \"output\": 0.12}, \"openai/gpt-4-turbo\": {\"input\":0.01,\"output\": 0.03}, \"openai/gpt-4o\": {\"input\": 0.005,\"output\": 0.015}, \"openai/gpt-4o-2024-05-13\": {\"input\": 0.005, \"output\": 0.015}, \"openai/gpt-3.5-turbo-0125\": {\"input\": 0.0005, \"output\": 0.0015}, \"openai/gpt-3.5-turbo-1106\": {\"input\": 0.001, \"output\": 0.002}, \"openai/gpt-3.5-turbo-instruct\": {\"input\": 0.0015, \"output\": 0.002}, \"openai/gpt-3.5-turbo-16k-0613\": {\"input\": 0.003, \"output\": 0.004}, \"openai/whisper-1\": {\"input\": 0.006, \"output\": 0.006}, \"openai/tts-1\": {\"input\": 0.015, \"output\": 0.015}, \"openai/tts-hd-1\": {\"input\": 0.03, \"output\": 0.03}, \"openai/text-embedding-ada-002-v2\": {\"input\": 0.0001, \"output\": 0.0001}, \"openai/text-davinci:003\": {\"input\": 0.02, \"output\": 0.02}, \"openai/text-ada-001\": {\"input\": 0.0004, \"output\": 0.0004}, \"azure/gpt-35-turbo-20220309\":{\"input\": 0.0015, \"output\": 0.002}, \"azure/gpt-35-turbo-20230613\":{\"input\": 0.0015, \"output\": 0.002}, \"azure/gpt-35-turbo-16k-20230613\":{\"input\": 0.003, \"output\": 0.004}, \"azure/gpt-35-turbo-1106\":{\"input\": 0.001, \"output\": 0.002}, \"azure/gpt-4-20230321\":{\"input\": 0.03, \"output\": 0.06}, \"azure/gpt-4-32k-20230321\":{\"input\": 0.06, \"output\": 0.12}, \"azure/gpt-4-1106-preview\": {\"input\": 0.01, \"output\": 0.03}, \"azure/gpt-4-0125-preview\": {\"input\": 0.01, \"output\": 0.03}, \"azure/gpt-4-visual-preview\": {\"input\": 0.01, \"output\": 0.03}, \"azure/gpt-4-turbo-20240409\": {\"input\":0.01,\"output\": 0.03}, \"azure/gpt-4o\": {\"input\": 0.005,\"output\": 0.015}, \"azure/gpt-4o-20240513\": {\"input\": 0.005, \"output\": 0.015}, \"qwen/qwen-vl-plus\": {\"input\": 0.008, \"output\": 0.008}, \"qwen/qwen-vl-max\": {\"input\": 0.02, \"output\": 0.02}, \"gemini/gemini-1.5-flash\": {\"input\": 0.00035, \"output\": 0.00105}, \"gemini/gemini-1.5-pro\": {\"input\": 0.0035, \"output\": 0.0105}, \"gemini/gemini-1.0-pro\": {\"input\": 0.0005, \"output\": 0.0015}, } Please refer to the official pricing documentation of the respective LLM API provider for the most accurate pricing information.","title":"Pricing Configuration"},{"location":"configurations/user_configuration/","text":"User Configuration An overview of the user configuration options available in UFO. You need to rename the config.yaml.template in the folder ufo/config to config.yaml to configure the LLMs and other custom settings. LLM Configuration You can configure the LLMs for the HOST_AGENT and APP_AGENT separately in the config.yaml file. The FollowerAgent and EvaluationAgent share the same LLM configuration as the APP_AGENT . Additionally, you can configure a backup LLM engine in the BACKUP_AGENT field to handle cases where the primary engines fail during inference. Below are the configuration options for the LLMs, using OpenAI and Azure OpenAI (AOAI) as examples. You can find the settings for other LLM API configurations and usage in the Supported Models section of the documentation. Configuration Option Description Type Default Value VISUAL_MODE Whether to use visual mode to understand screenshots and take actions Boolean True API_TYPE The API type: \"openai\" for the OpenAI API, \"aoai\" for the AOAI API. String \"openai\" API_BASE The API endpoint for the LLM String \"https://api.openai.com/v1/chat/completions\" API_KEY The API key for the LLM String \"sk-\" API_VERSION The version of the API String \"2024-02-15-preview\" API_MODEL The LLM model name String \"gpt-4-vision-preview\" For Azure OpenAI (AOAI) API The following additional configuration option is available for the AOAI API: Configuration Option Description Type Default Value API_DEPLOYMENT_ID The deployment ID, only available for the AOAI API String \"\" Ensure to fill in the necessary API details for both the HOST_AGENT and APP_AGENT to enable UFO to interact with the LLMs effectively. LLM Parameters You can also configure additional parameters for the LLMs in the config.yaml file: Configuration Option Description Type Default Value MAX_TOKENS The maximum token limit for the response completion Integer 2000 MAX_RETRY The maximum retry limit for the response completion Integer 3 TEMPERATURE The temperature of the model: the lower the value, the more consistent the output of the model Float 0.0 TOP_P The top_p of the model: the lower the value, the more conservative the output of the model Float 0.0 TIMEOUT The call timeout in seconds Integer 60 For RAG Configuration to Enhance the UFO Agent You can configure the RAG parameters in the config.yaml file to enhance the UFO agent with additional knowledge sources: RAG Configuration for the Offline Docs Configure the following parameters to allow UFO to use offline documents for the decision-making process: Configuration Option Description Type Default Value RAG_OFFLINE_DOCS Whether to use the offline RAG Boolean False RAG_OFFLINE_DOCS_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 1 RAG Configuration for the Bing search Configure the following parameters to allow UFO to use online Bing search for the decision-making process: Configuration Option Description Type Default Value RAG_ONLINE_SEARCH Whether to use the Bing search Boolean False BING_API_KEY The Bing search API key String \"\" RAG_ONLINE_SEARCH_TOPK The topk for the online search Integer 5 RAG_ONLINE_RETRIEVED_TOPK The topk for the online retrieved searched results Integer 1 RAG Configuration for experience Configure the following parameters to allow UFO to use the RAG from its self-experience: Configuration Option Description Type Default Value RAG_EXPERIENCE Whether to use the RAG from its self-experience Boolean False RAG_EXPERIENCE_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 5 RAG Configuration for demonstration Configure the following parameters to allow UFO to use the RAG from user demonstration: Configuration Option Description Type Default Value RAG_DEMONSTRATION Whether to use the RAG from its user demonstration Boolean False RAG_DEMONSTRATION_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 5 RAG_DEMONSTRATION_COMPLETION_N The number of completion choices for the demonstration result Integer 3 Explore the various RAG configurations to enhance the UFO agent with additional knowledge sources and improve its decision-making capabilities.","title":"User Configuration"},{"location":"configurations/user_configuration/#user-configuration","text":"An overview of the user configuration options available in UFO. You need to rename the config.yaml.template in the folder ufo/config to config.yaml to configure the LLMs and other custom settings.","title":"User Configuration"},{"location":"configurations/user_configuration/#llm-configuration","text":"You can configure the LLMs for the HOST_AGENT and APP_AGENT separately in the config.yaml file. The FollowerAgent and EvaluationAgent share the same LLM configuration as the APP_AGENT . Additionally, you can configure a backup LLM engine in the BACKUP_AGENT field to handle cases where the primary engines fail during inference. Below are the configuration options for the LLMs, using OpenAI and Azure OpenAI (AOAI) as examples. You can find the settings for other LLM API configurations and usage in the Supported Models section of the documentation. Configuration Option Description Type Default Value VISUAL_MODE Whether to use visual mode to understand screenshots and take actions Boolean True API_TYPE The API type: \"openai\" for the OpenAI API, \"aoai\" for the AOAI API. String \"openai\" API_BASE The API endpoint for the LLM String \"https://api.openai.com/v1/chat/completions\" API_KEY The API key for the LLM String \"sk-\" API_VERSION The version of the API String \"2024-02-15-preview\" API_MODEL The LLM model name String \"gpt-4-vision-preview\"","title":"LLM Configuration"},{"location":"configurations/user_configuration/#for-azure-openai-aoai-api","text":"The following additional configuration option is available for the AOAI API: Configuration Option Description Type Default Value API_DEPLOYMENT_ID The deployment ID, only available for the AOAI API String \"\" Ensure to fill in the necessary API details for both the HOST_AGENT and APP_AGENT to enable UFO to interact with the LLMs effectively.","title":"For Azure OpenAI (AOAI) API"},{"location":"configurations/user_configuration/#llm-parameters","text":"You can also configure additional parameters for the LLMs in the config.yaml file: Configuration Option Description Type Default Value MAX_TOKENS The maximum token limit for the response completion Integer 2000 MAX_RETRY The maximum retry limit for the response completion Integer 3 TEMPERATURE The temperature of the model: the lower the value, the more consistent the output of the model Float 0.0 TOP_P The top_p of the model: the lower the value, the more conservative the output of the model Float 0.0 TIMEOUT The call timeout in seconds Integer 60","title":"LLM Parameters"},{"location":"configurations/user_configuration/#for-rag-configuration-to-enhance-the-ufo-agent","text":"You can configure the RAG parameters in the config.yaml file to enhance the UFO agent with additional knowledge sources:","title":"For RAG Configuration to Enhance the UFO Agent"},{"location":"configurations/user_configuration/#rag-configuration-for-the-offline-docs","text":"Configure the following parameters to allow UFO to use offline documents for the decision-making process: Configuration Option Description Type Default Value RAG_OFFLINE_DOCS Whether to use the offline RAG Boolean False RAG_OFFLINE_DOCS_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 1","title":"RAG Configuration for the Offline Docs"},{"location":"configurations/user_configuration/#rag-configuration-for-the-bing-search","text":"Configure the following parameters to allow UFO to use online Bing search for the decision-making process: Configuration Option Description Type Default Value RAG_ONLINE_SEARCH Whether to use the Bing search Boolean False BING_API_KEY The Bing search API key String \"\" RAG_ONLINE_SEARCH_TOPK The topk for the online search Integer 5 RAG_ONLINE_RETRIEVED_TOPK The topk for the online retrieved searched results Integer 1","title":"RAG Configuration for the Bing search"},{"location":"configurations/user_configuration/#rag-configuration-for-experience","text":"Configure the following parameters to allow UFO to use the RAG from its self-experience: Configuration Option Description Type Default Value RAG_EXPERIENCE Whether to use the RAG from its self-experience Boolean False RAG_EXPERIENCE_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 5","title":"RAG Configuration for experience"},{"location":"configurations/user_configuration/#rag-configuration-for-demonstration","text":"Configure the following parameters to allow UFO to use the RAG from user demonstration: Configuration Option Description Type Default Value RAG_DEMONSTRATION Whether to use the RAG from its user demonstration Boolean False RAG_DEMONSTRATION_RETRIEVED_TOPK The topk for the offline retrieved documents Integer 5 RAG_DEMONSTRATION_COMPLETION_N The number of completion choices for the demonstration result Integer 3 Explore the various RAG configurations to enhance the UFO agent with additional knowledge sources and improve its decision-making capabilities.","title":"RAG Configuration for demonstration"},{"location":"creating_app_agent/demonstration_provision/","text":"Provide Human Demonstrations to the AppAgent Users or application developers can provide human demonstrations to the AppAgent to guide it in executing similar tasks in the future. The AppAgent uses these demonstrations to understand the context of the task and the steps required to execute it, effectively becoming an expert in the application. How to Prepare Human Demonstrations for the AppAgent? Currently, UFO supports learning from user trajectories recorded by Steps Recorder integrated within Windows. More tools will be supported in the future. Step 1: Recording User Demonstrations Follow the official guidance to use Steps Recorder to record user demonstrations. Step 2: Add Additional Information or Comments as Needed Include any specific details or instructions for UFO to notice by adding comments. Since Steps Recorder doesn't capture typed text, include any necessary typed content in the comments as well. Step 3: Review and Save the Recorded Demonstrations Review the recorded steps and save them to a ZIP file. Refer to the sample_record.zip for an example of recorded steps for a specific request, such as \"sending an email to example@gmail.com to say hi.\" Step 4: Create an Action Trajectory Indexer Once you have your demonstration record ZIP file ready, you can parse it as an example to support RAG for UFO. Follow these steps: # Assume you are in the cloned UFO folder python -m record_processor -r \"<your request for the demonstration>\" -p \"<record ZIP file path>\" Replace <your request for the demonstration> with the specific request, such as \"sending an email to example@gmail.com to say hi.\" Replace <record ZIP file path> with the full path to the ZIP file you just created. This command will parse the record and summarize it into an execution plan. You'll see a confirmation message similar to the following: Here are the plans summarized from your demonstration: Plan [1] (1) Input the email address 'example@gmail.com' in the 'To' field. (2) Input the subject of the email. I need to input 'Greetings'. (3) Input the content of the email. I need to input 'Hello,\\nI hope this message finds you well. I am writing to send you a warm greeting and to wish you a great day.\\nBest regards.' (4) Click the Send button to send the email. Plan [2] (1) *** (2) *** (3) *** Plan [3] (1) *** (2) *** (3) *** Would you like to save any one of them as a future reference for the agent? Press [1] [2] [3] to save the corresponding plan, or press any other key to skip. Press 1 to save the plan into its memory for future reference. A sample can be found here . You can view a demonstration video below: How to Use Human Demonstrations to Enhance the AppAgent? After creating the offline indexer, refer to the Learning from User Demonstrations section for guidance on how to use human demonstrations to enhance the AppAgent.","title":"Demonstration Provision"},{"location":"creating_app_agent/demonstration_provision/#provide-human-demonstrations-to-the-appagent","text":"Users or application developers can provide human demonstrations to the AppAgent to guide it in executing similar tasks in the future. The AppAgent uses these demonstrations to understand the context of the task and the steps required to execute it, effectively becoming an expert in the application.","title":"Provide Human Demonstrations to the AppAgent"},{"location":"creating_app_agent/demonstration_provision/#how-to-prepare-human-demonstrations-for-the-appagent","text":"Currently, UFO supports learning from user trajectories recorded by Steps Recorder integrated within Windows. More tools will be supported in the future.","title":"How to Prepare Human Demonstrations for the AppAgent?"},{"location":"creating_app_agent/demonstration_provision/#step-1-recording-user-demonstrations","text":"Follow the official guidance to use Steps Recorder to record user demonstrations.","title":"Step 1: Recording User Demonstrations"},{"location":"creating_app_agent/demonstration_provision/#step-2-add-additional-information-or-comments-as-needed","text":"Include any specific details or instructions for UFO to notice by adding comments. Since Steps Recorder doesn't capture typed text, include any necessary typed content in the comments as well.","title":"Step 2: Add Additional Information or Comments as Needed"},{"location":"creating_app_agent/demonstration_provision/#step-3-review-and-save-the-recorded-demonstrations","text":"Review the recorded steps and save them to a ZIP file. Refer to the sample_record.zip for an example of recorded steps for a specific request, such as \"sending an email to example@gmail.com to say hi.\"","title":"Step 3: Review and Save the Recorded Demonstrations"},{"location":"creating_app_agent/demonstration_provision/#step-4-create-an-action-trajectory-indexer","text":"Once you have your demonstration record ZIP file ready, you can parse it as an example to support RAG for UFO. Follow these steps: # Assume you are in the cloned UFO folder python -m record_processor -r \"<your request for the demonstration>\" -p \"<record ZIP file path>\" Replace <your request for the demonstration> with the specific request, such as \"sending an email to example@gmail.com to say hi.\" Replace <record ZIP file path> with the full path to the ZIP file you just created. This command will parse the record and summarize it into an execution plan. You'll see a confirmation message similar to the following: Here are the plans summarized from your demonstration: Plan [1] (1) Input the email address 'example@gmail.com' in the 'To' field. (2) Input the subject of the email. I need to input 'Greetings'. (3) Input the content of the email. I need to input 'Hello,\\nI hope this message finds you well. I am writing to send you a warm greeting and to wish you a great day.\\nBest regards.' (4) Click the Send button to send the email. Plan [2] (1) *** (2) *** (3) *** Plan [3] (1) *** (2) *** (3) *** Would you like to save any one of them as a future reference for the agent? Press [1] [2] [3] to save the corresponding plan, or press any other key to skip. Press 1 to save the plan into its memory for future reference. A sample can be found here . You can view a demonstration video below:","title":"Step 4: Create an Action Trajectory Indexer"},{"location":"creating_app_agent/demonstration_provision/#how-to-use-human-demonstrations-to-enhance-the-appagent","text":"After creating the offline indexer, refer to the Learning from User Demonstrations section for guidance on how to use human demonstrations to enhance the AppAgent.","title":"How to Use Human Demonstrations to Enhance the AppAgent?"},{"location":"creating_app_agent/help_document_provision/","text":"Providing Help Documents to the AppAgent Help documents provide guidance to the AppAgent in executing specific tasks. The AppAgent uses these documents to understand the context of the task and the steps required to execute it, effectively becoming an expert in the application. How to Provide Help Documents to the AppAgent? Step 1: Prepare Help Documents and Metadata UFO currently supports processing help documents in json format. More formats will be supported in the future. An example of a help document in json format is as follows: { \"application\": \"chrome\", \"request\": \"How to change the username in chrome profiles?\", \"guidance\": [ \"Click the profile icon in the upper-right corner of the Chrome window.\", \"Click the gear icon labeled 'Manage Chrome Profiles' in the profile menu.\", \"In the list of profiles, locate the profile whose name you want to change.\", \"Hover over the desired profile and click the three-dot menu icon on that profile card.\", \"Select 'Edit' from the dropdown menu.\", \"In the Edit Profile dialog, click inside the name field.\", \"Delete the current name and type your new desired username.\", \"Click 'Save' to confirm the changes.\", \"Verify that the profile name is updated in the profile list and in the top-right corner of Chrome.\" ] } Save each help document in a json file of your target folder. Step 2: Place Help Documents in the AppAgent Directory Once you have prepared all help documents and their metadata, place them into a folder. Sub-folders for the help documents are allowed, but ensure that each help document and its corresponding metadata are placed in the same directory. Step 3: Create a Help Document Indexer After organizing your documents in a folder named path_of_the_docs , you can create an offline indexer to support RAG for UFO. Follow these steps: # Assume you are in the cloned UFO folder python -m learner --app <app_name> --docs <path_of_the_docs> Replace <app_name> with the Exact Process Name of the application, such as WINWORD.EXE for Microsoft Word or POWERPNT.EXE for PowerPoint. Replace <path_of_the_docs> with the full path to the folder containing all your documents. This command will create an offline indexer for all documents in the path_of_the_docs folder using Faiss and embedding with sentence transformer (additional embeddings will be supported soon). By default, the created index will be placed here . Note Ensure the app_name is accurately defined, as it is used to match the offline indexer in online RAG. How to Use Help Documents to Enhance the AppAgent? After creating the offline indexer, you can find the guidance on how to use the help documents to enhance the AppAgent in the Learning from Help Documents section.","title":"Help Document Provision"},{"location":"creating_app_agent/help_document_provision/#providing-help-documents-to-the-appagent","text":"Help documents provide guidance to the AppAgent in executing specific tasks. The AppAgent uses these documents to understand the context of the task and the steps required to execute it, effectively becoming an expert in the application.","title":"Providing Help Documents to the AppAgent"},{"location":"creating_app_agent/help_document_provision/#how-to-provide-help-documents-to-the-appagent","text":"","title":"How to Provide Help Documents to the AppAgent?"},{"location":"creating_app_agent/help_document_provision/#step-1-prepare-help-documents-and-metadata","text":"UFO currently supports processing help documents in json format. More formats will be supported in the future. An example of a help document in json format is as follows: { \"application\": \"chrome\", \"request\": \"How to change the username in chrome profiles?\", \"guidance\": [ \"Click the profile icon in the upper-right corner of the Chrome window.\", \"Click the gear icon labeled 'Manage Chrome Profiles' in the profile menu.\", \"In the list of profiles, locate the profile whose name you want to change.\", \"Hover over the desired profile and click the three-dot menu icon on that profile card.\", \"Select 'Edit' from the dropdown menu.\", \"In the Edit Profile dialog, click inside the name field.\", \"Delete the current name and type your new desired username.\", \"Click 'Save' to confirm the changes.\", \"Verify that the profile name is updated in the profile list and in the top-right corner of Chrome.\" ] } Save each help document in a json file of your target folder.","title":"Step 1: Prepare Help Documents and Metadata"},{"location":"creating_app_agent/help_document_provision/#step-2-place-help-documents-in-the-appagent-directory","text":"Once you have prepared all help documents and their metadata, place them into a folder. Sub-folders for the help documents are allowed, but ensure that each help document and its corresponding metadata are placed in the same directory.","title":"Step 2: Place Help Documents in the AppAgent Directory"},{"location":"creating_app_agent/help_document_provision/#step-3-create-a-help-document-indexer","text":"After organizing your documents in a folder named path_of_the_docs , you can create an offline indexer to support RAG for UFO. Follow these steps: # Assume you are in the cloned UFO folder python -m learner --app <app_name> --docs <path_of_the_docs> Replace <app_name> with the Exact Process Name of the application, such as WINWORD.EXE for Microsoft Word or POWERPNT.EXE for PowerPoint. Replace <path_of_the_docs> with the full path to the folder containing all your documents. This command will create an offline indexer for all documents in the path_of_the_docs folder using Faiss and embedding with sentence transformer (additional embeddings will be supported soon). By default, the created index will be placed here . Note Ensure the app_name is accurately defined, as it is used to match the offline indexer in online RAG.","title":"Step 3: Create a Help Document Indexer"},{"location":"creating_app_agent/help_document_provision/#how-to-use-help-documents-to-enhance-the-appagent","text":"After creating the offline indexer, you can find the guidance on how to use the help documents to enhance the AppAgent in the Learning from Help Documents section.","title":"How to Use Help Documents to Enhance the AppAgent?"},{"location":"creating_app_agent/overview/","text":"Creating Your AppAgent UFO provides a flexible framework and SDK for application developers to empower their applications with AI capabilities by wrapping them into an AppAgent . By creating an AppAgent , you can leverage the power of UFO to interact with your application and automate tasks. To create an AppAgent , you can provide the following components: Component Description Usage Documentation Help Documents The help documents for the application to guide the AppAgent in executing tasks. Learning from Help Documents User Demonstrations The user demonstrations for the application to guide the AppAgent in executing tasks. Learning from User Demonstrations Native API Wrappers The native API wrappers for the application to interact with the application. Automator","title":"Overview"},{"location":"creating_app_agent/overview/#creating-your-appagent","text":"UFO provides a flexible framework and SDK for application developers to empower their applications with AI capabilities by wrapping them into an AppAgent . By creating an AppAgent , you can leverage the power of UFO to interact with your application and automate tasks. To create an AppAgent , you can provide the following components: Component Description Usage Documentation Help Documents The help documents for the application to guide the AppAgent in executing tasks. Learning from Help Documents User Demonstrations The user demonstrations for the application to guide the AppAgent in executing tasks. Learning from User Demonstrations Native API Wrappers The native API wrappers for the application to interact with the application. Automator","title":"Creating Your AppAgent"},{"location":"creating_app_agent/warpping_app_native_api/","text":"Wrapping Your App's Native API UFO takes actions on applications based on UI controls, but providing native API to its toolboxes can enhance the efficiency and accuracy of the actions. This document provides guidance on how to wrap your application's native API into UFO's toolboxes. How to Wrap Your App's Native API? Before developing the native API wrappers, we strongly recommend that you read the design of the Automator . Step 1: Create a Receiver for the Native API The Receiver is a class that receives the native API calls from the AppAgent and executes them. To wrap your application's native API, you need to create a Receiver class that contains the methods to execute the native API calls. To create a Receiver class, follow these steps: 1. Create a Folder for Your Application Navigate to the ufo/automator/app_api/ directory. Create a folder named after your application. 2. Create a Python File Inside the folder you just created, add a Python file named after your application, for example, {your_application}_client.py . 3. Define the Receiver Class In the Python file, define a class named {Your_Receiver} , inheriting from the ReceiverBasic class located in ufo/automator/basic.py . Initialize the Your_Receiver class with the object that executes the native API calls. For example, if your API is based on a com object, initialize the com object in the __init__ method of the Your_Receiver class. Example of WinCOMReceiverBasic class: class WinCOMReceiverBasic(ReceiverBasic): \"\"\" The base class for Windows COM client. \"\"\" _command_registry: Dict[str, Type[CommandBasic]] = {} def __init__(self, app_root_name: str, process_name: str, clsid: str) -> None: \"\"\" Initialize the Windows COM client. :param app_root_name: The app root name. :param process_name: The process name. :param clsid: The CLSID of the COM object. \"\"\" self.app_root_name = app_root_name self.process_name = process_name self.clsid = clsid self.client = win32com.client.Dispatch(self.clsid) self.com_object = self.get_object_from_process_name() 4. Define Methods to Execute Native API Calls Define the methods in the Your_Receiver class to execute the native API calls. Example of ExcelWinCOMReceiver class: def table2markdown(self, sheet_name: str) -> str: \"\"\" Convert the table in the sheet to a markdown table string. :param sheet_name: The sheet name. :return: The markdown table string. \"\"\" sheet = self.com_object.Sheets(sheet_name) data = sheet.UsedRange() df = pd.DataFrame(data[1:], columns=data[0]) df = df.dropna(axis=0, how=\"all\") df = df.applymap(self.format_value) return df.to_markdown(index=False) 5. Create a Factory Class Create your Factory class inheriting from the APIReceiverFactory class to manage multiple Receiver classes that share the same API type. Implement the create_receiver and name methods in the ReceiverFactory class. The create_receiver method should return the Receiver class. By default, the create_receiver takes the app_root_name and process_name as parameters and returns the Receiver class. Register the ReceiverFactory class with the decorator @ReceiverManager.register . Example of the COMReceiverFactory class: from ufo.automator.puppeteer import ReceiverManager @ReceiverManager.register class COMReceiverFactory(APIReceiverFactory): \"\"\" The factory class for the COM receiver. \"\"\" def create_receiver(self, app_root_name: str, process_name: str) -> WinCOMReceiverBasic: \"\"\" Create the wincom receiver. :param app_root_name: The app root name. :param process_name: The process name. :return: The receiver. \"\"\" com_receiver = self.__com_client_mapper(app_root_name) clsid = self.__app_root_mappping(app_root_name) if clsid is None or com_receiver is None: # print_with_color(f\"Warning: Win32COM API is not supported for {process_name}.\", \"yellow\") return None return com_receiver(app_root_name, process_name, clsid) @classmethod def name(cls) -> str: \"\"\" Get the name of the receiver factory. :return: The name of the receiver factory. \"\"\" return \"COM\" Note The create_receiver method should return None if the application is not supported. Note You must register your ReceiverFactory with the decorator @ReceiverManager.register for the ReceiverManager to manage the ReceiverFactory . The Receiver class is now ready to receive the native API calls from the AppAgent . Step 2: Create a Command for the Native API Commands are the actions that the AppAgent can execute on the application. To create a command for the native API, you need to create a Command class that contains the method to execute the native API calls. 1. Create a Command Class Create a Command class in the same Python file where the Receiver class is located. The Command class should inherit from the CommandBasic class located in ufo/automator/basic.py . Example: class WinCOMCommand(CommandBasic): \"\"\" The abstract command interface. \"\"\" def __init__(self, receiver: WinCOMReceiverBasic, params=None) -> None: \"\"\" Initialize the command. :param receiver: The receiver of the command. \"\"\" self.receiver = receiver self.params = params if params is not None else {} @abstractmethod def execute(self): pass @classmethod def name(cls) -> str: \"\"\" Get the name of the command. :return: The name of the command. \"\"\" return cls.__name__ 2. Define the Execute Method Define the execute method in the Command class to call the receiver to execute the native API calls. Example: def execute(self): \"\"\" Execute the command to insert a table. :return: The inserted table. \"\"\" return self.receiver.insert_excel_table( sheet_name=self.params.get(\"sheet_name\", 1), table=self.params.get(\"table\"), start_row=self.params.get(\"start_row\", 1), start_col=self.params.get(\"start_col\", 1), ) 3. Register the Command Class: Register the Command class in the corresponding Receiver class using the @your_receiver.register decorator. Example: @ExcelWinCOMReceiver.register class InsertExcelTable(WinCOMCommand): ... The Command class is now registered in the Receiver class and available for the AppAgent to execute the native API calls. Step 3: Provide Prompt Descriptions for the Native API To let the AppAgent know the usage of the native API calls, you need to provide prompt descriptions. 1. Create an api.yaml File - Create an `api.yaml` file in the `ufo/prompts/apps/{your_app_name}` directory. 2. Define Prompt Descriptions Define the prompt descriptions for the native API calls in the api.yaml file. Example: table2markdown: summary: |- \"table2markdown\" is to get the table content in a sheet of the Excel app and convert it to markdown format. class_name: |- GetSheetContent usage: |- [1] API call: table2markdown(sheet_name: str) [2] Args: - sheet_name: The name of the sheet in the Excel app. [3] Example: table2markdown(sheet_name=\"Sheet1\") [4] Available control item: Any control item in the Excel app. [5] Return: the markdown format string of the table content of the sheet. Note The table2markdown is the name of the native API call. It MUST match the name() defined in the corresponding Command class! 3. Register the Prompt Address in config_dev.yaml Register the prompt address by adding to the APP_API_PROMPT_ADDRESS field of config_dev.yaml file with the application program name as the key and the prompt file address as the value. Example: APP_API_PROMPT_ADDRESS: { \"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\" \"your_application_program_name\": \"YOUR_APPLICATION_API_PROMPT\" } Note The your_application_program_name must match the name of the application program. The AppAgent can now use the prompt descriptions to understand the usage of the native API calls. By following these steps, you will have successfully wrapped the native API of your application into UFO's toolboxes, allowing the AppAgent to execute the native API calls on the application!","title":"Warpping App-Native API"},{"location":"creating_app_agent/warpping_app_native_api/#wrapping-your-apps-native-api","text":"UFO takes actions on applications based on UI controls, but providing native API to its toolboxes can enhance the efficiency and accuracy of the actions. This document provides guidance on how to wrap your application's native API into UFO's toolboxes.","title":"Wrapping Your App's Native API"},{"location":"creating_app_agent/warpping_app_native_api/#how-to-wrap-your-apps-native-api","text":"Before developing the native API wrappers, we strongly recommend that you read the design of the Automator .","title":"How to Wrap Your App's Native API?"},{"location":"creating_app_agent/warpping_app_native_api/#step-1-create-a-receiver-for-the-native-api","text":"The Receiver is a class that receives the native API calls from the AppAgent and executes them. To wrap your application's native API, you need to create a Receiver class that contains the methods to execute the native API calls. To create a Receiver class, follow these steps:","title":"Step 1: Create a Receiver for the Native API"},{"location":"creating_app_agent/warpping_app_native_api/#1-create-a-folder-for-your-application","text":"Navigate to the ufo/automator/app_api/ directory. Create a folder named after your application.","title":"1. Create a Folder for Your Application"},{"location":"creating_app_agent/warpping_app_native_api/#2-create-a-python-file","text":"Inside the folder you just created, add a Python file named after your application, for example, {your_application}_client.py .","title":"2. Create a Python File"},{"location":"creating_app_agent/warpping_app_native_api/#3-define-the-receiver-class","text":"In the Python file, define a class named {Your_Receiver} , inheriting from the ReceiverBasic class located in ufo/automator/basic.py . Initialize the Your_Receiver class with the object that executes the native API calls. For example, if your API is based on a com object, initialize the com object in the __init__ method of the Your_Receiver class. Example of WinCOMReceiverBasic class: class WinCOMReceiverBasic(ReceiverBasic): \"\"\" The base class for Windows COM client. \"\"\" _command_registry: Dict[str, Type[CommandBasic]] = {} def __init__(self, app_root_name: str, process_name: str, clsid: str) -> None: \"\"\" Initialize the Windows COM client. :param app_root_name: The app root name. :param process_name: The process name. :param clsid: The CLSID of the COM object. \"\"\" self.app_root_name = app_root_name self.process_name = process_name self.clsid = clsid self.client = win32com.client.Dispatch(self.clsid) self.com_object = self.get_object_from_process_name()","title":"3. Define the Receiver Class"},{"location":"creating_app_agent/warpping_app_native_api/#4-define-methods-to-execute-native-api-calls","text":"Define the methods in the Your_Receiver class to execute the native API calls. Example of ExcelWinCOMReceiver class: def table2markdown(self, sheet_name: str) -> str: \"\"\" Convert the table in the sheet to a markdown table string. :param sheet_name: The sheet name. :return: The markdown table string. \"\"\" sheet = self.com_object.Sheets(sheet_name) data = sheet.UsedRange() df = pd.DataFrame(data[1:], columns=data[0]) df = df.dropna(axis=0, how=\"all\") df = df.applymap(self.format_value) return df.to_markdown(index=False)","title":"4. Define Methods to Execute Native API Calls"},{"location":"creating_app_agent/warpping_app_native_api/#5-create-a-factory-class","text":"Create your Factory class inheriting from the APIReceiverFactory class to manage multiple Receiver classes that share the same API type. Implement the create_receiver and name methods in the ReceiverFactory class. The create_receiver method should return the Receiver class. By default, the create_receiver takes the app_root_name and process_name as parameters and returns the Receiver class. Register the ReceiverFactory class with the decorator @ReceiverManager.register . Example of the COMReceiverFactory class: from ufo.automator.puppeteer import ReceiverManager @ReceiverManager.register class COMReceiverFactory(APIReceiverFactory): \"\"\" The factory class for the COM receiver. \"\"\" def create_receiver(self, app_root_name: str, process_name: str) -> WinCOMReceiverBasic: \"\"\" Create the wincom receiver. :param app_root_name: The app root name. :param process_name: The process name. :return: The receiver. \"\"\" com_receiver = self.__com_client_mapper(app_root_name) clsid = self.__app_root_mappping(app_root_name) if clsid is None or com_receiver is None: # print_with_color(f\"Warning: Win32COM API is not supported for {process_name}.\", \"yellow\") return None return com_receiver(app_root_name, process_name, clsid) @classmethod def name(cls) -> str: \"\"\" Get the name of the receiver factory. :return: The name of the receiver factory. \"\"\" return \"COM\" Note The create_receiver method should return None if the application is not supported. Note You must register your ReceiverFactory with the decorator @ReceiverManager.register for the ReceiverManager to manage the ReceiverFactory . The Receiver class is now ready to receive the native API calls from the AppAgent .","title":"5. Create a Factory Class"},{"location":"creating_app_agent/warpping_app_native_api/#step-2-create-a-command-for-the-native-api","text":"Commands are the actions that the AppAgent can execute on the application. To create a command for the native API, you need to create a Command class that contains the method to execute the native API calls.","title":"Step 2: Create a Command for the Native API"},{"location":"creating_app_agent/warpping_app_native_api/#1-create-a-command-class","text":"Create a Command class in the same Python file where the Receiver class is located. The Command class should inherit from the CommandBasic class located in ufo/automator/basic.py . Example: class WinCOMCommand(CommandBasic): \"\"\" The abstract command interface. \"\"\" def __init__(self, receiver: WinCOMReceiverBasic, params=None) -> None: \"\"\" Initialize the command. :param receiver: The receiver of the command. \"\"\" self.receiver = receiver self.params = params if params is not None else {} @abstractmethod def execute(self): pass @classmethod def name(cls) -> str: \"\"\" Get the name of the command. :return: The name of the command. \"\"\" return cls.__name__","title":"1. Create a Command Class"},{"location":"creating_app_agent/warpping_app_native_api/#2-define-the-execute-method","text":"Define the execute method in the Command class to call the receiver to execute the native API calls. Example: def execute(self): \"\"\" Execute the command to insert a table. :return: The inserted table. \"\"\" return self.receiver.insert_excel_table( sheet_name=self.params.get(\"sheet_name\", 1), table=self.params.get(\"table\"), start_row=self.params.get(\"start_row\", 1), start_col=self.params.get(\"start_col\", 1), ) 3. Register the Command Class: Register the Command class in the corresponding Receiver class using the @your_receiver.register decorator. Example: @ExcelWinCOMReceiver.register class InsertExcelTable(WinCOMCommand): ... The Command class is now registered in the Receiver class and available for the AppAgent to execute the native API calls.","title":"2. Define the Execute Method"},{"location":"creating_app_agent/warpping_app_native_api/#step-3-provide-prompt-descriptions-for-the-native-api","text":"To let the AppAgent know the usage of the native API calls, you need to provide prompt descriptions.","title":"Step 3: Provide Prompt Descriptions for the Native API"},{"location":"creating_app_agent/warpping_app_native_api/#1-create-an-apiyaml-file","text":"- Create an `api.yaml` file in the `ufo/prompts/apps/{your_app_name}` directory.","title":"1. Create an api.yaml File"},{"location":"creating_app_agent/warpping_app_native_api/#2-define-prompt-descriptions","text":"Define the prompt descriptions for the native API calls in the api.yaml file. Example: table2markdown: summary: |- \"table2markdown\" is to get the table content in a sheet of the Excel app and convert it to markdown format. class_name: |- GetSheetContent usage: |- [1] API call: table2markdown(sheet_name: str) [2] Args: - sheet_name: The name of the sheet in the Excel app. [3] Example: table2markdown(sheet_name=\"Sheet1\") [4] Available control item: Any control item in the Excel app. [5] Return: the markdown format string of the table content of the sheet. Note The table2markdown is the name of the native API call. It MUST match the name() defined in the corresponding Command class!","title":"2. Define Prompt Descriptions"},{"location":"creating_app_agent/warpping_app_native_api/#3-register-the-prompt-address-in-config_devyaml","text":"Register the prompt address by adding to the APP_API_PROMPT_ADDRESS field of config_dev.yaml file with the application program name as the key and the prompt file address as the value. Example: APP_API_PROMPT_ADDRESS: { \"WINWORD.EXE\": \"ufo/prompts/apps/word/api.yaml\", \"EXCEL.EXE\": \"ufo/prompts/apps/excel/api.yaml\", \"msedge.exe\": \"ufo/prompts/apps/web/api.yaml\", \"chrome.exe\": \"ufo/prompts/apps/web/api.yaml\" \"your_application_program_name\": \"YOUR_APPLICATION_API_PROMPT\" } Note The your_application_program_name must match the name of the application program. The AppAgent can now use the prompt descriptions to understand the usage of the native API calls. By following these steps, you will have successfully wrapped the native API of your application into UFO's toolboxes, allowing the AppAgent to execute the native API calls on the application!","title":"3. Register the Prompt Address in config_dev.yaml"},{"location":"dataflow/execution/","text":"Execution The instantiated plans will be executed by a execute task. In this phase, given the task-action data, the execution process will match the real controller based on word environment and execute the plan step by step. After execution, evalution agent will evaluation the quality of the entire execution process. ExecuteFlow The ExecuteFlow class is designed to facilitate the execution and evaluation of tasks in a Windows application environment. It provides functionality to interact with the application's UI, execute predefined tasks, capture screenshots, and evaluate the results of the execution. The class also handles logging and error management for the tasks. Task Execution The task execution in the ExecuteFlow class follows a structured sequence to ensure accurate and traceable task performance: Initialization : Load configuration settings and log paths. Find the application window matching the task. Retrieve or create an ExecuteAgent for executing the task. Plan Execution : Loop through each step in the instantiated_plan . Parse the step to extract information like subtasks, control text, and the required operation. Action Execution : Find the control in the application window that matches the specified control text. If no matching control is found, raise an error. Perform the specified action (e.g., click, input text) using the agent's Puppeteer framework. Capture screenshots of the application window and selected controls for logging and debugging. Result Logging : Log details of the step execution, including control information, performed action, and results. Finalization : Save the final state of the application window. Quit the application client gracefully. Evaluation The evaluation process in the ExecuteFlow class is designed to assess the performance of the executed task based on predefined prompts: Start Evaluation : Evaluation begins immediately after task execution. It uses an ExecuteEvalAgent initialized during class construction. Perform Evaluation : The ExecuteEvalAgent evaluates the task using a combination of input prompts (e.g., main prompt and API prompt) and logs generated during task execution. The evaluation process outputs a result summary (e.g., quality flag, comments, and task type). Log and Output Results : Display the evaluation results in the console. Return the evaluation summary alongside the executed plan for further analysis or reporting. Reference ExecuteFlow Bases: AppAgentProcessor ExecuteFlow class for executing the task and saving the result. Initialize the execute flow for a task. Parameters: task_file_name ( str ) \u2013 Name of the task file being processed. context ( Context ) \u2013 Context object for the current session. environment ( WindowsAppEnv ) \u2013 Environment object for the application being processed. Source code in execution/workflow/execute_flow.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , task_file_name : str , context : Context , environment : WindowsAppEnv ) -> None : \"\"\" Initialize the execute flow for a task. :param task_file_name: Name of the task file being processed. :param context: Context object for the current session. :param environment: Environment object for the application being processed. \"\"\" super () . __init__ ( agent = ExecuteAgent , context = context ) self . execution_time = None self . eval_time = None self . _app_env = environment self . _task_file_name = task_file_name self . _app_name = self . _app_env . app_name log_path = _configs [ \"EXECUTE_LOG_PATH\" ] . format ( task = task_file_name ) self . _initialize_logs ( log_path ) self . application_window = self . _app_env . find_matching_window ( task_file_name ) self . app_agent = self . _get_or_create_execute_agent () self . eval_agent = self . _get_or_create_evaluation_agent () self . _matched_control = None # Matched control for the current step. execute ( request , instantiated_plan ) Execute the execute flow: Execute the task and save the result. Parameters: request ( str ) \u2013 Original request to be executed. instantiated_plan ( List [ Dict [ str , Any ]] ) \u2013 Instantiated plan containing steps to execute. Returns: Tuple [ List [ Dict [ str , Any ]], Dict [ str , str ]] \u2013 Tuple containing task quality flag, comment, and task type. Source code in execution/workflow/execute_flow.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def execute ( self , request : str , instantiated_plan : List [ Dict [ str , Any ]] ) -> Tuple [ List [ Dict [ str , Any ]], Dict [ str , str ]]: \"\"\" Execute the execute flow: Execute the task and save the result. :param request: Original request to be executed. :param instantiated_plan: Instantiated plan containing steps to execute. :return: Tuple containing task quality flag, comment, and task type. \"\"\" start_time = time . time () try : executed_plan = self . execute_plan ( instantiated_plan ) except Exception as error : raise RuntimeError ( f \"Execution failed. { error } \" ) finally : self . execution_time = round ( time . time () - start_time , 3 ) start_time = time . time () try : result , _ = self . eval_agent . evaluate ( request = request , log_path = self . log_path ) utils . print_with_color ( f \"Result: { result } \" , \"green\" ) except Exception as error : raise RuntimeError ( f \"Evaluation failed. { error } \" ) finally : self . eval_time = round ( time . time () - start_time , 3 ) return executed_plan , result execute_action () Execute the action. Source code in execution/workflow/execute_flow.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 def execute_action ( self ) -> None : \"\"\" Execute the action. \"\"\" control_selected = None # Find the matching window and control. self . application_window = self . _app_env . find_matching_window ( self . _task_file_name ) if self . control_text == \"\" : control_selected = self . application_window else : self . _control_label , control_selected = ( self . _app_env . find_matching_controller ( self . filtered_annotation_dict , self . control_text ) ) if control_selected : self . _matched_control = control_selected . window_text () if not control_selected : # If the control is not found, raise an error. raise RuntimeError ( f \"Control with text ' { self . control_text } ' not found.\" ) try : # Get the selected control item from the annotation dictionary and LLM response. # The LLM response is a number index corresponding to the key in the annotation dictionary. if control_selected : if _ufo_configs . get ( \"SHOW_VISUAL_OUTLINE_ON_SCREEN\" , True ): control_selected . draw_outline ( colour = \"red\" , thickness = 3 ) time . sleep ( _ufo_configs . get ( \"RECTANGLE_TIME\" , 0 )) control_coordinates = PhotographerDecorator . coordinate_adjusted ( self . application_window . rectangle (), control_selected . rectangle () ) self . _control_log = { \"control_class\" : control_selected . element_info . class_name , \"control_type\" : control_selected . element_info . control_type , \"control_automation_id\" : control_selected . element_info . automation_id , \"control_friendly_class_name\" : control_selected . friendly_class_name (), \"control_coordinates\" : { \"left\" : control_coordinates [ 0 ], \"top\" : control_coordinates [ 1 ], \"right\" : control_coordinates [ 2 ], \"bottom\" : control_coordinates [ 3 ], }, } self . app_agent . Puppeteer . receiver_manager . create_ui_control_receiver ( control_selected , self . application_window ) # Save the screenshot of the tagged selected control. self . capture_control_screenshot ( control_selected ) self . _results = self . app_agent . Puppeteer . execute_command ( self . _operation , self . _args ) self . control_reannotate = None if not utils . is_json_serializable ( self . _results ): self . _results = \"\" return except Exception : self . general_error_handler () execute_plan ( instantiated_plan ) Get the executed result from the execute agent. Parameters: instantiated_plan ( List [ Dict [ str , Any ]] ) \u2013 Plan containing steps to execute. Returns: List [ Dict [ str , Any ]] \u2013 List of executed steps. Source code in execution/workflow/execute_flow.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def execute_plan ( self , instantiated_plan : List [ Dict [ str , Any ]] ) -> List [ Dict [ str , Any ]]: \"\"\" Get the executed result from the execute agent. :param instantiated_plan: Plan containing steps to execute. :return: List of executed steps. \"\"\" # Initialize the step counter and capture the initial screenshot. self . session_step = 0 try : time . sleep ( 1 ) # Initialize the API receiver self . app_agent . Puppeteer . receiver_manager . create_api_receiver ( self . app_agent . _app_root_name , self . app_agent . _process_name ) # Initialize the control receiver current_receiver = self . app_agent . Puppeteer . receiver_manager . receiver_list [ - 1 ] if current_receiver is not None : self . application_window = self . _app_env . find_matching_window ( self . _task_file_name ) current_receiver . com_object = ( current_receiver . get_object_from_process_name () ) self . init_and_final_capture_screenshot () except Exception as error : raise RuntimeError ( f \"Execution initialization failed. { error } \" ) # Initialize the success flag for each step. for index , step_plan in enumerate ( instantiated_plan ): instantiated_plan [ index ][ \"Success\" ] = None instantiated_plan [ index ][ \"MatchedControlText\" ] = None for index , step_plan in enumerate ( instantiated_plan ): try : self . session_step += 1 # Check if the maximum steps have been exceeded. if self . session_step > _configs [ \"MAX_STEPS\" ]: raise RuntimeError ( \"Maximum steps exceeded.\" ) self . _parse_step_plan ( step_plan ) try : self . process () instantiated_plan [ index ][ \"Success\" ] = True instantiated_plan [ index ][ \"ControlLabel\" ] = self . _control_label instantiated_plan [ index ][ \"MatchedControlText\" ] = self . _matched_control except Exception as ControllerNotFoundError : instantiated_plan [ index ][ \"Success\" ] = False raise ControllerNotFoundError except Exception as error : err_info = RuntimeError ( f \"Step { self . session_step } execution failed. { error } \" ) raise err_info # capture the final screenshot self . session_step += 1 time . sleep ( 1 ) self . init_and_final_capture_screenshot () # save the final state of the app win_com_receiver = None for receiver in reversed ( self . app_agent . Puppeteer . receiver_manager . receiver_list ): if isinstance ( receiver , WinCOMReceiverBasic ): if receiver . client is not None : win_com_receiver = receiver break if win_com_receiver is not None : win_com_receiver . save () time . sleep ( 1 ) win_com_receiver . client . Quit () print ( \"Execution complete.\" ) return instantiated_plan general_error_handler () Handle general errors. Source code in execution/workflow/execute_flow.py 374 375 376 377 378 379 def general_error_handler ( self ) -> None : \"\"\" Handle general errors. \"\"\" pass init_and_final_capture_screenshot () Capture the screenshot. Source code in execution/workflow/execute_flow.py 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 def init_and_final_capture_screenshot ( self ) -> None : \"\"\" Capture the screenshot. \"\"\" # Define the paths for the screenshots saved. screenshot_save_path = self . log_path + f \"action_step { self . session_step } .png\" self . _memory_data . add_values_from_dict ( { \"CleanScreenshot\" : screenshot_save_path , } ) self . photographer . capture_app_window_screenshot ( self . application_window , save_path = screenshot_save_path ) # Capture the control screenshot. control_selected = self . _app_env . app_window self . capture_control_screenshot ( control_selected ) log_save () Log the constructed prompt message for the PrefillAgent. Source code in execution/workflow/execute_flow.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 def log_save ( self ) -> None : \"\"\" Log the constructed prompt message for the PrefillAgent. \"\"\" step_memory = { \"Step\" : self . session_step , \"Subtask\" : self . subtask , \"ControlLabel\" : self . _control_label , \"ControlText\" : self . control_text , \"Action\" : self . action , \"ActionType\" : self . app_agent . Puppeteer . get_command_types ( self . _operation ), \"Results\" : self . _results , \"Application\" : self . app_agent . _app_root_name , \"TimeCost\" : self . time_cost , } self . _memory_data . add_values_from_dict ( step_memory ) self . log ( self . _memory_data . to_dict ()) print_step_info () Print the step information. Source code in execution/workflow/execute_flow.py 231 232 233 234 235 236 237 238 239 240 241 242 def print_step_info ( self ) -> None : \"\"\" Print the step information. \"\"\" utils . print_with_color ( \"Step {step} : {subtask} \" . format ( step = self . session_step , subtask = self . subtask , ), \"magenta\" , ) process () Process the current step. Source code in execution/workflow/execute_flow.py 219 220 221 222 223 224 225 226 227 228 229 def process ( self ) -> None : \"\"\" Process the current step. \"\"\" step_start_time = time . time () self . print_step_info () self . capture_screenshot () self . execute_action () self . time_cost = round ( time . time () - step_start_time , 3 ) self . log_save () ExecuteAgent Bases: AppAgent The Agent for task execution. Initialize the ExecuteAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The name of the process. app_root_name ( str ) \u2013 The name of the app root. Source code in execution/agent/execute_agent.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , name : str , process_name : str , app_root_name : str , ): \"\"\" Initialize the ExecuteAgent. :param name: The name of the agent. :param process_name: The name of the process. :param app_root_name: The name of the app root. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = None self . _process_name = process_name self . _app_root_name = app_root_name self . Puppeteer = self . create_puppeteer_interface () ExecuteEvalAgent Bases: EvaluationAgent The Agent for task execution evaluation. Initialize the ExecuteEvalAgent. Parameters: name ( str ) \u2013 The name of the agent. app_root_name ( str ) \u2013 The name of the app root. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Source code in execution/agent/execute_eval_agent.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the ExecuteEvalAgent. :param name: The name of the agent. :param app_root_name: The name of the app root. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. \"\"\" super () . __init__ ( name = name , app_root_name = app_root_name , is_visual = is_visual , main_prompt = main_prompt , example_prompt = example_prompt , api_prompt = api_prompt , ) get_prompter ( is_visual , prompt_template , example_prompt_template , api_prompt_template , root_name = None ) Get the prompter for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. prompt_template ( str ) \u2013 The prompt template. example_prompt_template ( str ) \u2013 The example prompt template. api_prompt_template ( str ) \u2013 The API prompt template. root_name ( Optional [ str ] , default: None ) \u2013 The name of the root. Returns: ExecuteEvalAgentPrompter \u2013 The prompter. Source code in execution/agent/execute_eval_agent.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_prompter ( self , is_visual : bool , prompt_template : str , example_prompt_template : str , api_prompt_template : str , root_name : Optional [ str ] = None , ) -> ExecuteEvalAgentPrompter : \"\"\" Get the prompter for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param prompt_template: The prompt template. :param example_prompt_template: The example prompt template. :param api_prompt_template: The API prompt template. :param root_name: The name of the root. :return: The prompter. \"\"\" return ExecuteEvalAgentPrompter ( is_visual = is_visual , prompt_template = prompt_template , example_prompt_template = example_prompt_template , api_prompt_template = api_prompt_template , root_name = root_name , )","title":"Execution"},{"location":"dataflow/execution/#execution","text":"The instantiated plans will be executed by a execute task. In this phase, given the task-action data, the execution process will match the real controller based on word environment and execute the plan step by step. After execution, evalution agent will evaluation the quality of the entire execution process.","title":"Execution"},{"location":"dataflow/execution/#executeflow","text":"The ExecuteFlow class is designed to facilitate the execution and evaluation of tasks in a Windows application environment. It provides functionality to interact with the application's UI, execute predefined tasks, capture screenshots, and evaluate the results of the execution. The class also handles logging and error management for the tasks.","title":"ExecuteFlow"},{"location":"dataflow/execution/#task-execution","text":"The task execution in the ExecuteFlow class follows a structured sequence to ensure accurate and traceable task performance: Initialization : Load configuration settings and log paths. Find the application window matching the task. Retrieve or create an ExecuteAgent for executing the task. Plan Execution : Loop through each step in the instantiated_plan . Parse the step to extract information like subtasks, control text, and the required operation. Action Execution : Find the control in the application window that matches the specified control text. If no matching control is found, raise an error. Perform the specified action (e.g., click, input text) using the agent's Puppeteer framework. Capture screenshots of the application window and selected controls for logging and debugging. Result Logging : Log details of the step execution, including control information, performed action, and results. Finalization : Save the final state of the application window. Quit the application client gracefully.","title":"Task Execution"},{"location":"dataflow/execution/#evaluation","text":"The evaluation process in the ExecuteFlow class is designed to assess the performance of the executed task based on predefined prompts: Start Evaluation : Evaluation begins immediately after task execution. It uses an ExecuteEvalAgent initialized during class construction. Perform Evaluation : The ExecuteEvalAgent evaluates the task using a combination of input prompts (e.g., main prompt and API prompt) and logs generated during task execution. The evaluation process outputs a result summary (e.g., quality flag, comments, and task type). Log and Output Results : Display the evaluation results in the console. Return the evaluation summary alongside the executed plan for further analysis or reporting.","title":"Evaluation"},{"location":"dataflow/execution/#reference","text":"","title":"Reference"},{"location":"dataflow/execution/#executeflow_1","text":"Bases: AppAgentProcessor ExecuteFlow class for executing the task and saving the result. Initialize the execute flow for a task. Parameters: task_file_name ( str ) \u2013 Name of the task file being processed. context ( Context ) \u2013 Context object for the current session. environment ( WindowsAppEnv ) \u2013 Environment object for the application being processed. Source code in execution/workflow/execute_flow.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , task_file_name : str , context : Context , environment : WindowsAppEnv ) -> None : \"\"\" Initialize the execute flow for a task. :param task_file_name: Name of the task file being processed. :param context: Context object for the current session. :param environment: Environment object for the application being processed. \"\"\" super () . __init__ ( agent = ExecuteAgent , context = context ) self . execution_time = None self . eval_time = None self . _app_env = environment self . _task_file_name = task_file_name self . _app_name = self . _app_env . app_name log_path = _configs [ \"EXECUTE_LOG_PATH\" ] . format ( task = task_file_name ) self . _initialize_logs ( log_path ) self . application_window = self . _app_env . find_matching_window ( task_file_name ) self . app_agent = self . _get_or_create_execute_agent () self . eval_agent = self . _get_or_create_evaluation_agent () self . _matched_control = None # Matched control for the current step.","title":"ExecuteFlow"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.execute","text":"Execute the execute flow: Execute the task and save the result. Parameters: request ( str ) \u2013 Original request to be executed. instantiated_plan ( List [ Dict [ str , Any ]] ) \u2013 Instantiated plan containing steps to execute. Returns: Tuple [ List [ Dict [ str , Any ]], Dict [ str , str ]] \u2013 Tuple containing task quality flag, comment, and task type. Source code in execution/workflow/execute_flow.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def execute ( self , request : str , instantiated_plan : List [ Dict [ str , Any ]] ) -> Tuple [ List [ Dict [ str , Any ]], Dict [ str , str ]]: \"\"\" Execute the execute flow: Execute the task and save the result. :param request: Original request to be executed. :param instantiated_plan: Instantiated plan containing steps to execute. :return: Tuple containing task quality flag, comment, and task type. \"\"\" start_time = time . time () try : executed_plan = self . execute_plan ( instantiated_plan ) except Exception as error : raise RuntimeError ( f \"Execution failed. { error } \" ) finally : self . execution_time = round ( time . time () - start_time , 3 ) start_time = time . time () try : result , _ = self . eval_agent . evaluate ( request = request , log_path = self . log_path ) utils . print_with_color ( f \"Result: { result } \" , \"green\" ) except Exception as error : raise RuntimeError ( f \"Evaluation failed. { error } \" ) finally : self . eval_time = round ( time . time () - start_time , 3 ) return executed_plan , result","title":"execute"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.execute_action","text":"Execute the action. Source code in execution/workflow/execute_flow.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 def execute_action ( self ) -> None : \"\"\" Execute the action. \"\"\" control_selected = None # Find the matching window and control. self . application_window = self . _app_env . find_matching_window ( self . _task_file_name ) if self . control_text == \"\" : control_selected = self . application_window else : self . _control_label , control_selected = ( self . _app_env . find_matching_controller ( self . filtered_annotation_dict , self . control_text ) ) if control_selected : self . _matched_control = control_selected . window_text () if not control_selected : # If the control is not found, raise an error. raise RuntimeError ( f \"Control with text ' { self . control_text } ' not found.\" ) try : # Get the selected control item from the annotation dictionary and LLM response. # The LLM response is a number index corresponding to the key in the annotation dictionary. if control_selected : if _ufo_configs . get ( \"SHOW_VISUAL_OUTLINE_ON_SCREEN\" , True ): control_selected . draw_outline ( colour = \"red\" , thickness = 3 ) time . sleep ( _ufo_configs . get ( \"RECTANGLE_TIME\" , 0 )) control_coordinates = PhotographerDecorator . coordinate_adjusted ( self . application_window . rectangle (), control_selected . rectangle () ) self . _control_log = { \"control_class\" : control_selected . element_info . class_name , \"control_type\" : control_selected . element_info . control_type , \"control_automation_id\" : control_selected . element_info . automation_id , \"control_friendly_class_name\" : control_selected . friendly_class_name (), \"control_coordinates\" : { \"left\" : control_coordinates [ 0 ], \"top\" : control_coordinates [ 1 ], \"right\" : control_coordinates [ 2 ], \"bottom\" : control_coordinates [ 3 ], }, } self . app_agent . Puppeteer . receiver_manager . create_ui_control_receiver ( control_selected , self . application_window ) # Save the screenshot of the tagged selected control. self . capture_control_screenshot ( control_selected ) self . _results = self . app_agent . Puppeteer . execute_command ( self . _operation , self . _args ) self . control_reannotate = None if not utils . is_json_serializable ( self . _results ): self . _results = \"\" return except Exception : self . general_error_handler ()","title":"execute_action"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.execute_plan","text":"Get the executed result from the execute agent. Parameters: instantiated_plan ( List [ Dict [ str , Any ]] ) \u2013 Plan containing steps to execute. Returns: List [ Dict [ str , Any ]] \u2013 List of executed steps. Source code in execution/workflow/execute_flow.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def execute_plan ( self , instantiated_plan : List [ Dict [ str , Any ]] ) -> List [ Dict [ str , Any ]]: \"\"\" Get the executed result from the execute agent. :param instantiated_plan: Plan containing steps to execute. :return: List of executed steps. \"\"\" # Initialize the step counter and capture the initial screenshot. self . session_step = 0 try : time . sleep ( 1 ) # Initialize the API receiver self . app_agent . Puppeteer . receiver_manager . create_api_receiver ( self . app_agent . _app_root_name , self . app_agent . _process_name ) # Initialize the control receiver current_receiver = self . app_agent . Puppeteer . receiver_manager . receiver_list [ - 1 ] if current_receiver is not None : self . application_window = self . _app_env . find_matching_window ( self . _task_file_name ) current_receiver . com_object = ( current_receiver . get_object_from_process_name () ) self . init_and_final_capture_screenshot () except Exception as error : raise RuntimeError ( f \"Execution initialization failed. { error } \" ) # Initialize the success flag for each step. for index , step_plan in enumerate ( instantiated_plan ): instantiated_plan [ index ][ \"Success\" ] = None instantiated_plan [ index ][ \"MatchedControlText\" ] = None for index , step_plan in enumerate ( instantiated_plan ): try : self . session_step += 1 # Check if the maximum steps have been exceeded. if self . session_step > _configs [ \"MAX_STEPS\" ]: raise RuntimeError ( \"Maximum steps exceeded.\" ) self . _parse_step_plan ( step_plan ) try : self . process () instantiated_plan [ index ][ \"Success\" ] = True instantiated_plan [ index ][ \"ControlLabel\" ] = self . _control_label instantiated_plan [ index ][ \"MatchedControlText\" ] = self . _matched_control except Exception as ControllerNotFoundError : instantiated_plan [ index ][ \"Success\" ] = False raise ControllerNotFoundError except Exception as error : err_info = RuntimeError ( f \"Step { self . session_step } execution failed. { error } \" ) raise err_info # capture the final screenshot self . session_step += 1 time . sleep ( 1 ) self . init_and_final_capture_screenshot () # save the final state of the app win_com_receiver = None for receiver in reversed ( self . app_agent . Puppeteer . receiver_manager . receiver_list ): if isinstance ( receiver , WinCOMReceiverBasic ): if receiver . client is not None : win_com_receiver = receiver break if win_com_receiver is not None : win_com_receiver . save () time . sleep ( 1 ) win_com_receiver . client . Quit () print ( \"Execution complete.\" ) return instantiated_plan","title":"execute_plan"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.general_error_handler","text":"Handle general errors. Source code in execution/workflow/execute_flow.py 374 375 376 377 378 379 def general_error_handler ( self ) -> None : \"\"\" Handle general errors. \"\"\" pass","title":"general_error_handler"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.init_and_final_capture_screenshot","text":"Capture the screenshot. Source code in execution/workflow/execute_flow.py 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 def init_and_final_capture_screenshot ( self ) -> None : \"\"\" Capture the screenshot. \"\"\" # Define the paths for the screenshots saved. screenshot_save_path = self . log_path + f \"action_step { self . session_step } .png\" self . _memory_data . add_values_from_dict ( { \"CleanScreenshot\" : screenshot_save_path , } ) self . photographer . capture_app_window_screenshot ( self . application_window , save_path = screenshot_save_path ) # Capture the control screenshot. control_selected = self . _app_env . app_window self . capture_control_screenshot ( control_selected )","title":"init_and_final_capture_screenshot"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.log_save","text":"Log the constructed prompt message for the PrefillAgent. Source code in execution/workflow/execute_flow.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 def log_save ( self ) -> None : \"\"\" Log the constructed prompt message for the PrefillAgent. \"\"\" step_memory = { \"Step\" : self . session_step , \"Subtask\" : self . subtask , \"ControlLabel\" : self . _control_label , \"ControlText\" : self . control_text , \"Action\" : self . action , \"ActionType\" : self . app_agent . Puppeteer . get_command_types ( self . _operation ), \"Results\" : self . _results , \"Application\" : self . app_agent . _app_root_name , \"TimeCost\" : self . time_cost , } self . _memory_data . add_values_from_dict ( step_memory ) self . log ( self . _memory_data . to_dict ())","title":"log_save"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.print_step_info","text":"Print the step information. Source code in execution/workflow/execute_flow.py 231 232 233 234 235 236 237 238 239 240 241 242 def print_step_info ( self ) -> None : \"\"\" Print the step information. \"\"\" utils . print_with_color ( \"Step {step} : {subtask} \" . format ( step = self . session_step , subtask = self . subtask , ), \"magenta\" , )","title":"print_step_info"},{"location":"dataflow/execution/#execution.workflow.execute_flow.ExecuteFlow.process","text":"Process the current step. Source code in execution/workflow/execute_flow.py 219 220 221 222 223 224 225 226 227 228 229 def process ( self ) -> None : \"\"\" Process the current step. \"\"\" step_start_time = time . time () self . print_step_info () self . capture_screenshot () self . execute_action () self . time_cost = round ( time . time () - step_start_time , 3 ) self . log_save ()","title":"process"},{"location":"dataflow/execution/#executeagent","text":"Bases: AppAgent The Agent for task execution. Initialize the ExecuteAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The name of the process. app_root_name ( str ) \u2013 The name of the app root. Source code in execution/agent/execute_agent.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , name : str , process_name : str , app_root_name : str , ): \"\"\" Initialize the ExecuteAgent. :param name: The name of the agent. :param process_name: The name of the process. :param app_root_name: The name of the app root. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = None self . _process_name = process_name self . _app_root_name = app_root_name self . Puppeteer = self . create_puppeteer_interface ()","title":"ExecuteAgent"},{"location":"dataflow/execution/#executeevalagent","text":"Bases: EvaluationAgent The Agent for task execution evaluation. Initialize the ExecuteEvalAgent. Parameters: name ( str ) \u2013 The name of the agent. app_root_name ( str ) \u2013 The name of the app root. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Source code in execution/agent/execute_eval_agent.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , name : str , app_root_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the ExecuteEvalAgent. :param name: The name of the agent. :param app_root_name: The name of the app root. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. \"\"\" super () . __init__ ( name = name , app_root_name = app_root_name , is_visual = is_visual , main_prompt = main_prompt , example_prompt = example_prompt , api_prompt = api_prompt , )","title":"ExecuteEvalAgent"},{"location":"dataflow/execution/#execution.agent.execute_eval_agent.ExecuteEvalAgent.get_prompter","text":"Get the prompter for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. prompt_template ( str ) \u2013 The prompt template. example_prompt_template ( str ) \u2013 The example prompt template. api_prompt_template ( str ) \u2013 The API prompt template. root_name ( Optional [ str ] , default: None ) \u2013 The name of the root. Returns: ExecuteEvalAgentPrompter \u2013 The prompter. Source code in execution/agent/execute_eval_agent.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def get_prompter ( self , is_visual : bool , prompt_template : str , example_prompt_template : str , api_prompt_template : str , root_name : Optional [ str ] = None , ) -> ExecuteEvalAgentPrompter : \"\"\" Get the prompter for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param prompt_template: The prompt template. :param example_prompt_template: The example prompt template. :param api_prompt_template: The API prompt template. :param root_name: The name of the root. :return: The prompter. \"\"\" return ExecuteEvalAgentPrompter ( is_visual = is_visual , prompt_template = prompt_template , example_prompt_template = example_prompt_template , api_prompt_template = api_prompt_template , root_name = root_name , )","title":"get_prompter"},{"location":"dataflow/instantiation/","text":"Instantiation There are three key steps in the instantiation process: Choose a template file according to the specified app and instruction. Prefill the task using the current screenshot. Filter the established task. Given the initial task, the dataflow first choose a template ( Phase 1 ), the prefill the initial task based on word envrionment to obtain task-action data ( Phase 2 ). Finnally, it will filter the established task to evaluate the quality of task-action data. 1. Choose Template File Templates for your app must be defined and described in dataflow/templates/app . For instance, if you want to instantiate tasks for the Word application, place the relevant .docx files in dataflow /templates/word , along with a description.json file. The appropriate template will be selected based on how well its description matches the instruction. The ChooseTemplateFlow uses semantic matching, where task descriptions are compared with template descriptions using embeddings and FAISS for efficient nearest neighbor search. If semantic matching fails, a random template is chosen from the available files. 2. Prefill the Task PrefillFlow The PrefillFlow class orchestrates the refinement of task plans and UI interactions by leveraging PrefillAgent for task planning and action generation. It automates UI control updates, captures screenshots, and manages logs for messages and responses during execution. PrefillAgent The PrefillAgent class facilitates task instantiation and action sequence generation by constructing tailored prompt messages using the PrefillPrompter . It integrates system, user, and dynamic context to generate actionable inputs for down-stream workflows. 3. Filter Task FilterFlow The FilterFlow class is designed to process and refine task plans by leveraging a FilterAgent . The FilterFlow class acts as a bridge between the instantiation of tasks and the execution of a filtering process, aiming to refine task steps and prefill task-related files based on predefined filtering criteria. FilterAgent The FilterAgent class is a specialized agent used to evaluate whether an instantiated task is correct. It inherits from the BasicAgent class and includes several methods and attributes to handle its functionality. Reference ChooseTemplateFlow Class to select and copy the most relevant template file based on the given task context. Initialize the flow with the given task context. Parameters: app_name ( str ) \u2013 The name of the application. file_extension ( str ) \u2013 The file extension of the template. task_file_name ( str ) \u2013 The name of the task file. Source code in instantiation/workflow/choose_template_flow.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , app_name : str , task_file_name : str , file_extension : str ): \"\"\" Initialize the flow with the given task context. :param app_name: The name of the application. :param file_extension: The file extension of the template. :param task_file_name: The name of the task file. \"\"\" self . _app_name = app_name self . _file_extension = file_extension self . _task_file_name = task_file_name self . execution_time = None self . _embedding_model = self . _load_embedding_model ( model_name = _configs [ \"CONTROL_FILTER_MODEL_SEMANTIC_NAME\" ] ) execute () Execute the flow and return the copied template path. Returns: str \u2013 The path to the copied template file. Source code in instantiation/workflow/choose_template_flow.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def execute ( self ) -> str : \"\"\" Execute the flow and return the copied template path. :return: The path to the copied template file. \"\"\" start_time = time . time () try : template_copied_path = self . _choose_template_and_copy () except Exception as e : raise e finally : self . execution_time = round ( time . time () - start_time , 3 ) return template_copied_path PrefillFlow Bases: AppAgentProcessor Class to manage the prefill process by refining planning steps and automating UI interactions Initialize the prefill flow with the application context. Parameters: app_name ( str ) \u2013 The name of the application. task_file_name ( str ) \u2013 The name of the task file for logging and tracking. environment ( WindowsAppEnv ) \u2013 The environment of the app. Source code in instantiation/workflow/prefill_flow.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , app_name : str , task_file_name : str , environment : WindowsAppEnv , ) -> None : \"\"\" Initialize the prefill flow with the application context. :param app_name: The name of the application. :param task_file_name: The name of the task file for logging and tracking. :param environment: The environment of the app. \"\"\" self . execution_time = None self . _app_name = app_name self . _task_file_name = task_file_name self . _app_env = environment # Create or reuse a PrefillAgent for the app if self . _app_name not in PrefillFlow . _app_prefill_agent_dict : PrefillFlow . _app_prefill_agent_dict [ self . _app_name ] = PrefillAgent ( \"prefill\" , self . _app_name , is_visual = True , main_prompt = _configs [ \"PREFILL_PROMPT\" ], example_prompt = _configs [ \"PREFILL_EXAMPLE_PROMPT\" ], api_prompt = _configs [ \"API_PROMPT\" ], ) self . _prefill_agent = PrefillFlow . _app_prefill_agent_dict [ self . _app_name ] # Initialize execution step and UI control tools self . _execute_step = 0 self . _control_inspector = ControlInspectorFacade ( _BACKEND ) self . _photographer = PhotographerFacade () # Set default states self . _status = \"\" # Initialize loggers for messages and responses self . _log_path_configs = _configs [ \"PREFILL_LOG_PATH\" ] . format ( task = self . _task_file_name ) os . makedirs ( self . _log_path_configs , exist_ok = True ) # Set up loggers self . _message_logger = BaseSession . initialize_logger ( self . _log_path_configs , \"prefill_messages.json\" , \"w\" , _configs ) self . _response_logger = BaseSession . initialize_logger ( self . _log_path_configs , \"prefill_responses.json\" , \"w\" , _configs ) execute ( template_copied_path , original_task , refined_steps ) Start the execution by retrieving the instantiated result. Parameters: template_copied_path ( str ) \u2013 The path of the copied template to use. original_task ( str ) \u2013 The original task to refine. refined_steps ( List [ str ] ) \u2013 The steps to guide the refinement process. Returns: Dict [ str , Any ] \u2013 The refined task and corresponding action plans. Source code in instantiation/workflow/prefill_flow.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def execute ( self , template_copied_path : str , original_task : str , refined_steps : List [ str ] ) -> Dict [ str , Any ]: \"\"\" Start the execution by retrieving the instantiated result. :param template_copied_path: The path of the copied template to use. :param original_task: The original task to refine. :param refined_steps: The steps to guide the refinement process. :return: The refined task and corresponding action plans. \"\"\" start_time = time . time () try : instantiated_request , instantiated_plan = self . _instantiate_task ( template_copied_path , original_task , refined_steps ) except Exception as e : raise e finally : self . execution_time = round ( time . time () - start_time , 3 ) return { \"instantiated_request\" : instantiated_request , \"instantiated_plan\" : instantiated_plan , } PrefillAgent Bases: BasicAgent The Agent for task instantialization and action sequence generation. Initialize the PrefillAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The name of the process. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Source code in instantiation/agent/prefill_agent.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , name : str , process_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the PrefillAgent. :param name: The name of the agent. :param process_name: The name of the process. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = None self . prompter : PrefillPrompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) self . _process_name = process_name get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) Get the prompt for the agent. This is the abstract method from BasicAgent that needs to be implemented. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Returns: str \u2013 The prompt string. Source code in instantiation/agent/prefill_agent.py 44 45 46 47 48 49 50 51 52 53 54 55 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str ) -> str : \"\"\" Get the prompt for the agent. This is the abstract method from BasicAgent that needs to be implemented. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. :return: The prompt string. \"\"\" return PrefillPrompter ( is_visual , main_prompt , example_prompt , api_prompt ) message_constructor ( dynamic_examples , given_task , reference_steps , log_path ) Construct the prompt message for the PrefillAgent. Parameters: dynamic_examples ( str ) \u2013 The dynamic examples retrieved from the self-demonstration and human demonstration. given_task ( str ) \u2013 The given task. reference_steps ( List [ str ] ) \u2013 The reference steps. log_path ( str ) \u2013 The path of the log. Returns: List [ str ] \u2013 The prompt message. Source code in instantiation/agent/prefill_agent.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def message_constructor ( self , dynamic_examples : str , given_task : str , reference_steps : List [ str ], log_path : str , ) -> List [ str ]: \"\"\" Construct the prompt message for the PrefillAgent. :param dynamic_examples: The dynamic examples retrieved from the self-demonstration and human demonstration. :param given_task: The given task. :param reference_steps: The reference steps. :param log_path: The path of the log. :return: The prompt message. \"\"\" prefill_agent_prompt_system_message = self . prompter . system_prompt_construction ( dynamic_examples ) prefill_agent_prompt_user_message = self . prompter . user_content_construction ( given_task , reference_steps , log_path ) appagent_prompt_message = self . prompter . prompt_construction ( prefill_agent_prompt_system_message , prefill_agent_prompt_user_message , ) return appagent_prompt_message process_comfirmation () Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. Source code in instantiation/agent/prefill_agent.py 86 87 88 89 90 91 92 def process_comfirmation ( self ) -> None : \"\"\" Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. \"\"\" pass FilterFlow Class to refine the plan steps and prefill the file based on filtering criteria. Initialize the filter flow for a task. Parameters: app_name ( str ) \u2013 Name of the application being processed. task_file_name ( str ) \u2013 Name of the task file being processed. Source code in instantiation/workflow/filter_flow.py 21 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , app_name : str , task_file_name : str ) -> None : \"\"\" Initialize the filter flow for a task. :param app_name: Name of the application being processed. :param task_file_name: Name of the task file being processed. \"\"\" self . execution_time = None self . _app_name = app_name self . _log_path_configs = _configs [ \"FILTER_LOG_PATH\" ] . format ( task = task_file_name ) self . _filter_agent = self . _get_or_create_filter_agent () self . _initialize_logs () execute ( instantiated_request ) Execute the filter flow: Filter the task and save the result. Parameters: instantiated_request ( str ) \u2013 Request object to be filtered. Returns: Dict [ str , Any ] \u2013 Tuple containing task quality flag, comment, and task type. Source code in instantiation/workflow/filter_flow.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def execute ( self , instantiated_request : str ) -> Dict [ str , Any ]: \"\"\" Execute the filter flow: Filter the task and save the result. :param instantiated_request: Request object to be filtered. :return: Tuple containing task quality flag, comment, and task type. \"\"\" start_time = time . time () try : judge , thought , request_type = self . _get_filtered_result ( instantiated_request ) except Exception as e : raise e finally : self . execution_time = round ( time . time () - start_time , 3 ) return { \"judge\" : judge , \"thought\" : thought , \"request_type\" : request_type , } FilterAgent Bases: BasicAgent The Agent to evaluate the instantiated task is correct or not. Initialize the FilterAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The name of the process. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Source code in instantiation/agent/filter_agent.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , name : str , process_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the FilterAgent. :param name: The name of the agent. :param process_name: The name of the process. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = None self . prompter : FilterPrompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) self . _process_name = process_name get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) Get the prompt for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Returns: FilterPrompter \u2013 The prompt string. Source code in instantiation/agent/filter_agent.py 43 44 45 46 47 48 49 50 51 52 53 54 55 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str ) -> FilterPrompter : \"\"\" Get the prompt for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. :return: The prompt string. \"\"\" return FilterPrompter ( is_visual , main_prompt , example_prompt , api_prompt ) message_constructor ( request , app ) Construct the prompt message for the FilterAgent. Parameters: request ( str ) \u2013 The request sentence. app ( str ) \u2013 The name of the operated app. Returns: List [ str ] \u2013 The prompt message. Source code in instantiation/agent/filter_agent.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def message_constructor ( self , request : str , app : str ) -> List [ str ]: \"\"\" Construct the prompt message for the FilterAgent. :param request: The request sentence. :param app: The name of the operated app. :return: The prompt message. \"\"\" filter_agent_prompt_system_message = self . prompter . system_prompt_construction ( app = app ) filter_agent_prompt_user_message = self . prompter . user_content_construction ( request ) filter_agent_prompt_message = self . prompter . prompt_construction ( filter_agent_prompt_system_message , filter_agent_prompt_user_message ) return filter_agent_prompt_message process_comfirmation () Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. Source code in instantiation/agent/filter_agent.py 77 78 79 80 81 82 83 def process_comfirmation ( self ) -> None : \"\"\" Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. \"\"\" pass","title":"Instantiation"},{"location":"dataflow/instantiation/#instantiation","text":"There are three key steps in the instantiation process: Choose a template file according to the specified app and instruction. Prefill the task using the current screenshot. Filter the established task. Given the initial task, the dataflow first choose a template ( Phase 1 ), the prefill the initial task based on word envrionment to obtain task-action data ( Phase 2 ). Finnally, it will filter the established task to evaluate the quality of task-action data.","title":"Instantiation"},{"location":"dataflow/instantiation/#1-choose-template-file","text":"Templates for your app must be defined and described in dataflow/templates/app . For instance, if you want to instantiate tasks for the Word application, place the relevant .docx files in dataflow /templates/word , along with a description.json file. The appropriate template will be selected based on how well its description matches the instruction. The ChooseTemplateFlow uses semantic matching, where task descriptions are compared with template descriptions using embeddings and FAISS for efficient nearest neighbor search. If semantic matching fails, a random template is chosen from the available files.","title":"1. Choose Template File"},{"location":"dataflow/instantiation/#2-prefill-the-task","text":"","title":"2. Prefill the Task"},{"location":"dataflow/instantiation/#prefillflow","text":"The PrefillFlow class orchestrates the refinement of task plans and UI interactions by leveraging PrefillAgent for task planning and action generation. It automates UI control updates, captures screenshots, and manages logs for messages and responses during execution.","title":"PrefillFlow"},{"location":"dataflow/instantiation/#prefillagent","text":"The PrefillAgent class facilitates task instantiation and action sequence generation by constructing tailored prompt messages using the PrefillPrompter . It integrates system, user, and dynamic context to generate actionable inputs for down-stream workflows.","title":"PrefillAgent"},{"location":"dataflow/instantiation/#3-filter-task","text":"","title":"3. Filter Task"},{"location":"dataflow/instantiation/#filterflow","text":"The FilterFlow class is designed to process and refine task plans by leveraging a FilterAgent . The FilterFlow class acts as a bridge between the instantiation of tasks and the execution of a filtering process, aiming to refine task steps and prefill task-related files based on predefined filtering criteria.","title":"FilterFlow"},{"location":"dataflow/instantiation/#filteragent","text":"The FilterAgent class is a specialized agent used to evaluate whether an instantiated task is correct. It inherits from the BasicAgent class and includes several methods and attributes to handle its functionality.","title":"FilterAgent"},{"location":"dataflow/instantiation/#reference","text":"","title":"Reference"},{"location":"dataflow/instantiation/#choosetemplateflow","text":"Class to select and copy the most relevant template file based on the given task context. Initialize the flow with the given task context. Parameters: app_name ( str ) \u2013 The name of the application. file_extension ( str ) \u2013 The file extension of the template. task_file_name ( str ) \u2013 The name of the task file. Source code in instantiation/workflow/choose_template_flow.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , app_name : str , task_file_name : str , file_extension : str ): \"\"\" Initialize the flow with the given task context. :param app_name: The name of the application. :param file_extension: The file extension of the template. :param task_file_name: The name of the task file. \"\"\" self . _app_name = app_name self . _file_extension = file_extension self . _task_file_name = task_file_name self . execution_time = None self . _embedding_model = self . _load_embedding_model ( model_name = _configs [ \"CONTROL_FILTER_MODEL_SEMANTIC_NAME\" ] )","title":"ChooseTemplateFlow"},{"location":"dataflow/instantiation/#instantiation.workflow.choose_template_flow.ChooseTemplateFlow.execute","text":"Execute the flow and return the copied template path. Returns: str \u2013 The path to the copied template file. Source code in instantiation/workflow/choose_template_flow.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def execute ( self ) -> str : \"\"\" Execute the flow and return the copied template path. :return: The path to the copied template file. \"\"\" start_time = time . time () try : template_copied_path = self . _choose_template_and_copy () except Exception as e : raise e finally : self . execution_time = round ( time . time () - start_time , 3 ) return template_copied_path","title":"execute"},{"location":"dataflow/instantiation/#prefillflow_1","text":"Bases: AppAgentProcessor Class to manage the prefill process by refining planning steps and automating UI interactions Initialize the prefill flow with the application context. Parameters: app_name ( str ) \u2013 The name of the application. task_file_name ( str ) \u2013 The name of the task file for logging and tracking. environment ( WindowsAppEnv ) \u2013 The environment of the app. Source code in instantiation/workflow/prefill_flow.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , app_name : str , task_file_name : str , environment : WindowsAppEnv , ) -> None : \"\"\" Initialize the prefill flow with the application context. :param app_name: The name of the application. :param task_file_name: The name of the task file for logging and tracking. :param environment: The environment of the app. \"\"\" self . execution_time = None self . _app_name = app_name self . _task_file_name = task_file_name self . _app_env = environment # Create or reuse a PrefillAgent for the app if self . _app_name not in PrefillFlow . _app_prefill_agent_dict : PrefillFlow . _app_prefill_agent_dict [ self . _app_name ] = PrefillAgent ( \"prefill\" , self . _app_name , is_visual = True , main_prompt = _configs [ \"PREFILL_PROMPT\" ], example_prompt = _configs [ \"PREFILL_EXAMPLE_PROMPT\" ], api_prompt = _configs [ \"API_PROMPT\" ], ) self . _prefill_agent = PrefillFlow . _app_prefill_agent_dict [ self . _app_name ] # Initialize execution step and UI control tools self . _execute_step = 0 self . _control_inspector = ControlInspectorFacade ( _BACKEND ) self . _photographer = PhotographerFacade () # Set default states self . _status = \"\" # Initialize loggers for messages and responses self . _log_path_configs = _configs [ \"PREFILL_LOG_PATH\" ] . format ( task = self . _task_file_name ) os . makedirs ( self . _log_path_configs , exist_ok = True ) # Set up loggers self . _message_logger = BaseSession . initialize_logger ( self . _log_path_configs , \"prefill_messages.json\" , \"w\" , _configs ) self . _response_logger = BaseSession . initialize_logger ( self . _log_path_configs , \"prefill_responses.json\" , \"w\" , _configs )","title":"PrefillFlow"},{"location":"dataflow/instantiation/#instantiation.workflow.prefill_flow.PrefillFlow.execute","text":"Start the execution by retrieving the instantiated result. Parameters: template_copied_path ( str ) \u2013 The path of the copied template to use. original_task ( str ) \u2013 The original task to refine. refined_steps ( List [ str ] ) \u2013 The steps to guide the refinement process. Returns: Dict [ str , Any ] \u2013 The refined task and corresponding action plans. Source code in instantiation/workflow/prefill_flow.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def execute ( self , template_copied_path : str , original_task : str , refined_steps : List [ str ] ) -> Dict [ str , Any ]: \"\"\" Start the execution by retrieving the instantiated result. :param template_copied_path: The path of the copied template to use. :param original_task: The original task to refine. :param refined_steps: The steps to guide the refinement process. :return: The refined task and corresponding action plans. \"\"\" start_time = time . time () try : instantiated_request , instantiated_plan = self . _instantiate_task ( template_copied_path , original_task , refined_steps ) except Exception as e : raise e finally : self . execution_time = round ( time . time () - start_time , 3 ) return { \"instantiated_request\" : instantiated_request , \"instantiated_plan\" : instantiated_plan , }","title":"execute"},{"location":"dataflow/instantiation/#prefillagent_1","text":"Bases: BasicAgent The Agent for task instantialization and action sequence generation. Initialize the PrefillAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The name of the process. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Source code in instantiation/agent/prefill_agent.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , name : str , process_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the PrefillAgent. :param name: The name of the agent. :param process_name: The name of the process. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = None self . prompter : PrefillPrompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) self . _process_name = process_name","title":"PrefillAgent"},{"location":"dataflow/instantiation/#instantiation.agent.prefill_agent.PrefillAgent.get_prompter","text":"Get the prompt for the agent. This is the abstract method from BasicAgent that needs to be implemented. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Returns: str \u2013 The prompt string. Source code in instantiation/agent/prefill_agent.py 44 45 46 47 48 49 50 51 52 53 54 55 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str ) -> str : \"\"\" Get the prompt for the agent. This is the abstract method from BasicAgent that needs to be implemented. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. :return: The prompt string. \"\"\" return PrefillPrompter ( is_visual , main_prompt , example_prompt , api_prompt )","title":"get_prompter"},{"location":"dataflow/instantiation/#instantiation.agent.prefill_agent.PrefillAgent.message_constructor","text":"Construct the prompt message for the PrefillAgent. Parameters: dynamic_examples ( str ) \u2013 The dynamic examples retrieved from the self-demonstration and human demonstration. given_task ( str ) \u2013 The given task. reference_steps ( List [ str ] ) \u2013 The reference steps. log_path ( str ) \u2013 The path of the log. Returns: List [ str ] \u2013 The prompt message. Source code in instantiation/agent/prefill_agent.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def message_constructor ( self , dynamic_examples : str , given_task : str , reference_steps : List [ str ], log_path : str , ) -> List [ str ]: \"\"\" Construct the prompt message for the PrefillAgent. :param dynamic_examples: The dynamic examples retrieved from the self-demonstration and human demonstration. :param given_task: The given task. :param reference_steps: The reference steps. :param log_path: The path of the log. :return: The prompt message. \"\"\" prefill_agent_prompt_system_message = self . prompter . system_prompt_construction ( dynamic_examples ) prefill_agent_prompt_user_message = self . prompter . user_content_construction ( given_task , reference_steps , log_path ) appagent_prompt_message = self . prompter . prompt_construction ( prefill_agent_prompt_system_message , prefill_agent_prompt_user_message , ) return appagent_prompt_message","title":"message_constructor"},{"location":"dataflow/instantiation/#instantiation.agent.prefill_agent.PrefillAgent.process_comfirmation","text":"Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. Source code in instantiation/agent/prefill_agent.py 86 87 88 89 90 91 92 def process_comfirmation ( self ) -> None : \"\"\" Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. \"\"\" pass","title":"process_comfirmation"},{"location":"dataflow/instantiation/#filterflow_1","text":"Class to refine the plan steps and prefill the file based on filtering criteria. Initialize the filter flow for a task. Parameters: app_name ( str ) \u2013 Name of the application being processed. task_file_name ( str ) \u2013 Name of the task file being processed. Source code in instantiation/workflow/filter_flow.py 21 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , app_name : str , task_file_name : str ) -> None : \"\"\" Initialize the filter flow for a task. :param app_name: Name of the application being processed. :param task_file_name: Name of the task file being processed. \"\"\" self . execution_time = None self . _app_name = app_name self . _log_path_configs = _configs [ \"FILTER_LOG_PATH\" ] . format ( task = task_file_name ) self . _filter_agent = self . _get_or_create_filter_agent () self . _initialize_logs ()","title":"FilterFlow"},{"location":"dataflow/instantiation/#instantiation.workflow.filter_flow.FilterFlow.execute","text":"Execute the filter flow: Filter the task and save the result. Parameters: instantiated_request ( str ) \u2013 Request object to be filtered. Returns: Dict [ str , Any ] \u2013 Tuple containing task quality flag, comment, and task type. Source code in instantiation/workflow/filter_flow.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def execute ( self , instantiated_request : str ) -> Dict [ str , Any ]: \"\"\" Execute the filter flow: Filter the task and save the result. :param instantiated_request: Request object to be filtered. :return: Tuple containing task quality flag, comment, and task type. \"\"\" start_time = time . time () try : judge , thought , request_type = self . _get_filtered_result ( instantiated_request ) except Exception as e : raise e finally : self . execution_time = round ( time . time () - start_time , 3 ) return { \"judge\" : judge , \"thought\" : thought , \"request_type\" : request_type , }","title":"execute"},{"location":"dataflow/instantiation/#filteragent_1","text":"Bases: BasicAgent The Agent to evaluate the instantiated task is correct or not. Initialize the FilterAgent. Parameters: name ( str ) \u2013 The name of the agent. process_name ( str ) \u2013 The name of the process. is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Source code in instantiation/agent/filter_agent.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , name : str , process_name : str , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str , ): \"\"\" Initialize the FilterAgent. :param name: The name of the agent. :param process_name: The name of the process. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. \"\"\" self . _step = 0 self . _complete = False self . _name = name self . _status = None self . prompter : FilterPrompter = self . get_prompter ( is_visual , main_prompt , example_prompt , api_prompt ) self . _process_name = process_name","title":"FilterAgent"},{"location":"dataflow/instantiation/#instantiation.agent.filter_agent.FilterAgent.get_prompter","text":"Get the prompt for the agent. Parameters: is_visual ( bool ) \u2013 The flag indicating whether the agent is visual or not. main_prompt ( str ) \u2013 The main prompt. example_prompt ( str ) \u2013 The example prompt. api_prompt ( str ) \u2013 The API prompt. Returns: FilterPrompter \u2013 The prompt string. Source code in instantiation/agent/filter_agent.py 43 44 45 46 47 48 49 50 51 52 53 54 55 def get_prompter ( self , is_visual : bool , main_prompt : str , example_prompt : str , api_prompt : str ) -> FilterPrompter : \"\"\" Get the prompt for the agent. :param is_visual: The flag indicating whether the agent is visual or not. :param main_prompt: The main prompt. :param example_prompt: The example prompt. :param api_prompt: The API prompt. :return: The prompt string. \"\"\" return FilterPrompter ( is_visual , main_prompt , example_prompt , api_prompt )","title":"get_prompter"},{"location":"dataflow/instantiation/#instantiation.agent.filter_agent.FilterAgent.message_constructor","text":"Construct the prompt message for the FilterAgent. Parameters: request ( str ) \u2013 The request sentence. app ( str ) \u2013 The name of the operated app. Returns: List [ str ] \u2013 The prompt message. Source code in instantiation/agent/filter_agent.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def message_constructor ( self , request : str , app : str ) -> List [ str ]: \"\"\" Construct the prompt message for the FilterAgent. :param request: The request sentence. :param app: The name of the operated app. :return: The prompt message. \"\"\" filter_agent_prompt_system_message = self . prompter . system_prompt_construction ( app = app ) filter_agent_prompt_user_message = self . prompter . user_content_construction ( request ) filter_agent_prompt_message = self . prompter . prompt_construction ( filter_agent_prompt_system_message , filter_agent_prompt_user_message ) return filter_agent_prompt_message","title":"message_constructor"},{"location":"dataflow/instantiation/#instantiation.agent.filter_agent.FilterAgent.process_comfirmation","text":"Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. Source code in instantiation/agent/filter_agent.py 77 78 79 80 81 82 83 def process_comfirmation ( self ) -> None : \"\"\" Confirm the process. This is the abstract method from BasicAgent that needs to be implemented. \"\"\" pass","title":"process_comfirmation"},{"location":"dataflow/overview/","text":"Introduction This repository contains the implementation of the Data Collection process for training the Large Action Models (LAMs) in the paper of Large Action Models: From Inception to Implementation . The Data Collection process is designed to streamline task processing, ensuring that all necessary steps are seamlessly integrated from initialization to execution. This module is part of the UFO project. Dataflow Dataflow uses UFO to implement instantiation , execution , and dataflow for a given task, with options for batch processing and single processing. Instantiation : Instantiation refers to the process of setting up and preparing a task for execution. This step typically involves choosing template , prefill and filter . Execution : Execution is the actual process of running the task. This step involves carrying out the actions or operations specified by the Instantiation . And after execution, an evaluate agent will evaluate the quality of the whole execution process. Dataflow : Dataflow is the overarching process that combines instantiation and execution into a single pipeline. It provides an end-to-end solution for processing tasks, ensuring that all necessary steps (from initialization to execution) are seamlessly integrated. You can use instantiation and execution independently if you only need to perform one specific part of the process. When both steps are required for a task, the dataflow process streamlines them, allowing you to execute tasks from start to finish in a single pipeline. The overall processing of dataflow is as below. Given a task-plan data, the LLMwill instantiatie the task-action data, including choosing template, prefill, filter. How To Use 1. Install Packages You should install the necessary packages in the UFO root folder: pip install -r requirements.txt 2. Configure the LLMs Before running dataflow, you need to provide your LLM configurations individually for PrefillAgent and FilterAgent . You can create your own config file dataflow/config/config.yaml , by copying the dataflow/config/config.yaml.template and editing config for PREFILL_AGENT and FILTER_AGENT as follows: OpenAI VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"openai\" , # The API type, \"openai\" for the OpenAI API. API_BASE: \"https://api.openai.com/v1/chat/completions\", # The the OpenAI API endpoint. API_KEY: \"sk-\", # The OpenAI API key, begin with sk- API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The only OpenAI model Azure OpenAI (AOAI) VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"aoai\" , # The API type, \"aoai\" for the Azure OpenAI. API_BASE: \"YOUR_ENDPOINT\", # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com API_KEY: \"YOUR_KEY\", # The aoai API key API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The only OpenAI model API_DEPLOYMENT_ID: \"YOUR_AOAI_DEPLOYMENT\", # The deployment id for the AOAI API You can also non-visial model (e.g., GPT-4) for each agent, by setting VISUAL_MODE: False and proper API_MODEL (openai) and API_DEPLOYMENT_ID (aoai). Non-Visual Model Configuration You can utilize non-visual models (e.g., GPT-4) for each agent by configuring the following settings in the config.yaml file: VISUAL_MODE: False # To enable non-visual mode. Specify the appropriate API_MODEL (OpenAI) and API_DEPLOYMENT_ID (AOAI) for each agent. Ensure you configure these settings accurately to leverage non-visual models effectively. Other Configurations config_dev.yaml specifies the paths of relevant files and contains default settings. The match strategy for the window match and control filter supports options: 'contains' , 'fuzzy' , and 'regex' , allowing flexible matching strategy for users. The MAX_STEPS is the max step for the execute_flow, which can be set by users. Note The specific implementation and invocation method of the matching strategy can refer to windows_app_env . Note BE CAREFUL! If you are using GitHub or other open-source tools, do not expose your config.yaml online, as it contains your private keys. 3. Prepare Files Certain files need to be prepared before running the task. 3.1. Tasks as JSON The tasks that need to be instantiated should be organized in a folder of JSON files, with the default folder path set to dataflow /tasks . This path can be changed in the dataflow/config/config.yaml file, or you can specify it in the terminal, as mentioned in 4. Start Running . For example, a task stored in dataflow/tasks/prefill/ may look like this: { // The app you want to use \"app\": \"word\", // A unique ID to distinguish different tasks \"unique_id\": \"1\", // The task and steps to be instantiated \"task\": \"Type 'hello' and set the font type to Arial\", \"refined_steps\": [ \"Type 'hello'\", \"Set the font to Arial\" ] } 3.2. Templates and Descriptions You should place an app file as a reference for instantiation in a folder named after the app. For example, if you have template1.docx for Word, it should be located at dataflow/templates/word/template1.docx . Additionally, for each app folder, there should be a description.json file located at dataflow/templates/word/description.json , which describes each template file in detail. It may look like this: { \"template1.docx\": \"A document with a rectangle shape\", \"template2.docx\": \"A document with a line of text\" } If a description.json file is not present, one template file will be selected at random. 3.3. Final Structure Ensure the following files are in place: JSON files to be instantiated Templates as references for instantiation Description file in JSON format The structure of the files can be: dataflow/ | \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 prefill \u2502 \u251c\u2500\u2500 bulleted.json \u2502 \u251c\u2500\u2500 delete.json \u2502 \u251c\u2500\u2500 draw.json \u2502 \u251c\u2500\u2500 macro.json \u2502 \u2514\u2500\u2500 rotate.json \u251c\u2500\u2500 templates \u2502 \u2514\u2500\u2500 word \u2502 \u251c\u2500\u2500 description.json \u2502 \u251c\u2500\u2500 template1.docx \u2502 \u251c\u2500\u2500 template2.docx \u2502 \u251c\u2500\u2500 template3.docx \u2502 \u251c\u2500\u2500 template4.docx \u2502 \u251c\u2500\u2500 template5.docx \u2502 \u251c\u2500\u2500 template6.docx \u2502 \u2514\u2500\u2500 template7.docx \u2514\u2500\u2500 ... 4. Start Running After finishing the previous steps, you can use the following commands in the command line. We provide single / batch process, for which you need to give the single file path / folder path. Determine the type of path provided by the user and automatically decide whether to process a single task or batch tasks. Also, you can choose to use instantiation / execution sections individually, or use them as a whole section, which is named as dataflow . The default task hub is set to be \"TASKS_HUB\" in dataflow/config_dev.yaml . Dataflow Task: python -m dataflow -dataflow --task_path path_to_task_file Instantiation Task: python -m dataflow -instantiation --task_path path_to_task_file Execution Task: python -m dataflow -execution --task_path path_to_task_file Note Users should be careful to save the original files while using this project; otherwise, the files will be closed when the app is shut down. After starting the project, users should not close the app window while the program is taking screenshots. Workflow Instantiation There are three key steps in the instantiation process: Choose a template file according to the specified app and instruction. Prefill the task using the current screenshot. Filter the established task. Given the initial task, the dataflow first choose a template ( Phase 1 ), the prefill the initial task based on word envrionment to obtain task-action data ( Phase 2 ). Finnally, it will filter the established task to evaluate the quality of task-action data. ( Phase 3 ) Note The more detailed code design documentation for instantiation can be found in instantiation . Execution The instantiated plans will be executed by a execute task. After execution, evalution agent will evaluation the quality of the entire execution process. Note The more detailed code design documentation for execution can be found in execution . Result The results will be saved in the results\\ directory under instantiation , execution , and dataflow , and will be further stored in subdirectories based on the execution outcomes. Note The more detailed information of result can be found in result . Quick Start We prepare two cases to show the dataflow, which can be found in dataflow\\tasks\\prefill . So after installing required packages, you can type the following command in the command line: python -m dataflow -dataflow And you can see the hints showing in the terminal, which means the dataflow is working. Structure of related files After the two tasks are finished, the task and output files would appear as follows: UFO/ \u251c\u2500\u2500 dataflow/ \u2502 \u2514\u2500\u2500 results/ \u2502 \u251c\u2500\u2500 saved_document/ # Directory for saved documents \u2502 \u2502 \u251c\u2500\u2500 bulleted.docx # Result of the \"bulleted\" task \u2502 \u2502 \u2514\u2500\u2500 rotate.docx # Result of the \"rotate\" task \u2502 \u251c\u2500\u2500 dataflow/ # Dataflow results directory \u2502 \u2502 \u251c\u2500\u2500 execution_pass/ # Successfully executed tasks \u2502 \u2502 \u2502 \u251c\u2500\u2500 bulleted.json # Execution result for the \"bulleted\" task \u2502 \u2502 \u2502 \u251c\u2500\u2500 rotate.json # Execution result for the \"rotate\" task \u2502 \u2502 \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 ... The specific results can be referenced in the result in JSON format along with example data. Log files The corresponding logs can be found in the directories logs/bulleted and logs/rotate , as shown below. Detailed logs for each workflow are recorded, capturing every step of the execution process. Reference AppEnum Bases: Enum Enum class for applications. Initialize the application enum. Parameters: id ( int ) \u2013 The ID of the application. description ( str ) \u2013 The description of the application. file_extension ( str ) \u2013 The file extension of the application. win_app ( str ) \u2013 The Windows application name. Source code in dataflow/data_flow_controller.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def __init__ ( self , id : int , description : str , file_extension : str , win_app : str ): \"\"\" Initialize the application enum. :param id: The ID of the application. :param description: The description of the application. :param file_extension: The file extension of the application. :param win_app: The Windows application name. \"\"\" self . id = id self . description = description self . file_extension = file_extension self . win_app = win_app self . app_root_name = win_app . upper () + \".EXE\" TaskObject Initialize the task object. Parameters: task_file_path ( str ) \u2013 The path to the task file. task_type ( str ) \u2013 The task_type of the task object (dataflow, instantiation, or execution). Source code in dataflow/data_flow_controller.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , task_file_path : str , task_type : str ) -> None : \"\"\" Initialize the task object. :param task_file_path: The path to the task file. :param task_type: The task_type of the task object (dataflow, instantiation, or execution). \"\"\" self . task_file_path = task_file_path self . task_file_base_name = os . path . basename ( task_file_path ) self . task_file_name = self . task_file_base_name . split ( \".\" )[ 0 ] task_json_file = load_json_file ( task_file_path ) self . app_object = self . _choose_app_from_json ( task_json_file [ \"app\" ]) # Initialize the task attributes based on the task_type self . _init_attr ( task_type , task_json_file ) DataFlowController Flow controller class to manage the instantiation and execution process. Initialize the flow controller. Parameters: task_path ( str ) \u2013 The path to the task file. task_type ( str ) \u2013 The task_type of the flow controller (instantiation, execution, or dataflow). Source code in dataflow/data_flow_controller.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def __init__ ( self , task_path : str , task_type : str ) -> None : \"\"\" Initialize the flow controller. :param task_path: The path to the task file. :param task_type: The task_type of the flow controller (instantiation, execution, or dataflow). \"\"\" self . task_object = TaskObject ( task_path , task_type ) self . app_env = None self . app_name = self . task_object . app_object . description . lower () self . task_file_name = self . task_object . task_file_name self . schema = self . _load_schema ( task_type ) self . task_type = task_type self . task_info = self . init_task_info () self . result_hub = _configs [ \"RESULT_HUB\" ] . format ( task_type = task_type ) instantiated_plan property writable Get the instantiated plan from the task information. Returns: List [ Dict [ str , Any ]] \u2013 The instantiated plan. template_copied_path property Get the copied template path from the task information. Returns: str \u2013 The copied template path. execute_execution ( request , plan ) Execute the execution process. Parameters: request ( str ) \u2013 The task request to be executed. plan ( Dict [ str , any ] ) \u2013 The execution plan containing detailed steps. Source code in dataflow/data_flow_controller.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 def execute_execution ( self , request : str , plan : Dict [ str , any ]) -> None : \"\"\" Execute the execution process. :param request: The task request to be executed. :param plan: The execution plan containing detailed steps. \"\"\" print_with_color ( \"Executing the execution process...\" , \"blue\" ) execute_flow = None try : self . app_env . start ( self . template_copied_path ) # Initialize the execution context and flow context = Context () execute_flow = ExecuteFlow ( self . task_file_name , context , self . app_env ) # Execute the plan executed_plan , execute_result = execute_flow . execute ( request , plan ) # Update the instantiated plan self . instantiated_plan = executed_plan # Record execution results and time metrics self . task_info [ \"execution_result\" ][ \"result\" ] = execute_result self . task_info [ \"time_cost\" ][ \"execute\" ] = execute_flow . execution_time self . task_info [ \"time_cost\" ][ \"execute_eval\" ] = execute_flow . eval_time except Exception as e : # Handle and log any exceptions that occur during execution self . task_info [ \"execution_result\" ][ \"error\" ] = { \"type\" : str ( type ( e ) . __name__ ), \"message\" : str ( e ), \"traceback\" : traceback . format_exc (), } print_with_color ( f \"Error in Execution: { e } \" , \"red\" ) raise e finally : # Record the total time cost of the execution process if execute_flow and hasattr ( execute_flow , \"execution_time\" ): self . task_info [ \"time_cost\" ][ \"execute\" ] = execute_flow . execution_time else : self . task_info [ \"time_cost\" ][ \"execute\" ] = None if execute_flow and hasattr ( execute_flow , \"eval_time\" ): self . task_info [ \"time_cost\" ][ \"execute_eval\" ] = execute_flow . eval_time else : self . task_info [ \"time_cost\" ][ \"execute_eval\" ] = None execute_instantiation () Execute the instantiation process. Returns: Optional [ List [ Dict [ str , Any ]]] \u2013 The instantiation plan if successful. Source code in dataflow/data_flow_controller.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def execute_instantiation ( self ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\" Execute the instantiation process. :return: The instantiation plan if successful. \"\"\" print_with_color ( f \"Instantiating task { self . task_object . task_file_name } ...\" , \"blue\" ) template_copied_path = self . instantiation_single_flow ( ChooseTemplateFlow , \"choose_template\" , init_params = [ self . task_object . app_object . file_extension ], execute_params = [], ) if template_copied_path : self . app_env . start ( template_copied_path ) prefill_result = self . instantiation_single_flow ( PrefillFlow , \"prefill\" , init_params = [ self . app_env ], execute_params = [ template_copied_path , self . task_object . task , self . task_object . refined_steps , ], ) self . app_env . close () if prefill_result : self . instantiation_single_flow ( FilterFlow , \"instantiation_evaluation\" , init_params = [], execute_params = [ prefill_result [ \"instantiated_request\" ]], ) return prefill_result [ \"instantiated_plan\" ] init_task_info () Initialize the task information. Returns: Dict [ str , Any ] \u2013 The initialized task information. Source code in dataflow/data_flow_controller.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def init_task_info ( self ) -> Dict [ str , Any ]: \"\"\" Initialize the task information. :return: The initialized task information. \"\"\" init_task_info = None if self . task_type == \"execution\" : # read from the instantiated task file init_task_info = load_json_file ( self . task_object . task_file_path ) else : init_task_info = { \"unique_id\" : self . task_object . unique_id , \"app\" : self . app_name , \"original\" : { \"original_task\" : self . task_object . task , \"original_steps\" : self . task_object . refined_steps , }, \"execution_result\" : { \"result\" : None , \"error\" : None }, \"instantiation_result\" : { \"choose_template\" : { \"result\" : None , \"error\" : None }, \"prefill\" : { \"result\" : None , \"error\" : None }, \"instantiation_evaluation\" : { \"result\" : None , \"error\" : None }, }, \"time_cost\" : {}, } return init_task_info instantiation_single_flow ( flow_class , flow_type , init_params = None , execute_params = None ) Execute a single flow process in the instantiation phase. Parameters: flow_class ( AppAgentProcessor ) \u2013 The flow class to instantiate. flow_type ( str ) \u2013 The type of the flow. init_params \u2013 The initialization parameters for the flow. execute_params \u2013 The execution parameters for the flow. Returns: Optional [ Dict [ str , Any ]] \u2013 The result of the flow process. Source code in dataflow/data_flow_controller.py 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 def instantiation_single_flow ( self , flow_class : AppAgentProcessor , flow_type : str , init_params = None , execute_params = None , ) -> Optional [ Dict [ str , Any ]]: \"\"\" Execute a single flow process in the instantiation phase. :param flow_class: The flow class to instantiate. :param flow_type: The type of the flow. :param init_params: The initialization parameters for the flow. :param execute_params: The execution parameters for the flow. :return: The result of the flow process. \"\"\" flow_instance = None try : flow_instance = flow_class ( self . app_name , self . task_file_name , * init_params ) result = flow_instance . execute ( * execute_params ) self . task_info [ \"instantiation_result\" ][ flow_type ][ \"result\" ] = result return result except Exception as e : self . task_info [ \"instantiation_result\" ][ flow_type ][ \"error\" ] = { \"type\" : str ( e . __class__ ), \"error_message\" : str ( e ), \"traceback\" : traceback . format_exc (), } print_with_color ( f \"Error in { flow_type } : { e } { traceback . format_exc () } \" ) finally : if flow_instance and hasattr ( flow_instance , \"execution_time\" ): self . task_info [ \"time_cost\" ][ flow_type ] = flow_instance . execution_time else : self . task_info [ \"time_cost\" ][ flow_type ] = None reformat_to_batch ( path ) Transfer the result to the result hub. Source code in dataflow/data_flow_controller.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 def reformat_to_batch ( self , path ) -> None : \"\"\" Transfer the result to the result hub. \"\"\" os . makedirs ( path , exist_ok = True ) source_files_path = os . path . join ( self . result_hub , self . task_type + \"_pass\" , ) source_template_path = os . path . join ( os . path . dirname ( self . result_hub ), \"saved_document\" , ) target_file_path = os . path . join ( path , \"tasks\" , ) target_template_path = os . path . join ( path , \"files\" , ) os . makedirs (( target_file_path ), exist_ok = True ) os . makedirs (( target_template_path ), exist_ok = True ) for file in os . listdir ( source_files_path ): if file . endswith ( \".json\" ): source_file = os . path . join ( source_files_path , file ) target_file = os . path . join ( target_file_path , file ) target_object = os . path . join ( target_template_path , file . replace ( \".json\" , \".docx\" ) ) is_successed = reformat_json_file ( target_file , target_object , load_json_file ( source_file ), ) if is_successed : shutil . copy ( os . path . join ( source_template_path , file . replace ( \".json\" , \".docx\" ) ), target_template_path , ) run () Run the instantiation and execution process. Source code in dataflow/data_flow_controller.py 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 def run ( self ) -> None : \"\"\" Run the instantiation and execution process. \"\"\" start_time = time . time () try : self . app_env = WindowsAppEnv ( self . task_object . app_object ) if self . task_type == \"dataflow\" : plan = self . execute_instantiation () self . execute_execution ( self . task_object . task , plan ) elif self . task_type == \"instantiation\" : self . execute_instantiation () elif self . task_type == \"execution\" : plan = self . instantiated_plan self . execute_execution ( self . task_object . task , plan ) else : raise ValueError ( f \"Unsupported task_type: { self . task_type } \" ) except Exception as e : raise e finally : # Update or record the total time cost of the process total_time = round ( time . time () - start_time , 3 ) new_total_time = ( self . task_info . get ( \"time_cost\" , {}) . get ( \"total\" , 0 ) + total_time ) self . task_info [ \"time_cost\" ][ \"total\" ] = round ( new_total_time , 3 ) self . save_result () if _configs [ \"REFORMAT_TO_BATCH\" ]: self . reformat_to_batch ( _configs [ \"REFORMAT_TO_BATCH_HUB\" ]) save_result () Validate and save the instantiated task result. Source code in dataflow/data_flow_controller.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def save_result ( self ) -> None : \"\"\" Validate and save the instantiated task result. \"\"\" validation_error = None # Validate the result against the schema try : validate ( instance = self . task_info , schema = self . schema ) except ValidationError as e : # Record the validation error but allow the process to continue validation_error = str ( e . message ) print_with_color ( f \"Validation Error: { e . message } \" , \"yellow\" ) # Determine the target directory based on task_type and quality/completeness target_file = None if self . task_type == \"instantiation\" : # Determine the quality of the instantiation if not self . task_info [ \"instantiation_result\" ][ \"instantiation_evaluation\" ][ \"result\" ]: target_file = INSTANTIATION_RESULT_MAP [ False ] else : is_quality_good = self . task_info [ \"instantiation_result\" ][ \"instantiation_evaluation\" ][ \"result\" ][ \"judge\" ] target_file = INSTANTIATION_RESULT_MAP . get ( is_quality_good , INSTANTIATION_RESULT_MAP [ False ] ) else : # Determine the completion status of the execution if not self . task_info [ \"execution_result\" ][ \"result\" ]: target_file = EXECUTION_RESULT_MAP [ \"no\" ] else : is_completed = self . task_info [ \"execution_result\" ][ \"result\" ][ \"complete\" ] target_file = EXECUTION_RESULT_MAP . get ( is_completed , EXECUTION_RESULT_MAP [ \"no\" ] ) # Construct the full path to save the result new_task_path = os . path . join ( self . result_hub , target_file , self . task_object . task_file_base_name ) os . makedirs ( os . path . dirname ( new_task_path ), exist_ok = True ) save_json_file ( new_task_path , self . task_info ) print ( f \"Task saved to { new_task_path } \" ) # If validation failed, indicate that the saved result may need further inspection if validation_error : print ( \"The saved task result does not conform to the expected schema and may require review.\" )","title":"Overview"},{"location":"dataflow/overview/#introduction","text":"This repository contains the implementation of the Data Collection process for training the Large Action Models (LAMs) in the paper of Large Action Models: From Inception to Implementation . The Data Collection process is designed to streamline task processing, ensuring that all necessary steps are seamlessly integrated from initialization to execution. This module is part of the UFO project.","title":"Introduction"},{"location":"dataflow/overview/#dataflow","text":"Dataflow uses UFO to implement instantiation , execution , and dataflow for a given task, with options for batch processing and single processing. Instantiation : Instantiation refers to the process of setting up and preparing a task for execution. This step typically involves choosing template , prefill and filter . Execution : Execution is the actual process of running the task. This step involves carrying out the actions or operations specified by the Instantiation . And after execution, an evaluate agent will evaluate the quality of the whole execution process. Dataflow : Dataflow is the overarching process that combines instantiation and execution into a single pipeline. It provides an end-to-end solution for processing tasks, ensuring that all necessary steps (from initialization to execution) are seamlessly integrated. You can use instantiation and execution independently if you only need to perform one specific part of the process. When both steps are required for a task, the dataflow process streamlines them, allowing you to execute tasks from start to finish in a single pipeline. The overall processing of dataflow is as below. Given a task-plan data, the LLMwill instantiatie the task-action data, including choosing template, prefill, filter.","title":"Dataflow"},{"location":"dataflow/overview/#how-to-use","text":"","title":"How To Use"},{"location":"dataflow/overview/#1-install-packages","text":"You should install the necessary packages in the UFO root folder: pip install -r requirements.txt","title":"1. Install Packages"},{"location":"dataflow/overview/#2-configure-the-llms","text":"Before running dataflow, you need to provide your LLM configurations individually for PrefillAgent and FilterAgent . You can create your own config file dataflow/config/config.yaml , by copying the dataflow/config/config.yaml.template and editing config for PREFILL_AGENT and FILTER_AGENT as follows:","title":"2. Configure the LLMs"},{"location":"dataflow/overview/#openai","text":"VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"openai\" , # The API type, \"openai\" for the OpenAI API. API_BASE: \"https://api.openai.com/v1/chat/completions\", # The the OpenAI API endpoint. API_KEY: \"sk-\", # The OpenAI API key, begin with sk- API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The only OpenAI model","title":"OpenAI"},{"location":"dataflow/overview/#azure-openai-aoai","text":"VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"aoai\" , # The API type, \"aoai\" for the Azure OpenAI. API_BASE: \"YOUR_ENDPOINT\", # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com API_KEY: \"YOUR_KEY\", # The aoai API key API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The only OpenAI model API_DEPLOYMENT_ID: \"YOUR_AOAI_DEPLOYMENT\", # The deployment id for the AOAI API You can also non-visial model (e.g., GPT-4) for each agent, by setting VISUAL_MODE: False and proper API_MODEL (openai) and API_DEPLOYMENT_ID (aoai).","title":"Azure OpenAI (AOAI)"},{"location":"dataflow/overview/#non-visual-model-configuration","text":"You can utilize non-visual models (e.g., GPT-4) for each agent by configuring the following settings in the config.yaml file: VISUAL_MODE: False # To enable non-visual mode. Specify the appropriate API_MODEL (OpenAI) and API_DEPLOYMENT_ID (AOAI) for each agent. Ensure you configure these settings accurately to leverage non-visual models effectively.","title":"Non-Visual Model Configuration"},{"location":"dataflow/overview/#other-configurations","text":"config_dev.yaml specifies the paths of relevant files and contains default settings. The match strategy for the window match and control filter supports options: 'contains' , 'fuzzy' , and 'regex' , allowing flexible matching strategy for users. The MAX_STEPS is the max step for the execute_flow, which can be set by users. Note The specific implementation and invocation method of the matching strategy can refer to windows_app_env . Note BE CAREFUL! If you are using GitHub or other open-source tools, do not expose your config.yaml online, as it contains your private keys.","title":"Other Configurations"},{"location":"dataflow/overview/#3-prepare-files","text":"Certain files need to be prepared before running the task.","title":"3. Prepare Files"},{"location":"dataflow/overview/#31-tasks-as-json","text":"The tasks that need to be instantiated should be organized in a folder of JSON files, with the default folder path set to dataflow /tasks . This path can be changed in the dataflow/config/config.yaml file, or you can specify it in the terminal, as mentioned in 4. Start Running . For example, a task stored in dataflow/tasks/prefill/ may look like this: { // The app you want to use \"app\": \"word\", // A unique ID to distinguish different tasks \"unique_id\": \"1\", // The task and steps to be instantiated \"task\": \"Type 'hello' and set the font type to Arial\", \"refined_steps\": [ \"Type 'hello'\", \"Set the font to Arial\" ] }","title":"3.1. Tasks as JSON"},{"location":"dataflow/overview/#32-templates-and-descriptions","text":"You should place an app file as a reference for instantiation in a folder named after the app. For example, if you have template1.docx for Word, it should be located at dataflow/templates/word/template1.docx . Additionally, for each app folder, there should be a description.json file located at dataflow/templates/word/description.json , which describes each template file in detail. It may look like this: { \"template1.docx\": \"A document with a rectangle shape\", \"template2.docx\": \"A document with a line of text\" } If a description.json file is not present, one template file will be selected at random.","title":"3.2. Templates and Descriptions"},{"location":"dataflow/overview/#33-final-structure","text":"Ensure the following files are in place: JSON files to be instantiated Templates as references for instantiation Description file in JSON format The structure of the files can be: dataflow/ | \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 prefill \u2502 \u251c\u2500\u2500 bulleted.json \u2502 \u251c\u2500\u2500 delete.json \u2502 \u251c\u2500\u2500 draw.json \u2502 \u251c\u2500\u2500 macro.json \u2502 \u2514\u2500\u2500 rotate.json \u251c\u2500\u2500 templates \u2502 \u2514\u2500\u2500 word \u2502 \u251c\u2500\u2500 description.json \u2502 \u251c\u2500\u2500 template1.docx \u2502 \u251c\u2500\u2500 template2.docx \u2502 \u251c\u2500\u2500 template3.docx \u2502 \u251c\u2500\u2500 template4.docx \u2502 \u251c\u2500\u2500 template5.docx \u2502 \u251c\u2500\u2500 template6.docx \u2502 \u2514\u2500\u2500 template7.docx \u2514\u2500\u2500 ...","title":"3.3. Final Structure"},{"location":"dataflow/overview/#4-start-running","text":"After finishing the previous steps, you can use the following commands in the command line. We provide single / batch process, for which you need to give the single file path / folder path. Determine the type of path provided by the user and automatically decide whether to process a single task or batch tasks. Also, you can choose to use instantiation / execution sections individually, or use them as a whole section, which is named as dataflow . The default task hub is set to be \"TASKS_HUB\" in dataflow/config_dev.yaml . Dataflow Task: python -m dataflow -dataflow --task_path path_to_task_file Instantiation Task: python -m dataflow -instantiation --task_path path_to_task_file Execution Task: python -m dataflow -execution --task_path path_to_task_file Note Users should be careful to save the original files while using this project; otherwise, the files will be closed when the app is shut down. After starting the project, users should not close the app window while the program is taking screenshots.","title":"4. Start Running"},{"location":"dataflow/overview/#workflow","text":"","title":"Workflow"},{"location":"dataflow/overview/#instantiation","text":"There are three key steps in the instantiation process: Choose a template file according to the specified app and instruction. Prefill the task using the current screenshot. Filter the established task. Given the initial task, the dataflow first choose a template ( Phase 1 ), the prefill the initial task based on word envrionment to obtain task-action data ( Phase 2 ). Finnally, it will filter the established task to evaluate the quality of task-action data. ( Phase 3 ) Note The more detailed code design documentation for instantiation can be found in instantiation .","title":"Instantiation"},{"location":"dataflow/overview/#execution","text":"The instantiated plans will be executed by a execute task. After execution, evalution agent will evaluation the quality of the entire execution process. Note The more detailed code design documentation for execution can be found in execution .","title":"Execution"},{"location":"dataflow/overview/#result","text":"The results will be saved in the results\\ directory under instantiation , execution , and dataflow , and will be further stored in subdirectories based on the execution outcomes. Note The more detailed information of result can be found in result .","title":"Result"},{"location":"dataflow/overview/#quick-start","text":"We prepare two cases to show the dataflow, which can be found in dataflow\\tasks\\prefill . So after installing required packages, you can type the following command in the command line: python -m dataflow -dataflow And you can see the hints showing in the terminal, which means the dataflow is working.","title":"Quick Start"},{"location":"dataflow/overview/#structure-of-related-files","text":"After the two tasks are finished, the task and output files would appear as follows: UFO/ \u251c\u2500\u2500 dataflow/ \u2502 \u2514\u2500\u2500 results/ \u2502 \u251c\u2500\u2500 saved_document/ # Directory for saved documents \u2502 \u2502 \u251c\u2500\u2500 bulleted.docx # Result of the \"bulleted\" task \u2502 \u2502 \u2514\u2500\u2500 rotate.docx # Result of the \"rotate\" task \u2502 \u251c\u2500\u2500 dataflow/ # Dataflow results directory \u2502 \u2502 \u251c\u2500\u2500 execution_pass/ # Successfully executed tasks \u2502 \u2502 \u2502 \u251c\u2500\u2500 bulleted.json # Execution result for the \"bulleted\" task \u2502 \u2502 \u2502 \u251c\u2500\u2500 rotate.json # Execution result for the \"rotate\" task \u2502 \u2502 \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 ... The specific results can be referenced in the result in JSON format along with example data.","title":"Structure of related files"},{"location":"dataflow/overview/#log-files","text":"The corresponding logs can be found in the directories logs/bulleted and logs/rotate , as shown below. Detailed logs for each workflow are recorded, capturing every step of the execution process.","title":"Log files"},{"location":"dataflow/overview/#reference","text":"","title":"Reference"},{"location":"dataflow/overview/#appenum","text":"Bases: Enum Enum class for applications. Initialize the application enum. Parameters: id ( int ) \u2013 The ID of the application. description ( str ) \u2013 The description of the application. file_extension ( str ) \u2013 The file extension of the application. win_app ( str ) \u2013 The Windows application name. Source code in dataflow/data_flow_controller.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def __init__ ( self , id : int , description : str , file_extension : str , win_app : str ): \"\"\" Initialize the application enum. :param id: The ID of the application. :param description: The description of the application. :param file_extension: The file extension of the application. :param win_app: The Windows application name. \"\"\" self . id = id self . description = description self . file_extension = file_extension self . win_app = win_app self . app_root_name = win_app . upper () + \".EXE\"","title":"AppEnum"},{"location":"dataflow/overview/#taskobject","text":"Initialize the task object. Parameters: task_file_path ( str ) \u2013 The path to the task file. task_type ( str ) \u2013 The task_type of the task object (dataflow, instantiation, or execution). Source code in dataflow/data_flow_controller.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , task_file_path : str , task_type : str ) -> None : \"\"\" Initialize the task object. :param task_file_path: The path to the task file. :param task_type: The task_type of the task object (dataflow, instantiation, or execution). \"\"\" self . task_file_path = task_file_path self . task_file_base_name = os . path . basename ( task_file_path ) self . task_file_name = self . task_file_base_name . split ( \".\" )[ 0 ] task_json_file = load_json_file ( task_file_path ) self . app_object = self . _choose_app_from_json ( task_json_file [ \"app\" ]) # Initialize the task attributes based on the task_type self . _init_attr ( task_type , task_json_file )","title":"TaskObject"},{"location":"dataflow/overview/#dataflowcontroller","text":"Flow controller class to manage the instantiation and execution process. Initialize the flow controller. Parameters: task_path ( str ) \u2013 The path to the task file. task_type ( str ) \u2013 The task_type of the flow controller (instantiation, execution, or dataflow). Source code in dataflow/data_flow_controller.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def __init__ ( self , task_path : str , task_type : str ) -> None : \"\"\" Initialize the flow controller. :param task_path: The path to the task file. :param task_type: The task_type of the flow controller (instantiation, execution, or dataflow). \"\"\" self . task_object = TaskObject ( task_path , task_type ) self . app_env = None self . app_name = self . task_object . app_object . description . lower () self . task_file_name = self . task_object . task_file_name self . schema = self . _load_schema ( task_type ) self . task_type = task_type self . task_info = self . init_task_info () self . result_hub = _configs [ \"RESULT_HUB\" ] . format ( task_type = task_type )","title":"DataFlowController"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.instantiated_plan","text":"Get the instantiated plan from the task information. Returns: List [ Dict [ str , Any ]] \u2013 The instantiated plan.","title":"instantiated_plan"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.template_copied_path","text":"Get the copied template path from the task information. Returns: str \u2013 The copied template path.","title":"template_copied_path"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.execute_execution","text":"Execute the execution process. Parameters: request ( str ) \u2013 The task request to be executed. plan ( Dict [ str , any ] ) \u2013 The execution plan containing detailed steps. Source code in dataflow/data_flow_controller.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 def execute_execution ( self , request : str , plan : Dict [ str , any ]) -> None : \"\"\" Execute the execution process. :param request: The task request to be executed. :param plan: The execution plan containing detailed steps. \"\"\" print_with_color ( \"Executing the execution process...\" , \"blue\" ) execute_flow = None try : self . app_env . start ( self . template_copied_path ) # Initialize the execution context and flow context = Context () execute_flow = ExecuteFlow ( self . task_file_name , context , self . app_env ) # Execute the plan executed_plan , execute_result = execute_flow . execute ( request , plan ) # Update the instantiated plan self . instantiated_plan = executed_plan # Record execution results and time metrics self . task_info [ \"execution_result\" ][ \"result\" ] = execute_result self . task_info [ \"time_cost\" ][ \"execute\" ] = execute_flow . execution_time self . task_info [ \"time_cost\" ][ \"execute_eval\" ] = execute_flow . eval_time except Exception as e : # Handle and log any exceptions that occur during execution self . task_info [ \"execution_result\" ][ \"error\" ] = { \"type\" : str ( type ( e ) . __name__ ), \"message\" : str ( e ), \"traceback\" : traceback . format_exc (), } print_with_color ( f \"Error in Execution: { e } \" , \"red\" ) raise e finally : # Record the total time cost of the execution process if execute_flow and hasattr ( execute_flow , \"execution_time\" ): self . task_info [ \"time_cost\" ][ \"execute\" ] = execute_flow . execution_time else : self . task_info [ \"time_cost\" ][ \"execute\" ] = None if execute_flow and hasattr ( execute_flow , \"eval_time\" ): self . task_info [ \"time_cost\" ][ \"execute_eval\" ] = execute_flow . eval_time else : self . task_info [ \"time_cost\" ][ \"execute_eval\" ] = None","title":"execute_execution"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.execute_instantiation","text":"Execute the instantiation process. Returns: Optional [ List [ Dict [ str , Any ]]] \u2013 The instantiation plan if successful. Source code in dataflow/data_flow_controller.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def execute_instantiation ( self ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\" Execute the instantiation process. :return: The instantiation plan if successful. \"\"\" print_with_color ( f \"Instantiating task { self . task_object . task_file_name } ...\" , \"blue\" ) template_copied_path = self . instantiation_single_flow ( ChooseTemplateFlow , \"choose_template\" , init_params = [ self . task_object . app_object . file_extension ], execute_params = [], ) if template_copied_path : self . app_env . start ( template_copied_path ) prefill_result = self . instantiation_single_flow ( PrefillFlow , \"prefill\" , init_params = [ self . app_env ], execute_params = [ template_copied_path , self . task_object . task , self . task_object . refined_steps , ], ) self . app_env . close () if prefill_result : self . instantiation_single_flow ( FilterFlow , \"instantiation_evaluation\" , init_params = [], execute_params = [ prefill_result [ \"instantiated_request\" ]], ) return prefill_result [ \"instantiated_plan\" ]","title":"execute_instantiation"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.init_task_info","text":"Initialize the task information. Returns: Dict [ str , Any ] \u2013 The initialized task information. Source code in dataflow/data_flow_controller.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def init_task_info ( self ) -> Dict [ str , Any ]: \"\"\" Initialize the task information. :return: The initialized task information. \"\"\" init_task_info = None if self . task_type == \"execution\" : # read from the instantiated task file init_task_info = load_json_file ( self . task_object . task_file_path ) else : init_task_info = { \"unique_id\" : self . task_object . unique_id , \"app\" : self . app_name , \"original\" : { \"original_task\" : self . task_object . task , \"original_steps\" : self . task_object . refined_steps , }, \"execution_result\" : { \"result\" : None , \"error\" : None }, \"instantiation_result\" : { \"choose_template\" : { \"result\" : None , \"error\" : None }, \"prefill\" : { \"result\" : None , \"error\" : None }, \"instantiation_evaluation\" : { \"result\" : None , \"error\" : None }, }, \"time_cost\" : {}, } return init_task_info","title":"init_task_info"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.instantiation_single_flow","text":"Execute a single flow process in the instantiation phase. Parameters: flow_class ( AppAgentProcessor ) \u2013 The flow class to instantiate. flow_type ( str ) \u2013 The type of the flow. init_params \u2013 The initialization parameters for the flow. execute_params \u2013 The execution parameters for the flow. Returns: Optional [ Dict [ str , Any ]] \u2013 The result of the flow process. Source code in dataflow/data_flow_controller.py 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 def instantiation_single_flow ( self , flow_class : AppAgentProcessor , flow_type : str , init_params = None , execute_params = None , ) -> Optional [ Dict [ str , Any ]]: \"\"\" Execute a single flow process in the instantiation phase. :param flow_class: The flow class to instantiate. :param flow_type: The type of the flow. :param init_params: The initialization parameters for the flow. :param execute_params: The execution parameters for the flow. :return: The result of the flow process. \"\"\" flow_instance = None try : flow_instance = flow_class ( self . app_name , self . task_file_name , * init_params ) result = flow_instance . execute ( * execute_params ) self . task_info [ \"instantiation_result\" ][ flow_type ][ \"result\" ] = result return result except Exception as e : self . task_info [ \"instantiation_result\" ][ flow_type ][ \"error\" ] = { \"type\" : str ( e . __class__ ), \"error_message\" : str ( e ), \"traceback\" : traceback . format_exc (), } print_with_color ( f \"Error in { flow_type } : { e } { traceback . format_exc () } \" ) finally : if flow_instance and hasattr ( flow_instance , \"execution_time\" ): self . task_info [ \"time_cost\" ][ flow_type ] = flow_instance . execution_time else : self . task_info [ \"time_cost\" ][ flow_type ] = None","title":"instantiation_single_flow"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.reformat_to_batch","text":"Transfer the result to the result hub. Source code in dataflow/data_flow_controller.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 def reformat_to_batch ( self , path ) -> None : \"\"\" Transfer the result to the result hub. \"\"\" os . makedirs ( path , exist_ok = True ) source_files_path = os . path . join ( self . result_hub , self . task_type + \"_pass\" , ) source_template_path = os . path . join ( os . path . dirname ( self . result_hub ), \"saved_document\" , ) target_file_path = os . path . join ( path , \"tasks\" , ) target_template_path = os . path . join ( path , \"files\" , ) os . makedirs (( target_file_path ), exist_ok = True ) os . makedirs (( target_template_path ), exist_ok = True ) for file in os . listdir ( source_files_path ): if file . endswith ( \".json\" ): source_file = os . path . join ( source_files_path , file ) target_file = os . path . join ( target_file_path , file ) target_object = os . path . join ( target_template_path , file . replace ( \".json\" , \".docx\" ) ) is_successed = reformat_json_file ( target_file , target_object , load_json_file ( source_file ), ) if is_successed : shutil . copy ( os . path . join ( source_template_path , file . replace ( \".json\" , \".docx\" ) ), target_template_path , )","title":"reformat_to_batch"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.run","text":"Run the instantiation and execution process. Source code in dataflow/data_flow_controller.py 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 def run ( self ) -> None : \"\"\" Run the instantiation and execution process. \"\"\" start_time = time . time () try : self . app_env = WindowsAppEnv ( self . task_object . app_object ) if self . task_type == \"dataflow\" : plan = self . execute_instantiation () self . execute_execution ( self . task_object . task , plan ) elif self . task_type == \"instantiation\" : self . execute_instantiation () elif self . task_type == \"execution\" : plan = self . instantiated_plan self . execute_execution ( self . task_object . task , plan ) else : raise ValueError ( f \"Unsupported task_type: { self . task_type } \" ) except Exception as e : raise e finally : # Update or record the total time cost of the process total_time = round ( time . time () - start_time , 3 ) new_total_time = ( self . task_info . get ( \"time_cost\" , {}) . get ( \"total\" , 0 ) + total_time ) self . task_info [ \"time_cost\" ][ \"total\" ] = round ( new_total_time , 3 ) self . save_result () if _configs [ \"REFORMAT_TO_BATCH\" ]: self . reformat_to_batch ( _configs [ \"REFORMAT_TO_BATCH_HUB\" ])","title":"run"},{"location":"dataflow/overview/#data_flow_controller.DataFlowController.save_result","text":"Validate and save the instantiated task result. Source code in dataflow/data_flow_controller.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def save_result ( self ) -> None : \"\"\" Validate and save the instantiated task result. \"\"\" validation_error = None # Validate the result against the schema try : validate ( instance = self . task_info , schema = self . schema ) except ValidationError as e : # Record the validation error but allow the process to continue validation_error = str ( e . message ) print_with_color ( f \"Validation Error: { e . message } \" , \"yellow\" ) # Determine the target directory based on task_type and quality/completeness target_file = None if self . task_type == \"instantiation\" : # Determine the quality of the instantiation if not self . task_info [ \"instantiation_result\" ][ \"instantiation_evaluation\" ][ \"result\" ]: target_file = INSTANTIATION_RESULT_MAP [ False ] else : is_quality_good = self . task_info [ \"instantiation_result\" ][ \"instantiation_evaluation\" ][ \"result\" ][ \"judge\" ] target_file = INSTANTIATION_RESULT_MAP . get ( is_quality_good , INSTANTIATION_RESULT_MAP [ False ] ) else : # Determine the completion status of the execution if not self . task_info [ \"execution_result\" ][ \"result\" ]: target_file = EXECUTION_RESULT_MAP [ \"no\" ] else : is_completed = self . task_info [ \"execution_result\" ][ \"result\" ][ \"complete\" ] target_file = EXECUTION_RESULT_MAP . get ( is_completed , EXECUTION_RESULT_MAP [ \"no\" ] ) # Construct the full path to save the result new_task_path = os . path . join ( self . result_hub , target_file , self . task_object . task_file_base_name ) os . makedirs ( os . path . dirname ( new_task_path ), exist_ok = True ) save_json_file ( new_task_path , self . task_info ) print ( f \"Task saved to { new_task_path } \" ) # If validation failed, indicate that the saved result may need further inspection if validation_error : print ( \"The saved task result does not conform to the expected schema and may require review.\" )","title":"save_result"},{"location":"dataflow/result/","text":"Result The results will be saved in the \"dataflow/results\" directory under instantiation , execution , and dataflow , and will be further stored in subdirectories based on the result. The results are saved by validating the task information against a schema ( instantiation_schema or execution_schema.json in the \"dataflow/schema\" ) and determining the target directory based on the task type and its evaluation status , then storing the result in the appropriate location. The structure of the storage and the specific meaning of the schema are as follows. Overall Result Struction The structure of the results of the task is as below: UFO/ \u251c\u2500\u2500 dataflow/ # Root folder for dataflow \u2502 \u2514\u2500\u2500 results/ # Directory for storing task processing results \u2502 \u251c\u2500\u2500 saved_document/ # Directory for final document results \u2502 \u251c\u2500\u2500 instantiation/ # Directory for instantiation results \u2502 \u2502 \u251c\u2500\u2500 instantiation_pass/ # Tasks successfully instantiated \u2502 \u2502 \u2514\u2500\u2500 instantiation_fail/ # Tasks that failed instantiation \u2502 \u251c\u2500\u2500 execution/ # Directory for execution results \u2502 \u2502 \u251c\u2500\u2500 execution_pass/ # Tasks successfully executed \u2502 \u2502 \u251c\u2500\u2500 execution_fail/ # Tasks that failed execution \u2502 \u2502 \u2514\u2500\u2500 execution_unsure/ # Tasks with uncertain execution results \u2502 \u251c\u2500\u2500 dataflow/ # Directory for dataflow results \u2502 \u2502 \u251c\u2500\u2500 execution_pass/ # Tasks successfully executed \u2502 \u2502 \u251c\u2500\u2500 execution_fail/ # Tasks that failed execution \u2502 \u2502 \u2514\u2500\u2500 execution_unsure/ # Tasks with uncertain execution results \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 ... General Description: This directory structure organizes the results of task processing into specific categories, including instantiation , execution , and dataflow outcomes. Instantiation: The instantiation directory contains subfolders for tasks that were successfully instantiated ( instantiation_pass ) and those that failed during instantiation ( instantiation_fail ). This corresponds to the result of instantiation_evaluation , with the field name \"judge\" . Execution: Results of task execution are stored under the execution directory, categorized into successful tasks ( execution_pass ), failed tasks ( execution_fail ), and tasks with uncertain outcomes ( execution_unsure ). This corresponds to the evaluation result of execute_flow , with the field name \"complete\" . Dataflow Results: The dataflow directory similarly stores the results of tasks based on the execution outcome: execution_pass for success, execution_fail for failure, or execution_unsure for uncertainty. This corresponds to the evaluation result of execute_flow , with the field name \"complete\" . Saved Documents: Instantiated results are separately stored in the saved_document directory for easy access and reference. Overall Description The result data include unique_id \uff0c app , original , execution_result , instantiation_result , time_cost . The result data includes the following fields: Field Description unique_id A unique identifier for the task. app The name of the application that processes the task. original Contains details about the original task, including: original.original_task A description of the original task. original.original_steps A list of steps involved in the original task. execution_result Stores the result of task execution , including any errors encountered and execution evaluation. instantiation_result Provides details of the instantiation process, including: instantiation_result.choose_template The template selection result and any associated errors. instantiation_result.prefill Information about pre-filled task, including the instantiated request and plan. instantiation_result.instantiation_evaluation Evaluation results of the instantiated task, including judgments and feedback. time_cost Tracks the time taken for various stages of the process, such as template selection, pre-filling, and evaluation. Instantiation Result Schema The instantiation schema in \"dataflow/schema/instantiation_schema.json\" defines the structure of a JSON object that is used to validate the results of task instantiation . Schema Tabular Description Field Description unique_id A unique identifier for the task. app The name of the application that processes the task. original Contains details about the original task, including: original.original_task A description of the original task. original.original_steps A list of steps involved in the original task. execution_result Stores the result of task execution, including any errors encountered and execution evaluation. execution_result.result Indicates the execution result (or null if not applicable). execution_result.error Details any errors encountered during task execution. instantiation_result Provides details of the instantiation process, including: instantiation_result.choose_template The template selection result and any associated errors. instantiation_result.prefill Information about pre-filled tasks, including the instantiated request and plan. instantiation_result.prefill.result Contains details of instantiated requests and plans. instantiation_result.prefill.result.instantiated_request The instantiated task request. instantiation_result.prefill.result.instantiated_plan Contains details of the instantiated steps. instantiation_result.prefill.result.instantiated_plan.step The step sequence number. instantiation_result.prefill.result.instantiated_plan.subtask The description of the subtask. instantiation_result.prefill.result.instantiated_plan.control_label Control label for the step (or null if not applicable). instantiation_result.prefill.result.instantiated_plan.control_text Contextual text for the step. instantiation_result.prefill.result.instantiated_plan.function The function executed in this step. instantiation_result.prefill.result.instantiated_plan.args Parameters required for the function. instantiation_result.prefill.error Errors, if any, during the prefill process. instantiation_result.instantiation_evaluation Evaluation results of the instantiated task, including judgments and feedback. instantiation_result.instantiation_evaluation.result Contains detailed evaluation results. instantiation_result.instantiation_evaluation.result.judge Indicates whether the evaluation passed. instantiation_result.instantiation_evaluation.result.thought Feedback or observations from the evaluator. instantiation_result.instantiation_evaluation.result.request_type Classification of the request type. instantiation_result.instantiation_evaluation.error Errors, if any, during the evaluation. time_cost Tracks the time taken for various stages of the process, such as template selection, pre-filling, and evaluation. time_cost.choose_template Time taken for the template selection stage. time_cost.prefill Time taken for the prefill stage. time_cost.instantiation_evaluation Time taken for the evaluation stage. time_cost.total Total time taken for the task. Example Data { \"unique_id\": \"5\", \"app\": \"word\", \"original\": { \"original_task\": \"Turning lines of text into a bulleted list in Word\", \"original_steps\": [ \"1. Place the cursor at the beginning of the line of text you want to turn into a bulleted list\", \"2. Click the Bullets button in the Paragraph group on the Home tab and choose a bullet style\" ] }, \"execution_result\": { \"result\": null, \"error\": null }, \"instantiation_result\": { \"choose_template\": { \"result\": \"dataflow\\\\results\\\\saved_document\\\\bulleted.docx\", \"error\": null }, \"prefill\": { \"result\": { \"instantiated_request\": \"Turn the line of text 'text to edit' into a bulleted list in Word.\", \"instantiated_plan\": [ { \"Step\": 1, \"Subtask\": \"Place the cursor at the beginning of the text 'text to edit'\", \"ControlLabel\": null, \"ControlText\": \"\", \"Function\": \"select_text\", \"Args\": { \"text\": \"text to edit\" } }, { \"Step\": 2, \"Subtask\": \"Click the Bullets button in the Paragraph group on the Home tab\", \"ControlLabel\": null, \"ControlText\": \"Bullets\", \"Function\": \"click_input\", \"Args\": { \"button\": \"left\", \"double\": false } } ] }, \"error\": null }, \"instantiation_evaluation\": { \"result\": { \"judge\": true, \"thought\": \"The task is specific and involves a basic function in Word that can be executed locally without any external dependencies.\", \"request_type\": \"None\" }, \"error\": null } }, \"time_cost\": { \"choose_template\": 0.012, \"prefill\": 15.649, \"instantiation_evaluation\": 2.469, \"execute\": null, \"execute_eval\": null, \"total\": 18.130 } } Execution Result Schema The execution result schema in the \"dataflow/schema/execution_schema.json\" defines the structure of a JSON object that is used to validate the results of task execution or dataflow . The execution result schema provides comprehensive feedback on execution , emphasizing key success metrics ( reason , sub_scores , complete ) recorded in the result field of execution_result . Key enhancements include: Each step in the instantiated_plan has been augmented with: Success : Indicates if the step executed successfully (no errors). MatchedControlText : Records the name of the last matched control. ControlLabel : Be updated to reflect the final selected control. The execute \u3001 execute_eval and total in the time_cost field is updated. Schema Tabular Description Field Description unique_id A unique identifier for the task. app The name of the application that processes the task. original Contains details about the original task, including: original.original_task A description of the original task. original.original_steps A list of steps involved in the original task. execution_result Represents the result of task execution, including any errors encountered and execution evaluation. execution_result.result Indicates the result of the task execution. execution_result.error Indicates any errors that occurred during execution. instantiation_result Provides details about the task instantiation, including: instantiation_result.choose_template.result The template selection result. instantiation_result.choose_template.error Errors, if any, during template selection. instantiation_result.prefill.result.instantiated_request The instantiated task request. instantiation_result.prefill.result.instantiated_plan.Step The step sequence number. instantiation_result.prefill.result.instantiated_plan.Subtask The description of the subtask. instantiation_result.prefill.result.instantiated_plan.ControlLabel Control label for the step. instantiation_result.prefill.result.instantiated_plan.ControlText Contextual text for the step. instantiation_result.prefill.result.instantiated_plan.Function The function executed in this step. instantiation_result.prefill.result.instantiated_plan.Args Parameters required for the function. instantiation_result.prefill.result.instantiated_plan.Success Indicates if the step was executed successfully without errors. instantiation_result.prefill.result.instantiated_plan.MatchedControlText The final matched control text in the execution flow. instantiation_result.prefill.error Errors, if any, during the prefill process. instantiation_result.instantiation_evaluation.result.judge Indicates whether the evaluation passed. instantiation_result.instantiation_evaluation.result.thought Feedback or observations from the evaluator. instantiation_result.instantiation_evaluation.result.request_type Classification of the request type. instantiation_result.instantiation_evaluation.error Errors, if any, during the evaluation. time_cost Tracks the time taken for various stages of the process, including: time_cost.choose_template Time taken for the template selection stage. time_cost.prefill Time taken for the prefill stage. time_cost.instantiation_evaluation Time taken for the evaluation stage. time_cost.execute Time taken for the execute stage. time_cost.execute_eval Time taken for the execute evaluation stage. time_cost.total Total time taken for the task. Example Data { \"unique_id\": \"5\", \"app\": \"word\", \"original\": { \"original_task\": \"Turning lines of text into a bulleted list in Word\", \"original_steps\": [ \"1. Place the cursor at the beginning of the line of text you want to turn into a bulleted list\", \"2. Click the Bullets button in the Paragraph group on the Home tab and choose a bullet style\" ] }, \"execution_result\": { \"result\": { \"reason\": \"The agent successfully selected the text 'text to edit' and then clicked on the 'Bullets' button in the Word application. The final screenshot shows that the text 'text to edit' has been converted into a bulleted list.\", \"sub_scores\": { \"text selection\": \"yes\", \"bulleted list conversion\": \"yes\" }, \"complete\": \"yes\" }, \"error\": null }, \"instantiation_result\": { \"choose_template\": { \"result\": \"dataflow\\\\results\\\\saved_document\\\\bulleted.docx\", \"error\": null }, \"prefill\": { \"result\": { \"instantiated_request\": \"Turn the line of text 'text to edit' into a bulleted list in Word.\", \"instantiated_plan\": [ { \"Step\": 1, \"Subtask\": \"Place the cursor at the beginning of the text 'text to edit'\", \"ControlLabel\": null, \"ControlText\": \"\", \"Function\": \"select_text\", \"Args\": { \"text\": \"text to edit\" }, \"Success\": true, \"MatchedControlText\": null }, { \"Step\": 2, \"Subtask\": \"Click the Bullets button in the Paragraph group on the Home tab\", \"ControlLabel\": \"61\", \"ControlText\": \"Bullets\", \"Function\": \"click_input\", \"Args\": { \"button\": \"left\", \"double\": false }, \"Success\": true, \"MatchedControlText\": \"Bullets\" } ] }, \"error\": null }, \"instantiation_evaluation\": { \"result\": { \"judge\": true, \"thought\": \"The task is specific and involves a basic function in Word that can be executed locally without any external dependencies.\", \"request_type\": \"None\" }, \"error\": null } }, \"time_cost\": { \"choose_template\": 0.012, \"prefill\": 15.649, \"instantiation_evaluation\": 2.469, \"execute\": 5.824, \"execute_eval\": 8.702, \"total\": 43.522 } }","title":"Result"},{"location":"dataflow/result/#result","text":"The results will be saved in the \"dataflow/results\" directory under instantiation , execution , and dataflow , and will be further stored in subdirectories based on the result. The results are saved by validating the task information against a schema ( instantiation_schema or execution_schema.json in the \"dataflow/schema\" ) and determining the target directory based on the task type and its evaluation status , then storing the result in the appropriate location. The structure of the storage and the specific meaning of the schema are as follows.","title":"Result"},{"location":"dataflow/result/#overall-result-struction","text":"The structure of the results of the task is as below: UFO/ \u251c\u2500\u2500 dataflow/ # Root folder for dataflow \u2502 \u2514\u2500\u2500 results/ # Directory for storing task processing results \u2502 \u251c\u2500\u2500 saved_document/ # Directory for final document results \u2502 \u251c\u2500\u2500 instantiation/ # Directory for instantiation results \u2502 \u2502 \u251c\u2500\u2500 instantiation_pass/ # Tasks successfully instantiated \u2502 \u2502 \u2514\u2500\u2500 instantiation_fail/ # Tasks that failed instantiation \u2502 \u251c\u2500\u2500 execution/ # Directory for execution results \u2502 \u2502 \u251c\u2500\u2500 execution_pass/ # Tasks successfully executed \u2502 \u2502 \u251c\u2500\u2500 execution_fail/ # Tasks that failed execution \u2502 \u2502 \u2514\u2500\u2500 execution_unsure/ # Tasks with uncertain execution results \u2502 \u251c\u2500\u2500 dataflow/ # Directory for dataflow results \u2502 \u2502 \u251c\u2500\u2500 execution_pass/ # Tasks successfully executed \u2502 \u2502 \u251c\u2500\u2500 execution_fail/ # Tasks that failed execution \u2502 \u2502 \u2514\u2500\u2500 execution_unsure/ # Tasks with uncertain execution results \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 ... General Description: This directory structure organizes the results of task processing into specific categories, including instantiation , execution , and dataflow outcomes. Instantiation: The instantiation directory contains subfolders for tasks that were successfully instantiated ( instantiation_pass ) and those that failed during instantiation ( instantiation_fail ). This corresponds to the result of instantiation_evaluation , with the field name \"judge\" . Execution: Results of task execution are stored under the execution directory, categorized into successful tasks ( execution_pass ), failed tasks ( execution_fail ), and tasks with uncertain outcomes ( execution_unsure ). This corresponds to the evaluation result of execute_flow , with the field name \"complete\" . Dataflow Results: The dataflow directory similarly stores the results of tasks based on the execution outcome: execution_pass for success, execution_fail for failure, or execution_unsure for uncertainty. This corresponds to the evaluation result of execute_flow , with the field name \"complete\" . Saved Documents: Instantiated results are separately stored in the saved_document directory for easy access and reference.","title":"Overall Result Struction"},{"location":"dataflow/result/#overall-description","text":"The result data include unique_id \uff0c app , original , execution_result , instantiation_result , time_cost . The result data includes the following fields: Field Description unique_id A unique identifier for the task. app The name of the application that processes the task. original Contains details about the original task, including: original.original_task A description of the original task. original.original_steps A list of steps involved in the original task. execution_result Stores the result of task execution , including any errors encountered and execution evaluation. instantiation_result Provides details of the instantiation process, including: instantiation_result.choose_template The template selection result and any associated errors. instantiation_result.prefill Information about pre-filled task, including the instantiated request and plan. instantiation_result.instantiation_evaluation Evaluation results of the instantiated task, including judgments and feedback. time_cost Tracks the time taken for various stages of the process, such as template selection, pre-filling, and evaluation.","title":"Overall Description"},{"location":"dataflow/result/#instantiation-result-schema","text":"The instantiation schema in \"dataflow/schema/instantiation_schema.json\" defines the structure of a JSON object that is used to validate the results of task instantiation .","title":"Instantiation Result Schema"},{"location":"dataflow/result/#schema-tabular-description","text":"Field Description unique_id A unique identifier for the task. app The name of the application that processes the task. original Contains details about the original task, including: original.original_task A description of the original task. original.original_steps A list of steps involved in the original task. execution_result Stores the result of task execution, including any errors encountered and execution evaluation. execution_result.result Indicates the execution result (or null if not applicable). execution_result.error Details any errors encountered during task execution. instantiation_result Provides details of the instantiation process, including: instantiation_result.choose_template The template selection result and any associated errors. instantiation_result.prefill Information about pre-filled tasks, including the instantiated request and plan. instantiation_result.prefill.result Contains details of instantiated requests and plans. instantiation_result.prefill.result.instantiated_request The instantiated task request. instantiation_result.prefill.result.instantiated_plan Contains details of the instantiated steps. instantiation_result.prefill.result.instantiated_plan.step The step sequence number. instantiation_result.prefill.result.instantiated_plan.subtask The description of the subtask. instantiation_result.prefill.result.instantiated_plan.control_label Control label for the step (or null if not applicable). instantiation_result.prefill.result.instantiated_plan.control_text Contextual text for the step. instantiation_result.prefill.result.instantiated_plan.function The function executed in this step. instantiation_result.prefill.result.instantiated_plan.args Parameters required for the function. instantiation_result.prefill.error Errors, if any, during the prefill process. instantiation_result.instantiation_evaluation Evaluation results of the instantiated task, including judgments and feedback. instantiation_result.instantiation_evaluation.result Contains detailed evaluation results. instantiation_result.instantiation_evaluation.result.judge Indicates whether the evaluation passed. instantiation_result.instantiation_evaluation.result.thought Feedback or observations from the evaluator. instantiation_result.instantiation_evaluation.result.request_type Classification of the request type. instantiation_result.instantiation_evaluation.error Errors, if any, during the evaluation. time_cost Tracks the time taken for various stages of the process, such as template selection, pre-filling, and evaluation. time_cost.choose_template Time taken for the template selection stage. time_cost.prefill Time taken for the prefill stage. time_cost.instantiation_evaluation Time taken for the evaluation stage. time_cost.total Total time taken for the task.","title":"Schema Tabular Description"},{"location":"dataflow/result/#example-data","text":"{ \"unique_id\": \"5\", \"app\": \"word\", \"original\": { \"original_task\": \"Turning lines of text into a bulleted list in Word\", \"original_steps\": [ \"1. Place the cursor at the beginning of the line of text you want to turn into a bulleted list\", \"2. Click the Bullets button in the Paragraph group on the Home tab and choose a bullet style\" ] }, \"execution_result\": { \"result\": null, \"error\": null }, \"instantiation_result\": { \"choose_template\": { \"result\": \"dataflow\\\\results\\\\saved_document\\\\bulleted.docx\", \"error\": null }, \"prefill\": { \"result\": { \"instantiated_request\": \"Turn the line of text 'text to edit' into a bulleted list in Word.\", \"instantiated_plan\": [ { \"Step\": 1, \"Subtask\": \"Place the cursor at the beginning of the text 'text to edit'\", \"ControlLabel\": null, \"ControlText\": \"\", \"Function\": \"select_text\", \"Args\": { \"text\": \"text to edit\" } }, { \"Step\": 2, \"Subtask\": \"Click the Bullets button in the Paragraph group on the Home tab\", \"ControlLabel\": null, \"ControlText\": \"Bullets\", \"Function\": \"click_input\", \"Args\": { \"button\": \"left\", \"double\": false } } ] }, \"error\": null }, \"instantiation_evaluation\": { \"result\": { \"judge\": true, \"thought\": \"The task is specific and involves a basic function in Word that can be executed locally without any external dependencies.\", \"request_type\": \"None\" }, \"error\": null } }, \"time_cost\": { \"choose_template\": 0.012, \"prefill\": 15.649, \"instantiation_evaluation\": 2.469, \"execute\": null, \"execute_eval\": null, \"total\": 18.130 } }","title":"Example Data"},{"location":"dataflow/result/#execution-result-schema","text":"The execution result schema in the \"dataflow/schema/execution_schema.json\" defines the structure of a JSON object that is used to validate the results of task execution or dataflow . The execution result schema provides comprehensive feedback on execution , emphasizing key success metrics ( reason , sub_scores , complete ) recorded in the result field of execution_result . Key enhancements include: Each step in the instantiated_plan has been augmented with: Success : Indicates if the step executed successfully (no errors). MatchedControlText : Records the name of the last matched control. ControlLabel : Be updated to reflect the final selected control. The execute \u3001 execute_eval and total in the time_cost field is updated.","title":"Execution Result Schema"},{"location":"dataflow/result/#schema-tabular-description_1","text":"Field Description unique_id A unique identifier for the task. app The name of the application that processes the task. original Contains details about the original task, including: original.original_task A description of the original task. original.original_steps A list of steps involved in the original task. execution_result Represents the result of task execution, including any errors encountered and execution evaluation. execution_result.result Indicates the result of the task execution. execution_result.error Indicates any errors that occurred during execution. instantiation_result Provides details about the task instantiation, including: instantiation_result.choose_template.result The template selection result. instantiation_result.choose_template.error Errors, if any, during template selection. instantiation_result.prefill.result.instantiated_request The instantiated task request. instantiation_result.prefill.result.instantiated_plan.Step The step sequence number. instantiation_result.prefill.result.instantiated_plan.Subtask The description of the subtask. instantiation_result.prefill.result.instantiated_plan.ControlLabel Control label for the step. instantiation_result.prefill.result.instantiated_plan.ControlText Contextual text for the step. instantiation_result.prefill.result.instantiated_plan.Function The function executed in this step. instantiation_result.prefill.result.instantiated_plan.Args Parameters required for the function. instantiation_result.prefill.result.instantiated_plan.Success Indicates if the step was executed successfully without errors. instantiation_result.prefill.result.instantiated_plan.MatchedControlText The final matched control text in the execution flow. instantiation_result.prefill.error Errors, if any, during the prefill process. instantiation_result.instantiation_evaluation.result.judge Indicates whether the evaluation passed. instantiation_result.instantiation_evaluation.result.thought Feedback or observations from the evaluator. instantiation_result.instantiation_evaluation.result.request_type Classification of the request type. instantiation_result.instantiation_evaluation.error Errors, if any, during the evaluation. time_cost Tracks the time taken for various stages of the process, including: time_cost.choose_template Time taken for the template selection stage. time_cost.prefill Time taken for the prefill stage. time_cost.instantiation_evaluation Time taken for the evaluation stage. time_cost.execute Time taken for the execute stage. time_cost.execute_eval Time taken for the execute evaluation stage. time_cost.total Total time taken for the task.","title":"Schema Tabular Description"},{"location":"dataflow/result/#example-data_1","text":"{ \"unique_id\": \"5\", \"app\": \"word\", \"original\": { \"original_task\": \"Turning lines of text into a bulleted list in Word\", \"original_steps\": [ \"1. Place the cursor at the beginning of the line of text you want to turn into a bulleted list\", \"2. Click the Bullets button in the Paragraph group on the Home tab and choose a bullet style\" ] }, \"execution_result\": { \"result\": { \"reason\": \"The agent successfully selected the text 'text to edit' and then clicked on the 'Bullets' button in the Word application. The final screenshot shows that the text 'text to edit' has been converted into a bulleted list.\", \"sub_scores\": { \"text selection\": \"yes\", \"bulleted list conversion\": \"yes\" }, \"complete\": \"yes\" }, \"error\": null }, \"instantiation_result\": { \"choose_template\": { \"result\": \"dataflow\\\\results\\\\saved_document\\\\bulleted.docx\", \"error\": null }, \"prefill\": { \"result\": { \"instantiated_request\": \"Turn the line of text 'text to edit' into a bulleted list in Word.\", \"instantiated_plan\": [ { \"Step\": 1, \"Subtask\": \"Place the cursor at the beginning of the text 'text to edit'\", \"ControlLabel\": null, \"ControlText\": \"\", \"Function\": \"select_text\", \"Args\": { \"text\": \"text to edit\" }, \"Success\": true, \"MatchedControlText\": null }, { \"Step\": 2, \"Subtask\": \"Click the Bullets button in the Paragraph group on the Home tab\", \"ControlLabel\": \"61\", \"ControlText\": \"Bullets\", \"Function\": \"click_input\", \"Args\": { \"button\": \"left\", \"double\": false }, \"Success\": true, \"MatchedControlText\": \"Bullets\" } ] }, \"error\": null }, \"instantiation_evaluation\": { \"result\": { \"judge\": true, \"thought\": \"The task is specific and involves a basic function in Word that can be executed locally without any external dependencies.\", \"request_type\": \"None\" }, \"error\": null } }, \"time_cost\": { \"choose_template\": 0.012, \"prefill\": 15.649, \"instantiation_evaluation\": 2.469, \"execute\": 5.824, \"execute_eval\": 8.702, \"total\": 43.522 } }","title":"Example Data"},{"location":"dataflow/windows_app_env/","text":"WindowsAppEnv The usage scenarios for the WindowsAppEnv class are as follows: Opening a specified document. Matching document windows using different strategies ( contains , fuzzy , and regex ). Matching the controls required for each step in the instantiated plan using various strategies ( contains , fuzzy , and regex ). Closing a specified document. The following sections provide a detailed explanation of the matching strategies for windows and controls , as well as their usage methods. Matching Strategies In the WindowsAppEnv class, matching strategies are rules that determine how to match window or control names with a given document name or target text. Based on the configuration file, three different matching strategies can be selected: contains , fuzzy , and regex . Contains matching is the simplest strategy, suitable when the window and document names match exactly. Fuzzy matching is more flexible and can match even when there are spelling errors or partial matches between the window title and document name. Regex matching offers the most flexibility, ideal for complex matching patterns in window titles. 1. Window Matching Example The method find_matching_window is responsible for matching windows based on the configured matching strategy. Here's how you can use it to find a window by providing a document name: Example: # Initialize your application object (assuming app_object is already defined) app_env = WindowsAppEnv(app_object) # Define the document name you're looking for doc_name = \"example_document_name\" # Call find_matching_window to find the window that matches the document name matching_window = app_env.find_matching_window(doc_name) if matching_window: print(f\"Found matching window: {matching_window.element_info.name}\") else: print(\"No matching window found.\") Explanation: app_env.find_matching_window(doc_name) will search through all open windows and match the window title using the strategy defined in the configuration (contains, fuzzy, or regex). If a match is found, the matching_window object will contain the matched window, and you can print the window's name. If no match is found, it will return None . 2. Control Matching Example To find a matching control within a window, you can use the find_matching_controller method. This method requires a dictionary of filtered controls and a control text to match against. Example: # Initialize your application object (assuming app_object is already defined) app_env = WindowsAppEnv(app_object) # Define a filtered annotation dictionary of controls (control_key, control_object) # Here, we assume you have a dictionary of UIAWrapper controls from a window. filtered_annotation_dict = { 1: some_control_1, # Example control objects 2: some_control_2, # Example control objects } # Define the control text you're searching for control_text = \"submit_button\" # Call find_matching_controller to find the best match controller_key, control_selected = app_env.find_matching_controller(filtered_annotation_dict, control_text) if control_selected: print(f\"Found matching control with key {controller_key}: {control_selected.window_text()}\") else: print(\"No matching control found.\") Explanation: filtered_annotation_dict is a dictionary where the key represents the control's ID and the value is the control object ( UIAWrapper ). control_text is the text you're searching for within those controls. app_env.find_matching_controller(filtered_annotation_dict, control_text) will calculate the matching score for each control based on the defined strategy and return the control with the highest match score. If a match is found, it will return the control object ( control_selected ) and its key ( controller_key ), which can be used for further interaction. Reference Represents the Windows Application Environment. Initializes the Windows Application Environment. Parameters: app_object ( object ) \u2013 The app object containing information about the application. Source code in env/env_manager.py 29 30 31 32 33 34 35 36 37 38 def __init__ ( self , app_object : object ) -> None : \"\"\" Initializes the Windows Application Environment. :param app_object: The app object containing information about the application. \"\"\" self . app_window = None self . app_root_name = app_object . app_root_name self . app_name = app_object . description . lower () self . win_app = app_object . win_app close () Tries to gracefully close the application; if it fails or is not closed, forcefully terminates the process. Source code in env/env_manager.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def close ( self ) -> None : \"\"\" Tries to gracefully close the application; if it fails or is not closed, forcefully terminates the process. \"\"\" try : # Gracefully close the application window if self . app_window and self . app_window . process_id (): self . app_window . close () sleep ( 1 ) # Forcefully close the application window if self . app_window . element_info . name . lower () != \"\" : self . _check_and_kill_process () except Exception as e : logging . warning ( f \"Graceful close failed: { e } . Attempting to forcefully terminate the process.\" ) self . _check_and_kill_process () raise e find_matching_controller ( filtered_annotation_dict , control_text ) \" Select the best matched controller. Parameters: filtered_annotation_dict ( Dict [ int , UIAWrapper ] ) \u2013 The filtered annotation dictionary. control_text ( str ) \u2013 The text content of the control for additional context. Returns: Tuple [ str , UIAWrapper ] \u2013 Tuple containing the key of the selected controller and the control object.s Source code in env/env_manager.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 def find_matching_controller ( self , filtered_annotation_dict : Dict [ int , UIAWrapper ], control_text : str ) -> Tuple [ str , UIAWrapper ]: \"\"\" \" Select the best matched controller. :param filtered_annotation_dict: The filtered annotation dictionary. :param control_text: The text content of the control for additional context. :return: Tuple containing the key of the selected controller and the control object.s \"\"\" control_selected = None controller_key = None highest_score = 0 # Iterate through the filtered annotation dictionary to find the best match for key , control in filtered_annotation_dict . items (): # Calculate the matching score using the match function score = self . _calculate_match_score ( control , control_text ) # Update the selected control if the score is higher if score > highest_score : highest_score = score controller_key = key control_selected = control return controller_key , control_selected find_matching_window ( doc_name ) Finds a matching window based on the process name and the configured matching strategy. Parameters: doc_name ( str ) \u2013 The document name associated with the application. Returns: Optional [ UIAWrapper ] \u2013 The matched window or None if no match is found. Source code in env/env_manager.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def find_matching_window ( self , doc_name : str ) -> Optional [ UIAWrapper ]: \"\"\" Finds a matching window based on the process name and the configured matching strategy. :param doc_name: The document name associated with the application. :return: The matched window or None if no match is found. \"\"\" desktop = Desktop ( backend = _BACKEND ) windows_list = desktop . windows () for window in windows_list : window_title = window . element_info . name . lower () if self . _match_window_name ( window_title , doc_name ): self . app_window = window return window return None start ( copied_template_path ) Starts the Windows environment. Parameters: copied_template_path ( str ) \u2013 The file path to the copied template to start the environment. Source code in env/env_manager.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def start ( self , copied_template_path : str ) -> None : \"\"\" Starts the Windows environment. :param copied_template_path: The file path to the copied template to start the environment. \"\"\" from ufo.automator.ui_control import openfile file_controller = openfile . FileController ( _BACKEND ) try : file_controller . execute_code ( { \"APP\" : self . win_app , \"file_path\" : copied_template_path } ) except Exception as e : logging . exception ( f \"Failed to start the application: { e } \" ) raise","title":"Windows App Environment"},{"location":"dataflow/windows_app_env/#windowsappenv","text":"The usage scenarios for the WindowsAppEnv class are as follows: Opening a specified document. Matching document windows using different strategies ( contains , fuzzy , and regex ). Matching the controls required for each step in the instantiated plan using various strategies ( contains , fuzzy , and regex ). Closing a specified document. The following sections provide a detailed explanation of the matching strategies for windows and controls , as well as their usage methods.","title":"WindowsAppEnv"},{"location":"dataflow/windows_app_env/#matching-strategies","text":"In the WindowsAppEnv class, matching strategies are rules that determine how to match window or control names with a given document name or target text. Based on the configuration file, three different matching strategies can be selected: contains , fuzzy , and regex . Contains matching is the simplest strategy, suitable when the window and document names match exactly. Fuzzy matching is more flexible and can match even when there are spelling errors or partial matches between the window title and document name. Regex matching offers the most flexibility, ideal for complex matching patterns in window titles.","title":"Matching Strategies"},{"location":"dataflow/windows_app_env/#1-window-matching-example","text":"The method find_matching_window is responsible for matching windows based on the configured matching strategy. Here's how you can use it to find a window by providing a document name:","title":"1. Window Matching Example"},{"location":"dataflow/windows_app_env/#example","text":"# Initialize your application object (assuming app_object is already defined) app_env = WindowsAppEnv(app_object) # Define the document name you're looking for doc_name = \"example_document_name\" # Call find_matching_window to find the window that matches the document name matching_window = app_env.find_matching_window(doc_name) if matching_window: print(f\"Found matching window: {matching_window.element_info.name}\") else: print(\"No matching window found.\")","title":"Example:"},{"location":"dataflow/windows_app_env/#explanation","text":"app_env.find_matching_window(doc_name) will search through all open windows and match the window title using the strategy defined in the configuration (contains, fuzzy, or regex). If a match is found, the matching_window object will contain the matched window, and you can print the window's name. If no match is found, it will return None .","title":"Explanation:"},{"location":"dataflow/windows_app_env/#2-control-matching-example","text":"To find a matching control within a window, you can use the find_matching_controller method. This method requires a dictionary of filtered controls and a control text to match against.","title":"2. Control Matching Example"},{"location":"dataflow/windows_app_env/#example_1","text":"# Initialize your application object (assuming app_object is already defined) app_env = WindowsAppEnv(app_object) # Define a filtered annotation dictionary of controls (control_key, control_object) # Here, we assume you have a dictionary of UIAWrapper controls from a window. filtered_annotation_dict = { 1: some_control_1, # Example control objects 2: some_control_2, # Example control objects } # Define the control text you're searching for control_text = \"submit_button\" # Call find_matching_controller to find the best match controller_key, control_selected = app_env.find_matching_controller(filtered_annotation_dict, control_text) if control_selected: print(f\"Found matching control with key {controller_key}: {control_selected.window_text()}\") else: print(\"No matching control found.\")","title":"Example:"},{"location":"dataflow/windows_app_env/#explanation_1","text":"filtered_annotation_dict is a dictionary where the key represents the control's ID and the value is the control object ( UIAWrapper ). control_text is the text you're searching for within those controls. app_env.find_matching_controller(filtered_annotation_dict, control_text) will calculate the matching score for each control based on the defined strategy and return the control with the highest match score. If a match is found, it will return the control object ( control_selected ) and its key ( controller_key ), which can be used for further interaction.","title":"Explanation:"},{"location":"dataflow/windows_app_env/#reference","text":"Represents the Windows Application Environment. Initializes the Windows Application Environment. Parameters: app_object ( object ) \u2013 The app object containing information about the application. Source code in env/env_manager.py 29 30 31 32 33 34 35 36 37 38 def __init__ ( self , app_object : object ) -> None : \"\"\" Initializes the Windows Application Environment. :param app_object: The app object containing information about the application. \"\"\" self . app_window = None self . app_root_name = app_object . app_root_name self . app_name = app_object . description . lower () self . win_app = app_object . win_app","title":"Reference"},{"location":"dataflow/windows_app_env/#env.env_manager.WindowsAppEnv.close","text":"Tries to gracefully close the application; if it fails or is not closed, forcefully terminates the process. Source code in env/env_manager.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def close ( self ) -> None : \"\"\" Tries to gracefully close the application; if it fails or is not closed, forcefully terminates the process. \"\"\" try : # Gracefully close the application window if self . app_window and self . app_window . process_id (): self . app_window . close () sleep ( 1 ) # Forcefully close the application window if self . app_window . element_info . name . lower () != \"\" : self . _check_and_kill_process () except Exception as e : logging . warning ( f \"Graceful close failed: { e } . Attempting to forcefully terminate the process.\" ) self . _check_and_kill_process () raise e","title":"close"},{"location":"dataflow/windows_app_env/#env.env_manager.WindowsAppEnv.find_matching_controller","text":"\" Select the best matched controller. Parameters: filtered_annotation_dict ( Dict [ int , UIAWrapper ] ) \u2013 The filtered annotation dictionary. control_text ( str ) \u2013 The text content of the control for additional context. Returns: Tuple [ str , UIAWrapper ] \u2013 Tuple containing the key of the selected controller and the control object.s Source code in env/env_manager.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 def find_matching_controller ( self , filtered_annotation_dict : Dict [ int , UIAWrapper ], control_text : str ) -> Tuple [ str , UIAWrapper ]: \"\"\" \" Select the best matched controller. :param filtered_annotation_dict: The filtered annotation dictionary. :param control_text: The text content of the control for additional context. :return: Tuple containing the key of the selected controller and the control object.s \"\"\" control_selected = None controller_key = None highest_score = 0 # Iterate through the filtered annotation dictionary to find the best match for key , control in filtered_annotation_dict . items (): # Calculate the matching score using the match function score = self . _calculate_match_score ( control , control_text ) # Update the selected control if the score is higher if score > highest_score : highest_score = score controller_key = key control_selected = control return controller_key , control_selected","title":"find_matching_controller"},{"location":"dataflow/windows_app_env/#env.env_manager.WindowsAppEnv.find_matching_window","text":"Finds a matching window based on the process name and the configured matching strategy. Parameters: doc_name ( str ) \u2013 The document name associated with the application. Returns: Optional [ UIAWrapper ] \u2013 The matched window or None if no match is found. Source code in env/env_manager.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def find_matching_window ( self , doc_name : str ) -> Optional [ UIAWrapper ]: \"\"\" Finds a matching window based on the process name and the configured matching strategy. :param doc_name: The document name associated with the application. :return: The matched window or None if no match is found. \"\"\" desktop = Desktop ( backend = _BACKEND ) windows_list = desktop . windows () for window in windows_list : window_title = window . element_info . name . lower () if self . _match_window_name ( window_title , doc_name ): self . app_window = window return window return None","title":"find_matching_window"},{"location":"dataflow/windows_app_env/#env.env_manager.WindowsAppEnv.start","text":"Starts the Windows environment. Parameters: copied_template_path ( str ) \u2013 The file path to the copied template to start the environment. Source code in env/env_manager.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def start ( self , copied_template_path : str ) -> None : \"\"\" Starts the Windows environment. :param copied_template_path: The file path to the copied template to start the environment. \"\"\" from ufo.automator.ui_control import openfile file_controller = openfile . FileController ( _BACKEND ) try : file_controller . execute_code ( { \"APP\" : self . win_app , \"file_path\" : copied_template_path } ) except Exception as e : logging . exception ( f \"Failed to start the application: { e } \" ) raise","title":"start"},{"location":"getting_started/more_guidance/","text":"More Guidance For Users If you are a user of UFO, and want to use it to automate your tasks on Windows, you can refer to User Configuration to set up your environment and start using UFO. For instance, except for configuring the HOST_AGENT and APP_AGENT , you can also configure the LLM parameters and RAG parameters in the config.yaml file to enhance the UFO agent with additional knowledge sources. For Developers If you are a developer who wants to contribute to UFO, you can take a look at the Developer Configuration to explore the development environment setup and the development workflow. You can also refer to the Project Structure to understand the project structure and the role of each component in UFO, and use the rest of the documentation to understand the architecture and design of UFO. Taking a look at the Session and Round can help you understand the core logic of UFO. For debugging and testing, it is recommended to check the log files in the ufo/logs directory to track the execution of UFO and identify any issues that may arise.","title":"More Guidance"},{"location":"getting_started/more_guidance/#more-guidance","text":"","title":"More Guidance"},{"location":"getting_started/more_guidance/#for-users","text":"If you are a user of UFO, and want to use it to automate your tasks on Windows, you can refer to User Configuration to set up your environment and start using UFO. For instance, except for configuring the HOST_AGENT and APP_AGENT , you can also configure the LLM parameters and RAG parameters in the config.yaml file to enhance the UFO agent with additional knowledge sources.","title":"For Users"},{"location":"getting_started/more_guidance/#for-developers","text":"If you are a developer who wants to contribute to UFO, you can take a look at the Developer Configuration to explore the development environment setup and the development workflow. You can also refer to the Project Structure to understand the project structure and the role of each component in UFO, and use the rest of the documentation to understand the architecture and design of UFO. Taking a look at the Session and Round can help you understand the core logic of UFO. For debugging and testing, it is recommended to check the log files in the ufo/logs directory to track the execution of UFO and identify any issues that may arise.","title":"For Developers"},{"location":"getting_started/quick_start/","text":"Quick Start \ud83d\udee0\ufe0f Step 1: Installation UFO requires Python >= 3.10 running on Windows OS >= 10 . It can be installed by running the following command: # [optional to create conda environment] # conda create -n ufo python=3.10 # conda activate ufo # clone the repository git clone https://github.com/microsoft/UFO.git cd UFO # install the requirements pip install -r requirements.txt # If you want to use the Qwen as your LLMs, uncomment the related libs. \u2699\ufe0f Step 2: Configure the LLMs Before running UFO, you need to provide your LLM configurations individually for HostAgent and AppAgent . You can create your own config file ufo/config/config.yaml , by copying the ufo/config/config.yaml.template and editing config for HOST_AGENT and APP_AGENT as follows: copy ufo\\config\\config.yaml.template ufo\\config\\config.yaml notepad ufo\\config\\config.yaml # paste your key & endpoint OpenAI VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"openai\" , # The API type, \"openai\" for the OpenAI API. API_BASE: \"https://api.openai.com/v1/chat/completions\", # The the OpenAI API endpoint. API_KEY: \"sk-\", # The OpenAI API key, begin with sk- API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model Azure OpenAI (AOAI) VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"aoai\" , # The API type, \"aoai\" for the Azure OpenAI. API_BASE: \"YOUR_ENDPOINT\", # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com API_KEY: \"YOUR_KEY\", # The aoai API key API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model API_DEPLOYMENT_ID: \"YOUR_AOAI_DEPLOYMENT\", # The deployment id for the AOAI API You can also non-visial model (e.g., GPT-4) for each agent, by setting VISUAL_MODE: False and proper API_MODEL (openai) and API_DEPLOYMENT_ID (aoai). You can also optionally set an backup LLM engine in the field of BACKUP_AGENT if the above engines failed during the inference. The API_MODEL can be any GPT models that can accept images as input. Non-Visual Model Configuration You can utilize non-visual models (e.g., GPT-4) for each agent by configuring the following settings in the config.yaml file: Info VISUAL_MODE: False Specify the appropriate API_MODEL (OpenAI) and API_DEPLOYMENT_ID (AOAI) for each agent. Optionally, you can set a backup language model (LLM) engine in the BACKUP_AGENT field to handle cases where the primary engines fail during inference. Ensure you configure these settings accurately to leverage non-visual models effectively. Note UFO also supports other LLMs and advanced configurations, such as customize your own model, please check the documents for more details. Because of the limitations of model input, a lite version of the prompt is provided to allow users to experience it, which is configured in config_dev.yaml . \ud83d\udcd4 Step 3: Additional Setting for RAG (optional). If you want to enhance UFO's ability with external knowledge, you can optionally configure it with an external database for retrieval augmented generation (RAG) in the ufo/config/config.yaml file. We provide the following options for RAG to enhance UFO's capabilities: Offline Help Document : Enable UFO to retrieve information from offline help documents. Online Bing Search Engine : Enhance UFO's capabilities by utilizing the most up-to-date online search results. Self-Experience : Save task completion trajectories into UFO's memory for future reference. User-Demonstration : Boost UFO's capabilities through user demonstration. Tip Consult their respective documentation for more information on how to configure these settings. \ud83c\udf89 Step 4: Start UFO \u2328\ufe0f You can execute the following on your Windows command Line (CLI): # assume you are in the cloned UFO folder python -m ufo --task <your_task_name> This will start the UFO process and you can interact with it through the command line interface. If everything goes well, you will see the following message: Welcome to use UFO\ud83d\udef8, A UI-focused Agent for Windows OS Interaction. _ _ _____ ___ | | | || ___| / _ \\ | | | || |_ | | | | | |_| || _| | |_| | \\___/ |_| \\___/ Please enter your request to be completed\ud83d\udef8: Alternatively, you can also directly invoke UFO with a specific task and request by using the following command: python -m ufo --task <your_task_name> -r \"<your_request>\" Step 5 \ud83c\udfa5: Execution Logs You can find the screenshots taken and request & response logs in the following folder: ./ufo/logs/<your_task_name>/ You may use them to debug, replay, or analyze the agent output. Note The LLM accepts screenshots of your desktop and application GUI as input. Please ensure that no sensitive or confidential information is visible or captured during the execution process. For further information, refer to DISCLAIMER.md .","title":"Quick Start"},{"location":"getting_started/quick_start/#quick-start","text":"","title":"Quick Start"},{"location":"getting_started/quick_start/#step-1-installation","text":"UFO requires Python >= 3.10 running on Windows OS >= 10 . It can be installed by running the following command: # [optional to create conda environment] # conda create -n ufo python=3.10 # conda activate ufo # clone the repository git clone https://github.com/microsoft/UFO.git cd UFO # install the requirements pip install -r requirements.txt # If you want to use the Qwen as your LLMs, uncomment the related libs.","title":"\ud83d\udee0\ufe0f Step 1: Installation"},{"location":"getting_started/quick_start/#step-2-configure-the-llms","text":"Before running UFO, you need to provide your LLM configurations individually for HostAgent and AppAgent . You can create your own config file ufo/config/config.yaml , by copying the ufo/config/config.yaml.template and editing config for HOST_AGENT and APP_AGENT as follows: copy ufo\\config\\config.yaml.template ufo\\config\\config.yaml notepad ufo\\config\\config.yaml # paste your key & endpoint","title":"\u2699\ufe0f Step 2: Configure the LLMs"},{"location":"getting_started/quick_start/#openai","text":"VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"openai\" , # The API type, \"openai\" for the OpenAI API. API_BASE: \"https://api.openai.com/v1/chat/completions\", # The the OpenAI API endpoint. API_KEY: \"sk-\", # The OpenAI API key, begin with sk- API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model","title":"OpenAI"},{"location":"getting_started/quick_start/#azure-openai-aoai","text":"VISUAL_MODE: True, # Whether to use the visual mode API_TYPE: \"aoai\" , # The API type, \"aoai\" for the Azure OpenAI. API_BASE: \"YOUR_ENDPOINT\", # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com API_KEY: \"YOUR_KEY\", # The aoai API key API_VERSION: \"2024-02-15-preview\", # \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model API_DEPLOYMENT_ID: \"YOUR_AOAI_DEPLOYMENT\", # The deployment id for the AOAI API You can also non-visial model (e.g., GPT-4) for each agent, by setting VISUAL_MODE: False and proper API_MODEL (openai) and API_DEPLOYMENT_ID (aoai). You can also optionally set an backup LLM engine in the field of BACKUP_AGENT if the above engines failed during the inference. The API_MODEL can be any GPT models that can accept images as input.","title":"Azure OpenAI (AOAI)"},{"location":"getting_started/quick_start/#non-visual-model-configuration","text":"You can utilize non-visual models (e.g., GPT-4) for each agent by configuring the following settings in the config.yaml file: Info VISUAL_MODE: False Specify the appropriate API_MODEL (OpenAI) and API_DEPLOYMENT_ID (AOAI) for each agent. Optionally, you can set a backup language model (LLM) engine in the BACKUP_AGENT field to handle cases where the primary engines fail during inference. Ensure you configure these settings accurately to leverage non-visual models effectively. Note UFO also supports other LLMs and advanced configurations, such as customize your own model, please check the documents for more details. Because of the limitations of model input, a lite version of the prompt is provided to allow users to experience it, which is configured in config_dev.yaml .","title":"Non-Visual Model Configuration"},{"location":"getting_started/quick_start/#step-3-additional-setting-for-rag-optional","text":"If you want to enhance UFO's ability with external knowledge, you can optionally configure it with an external database for retrieval augmented generation (RAG) in the ufo/config/config.yaml file. We provide the following options for RAG to enhance UFO's capabilities: Offline Help Document : Enable UFO to retrieve information from offline help documents. Online Bing Search Engine : Enhance UFO's capabilities by utilizing the most up-to-date online search results. Self-Experience : Save task completion trajectories into UFO's memory for future reference. User-Demonstration : Boost UFO's capabilities through user demonstration. Tip Consult their respective documentation for more information on how to configure these settings.","title":"\ud83d\udcd4 Step 3: Additional Setting for RAG (optional)."},{"location":"getting_started/quick_start/#step-4-start-ufo","text":"","title":"\ud83c\udf89 Step 4: Start UFO"},{"location":"getting_started/quick_start/#you-can-execute-the-following-on-your-windows-command-line-cli","text":"# assume you are in the cloned UFO folder python -m ufo --task <your_task_name> This will start the UFO process and you can interact with it through the command line interface. If everything goes well, you will see the following message: Welcome to use UFO\ud83d\udef8, A UI-focused Agent for Windows OS Interaction. _ _ _____ ___ | | | || ___| / _ \\ | | | || |_ | | | | | |_| || _| | |_| | \\___/ |_| \\___/ Please enter your request to be completed\ud83d\udef8: Alternatively, you can also directly invoke UFO with a specific task and request by using the following command: python -m ufo --task <your_task_name> -r \"<your_request>\"","title":"\u2328\ufe0f You can execute the following on your Windows command Line (CLI):"},{"location":"getting_started/quick_start/#step-5-execution-logs","text":"You can find the screenshots taken and request & response logs in the following folder: ./ufo/logs/<your_task_name>/ You may use them to debug, replay, or analyze the agent output. Note The LLM accepts screenshots of your desktop and application GUI as input. Please ensure that no sensitive or confidential information is visible or captured during the execution process. For further information, refer to DISCLAIMER.md .","title":"Step 5 \ud83c\udfa5: Execution Logs"},{"location":"logs/evaluation_logs/","text":"Evaluation Logs The evaluation logs store the evaluation results from the EvaluationAgent . The evaluation log contains the following information: Field Description Type Reason The detailed reason for your judgment, by observing the screenshot differences and the . String Sub-score The sub-score of the evaluation in decomposing the evaluation into multiple sub-goals. List of Dictionaries Complete The completion status of the evaluation, can be yes , no , or unsure . String level The level of the evaluation. String request The request sent to the EvaluationAgent . Dictionary id The ID of the evaluation. Integer","title":"Evaluation Logs"},{"location":"logs/evaluation_logs/#evaluation-logs","text":"The evaluation logs store the evaluation results from the EvaluationAgent . The evaluation log contains the following information: Field Description Type Reason The detailed reason for your judgment, by observing the screenshot differences and the . String Sub-score The sub-score of the evaluation in decomposing the evaluation into multiple sub-goals. List of Dictionaries Complete The completion status of the evaluation, can be yes , no , or unsure . String level The level of the evaluation. String request The request sent to the EvaluationAgent . Dictionary id The ID of the evaluation. Integer","title":"Evaluation Logs"},{"location":"logs/markdown_log_viewer/","text":"Markdown-Formatted Log Viewer We provide a Markdown-formatted log viewer for better readability and organization of logs for debugging and analysis. The Markdown log viewer is designed to display logs in a structured format, making it easier to identify issues and understand the flow of the application. Configuration To enable the Markdown log viewer, you need to set the LOG_TO_MARKDOWN option in the config_dev.yaml file to True . Below is the detailed configuration in the config_dev.yaml file: LOG_TO_MARKDOWN: True # Whether to log to markdown format After setting this option, the logs will be saved in a Markdown format in your logs/<task_name> directory. Tip We strongly recommend to turn on this option. The development team uses this option to debug the agent's behavior and improve the performance of the agent.","title":"Markdown Log Viewer"},{"location":"logs/markdown_log_viewer/#markdown-formatted-log-viewer","text":"We provide a Markdown-formatted log viewer for better readability and organization of logs for debugging and analysis. The Markdown log viewer is designed to display logs in a structured format, making it easier to identify issues and understand the flow of the application.","title":"Markdown-Formatted Log Viewer"},{"location":"logs/markdown_log_viewer/#configuration","text":"To enable the Markdown log viewer, you need to set the LOG_TO_MARKDOWN option in the config_dev.yaml file to True . Below is the detailed configuration in the config_dev.yaml file: LOG_TO_MARKDOWN: True # Whether to log to markdown format After setting this option, the logs will be saved in a Markdown format in your logs/<task_name> directory. Tip We strongly recommend to turn on this option. The development team uses this option to debug the agent's behavior and improve the performance of the agent.","title":"Configuration"},{"location":"logs/overview/","text":"UFO Logs Logs are essential for debugging and understanding the behavior of the UFO framework. There are three types of logs generated by UFO: Log Type Description Location Level Request Log Contains the prompt requests to LLMs. logs/{task_name}/request.log Info Step Log Contains the agent's response to the user's request and additional information at every step. logs/{task_name}/response.log Info Evaluation Log Contains the evaluation results from the EvaluationAgent . logs/{task_name}/evaluation.log Info Screenshots Contains the screenshots of the application UI. logs/{task_name}/ - All logs are stored in the logs/{task_name} directory.","title":"Overview"},{"location":"logs/overview/#ufo-logs","text":"Logs are essential for debugging and understanding the behavior of the UFO framework. There are three types of logs generated by UFO: Log Type Description Location Level Request Log Contains the prompt requests to LLMs. logs/{task_name}/request.log Info Step Log Contains the agent's response to the user's request and additional information at every step. logs/{task_name}/response.log Info Evaluation Log Contains the evaluation results from the EvaluationAgent . logs/{task_name}/evaluation.log Info Screenshots Contains the screenshots of the application UI. logs/{task_name}/ - All logs are stored in the logs/{task_name} directory.","title":"UFO Logs"},{"location":"logs/request_logs/","text":"Request Logs The request is the prompt requests to the LLMs. The request log is stored in the request.log file. The request log contains the following information for each step: Field Description step The step number of the session. prompt The prompt message sent to the LLMs. The request log is stored at the debug level. You can configure the logging level in the LOG_LEVEL field in the config_dev.yaml file. Tip You can use the following python code to read the request log: import json with open('logs/{task_name}/request.log', 'r') as f: for line in f: log = json.loads(line)","title":"Request Logs"},{"location":"logs/request_logs/#request-logs","text":"The request is the prompt requests to the LLMs. The request log is stored in the request.log file. The request log contains the following information for each step: Field Description step The step number of the session. prompt The prompt message sent to the LLMs. The request log is stored at the debug level. You can configure the logging level in the LOG_LEVEL field in the config_dev.yaml file. Tip You can use the following python code to read the request log: import json with open('logs/{task_name}/request.log', 'r') as f: for line in f: log = json.loads(line)","title":"Request Logs"},{"location":"logs/screenshots_logs/","text":"Screenshot Logs UFO also save desktop or application screenshots for debugging and evaluation purposes. The screenshot logs are stored in the logs/{task_name}/ . There are 4 types of screenshot logs generated by UFO, as detailed below. Clean Screenshots At each step, UFO saves a clean screenshot of the desktop or application. The clean screenshot is saved in the action_step{step_number}.png file. In addition, the clean screenshots are also saved when a sub-task, round or session is completed. The clean screenshots are saved in the action_round_{round_id}_sub_round_{sub_task_id}_final.png , action_round_{round_id}_final.png and action_step_final.png files, respectively. Below is an example of a clean screenshot. Annotation Screenshots UFO also saves annotated screenshots of the application, with each control item is annotated with a number, following the Set-of-Mark paradigm. The annotated screenshots are saved in the action_step{step_number}_annotated.png file. Below is an example of an annotated screenshot. Info Only selected types of controls are annotated in the screenshots. They are configured in the config_dev.yaml file under the CONTROL_LIST field. Tip Different types of controls are annotated with different colors. You can configure the colors in the config_dev.yaml file under the ANNOTATION_COLORS field. Concatenated Screenshots UFO also saves concatenated screenshots of the application, with clean and annotated screenshots concatenated side by side. The concatenated screenshots are saved in the action_step{step_number}_concat.png file. Below is an example of a concatenated screenshot. Info You can configure whether to feed the concatenated screenshots to the LLMs, or separate clean and annotated screenshots, in the config_dev.yaml file under the CONCAT_SCREENSHOT field. Selected Control Screenshots UFO saves screenshots of the selected control item for operation. The selected control screenshots are saved in the action_step{step_number}_selected_controls.png file. Below is an example of a selected control screenshot. Info You can configure whether to feed LLM with the selected control screenshots at the previous step to enhance the context, in the config_dev.yaml file under the INCLUDE_LAST_SCREENSHOT field.","title":"Screenshots"},{"location":"logs/screenshots_logs/#screenshot-logs","text":"UFO also save desktop or application screenshots for debugging and evaluation purposes. The screenshot logs are stored in the logs/{task_name}/ . There are 4 types of screenshot logs generated by UFO, as detailed below.","title":"Screenshot Logs"},{"location":"logs/screenshots_logs/#clean-screenshots","text":"At each step, UFO saves a clean screenshot of the desktop or application. The clean screenshot is saved in the action_step{step_number}.png file. In addition, the clean screenshots are also saved when a sub-task, round or session is completed. The clean screenshots are saved in the action_round_{round_id}_sub_round_{sub_task_id}_final.png , action_round_{round_id}_final.png and action_step_final.png files, respectively. Below is an example of a clean screenshot.","title":"Clean Screenshots"},{"location":"logs/screenshots_logs/#annotation-screenshots","text":"UFO also saves annotated screenshots of the application, with each control item is annotated with a number, following the Set-of-Mark paradigm. The annotated screenshots are saved in the action_step{step_number}_annotated.png file. Below is an example of an annotated screenshot.","title":"Annotation Screenshots"},{"location":"logs/screenshots_logs/#concatenated-screenshots","text":"UFO also saves concatenated screenshots of the application, with clean and annotated screenshots concatenated side by side. The concatenated screenshots are saved in the action_step{step_number}_concat.png file. Below is an example of a concatenated screenshot.","title":"Concatenated Screenshots"},{"location":"logs/screenshots_logs/#selected-control-screenshots","text":"UFO saves screenshots of the selected control item for operation. The selected control screenshots are saved in the action_step{step_number}_selected_controls.png file. Below is an example of a selected control screenshot.","title":"Selected Control Screenshots"},{"location":"logs/step_logs/","text":"Step Logs The step log contains the agent's response to the user's request and additional information at every step. The step log is stored in the response.log file. The log fields are different for HostAgent and AppAgent . The step log is at the info level. HostAgent Logs The HostAgent logs contain the following fields: LLM Output Field Description Type Observation The observation of current desktop screenshots. String Thought The logical reasoning process of the HostAgent . String Current Sub-Task The current sub-task to be executed by the AppAgent . String Message The message to be sent to the AppAgent for the completion of the sub-task. String ControlLabel The index of the selected application to execute the sub-task. String ControlText The name of the selected application to execute the sub-task. String Plan The plan for the following sub-tasks after the current sub-task. List of Strings Status The status of the agent, mapped to the AgentState . String Comment Additional comments or information provided to the user. String Questions The questions to be asked to the user for additional information. List of Strings Bash The bash command to be executed by the HostAgent . It can be used to open applications or execute system commands. String Additional Information Field Description Type Step The step number of the session. Integer RoundStep The step number of the current round. Integer AgentStep The step number of the HostAgent . Integer Round The round number of the session. Integer ControlLabel The index of the selected application to execute the sub-task. Integer ControlText The name of the selected application to execute the sub-task. String Request The user request. String Agent The agent that executed the step, set to HostAgent . String AgentName The name of the agent. String Application The application process name. String Cost The cost of the step. Float Results The results of the step, set to an empty string. String CleanScreenshot The image path of the desktop screenshot. String AnnotatedScreenshot The image path of the annotated application screenshot. String ConcatScreenshot The image path of the concatenated application screenshot. String SelectedControlScreenshot The image path of the selected control screenshot. String time_cost The time cost of each step in the process. Dictionary AppAgent Logs The AppAgent logs contain the following fields: LLM Output Field Description Type Observation The observation of the current application screenshots. String Thought The logical reasoning process of the AppAgent . String ControlLabel The index of the selected control to interact with. String ControlText The name of the selected control to interact with. String Function The function to be executed on the selected control. String Args The arguments required for the function execution. List of Strings Status The status of the agent, mapped to the AgentState . String Plan The plan for the following steps after the current action. List of Strings Comment Additional comments or information provided to the user. String SaveScreenshot The flag to save the screenshot of the application to the blackboard for future reference. Boolean Additional Information Field Description Type Step The step number of the session. Integer RoundStep The step number of the current round. Integer AgentStep The step number of the AppAgent . Integer Round The round number of the session. Integer Subtask The sub-task to be executed by the AppAgent . String SubtaskIndex The index of the sub-task in the current round. Integer Action The action to be executed by the AppAgent . String ActionType The type of the action to be executed. String Request The user request. String Agent The agent that executed the step, set to AppAgent . String AgentName The name of the agent. String Application The application process name. String Cost The cost of the step. Float Results The results of the step. String CleanScreenshot The image path of the desktop screenshot. String AnnotatedScreenshot The image path of the annotated application screenshot. String ConcatScreenshot The image path of the concatenated application screenshot. String time_cost The time cost of each step in the process. Dictionary Tip You can use the following python code to read the request log: import json with open('logs/{task_name}/request.log', 'r') as f: for line in f: log = json.loads(line) Info The FollowerAgent logs share the same fields as the AppAgent logs.","title":"Step Logs"},{"location":"logs/step_logs/#step-logs","text":"The step log contains the agent's response to the user's request and additional information at every step. The step log is stored in the response.log file. The log fields are different for HostAgent and AppAgent . The step log is at the info level.","title":"Step Logs"},{"location":"logs/step_logs/#hostagent-logs","text":"The HostAgent logs contain the following fields:","title":"HostAgent Logs"},{"location":"logs/step_logs/#llm-output","text":"Field Description Type Observation The observation of current desktop screenshots. String Thought The logical reasoning process of the HostAgent . String Current Sub-Task The current sub-task to be executed by the AppAgent . String Message The message to be sent to the AppAgent for the completion of the sub-task. String ControlLabel The index of the selected application to execute the sub-task. String ControlText The name of the selected application to execute the sub-task. String Plan The plan for the following sub-tasks after the current sub-task. List of Strings Status The status of the agent, mapped to the AgentState . String Comment Additional comments or information provided to the user. String Questions The questions to be asked to the user for additional information. List of Strings Bash The bash command to be executed by the HostAgent . It can be used to open applications or execute system commands. String","title":"LLM Output"},{"location":"logs/step_logs/#additional-information","text":"Field Description Type Step The step number of the session. Integer RoundStep The step number of the current round. Integer AgentStep The step number of the HostAgent . Integer Round The round number of the session. Integer ControlLabel The index of the selected application to execute the sub-task. Integer ControlText The name of the selected application to execute the sub-task. String Request The user request. String Agent The agent that executed the step, set to HostAgent . String AgentName The name of the agent. String Application The application process name. String Cost The cost of the step. Float Results The results of the step, set to an empty string. String CleanScreenshot The image path of the desktop screenshot. String AnnotatedScreenshot The image path of the annotated application screenshot. String ConcatScreenshot The image path of the concatenated application screenshot. String SelectedControlScreenshot The image path of the selected control screenshot. String time_cost The time cost of each step in the process. Dictionary","title":"Additional Information"},{"location":"logs/step_logs/#appagent-logs","text":"The AppAgent logs contain the following fields:","title":"AppAgent Logs"},{"location":"logs/step_logs/#llm-output_1","text":"Field Description Type Observation The observation of the current application screenshots. String Thought The logical reasoning process of the AppAgent . String ControlLabel The index of the selected control to interact with. String ControlText The name of the selected control to interact with. String Function The function to be executed on the selected control. String Args The arguments required for the function execution. List of Strings Status The status of the agent, mapped to the AgentState . String Plan The plan for the following steps after the current action. List of Strings Comment Additional comments or information provided to the user. String SaveScreenshot The flag to save the screenshot of the application to the blackboard for future reference. Boolean","title":"LLM Output"},{"location":"logs/step_logs/#additional-information_1","text":"Field Description Type Step The step number of the session. Integer RoundStep The step number of the current round. Integer AgentStep The step number of the AppAgent . Integer Round The round number of the session. Integer Subtask The sub-task to be executed by the AppAgent . String SubtaskIndex The index of the sub-task in the current round. Integer Action The action to be executed by the AppAgent . String ActionType The type of the action to be executed. String Request The user request. String Agent The agent that executed the step, set to AppAgent . String AgentName The name of the agent. String Application The application process name. String Cost The cost of the step. Float Results The results of the step. String CleanScreenshot The image path of the desktop screenshot. String AnnotatedScreenshot The image path of the annotated application screenshot. String ConcatScreenshot The image path of the concatenated application screenshot. String time_cost The time cost of each step in the process. Dictionary Tip You can use the following python code to read the request log: import json with open('logs/{task_name}/request.log', 'r') as f: for line in f: log = json.loads(line) Info The FollowerAgent logs share the same fields as the AppAgent logs.","title":"Additional Information"},{"location":"logs/ui_tree_logs/","text":"UI Tree Logs UFO can save the entire UI tree of the application window at every step for data collection purposes. The UI tree can represent the application's UI structure, including the window, controls, and their properties. The UI tree logs are saved in the logs/{task_name}/ui_tree folder. You have to set the SAVE_UI_TREE flag to True in the config_dev.yaml file to enable the UI tree logs. Below is an example of the UI tree logs for application: { \"id\": \"node_0\", \"name\": \"Mail - Chaoyun Zhang - Outlook\", \"control_type\": \"Window\", \"rectangle\": { \"left\": 628, \"top\": 258, \"right\": 3508, \"bottom\": 1795 }, \"adjusted_rectangle\": { \"left\": 0, \"top\": 0, \"right\": 2880, \"bottom\": 1537 }, \"relative_rectangle\": { \"left\": 0.0, \"top\": 0.0, \"right\": 1.0, \"bottom\": 1.0 }, \"level\": 0, \"children\": [ { \"id\": \"node_1\", \"name\": \"\", \"control_type\": \"Pane\", \"rectangle\": { \"left\": 3282, \"top\": 258, \"right\": 3498, \"bottom\": 330 }, \"adjusted_rectangle\": { \"left\": 2654, \"top\": 0, \"right\": 2870, \"bottom\": 72 }, \"relative_rectangle\": { \"left\": 0.9215277777777777, \"top\": 0.0, \"right\": 0.9965277777777778, \"bottom\": 0.0468445022771633 }, \"level\": 1, \"children\": [] } ] } Fields in the UI tree logs Below is a table of the fields in the UI tree logs: Field Description Type id The unique identifier of the UI tree node. String name The name of the UI tree node. String control_type The type of the UI tree node. String rectangle The absolute position of the UI tree node. Dictionary adjusted_rectangle The adjusted position of the UI tree node. Dictionary relative_rectangle The relative position of the UI tree node. Dictionary level The level of the UI tree node. Integer children The children of the UI tree node. List of UI tree nodes Reference A class to represent the UI tree. Initialize the UI tree with the root element. Parameters: root ( UIAWrapper ) \u2013 The root element of the UI tree. Source code in automator/ui_control/ui_tree.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , root : UIAWrapper ): \"\"\" Initialize the UI tree with the root element. :param root: The root element of the UI tree. \"\"\" self . root = root # The node counter to count the number of nodes in the UI tree. self . node_counter = 0 try : self . _ui_tree = self . _get_ui_tree ( self . root ) except Exception as e : self . _ui_tree = { \"error\" : traceback . format_exc ()} ui_tree property The UI tree. apply_ui_tree_diff ( ui_tree_1 , diff ) staticmethod Apply a UI tree diff to ui_tree_1 to get ui_tree_2. Parameters: ui_tree_1 ( Dict [ str , Any ] ) \u2013 The original UI tree. diff ( Dict [ str , Any ] ) \u2013 The diff to apply. Returns: Dict [ str , Any ] \u2013 The new UI tree after applying the diff. Source code in automator/ui_control/ui_tree.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 @staticmethod def apply_ui_tree_diff ( ui_tree_1 : Dict [ str , Any ], diff : Dict [ str , Any ] ) -> Dict [ str , Any ]: \"\"\" Apply a UI tree diff to ui_tree_1 to get ui_tree_2. :param ui_tree_1: The original UI tree. :param diff: The diff to apply. :return: The new UI tree after applying the diff. \"\"\" ui_tree_2 = copy . deepcopy ( ui_tree_1 ) # Build an ID map for quick node lookups def build_id_map ( node , id_map ): id_map [ node [ \"id\" ]] = node for child in node . get ( \"children\" , []): build_id_map ( child , id_map ) id_map = {} if \"id\" in ui_tree_2 : build_id_map ( ui_tree_2 , id_map ) def remove_node_by_path ( path ): # The path is a list of IDs from root to target node. # The target node is the last element. Its parent is the second to last element. if len ( path ) == 1 : # Removing the root for k in list ( ui_tree_2 . keys ()): del ui_tree_2 [ k ] id_map . clear () return target_id = path [ - 1 ] parent_id = path [ - 2 ] parent_node = id_map [ parent_id ] # Find and remove the child with target_id for i , c in enumerate ( parent_node . get ( \"children\" , [])): if c [ \"id\" ] == target_id : parent_node [ \"children\" ] . pop ( i ) break # Remove target_id from id_map if target_id in id_map : del id_map [ target_id ] def add_node_by_path ( path , node ): # Add the node at the specified path. The parent is path[-2], the node is path[-1]. # The path[-1] should be node[\"id\"]. if len ( path ) == 1 : # Replacing the root node entirely for k in list ( ui_tree_2 . keys ()): del ui_tree_2 [ k ] for k , v in node . items (): ui_tree_2 [ k ] = v # Rebuild id_map id_map . clear () if \"id\" in ui_tree_2 : build_id_map ( ui_tree_2 , id_map ) return target_id = path [ - 1 ] parent_id = path [ - 2 ] parent_node = id_map [ parent_id ] # Ensure children list exists if \"children\" not in parent_node : parent_node [ \"children\" ] = [] # Insert or append the node # We don't have a numeric index anymore, we just append, assuming order doesn't matter. # If order matters, we must store ordering info or do some heuristic. parent_node [ \"children\" ] . append ( node ) # Update the id_map with the newly added subtree build_id_map ( node , id_map ) def modify_node_by_path ( path , changes ): # Modify fields of the node at the given ID target_id = path [ - 1 ] node = id_map [ target_id ] for field , ( old_val , new_val ) in changes . items (): node [ field ] = new_val # Apply removals first # Sort removals by length of path descending so we remove deeper nodes first. # This ensures we don't remove parents before children. for removal in sorted ( diff [ \"removed\" ], key = lambda x : len ( x [ \"path\" ]), reverse = True ): remove_node_by_path ( removal [ \"path\" ]) # Apply additions # Additions can be applied directly. for addition in diff [ \"added\" ]: add_node_by_path ( addition [ \"path\" ], addition [ \"node\" ]) # Apply modifications for modification in diff [ \"modified\" ]: modify_node_by_path ( modification [ \"path\" ], modification [ \"changes\" ]) return ui_tree_2 flatten_ui_tree () Flatten the UI tree into a list in width-first order. Source code in automator/ui_control/ui_tree.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def flatten_ui_tree ( self ) -> List [ Dict [ str , Any ]]: \"\"\" Flatten the UI tree into a list in width-first order. \"\"\" def flatten_tree ( tree : Dict [ str , Any ], result : List [ Dict [ str , Any ]]): \"\"\" Flatten the tree. :param tree: The tree to flatten. :param result: The result list. \"\"\" tree_info = { \"name\" : tree [ \"name\" ], \"control_type\" : tree [ \"control_type\" ], \"rectangle\" : tree [ \"rectangle\" ], \"adjusted_rectangle\" : tree [ \"adjusted_rectangle\" ], \"relative_rectangle\" : tree [ \"relative_rectangle\" ], \"level\" : tree [ \"level\" ], } result . append ( tree_info ) for child in tree . get ( \"children\" , []): flatten_tree ( child , result ) result = [] flatten_tree ( self . ui_tree , result ) return result save_ui_tree_to_json ( file_path ) Save the UI tree to a JSON file. Parameters: file_path ( str ) \u2013 The file path to save the UI tree. Source code in automator/ui_control/ui_tree.py 103 104 105 106 107 108 109 110 111 112 113 114 115 def save_ui_tree_to_json ( self , file_path : str ) -> None : \"\"\" Save the UI tree to a JSON file. :param file_path: The file path to save the UI tree. \"\"\" # Check if the file directory exists. If not, create it. save_dir = os . path . dirname ( file_path ) if not os . path . exists ( save_dir ): os . makedirs ( save_dir ) with open ( file_path , \"w\" ) as file : json . dump ( self . ui_tree , file , indent = 4 ) ui_tree_diff ( ui_tree_1 , ui_tree_2 ) staticmethod Compute the difference between two UI trees. Parameters: ui_tree_1 ( Dict [ str , Any ] ) \u2013 The first UI tree. ui_tree_2 ( Dict [ str , Any ] ) \u2013 The second UI tree. Returns: \u2013 The difference between the two UI trees. Source code in automator/ui_control/ui_tree.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 @staticmethod def ui_tree_diff ( ui_tree_1 : Dict [ str , Any ], ui_tree_2 : Dict [ str , Any ]): \"\"\" Compute the difference between two UI trees. :param ui_tree_1: The first UI tree. :param ui_tree_2: The second UI tree. :return: The difference between the two UI trees. \"\"\" diff = { \"added\" : [], \"removed\" : [], \"modified\" : []} def compare_nodes ( node1 , node2 , path ): # Note: `path` is a list of IDs. The last element corresponds to the current node. # If node1 doesn't exist and node2 does, it's an addition. if node1 is None and node2 is not None : diff [ \"added\" ] . append ({ \"path\" : path , \"node\" : copy . deepcopy ( node2 )}) return # If node1 exists and node2 doesn't, it's a removal. if node1 is not None and node2 is None : diff [ \"removed\" ] . append ({ \"path\" : path , \"node\" : copy . deepcopy ( node1 )}) return # If both don't exist, nothing to do. if node1 is None and node2 is None : return # Both nodes exist, check for modifications at this node fields_to_compare = [ \"name\" , \"control_type\" , \"rectangle\" , \"adjusted_rectangle\" , \"relative_rectangle\" , \"level\" , ] changes = {} for field in fields_to_compare : if node1 [ field ] != node2 [ field ]: changes [ field ] = ( node1 [ field ], node2 [ field ]) if changes : diff [ \"modified\" ] . append ({ \"path\" : path , \"changes\" : changes }) # Compare children children1 = node1 . get ( \"children\" , []) children2 = node2 . get ( \"children\" , []) # We'll assume children order is stable. If not, differences will appear as adds/removes. max_len = max ( len ( children1 ), len ( children2 )) for i in range ( max_len ): c1 = children1 [ i ] if i < len ( children1 ) else None c2 = children2 [ i ] if i < len ( children2 ) else None # Use the child's id if available from c2 (prefer new tree), else from c1 if c2 is not None : child_id = c2 [ \"id\" ] elif c1 is not None : child_id = c1 [ \"id\" ] else : # Both None shouldn't happen since max_len ensures one must exist child_id = \"unknown_child_id\" compare_nodes ( c1 , c2 , path + [ child_id ]) # Initialize the path with the root node id if it exists if ui_tree_2 and \"id\" in ui_tree_2 : root_id = ui_tree_2 [ \"id\" ] elif ui_tree_1 and \"id\" in ui_tree_1 : root_id = ui_tree_1 [ \"id\" ] else : # If no root id is present, assume a placeholder root_id = \"root\" compare_nodes ( ui_tree_1 , ui_tree_2 , [ root_id ]) return diff Note Save the UI tree logs may increase the latency of the system. It is recommended to set the SAVE_UI_TREE flag to False when you do not need the UI tree logs.","title":"UI Tree"},{"location":"logs/ui_tree_logs/#ui-tree-logs","text":"UFO can save the entire UI tree of the application window at every step for data collection purposes. The UI tree can represent the application's UI structure, including the window, controls, and their properties. The UI tree logs are saved in the logs/{task_name}/ui_tree folder. You have to set the SAVE_UI_TREE flag to True in the config_dev.yaml file to enable the UI tree logs. Below is an example of the UI tree logs for application: { \"id\": \"node_0\", \"name\": \"Mail - Chaoyun Zhang - Outlook\", \"control_type\": \"Window\", \"rectangle\": { \"left\": 628, \"top\": 258, \"right\": 3508, \"bottom\": 1795 }, \"adjusted_rectangle\": { \"left\": 0, \"top\": 0, \"right\": 2880, \"bottom\": 1537 }, \"relative_rectangle\": { \"left\": 0.0, \"top\": 0.0, \"right\": 1.0, \"bottom\": 1.0 }, \"level\": 0, \"children\": [ { \"id\": \"node_1\", \"name\": \"\", \"control_type\": \"Pane\", \"rectangle\": { \"left\": 3282, \"top\": 258, \"right\": 3498, \"bottom\": 330 }, \"adjusted_rectangle\": { \"left\": 2654, \"top\": 0, \"right\": 2870, \"bottom\": 72 }, \"relative_rectangle\": { \"left\": 0.9215277777777777, \"top\": 0.0, \"right\": 0.9965277777777778, \"bottom\": 0.0468445022771633 }, \"level\": 1, \"children\": [] } ] }","title":"UI Tree Logs"},{"location":"logs/ui_tree_logs/#fields-in-the-ui-tree-logs","text":"Below is a table of the fields in the UI tree logs: Field Description Type id The unique identifier of the UI tree node. String name The name of the UI tree node. String control_type The type of the UI tree node. String rectangle The absolute position of the UI tree node. Dictionary adjusted_rectangle The adjusted position of the UI tree node. Dictionary relative_rectangle The relative position of the UI tree node. Dictionary level The level of the UI tree node. Integer children The children of the UI tree node. List of UI tree nodes","title":"Fields in the UI tree logs"},{"location":"logs/ui_tree_logs/#reference","text":"A class to represent the UI tree. Initialize the UI tree with the root element. Parameters: root ( UIAWrapper ) \u2013 The root element of the UI tree. Source code in automator/ui_control/ui_tree.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , root : UIAWrapper ): \"\"\" Initialize the UI tree with the root element. :param root: The root element of the UI tree. \"\"\" self . root = root # The node counter to count the number of nodes in the UI tree. self . node_counter = 0 try : self . _ui_tree = self . _get_ui_tree ( self . root ) except Exception as e : self . _ui_tree = { \"error\" : traceback . format_exc ()}","title":"Reference"},{"location":"logs/ui_tree_logs/#automator.ui_control.ui_tree.UITree.ui_tree","text":"The UI tree.","title":"ui_tree"},{"location":"logs/ui_tree_logs/#automator.ui_control.ui_tree.UITree.apply_ui_tree_diff","text":"Apply a UI tree diff to ui_tree_1 to get ui_tree_2. Parameters: ui_tree_1 ( Dict [ str , Any ] ) \u2013 The original UI tree. diff ( Dict [ str , Any ] ) \u2013 The diff to apply. Returns: Dict [ str , Any ] \u2013 The new UI tree after applying the diff. Source code in automator/ui_control/ui_tree.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 @staticmethod def apply_ui_tree_diff ( ui_tree_1 : Dict [ str , Any ], diff : Dict [ str , Any ] ) -> Dict [ str , Any ]: \"\"\" Apply a UI tree diff to ui_tree_1 to get ui_tree_2. :param ui_tree_1: The original UI tree. :param diff: The diff to apply. :return: The new UI tree after applying the diff. \"\"\" ui_tree_2 = copy . deepcopy ( ui_tree_1 ) # Build an ID map for quick node lookups def build_id_map ( node , id_map ): id_map [ node [ \"id\" ]] = node for child in node . get ( \"children\" , []): build_id_map ( child , id_map ) id_map = {} if \"id\" in ui_tree_2 : build_id_map ( ui_tree_2 , id_map ) def remove_node_by_path ( path ): # The path is a list of IDs from root to target node. # The target node is the last element. Its parent is the second to last element. if len ( path ) == 1 : # Removing the root for k in list ( ui_tree_2 . keys ()): del ui_tree_2 [ k ] id_map . clear () return target_id = path [ - 1 ] parent_id = path [ - 2 ] parent_node = id_map [ parent_id ] # Find and remove the child with target_id for i , c in enumerate ( parent_node . get ( \"children\" , [])): if c [ \"id\" ] == target_id : parent_node [ \"children\" ] . pop ( i ) break # Remove target_id from id_map if target_id in id_map : del id_map [ target_id ] def add_node_by_path ( path , node ): # Add the node at the specified path. The parent is path[-2], the node is path[-1]. # The path[-1] should be node[\"id\"]. if len ( path ) == 1 : # Replacing the root node entirely for k in list ( ui_tree_2 . keys ()): del ui_tree_2 [ k ] for k , v in node . items (): ui_tree_2 [ k ] = v # Rebuild id_map id_map . clear () if \"id\" in ui_tree_2 : build_id_map ( ui_tree_2 , id_map ) return target_id = path [ - 1 ] parent_id = path [ - 2 ] parent_node = id_map [ parent_id ] # Ensure children list exists if \"children\" not in parent_node : parent_node [ \"children\" ] = [] # Insert or append the node # We don't have a numeric index anymore, we just append, assuming order doesn't matter. # If order matters, we must store ordering info or do some heuristic. parent_node [ \"children\" ] . append ( node ) # Update the id_map with the newly added subtree build_id_map ( node , id_map ) def modify_node_by_path ( path , changes ): # Modify fields of the node at the given ID target_id = path [ - 1 ] node = id_map [ target_id ] for field , ( old_val , new_val ) in changes . items (): node [ field ] = new_val # Apply removals first # Sort removals by length of path descending so we remove deeper nodes first. # This ensures we don't remove parents before children. for removal in sorted ( diff [ \"removed\" ], key = lambda x : len ( x [ \"path\" ]), reverse = True ): remove_node_by_path ( removal [ \"path\" ]) # Apply additions # Additions can be applied directly. for addition in diff [ \"added\" ]: add_node_by_path ( addition [ \"path\" ], addition [ \"node\" ]) # Apply modifications for modification in diff [ \"modified\" ]: modify_node_by_path ( modification [ \"path\" ], modification [ \"changes\" ]) return ui_tree_2","title":"apply_ui_tree_diff"},{"location":"logs/ui_tree_logs/#automator.ui_control.ui_tree.UITree.flatten_ui_tree","text":"Flatten the UI tree into a list in width-first order. Source code in automator/ui_control/ui_tree.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def flatten_ui_tree ( self ) -> List [ Dict [ str , Any ]]: \"\"\" Flatten the UI tree into a list in width-first order. \"\"\" def flatten_tree ( tree : Dict [ str , Any ], result : List [ Dict [ str , Any ]]): \"\"\" Flatten the tree. :param tree: The tree to flatten. :param result: The result list. \"\"\" tree_info = { \"name\" : tree [ \"name\" ], \"control_type\" : tree [ \"control_type\" ], \"rectangle\" : tree [ \"rectangle\" ], \"adjusted_rectangle\" : tree [ \"adjusted_rectangle\" ], \"relative_rectangle\" : tree [ \"relative_rectangle\" ], \"level\" : tree [ \"level\" ], } result . append ( tree_info ) for child in tree . get ( \"children\" , []): flatten_tree ( child , result ) result = [] flatten_tree ( self . ui_tree , result ) return result","title":"flatten_ui_tree"},{"location":"logs/ui_tree_logs/#automator.ui_control.ui_tree.UITree.save_ui_tree_to_json","text":"Save the UI tree to a JSON file. Parameters: file_path ( str ) \u2013 The file path to save the UI tree. Source code in automator/ui_control/ui_tree.py 103 104 105 106 107 108 109 110 111 112 113 114 115 def save_ui_tree_to_json ( self , file_path : str ) -> None : \"\"\" Save the UI tree to a JSON file. :param file_path: The file path to save the UI tree. \"\"\" # Check if the file directory exists. If not, create it. save_dir = os . path . dirname ( file_path ) if not os . path . exists ( save_dir ): os . makedirs ( save_dir ) with open ( file_path , \"w\" ) as file : json . dump ( self . ui_tree , file , indent = 4 )","title":"save_ui_tree_to_json"},{"location":"logs/ui_tree_logs/#automator.ui_control.ui_tree.UITree.ui_tree_diff","text":"Compute the difference between two UI trees. Parameters: ui_tree_1 ( Dict [ str , Any ] ) \u2013 The first UI tree. ui_tree_2 ( Dict [ str , Any ] ) \u2013 The second UI tree. Returns: \u2013 The difference between the two UI trees. Source code in automator/ui_control/ui_tree.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 @staticmethod def ui_tree_diff ( ui_tree_1 : Dict [ str , Any ], ui_tree_2 : Dict [ str , Any ]): \"\"\" Compute the difference between two UI trees. :param ui_tree_1: The first UI tree. :param ui_tree_2: The second UI tree. :return: The difference between the two UI trees. \"\"\" diff = { \"added\" : [], \"removed\" : [], \"modified\" : []} def compare_nodes ( node1 , node2 , path ): # Note: `path` is a list of IDs. The last element corresponds to the current node. # If node1 doesn't exist and node2 does, it's an addition. if node1 is None and node2 is not None : diff [ \"added\" ] . append ({ \"path\" : path , \"node\" : copy . deepcopy ( node2 )}) return # If node1 exists and node2 doesn't, it's a removal. if node1 is not None and node2 is None : diff [ \"removed\" ] . append ({ \"path\" : path , \"node\" : copy . deepcopy ( node1 )}) return # If both don't exist, nothing to do. if node1 is None and node2 is None : return # Both nodes exist, check for modifications at this node fields_to_compare = [ \"name\" , \"control_type\" , \"rectangle\" , \"adjusted_rectangle\" , \"relative_rectangle\" , \"level\" , ] changes = {} for field in fields_to_compare : if node1 [ field ] != node2 [ field ]: changes [ field ] = ( node1 [ field ], node2 [ field ]) if changes : diff [ \"modified\" ] . append ({ \"path\" : path , \"changes\" : changes }) # Compare children children1 = node1 . get ( \"children\" , []) children2 = node2 . get ( \"children\" , []) # We'll assume children order is stable. If not, differences will appear as adds/removes. max_len = max ( len ( children1 ), len ( children2 )) for i in range ( max_len ): c1 = children1 [ i ] if i < len ( children1 ) else None c2 = children2 [ i ] if i < len ( children2 ) else None # Use the child's id if available from c2 (prefer new tree), else from c1 if c2 is not None : child_id = c2 [ \"id\" ] elif c1 is not None : child_id = c1 [ \"id\" ] else : # Both None shouldn't happen since max_len ensures one must exist child_id = \"unknown_child_id\" compare_nodes ( c1 , c2 , path + [ child_id ]) # Initialize the path with the root node id if it exists if ui_tree_2 and \"id\" in ui_tree_2 : root_id = ui_tree_2 [ \"id\" ] elif ui_tree_1 and \"id\" in ui_tree_1 : root_id = ui_tree_1 [ \"id\" ] else : # If no root id is present, assume a placeholder root_id = \"root\" compare_nodes ( ui_tree_1 , ui_tree_2 , [ root_id ]) return diff Note Save the UI tree logs may increase the latency of the system. It is recommended to set the SAVE_UI_TREE flag to False when you do not need the UI tree logs.","title":"ui_tree_diff"},{"location":"modules/context/","text":"Context The Context object is a shared state object that stores the state of the conversation across all Rounds within a Session . It is used to maintain the context of the conversation, as well as the overall status of the conversation. Context Attributes The attributes of the Context object are defined in the ContextNames class, which is an Enum . The ContextNames class specifies various context attributes used throughout the session. Below is the definition: class ContextNames(Enum): \"\"\" The context names. \"\"\" ID = \"ID\" # The ID of the session MODE = \"MODE\" # The mode of the session LOG_PATH = \"LOG_PATH\" # The folder path to store the logs REQUEST = \"REQUEST\" # The current request SUBTASK = \"SUBTASK\" # The current subtask processed by the AppAgent PREVIOUS_SUBTASKS = \"PREVIOUS_SUBTASKS\" # The previous subtasks processed by the AppAgent HOST_MESSAGE = \"HOST_MESSAGE\" # The message from the HostAgent sent to the AppAgent REQUEST_LOGGER = \"REQUEST_LOGGER\" # The logger for the LLM request LOGGER = \"LOGGER\" # The logger for the session EVALUATION_LOGGER = \"EVALUATION_LOGGER\" # The logger for the evaluation ROUND_STEP = \"ROUND_STEP\" # The step of all rounds SESSION_STEP = \"SESSION_STEP\" # The step of the current session CURRENT_ROUND_ID = \"CURRENT_ROUND_ID\" # The ID of the current round APPLICATION_WINDOW = \"APPLICATION_WINDOW\" # The window of the application APPLICATION_PROCESS_NAME = \"APPLICATION_PROCESS_NAME\" # The process name of the application APPLICATION_ROOT_NAME = \"APPLICATION_ROOT_NAME\" # The root name of the application CONTROL_REANNOTATION = \"CONTROL_REANNOTATION\" # The re-annotation of the control provided by the AppAgent SESSION_COST = \"SESSION_COST\" # The cost of the session ROUND_COST = \"ROUND_COST\" # The cost of all rounds ROUND_SUBTASK_AMOUNT = \"ROUND_SUBTASK_AMOUNT\" # The amount of subtasks in all rounds CURRENT_ROUND_STEP = \"CURRENT_ROUND_STEP\" # The step of the current round CURRENT_ROUND_COST = \"CURRENT_ROUND_COST\" # The cost of the current round CURRENT_ROUND_SUBTASK_AMOUNT = \"CURRENT_ROUND_SUBTASK_AMOUNT\" # The amount of subtasks in the current round STRUCTURAL_LOGS = \"STRUCTURAL_LOGS\" # The structural logs of the session Each attribute is a string that represents a specific aspect of the session context, ensuring that all necessary information is accessible and manageable within the application. Attributes Description Attribute Description ID The ID of the session. MODE The mode of the session. LOG_PATH The folder path to store the logs. REQUEST The current request. SUBTASK The current subtask processed by the AppAgent. PREVIOUS_SUBTASKS The previous subtasks processed by the AppAgent. HOST_MESSAGE The message from the HostAgent sent to the AppAgent. REQUEST_LOGGER The logger for the LLM request. LOGGER The logger for the session. EVALUATION_LOGGER The logger for the evaluation. ROUND_STEP The step of all rounds. SESSION_STEP The step of the current session. CURRENT_ROUND_ID The ID of the current round. APPLICATION_WINDOW The window of the application. APPLICATION_PROCESS_NAME The process name of the application. APPLICATION_ROOT_NAME The root name of the application. CONTROL_REANNOTATION The re-annotation of the control provided by the AppAgent. SESSION_COST The cost of the session. ROUND_COST The cost of all rounds. ROUND_SUBTASK_AMOUNT The amount of subtasks in all rounds. CURRENT_ROUND_STEP The step of the current round. CURRENT_ROUND_COST The cost of the current round. CURRENT_ROUND_SUBTASK_AMOUNT The amount of subtasks in the current round. STRUCTURAL_LOGS The structural logs of the session. Reference for the Context object The context class that maintains the context for the session and agent. current_round_cost property writable Get the current round cost. current_round_step property writable Get the current round step. current_round_subtask_amount property writable Get the current round subtask index. add_to_structural_logs ( data ) Add data to the structural logs. Parameters: data ( Dict [ str , Any ] ) \u2013 The data to add to the structural logs. Source code in module/context.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 def add_to_structural_logs ( self , data : Dict [ str , Any ]) -> None : \"\"\" Add data to the structural logs. :param data: The data to add to the structural logs. \"\"\" round_key = data . get ( \"Round\" , None ) subtask_key = data . get ( \"SubtaskIndex\" , None ) if round_key is None or subtask_key is None : return remaining_items = { key : data [ key ] for key in data } self . _context [ ContextNames . STRUCTURAL_LOGS . name ][ round_key ][ subtask_key ] . append ( remaining_items ) filter_structural_logs ( round_key , subtask_key , keys ) Filter the structural logs. Parameters: round_key ( int ) \u2013 The round key. subtask_key ( int ) \u2013 The subtask key. keys ( Union [ str , List [ str ]] ) \u2013 The keys to filter. Returns: Union [ List [ Any ], List [ Dict [ str , Any ]]] \u2013 The filtered structural logs. Source code in module/context.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def filter_structural_logs ( self , round_key : int , subtask_key : int , keys : Union [ str , List [ str ]] ) -> Union [ List [ Any ], List [ Dict [ str , Any ]]]: \"\"\" Filter the structural logs. :param round_key: The round key. :param subtask_key: The subtask key. :param keys: The keys to filter. :return: The filtered structural logs. \"\"\" structural_logs = self . _context [ ContextNames . STRUCTURAL_LOGS . name ][ round_key ][ subtask_key ] if isinstance ( keys , str ): return [ log [ keys ] for log in structural_logs ] elif isinstance ( keys , list ): return [{ key : log [ key ] for key in keys } for log in structural_logs ] else : raise TypeError ( f \"Keys should be a string or a list of strings.\" ) from_dict ( context_dict ) Load the context from a dictionary. Parameters: context_dict ( Dict [ str , Any ] ) \u2013 The dictionary of the context. Source code in module/context.py 340 341 342 343 344 345 346 347 348 349 350 def from_dict ( self , context_dict : Dict [ str , Any ]) -> None : \"\"\" Load the context from a dictionary. :param context_dict: The dictionary of the context. \"\"\" for key in ContextNames : if key . name in context_dict : self . _context [ key . name ] = context_dict . get ( key . name ) # Sync the current round step and cost self . _sync_round_values () get ( key ) Get the value from the context. Parameters: key ( ContextNames ) \u2013 The context name. Returns: Any \u2013 The value from the context. Source code in module/context.py 167 168 169 170 171 172 173 174 175 def get ( self , key : ContextNames ) -> Any : \"\"\" Get the value from the context. :param key: The context name. :return: The value from the context. \"\"\" # Sync the current round step and cost self . _sync_round_values () return self . _context . get ( key . name ) set ( key , value ) Set the value in the context. Parameters: key ( ContextNames ) \u2013 The context name. value ( Any ) \u2013 The value to set in the context. Source code in module/context.py 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 def set ( self , key : ContextNames , value : Any ) -> None : \"\"\" Set the value in the context. :param key: The context name. :param value: The value to set in the context. \"\"\" if key . name in self . _context : self . _context [ key . name ] = value # Sync the current round step and cost if key == ContextNames . CURRENT_ROUND_STEP : self . current_round_step = value if key == ContextNames . CURRENT_ROUND_COST : self . current_round_cost = value if key == ContextNames . CURRENT_ROUND_SUBTASK_AMOUNT : self . current_round_subtask_amount = value else : raise KeyError ( f \"Key ' { key } ' is not a valid context name.\" ) to_dict ( ensure_serializable = False ) Convert the context to a dictionary. Parameters: ensure_serializable ( bool , default: False ) \u2013 Ensure the context is serializable. Returns: Dict [ str , Any ] \u2013 The dictionary of the context. Source code in module/context.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def to_dict ( self , ensure_serializable : bool = False ) -> Dict [ str , Any ]: \"\"\" Convert the context to a dictionary. :param ensure_serializable: Ensure the context is serializable. :return: The dictionary of the context. \"\"\" import copy context_dict = copy . deepcopy ( self . _context ) if ensure_serializable : for key in ContextNames : if key . name in context_dict : print_with_color ( f \"Warn: The value of Context. { key . name } is not serializable.\" , \"yellow\" , ) if not is_json_serializable ( context_dict [ key . name ]): context_dict [ key . name ] = None return context_dict update_dict ( key , value ) Add a dictionary to a context key. The value and the context key should be dictionaries. Parameters: key ( ContextNames ) \u2013 The context key to update. value ( Dict [ str , Any ] ) \u2013 The dictionary to add to the context key. Source code in module/context.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def update_dict ( self , key : ContextNames , value : Dict [ str , Any ]) -> None : \"\"\" Add a dictionary to a context key. The value and the context key should be dictionaries. :param key: The context key to update. :param value: The dictionary to add to the context key. \"\"\" if key . name in self . _context : context_value = self . _context [ key . name ] if isinstance ( value , dict ) and isinstance ( context_value , dict ): self . _context [ key . name ] . update ( value ) else : raise TypeError ( f \"Value for key ' { key . name } ' is { key . value } , requires a dictionary.\" ) else : raise KeyError ( f \"Key ' { key . name } ' is not a valid context name.\" )","title":"Context"},{"location":"modules/context/#context","text":"The Context object is a shared state object that stores the state of the conversation across all Rounds within a Session . It is used to maintain the context of the conversation, as well as the overall status of the conversation.","title":"Context"},{"location":"modules/context/#context-attributes","text":"The attributes of the Context object are defined in the ContextNames class, which is an Enum . The ContextNames class specifies various context attributes used throughout the session. Below is the definition: class ContextNames(Enum): \"\"\" The context names. \"\"\" ID = \"ID\" # The ID of the session MODE = \"MODE\" # The mode of the session LOG_PATH = \"LOG_PATH\" # The folder path to store the logs REQUEST = \"REQUEST\" # The current request SUBTASK = \"SUBTASK\" # The current subtask processed by the AppAgent PREVIOUS_SUBTASKS = \"PREVIOUS_SUBTASKS\" # The previous subtasks processed by the AppAgent HOST_MESSAGE = \"HOST_MESSAGE\" # The message from the HostAgent sent to the AppAgent REQUEST_LOGGER = \"REQUEST_LOGGER\" # The logger for the LLM request LOGGER = \"LOGGER\" # The logger for the session EVALUATION_LOGGER = \"EVALUATION_LOGGER\" # The logger for the evaluation ROUND_STEP = \"ROUND_STEP\" # The step of all rounds SESSION_STEP = \"SESSION_STEP\" # The step of the current session CURRENT_ROUND_ID = \"CURRENT_ROUND_ID\" # The ID of the current round APPLICATION_WINDOW = \"APPLICATION_WINDOW\" # The window of the application APPLICATION_PROCESS_NAME = \"APPLICATION_PROCESS_NAME\" # The process name of the application APPLICATION_ROOT_NAME = \"APPLICATION_ROOT_NAME\" # The root name of the application CONTROL_REANNOTATION = \"CONTROL_REANNOTATION\" # The re-annotation of the control provided by the AppAgent SESSION_COST = \"SESSION_COST\" # The cost of the session ROUND_COST = \"ROUND_COST\" # The cost of all rounds ROUND_SUBTASK_AMOUNT = \"ROUND_SUBTASK_AMOUNT\" # The amount of subtasks in all rounds CURRENT_ROUND_STEP = \"CURRENT_ROUND_STEP\" # The step of the current round CURRENT_ROUND_COST = \"CURRENT_ROUND_COST\" # The cost of the current round CURRENT_ROUND_SUBTASK_AMOUNT = \"CURRENT_ROUND_SUBTASK_AMOUNT\" # The amount of subtasks in the current round STRUCTURAL_LOGS = \"STRUCTURAL_LOGS\" # The structural logs of the session Each attribute is a string that represents a specific aspect of the session context, ensuring that all necessary information is accessible and manageable within the application.","title":"Context Attributes"},{"location":"modules/context/#attributes-description","text":"Attribute Description ID The ID of the session. MODE The mode of the session. LOG_PATH The folder path to store the logs. REQUEST The current request. SUBTASK The current subtask processed by the AppAgent. PREVIOUS_SUBTASKS The previous subtasks processed by the AppAgent. HOST_MESSAGE The message from the HostAgent sent to the AppAgent. REQUEST_LOGGER The logger for the LLM request. LOGGER The logger for the session. EVALUATION_LOGGER The logger for the evaluation. ROUND_STEP The step of all rounds. SESSION_STEP The step of the current session. CURRENT_ROUND_ID The ID of the current round. APPLICATION_WINDOW The window of the application. APPLICATION_PROCESS_NAME The process name of the application. APPLICATION_ROOT_NAME The root name of the application. CONTROL_REANNOTATION The re-annotation of the control provided by the AppAgent. SESSION_COST The cost of the session. ROUND_COST The cost of all rounds. ROUND_SUBTASK_AMOUNT The amount of subtasks in all rounds. CURRENT_ROUND_STEP The step of the current round. CURRENT_ROUND_COST The cost of the current round. CURRENT_ROUND_SUBTASK_AMOUNT The amount of subtasks in the current round. STRUCTURAL_LOGS The structural logs of the session.","title":"Attributes Description"},{"location":"modules/context/#reference-for-the-context-object","text":"The context class that maintains the context for the session and agent.","title":"Reference for the Context object"},{"location":"modules/context/#module.context.Context.current_round_cost","text":"Get the current round cost.","title":"current_round_cost"},{"location":"modules/context/#module.context.Context.current_round_step","text":"Get the current round step.","title":"current_round_step"},{"location":"modules/context/#module.context.Context.current_round_subtask_amount","text":"Get the current round subtask index.","title":"current_round_subtask_amount"},{"location":"modules/context/#module.context.Context.add_to_structural_logs","text":"Add data to the structural logs. Parameters: data ( Dict [ str , Any ] ) \u2013 The data to add to the structural logs. Source code in module/context.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 def add_to_structural_logs ( self , data : Dict [ str , Any ]) -> None : \"\"\" Add data to the structural logs. :param data: The data to add to the structural logs. \"\"\" round_key = data . get ( \"Round\" , None ) subtask_key = data . get ( \"SubtaskIndex\" , None ) if round_key is None or subtask_key is None : return remaining_items = { key : data [ key ] for key in data } self . _context [ ContextNames . STRUCTURAL_LOGS . name ][ round_key ][ subtask_key ] . append ( remaining_items )","title":"add_to_structural_logs"},{"location":"modules/context/#module.context.Context.filter_structural_logs","text":"Filter the structural logs. Parameters: round_key ( int ) \u2013 The round key. subtask_key ( int ) \u2013 The subtask key. keys ( Union [ str , List [ str ]] ) \u2013 The keys to filter. Returns: Union [ List [ Any ], List [ Dict [ str , Any ]]] \u2013 The filtered structural logs. Source code in module/context.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def filter_structural_logs ( self , round_key : int , subtask_key : int , keys : Union [ str , List [ str ]] ) -> Union [ List [ Any ], List [ Dict [ str , Any ]]]: \"\"\" Filter the structural logs. :param round_key: The round key. :param subtask_key: The subtask key. :param keys: The keys to filter. :return: The filtered structural logs. \"\"\" structural_logs = self . _context [ ContextNames . STRUCTURAL_LOGS . name ][ round_key ][ subtask_key ] if isinstance ( keys , str ): return [ log [ keys ] for log in structural_logs ] elif isinstance ( keys , list ): return [{ key : log [ key ] for key in keys } for log in structural_logs ] else : raise TypeError ( f \"Keys should be a string or a list of strings.\" )","title":"filter_structural_logs"},{"location":"modules/context/#module.context.Context.from_dict","text":"Load the context from a dictionary. Parameters: context_dict ( Dict [ str , Any ] ) \u2013 The dictionary of the context. Source code in module/context.py 340 341 342 343 344 345 346 347 348 349 350 def from_dict ( self , context_dict : Dict [ str , Any ]) -> None : \"\"\" Load the context from a dictionary. :param context_dict: The dictionary of the context. \"\"\" for key in ContextNames : if key . name in context_dict : self . _context [ key . name ] = context_dict . get ( key . name ) # Sync the current round step and cost self . _sync_round_values ()","title":"from_dict"},{"location":"modules/context/#module.context.Context.get","text":"Get the value from the context. Parameters: key ( ContextNames ) \u2013 The context name. Returns: Any \u2013 The value from the context. Source code in module/context.py 167 168 169 170 171 172 173 174 175 def get ( self , key : ContextNames ) -> Any : \"\"\" Get the value from the context. :param key: The context name. :return: The value from the context. \"\"\" # Sync the current round step and cost self . _sync_round_values () return self . _context . get ( key . name )","title":"get"},{"location":"modules/context/#module.context.Context.set","text":"Set the value in the context. Parameters: key ( ContextNames ) \u2013 The context name. value ( Any ) \u2013 The value to set in the context. Source code in module/context.py 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 def set ( self , key : ContextNames , value : Any ) -> None : \"\"\" Set the value in the context. :param key: The context name. :param value: The value to set in the context. \"\"\" if key . name in self . _context : self . _context [ key . name ] = value # Sync the current round step and cost if key == ContextNames . CURRENT_ROUND_STEP : self . current_round_step = value if key == ContextNames . CURRENT_ROUND_COST : self . current_round_cost = value if key == ContextNames . CURRENT_ROUND_SUBTASK_AMOUNT : self . current_round_subtask_amount = value else : raise KeyError ( f \"Key ' { key } ' is not a valid context name.\" )","title":"set"},{"location":"modules/context/#module.context.Context.to_dict","text":"Convert the context to a dictionary. Parameters: ensure_serializable ( bool , default: False ) \u2013 Ensure the context is serializable. Returns: Dict [ str , Any ] \u2013 The dictionary of the context. Source code in module/context.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def to_dict ( self , ensure_serializable : bool = False ) -> Dict [ str , Any ]: \"\"\" Convert the context to a dictionary. :param ensure_serializable: Ensure the context is serializable. :return: The dictionary of the context. \"\"\" import copy context_dict = copy . deepcopy ( self . _context ) if ensure_serializable : for key in ContextNames : if key . name in context_dict : print_with_color ( f \"Warn: The value of Context. { key . name } is not serializable.\" , \"yellow\" , ) if not is_json_serializable ( context_dict [ key . name ]): context_dict [ key . name ] = None return context_dict","title":"to_dict"},{"location":"modules/context/#module.context.Context.update_dict","text":"Add a dictionary to a context key. The value and the context key should be dictionaries. Parameters: key ( ContextNames ) \u2013 The context key to update. value ( Dict [ str , Any ] ) \u2013 The dictionary to add to the context key. Source code in module/context.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def update_dict ( self , key : ContextNames , value : Dict [ str , Any ]) -> None : \"\"\" Add a dictionary to a context key. The value and the context key should be dictionaries. :param key: The context key to update. :param value: The dictionary to add to the context key. \"\"\" if key . name in self . _context : context_value = self . _context [ key . name ] if isinstance ( value , dict ) and isinstance ( context_value , dict ): self . _context [ key . name ] . update ( value ) else : raise TypeError ( f \"Value for key ' { key . name } ' is { key . value } , requires a dictionary.\" ) else : raise KeyError ( f \"Key ' { key . name } ' is not a valid context name.\" )","title":"update_dict"},{"location":"modules/round/","text":"Round A Round is a single interaction between the user and UFO that processes a single user request. A Round is responsible for orchestrating the HostAgent and AppAgent to fulfill the user's request. Round Lifecycle In a Round , the following steps are executed: 1. Round Initialization At the beginning of a Round , the Round object is created, and the user's request is processed by the HostAgent to determine the appropriate application to fulfill the request. 2. Action Execution Once created, the Round orchestrates the HostAgent and AppAgent to execute the necessary actions to fulfill the user's request. The core logic of a Round is shown below: def run(self) -> None: \"\"\" Run the round. \"\"\" while not self.is_finished(): self.agent.handle(self.context) self.state = self.agent.state.next_state(self.agent) self.agent = self.agent.state.next_agent(self.agent) self.agent.set_state(self.state) # If the subtask ends, capture the last snapshot of the application. if self.state.is_subtask_end(): time.sleep(configs[\"SLEEP_TIME\"]) self.capture_last_snapshot(sub_round_id=self.subtask_amount) self.subtask_amount += 1 self.agent.blackboard.add_requests( {\"request_{i}\".format(i=self.id), self.request} ) if self.application_window is not None: self.capture_last_snapshot() if self._should_evaluate: self.evaluation() At each step, the Round processes the user's request by invoking the handle method of the AppAgent or HostAgent based on the current state. The state determines the next agent to handle the request and the next state to transition to. 3. Request Completion The AppAgent completes the actions within the application. If the request spans multiple applications, the HostAgent may switch to a different application to continue the task. 4. Round Termination Once the user's request is fulfilled, the Round is terminated, and the results are returned to the user. If configured, the EvaluationAgent evaluates the completeness of the Round . Reference Bases: ABC A round of a session in UFO. A round manages a single user request and consists of multiple steps. A session may consists of multiple rounds of interactions. Initialize a round. Parameters: request ( str ) \u2013 The request of the round. agent ( BasicAgent ) \u2013 The initial agent of the round. context ( Context ) \u2013 The shared context of the round. should_evaluate ( bool ) \u2013 Whether to evaluate the round. id ( int ) \u2013 The id of the round. Source code in module/basic.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def __init__ ( self , request : str , agent : BasicAgent , context : Context , should_evaluate : bool , id : int , ) -> None : \"\"\" Initialize a round. :param request: The request of the round. :param agent: The initial agent of the round. :param context: The shared context of the round. :param should_evaluate: Whether to evaluate the round. :param id: The id of the round. \"\"\" self . _request = request self . _context = context self . _agent = agent self . _state = agent . state self . _id = id self . _should_evaluate = should_evaluate self . _init_context () agent property writable Get the agent of the round. return: The agent of the round. application_window property writable Get the application of the session. return: The application of the session. context property Get the context of the round. return: The context of the round. cost property Get the cost of the round. return: The cost of the round. id property Get the id of the round. return: The id of the round. log_path property Get the log path of the round. return: The log path of the round. request property Get the request of the round. return: The request of the round. state property writable Get the status of the round. return: The status of the round. step property Get the local step of the round. return: The step of the round. subtask_amount property writable Get the subtask amount of the round. return: The subtask amount of the round. capture_last_snapshot ( sub_round_id = None ) Capture the last snapshot of the application, including the screenshot and the XML file if configured. Parameters: sub_round_id ( Optional [ int ] , default: None ) \u2013 The id of the sub-round, default is None. Source code in module/basic.py 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 def capture_last_snapshot ( self , sub_round_id : Optional [ int ] = None ) -> None : \"\"\" Capture the last snapshot of the application, including the screenshot and the XML file if configured. :param sub_round_id: The id of the sub-round, default is None. \"\"\" # Capture the final screenshot if sub_round_id is None : screenshot_save_path = self . log_path + f \"action_round_ { self . id } _final.png\" else : screenshot_save_path = ( self . log_path + f \"action_round_ { self . id } _sub_round_ { sub_round_id } _final.png\" ) if self . application_window is not None : try : PhotographerFacade () . capture_app_window_screenshot ( self . application_window , save_path = screenshot_save_path ) except Exception as e : utils . print_with_color ( f \"Warning: The last snapshot capture failed, due to the error: { e } \" , \"yellow\" , ) if configs . get ( \"SAVE_UI_TREE\" , False ): step_ui_tree = ui_tree . UITree ( self . application_window ) ui_tree_path = os . path . join ( self . log_path , \"ui_trees\" ) ui_tree_file_name = ( f \"ui_tree_round_ { self . id } _final.json\" if sub_round_id is None else f \"ui_tree_round_ { self . id } _sub_round_ { sub_round_id } _final.json\" ) step_ui_tree . save_ui_tree_to_json ( os . path . join ( ui_tree_path , ui_tree_file_name , ) ) if configs . get ( \"SAVE_FULL_SCREEN\" , False ): desktop_save_path = ( self . log_path + f \"desktop_round_ { self . id } _sub_round_ { sub_round_id } _final.png\" ) # Capture the desktop screenshot for all screens. PhotographerFacade () . capture_desktop_screen_screenshot ( all_screens = True , save_path = desktop_save_path ) # Save the final XML file if configs [ \"LOG_XML\" ]: log_abs_path = os . path . abspath ( self . log_path ) xml_save_path = os . path . join ( log_abs_path , ( f \"xml/action_round_ { self . id } _final.xml\" if sub_round_id is None else f \"xml/action_round_ { self . id } _sub_round_ { sub_round_id } _final.xml\" ), ) if issubclass ( type ( self . agent ), HostAgent ): app_agent : AppAgent = self . agent . get_active_appagent () app_agent . Puppeteer . save_to_xml ( xml_save_path ) elif issubclass ( type ( self . agent ), AppAgent ): app_agent : AppAgent = self . agent app_agent . Puppeteer . save_to_xml ( xml_save_path ) evaluation () TODO: Evaluate the round. Source code in module/basic.py 326 327 328 329 330 def evaluation ( self ) -> None : \"\"\" TODO: Evaluate the round. \"\"\" pass is_finished () Check if the round is finished. return: True if the round is finished, otherwise False. Source code in module/basic.py 129 130 131 132 133 134 135 136 137 def is_finished ( self ) -> bool : \"\"\" Check if the round is finished. return: True if the round is finished, otherwise False. \"\"\" return ( self . state . is_round_end () or self . context . get ( ContextNames . SESSION_STEP ) >= configs [ \"MAX_STEP\" ] ) print_cost () Print the total cost of the round. Source code in module/basic.py 227 228 229 230 231 232 233 234 235 236 237 def print_cost ( self ) -> None : \"\"\" Print the total cost of the round. \"\"\" total_cost = self . cost if isinstance ( total_cost , float ): formatted_cost = \"$ {:.2f} \" . format ( total_cost ) utils . print_with_color ( f \"Request total cost for current round is { formatted_cost } \" , \"yellow\" ) run () Run the round. Source code in module/basic.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def run ( self ) -> None : \"\"\" Run the round. \"\"\" while not self . is_finished (): self . agent . handle ( self . context ) self . state = self . agent . state . next_state ( self . agent ) self . agent = self . agent . state . next_agent ( self . agent ) self . agent . set_state ( self . state ) # If the subtask ends, capture the last snapshot of the application. if self . state . is_subtask_end (): time . sleep ( configs [ \"SLEEP_TIME\" ]) self . capture_last_snapshot ( sub_round_id = self . subtask_amount ) self . subtask_amount += 1 self . agent . blackboard . add_requests ( { \"request_ {i} \" . format ( i = self . id ): self . request } ) if self . application_window is not None : self . capture_last_snapshot () if self . _should_evaluate : self . evaluation ()","title":"Round"},{"location":"modules/round/#round","text":"A Round is a single interaction between the user and UFO that processes a single user request. A Round is responsible for orchestrating the HostAgent and AppAgent to fulfill the user's request.","title":"Round"},{"location":"modules/round/#round-lifecycle","text":"In a Round , the following steps are executed:","title":"Round Lifecycle"},{"location":"modules/round/#1-round-initialization","text":"At the beginning of a Round , the Round object is created, and the user's request is processed by the HostAgent to determine the appropriate application to fulfill the request.","title":"1. Round Initialization"},{"location":"modules/round/#2-action-execution","text":"Once created, the Round orchestrates the HostAgent and AppAgent to execute the necessary actions to fulfill the user's request. The core logic of a Round is shown below: def run(self) -> None: \"\"\" Run the round. \"\"\" while not self.is_finished(): self.agent.handle(self.context) self.state = self.agent.state.next_state(self.agent) self.agent = self.agent.state.next_agent(self.agent) self.agent.set_state(self.state) # If the subtask ends, capture the last snapshot of the application. if self.state.is_subtask_end(): time.sleep(configs[\"SLEEP_TIME\"]) self.capture_last_snapshot(sub_round_id=self.subtask_amount) self.subtask_amount += 1 self.agent.blackboard.add_requests( {\"request_{i}\".format(i=self.id), self.request} ) if self.application_window is not None: self.capture_last_snapshot() if self._should_evaluate: self.evaluation() At each step, the Round processes the user's request by invoking the handle method of the AppAgent or HostAgent based on the current state. The state determines the next agent to handle the request and the next state to transition to.","title":"2. Action Execution"},{"location":"modules/round/#3-request-completion","text":"The AppAgent completes the actions within the application. If the request spans multiple applications, the HostAgent may switch to a different application to continue the task.","title":"3. Request Completion"},{"location":"modules/round/#4-round-termination","text":"Once the user's request is fulfilled, the Round is terminated, and the results are returned to the user. If configured, the EvaluationAgent evaluates the completeness of the Round .","title":"4. Round Termination"},{"location":"modules/round/#reference","text":"Bases: ABC A round of a session in UFO. A round manages a single user request and consists of multiple steps. A session may consists of multiple rounds of interactions. Initialize a round. Parameters: request ( str ) \u2013 The request of the round. agent ( BasicAgent ) \u2013 The initial agent of the round. context ( Context ) \u2013 The shared context of the round. should_evaluate ( bool ) \u2013 Whether to evaluate the round. id ( int ) \u2013 The id of the round. Source code in module/basic.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def __init__ ( self , request : str , agent : BasicAgent , context : Context , should_evaluate : bool , id : int , ) -> None : \"\"\" Initialize a round. :param request: The request of the round. :param agent: The initial agent of the round. :param context: The shared context of the round. :param should_evaluate: Whether to evaluate the round. :param id: The id of the round. \"\"\" self . _request = request self . _context = context self . _agent = agent self . _state = agent . state self . _id = id self . _should_evaluate = should_evaluate self . _init_context ()","title":"Reference"},{"location":"modules/round/#module.basic.BaseRound.agent","text":"Get the agent of the round. return: The agent of the round.","title":"agent"},{"location":"modules/round/#module.basic.BaseRound.application_window","text":"Get the application of the session. return: The application of the session.","title":"application_window"},{"location":"modules/round/#module.basic.BaseRound.context","text":"Get the context of the round. return: The context of the round.","title":"context"},{"location":"modules/round/#module.basic.BaseRound.cost","text":"Get the cost of the round. return: The cost of the round.","title":"cost"},{"location":"modules/round/#module.basic.BaseRound.id","text":"Get the id of the round. return: The id of the round.","title":"id"},{"location":"modules/round/#module.basic.BaseRound.log_path","text":"Get the log path of the round. return: The log path of the round.","title":"log_path"},{"location":"modules/round/#module.basic.BaseRound.request","text":"Get the request of the round. return: The request of the round.","title":"request"},{"location":"modules/round/#module.basic.BaseRound.state","text":"Get the status of the round. return: The status of the round.","title":"state"},{"location":"modules/round/#module.basic.BaseRound.step","text":"Get the local step of the round. return: The step of the round.","title":"step"},{"location":"modules/round/#module.basic.BaseRound.subtask_amount","text":"Get the subtask amount of the round. return: The subtask amount of the round.","title":"subtask_amount"},{"location":"modules/round/#module.basic.BaseRound.capture_last_snapshot","text":"Capture the last snapshot of the application, including the screenshot and the XML file if configured. Parameters: sub_round_id ( Optional [ int ] , default: None ) \u2013 The id of the sub-round, default is None. Source code in module/basic.py 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 def capture_last_snapshot ( self , sub_round_id : Optional [ int ] = None ) -> None : \"\"\" Capture the last snapshot of the application, including the screenshot and the XML file if configured. :param sub_round_id: The id of the sub-round, default is None. \"\"\" # Capture the final screenshot if sub_round_id is None : screenshot_save_path = self . log_path + f \"action_round_ { self . id } _final.png\" else : screenshot_save_path = ( self . log_path + f \"action_round_ { self . id } _sub_round_ { sub_round_id } _final.png\" ) if self . application_window is not None : try : PhotographerFacade () . capture_app_window_screenshot ( self . application_window , save_path = screenshot_save_path ) except Exception as e : utils . print_with_color ( f \"Warning: The last snapshot capture failed, due to the error: { e } \" , \"yellow\" , ) if configs . get ( \"SAVE_UI_TREE\" , False ): step_ui_tree = ui_tree . UITree ( self . application_window ) ui_tree_path = os . path . join ( self . log_path , \"ui_trees\" ) ui_tree_file_name = ( f \"ui_tree_round_ { self . id } _final.json\" if sub_round_id is None else f \"ui_tree_round_ { self . id } _sub_round_ { sub_round_id } _final.json\" ) step_ui_tree . save_ui_tree_to_json ( os . path . join ( ui_tree_path , ui_tree_file_name , ) ) if configs . get ( \"SAVE_FULL_SCREEN\" , False ): desktop_save_path = ( self . log_path + f \"desktop_round_ { self . id } _sub_round_ { sub_round_id } _final.png\" ) # Capture the desktop screenshot for all screens. PhotographerFacade () . capture_desktop_screen_screenshot ( all_screens = True , save_path = desktop_save_path ) # Save the final XML file if configs [ \"LOG_XML\" ]: log_abs_path = os . path . abspath ( self . log_path ) xml_save_path = os . path . join ( log_abs_path , ( f \"xml/action_round_ { self . id } _final.xml\" if sub_round_id is None else f \"xml/action_round_ { self . id } _sub_round_ { sub_round_id } _final.xml\" ), ) if issubclass ( type ( self . agent ), HostAgent ): app_agent : AppAgent = self . agent . get_active_appagent () app_agent . Puppeteer . save_to_xml ( xml_save_path ) elif issubclass ( type ( self . agent ), AppAgent ): app_agent : AppAgent = self . agent app_agent . Puppeteer . save_to_xml ( xml_save_path )","title":"capture_last_snapshot"},{"location":"modules/round/#module.basic.BaseRound.evaluation","text":"TODO: Evaluate the round. Source code in module/basic.py 326 327 328 329 330 def evaluation ( self ) -> None : \"\"\" TODO: Evaluate the round. \"\"\" pass","title":"evaluation"},{"location":"modules/round/#module.basic.BaseRound.is_finished","text":"Check if the round is finished. return: True if the round is finished, otherwise False. Source code in module/basic.py 129 130 131 132 133 134 135 136 137 def is_finished ( self ) -> bool : \"\"\" Check if the round is finished. return: True if the round is finished, otherwise False. \"\"\" return ( self . state . is_round_end () or self . context . get ( ContextNames . SESSION_STEP ) >= configs [ \"MAX_STEP\" ] )","title":"is_finished"},{"location":"modules/round/#module.basic.BaseRound.print_cost","text":"Print the total cost of the round. Source code in module/basic.py 227 228 229 230 231 232 233 234 235 236 237 def print_cost ( self ) -> None : \"\"\" Print the total cost of the round. \"\"\" total_cost = self . cost if isinstance ( total_cost , float ): formatted_cost = \"$ {:.2f} \" . format ( total_cost ) utils . print_with_color ( f \"Request total cost for current round is { formatted_cost } \" , \"yellow\" )","title":"print_cost"},{"location":"modules/round/#module.basic.BaseRound.run","text":"Run the round. Source code in module/basic.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def run ( self ) -> None : \"\"\" Run the round. \"\"\" while not self . is_finished (): self . agent . handle ( self . context ) self . state = self . agent . state . next_state ( self . agent ) self . agent = self . agent . state . next_agent ( self . agent ) self . agent . set_state ( self . state ) # If the subtask ends, capture the last snapshot of the application. if self . state . is_subtask_end (): time . sleep ( configs [ \"SLEEP_TIME\" ]) self . capture_last_snapshot ( sub_round_id = self . subtask_amount ) self . subtask_amount += 1 self . agent . blackboard . add_requests ( { \"request_ {i} \" . format ( i = self . id ): self . request } ) if self . application_window is not None : self . capture_last_snapshot () if self . _should_evaluate : self . evaluation ()","title":"run"},{"location":"modules/session/","text":"Session A Session is a conversation instance between the user and UFO. It is a continuous interaction that starts when the user initiates a request and ends when the request is completed. UFO supports multiple requests within the same session. Each request is processed sequentially, by a Round of interaction, until the user's request is fulfilled. We show the relationship between Session and Round in the following figure: Session Lifecycle The lifecycle of a Session is as follows: 1. Session Initialization A Session is initialized when the user starts a conversation with UFO. The Session object is created, and the first Round of interaction is initiated. At this stage, the user's request is processed by the HostAgent to determine the appropriate application to fulfill the request. The Context object is created to store the state of the conversation shared across all Rounds within the Session . 2. Session Processing Once the Session is initialized, the Round of interaction begins, which completes a single user request by orchestrating the HostAgent and AppAgent . 3. Next Round After the completion of the first Round , the Session requests the next request from the user to start the next Round of interaction. This process continues until there are no more requests from the user. The core logic of a Session is shown below: def run(self) -> None: \"\"\" Run the session. \"\"\" while not self.is_finished(): round = self.create_new_round() if round is None: break round.run() if self.application_window is not None: self.capture_last_snapshot() if self._should_evaluate and not self.is_error(): self.evaluation() self.print_cost() 4. Session Termination If the user has no more requests or decides to end the conversation, the Session is terminated, and the conversation ends. The EvaluationAgent evaluates the completeness of the Session if it is configured to do so. Reference Bases: ABC A basic session in UFO. A session consists of multiple rounds of interactions and conversations. Initialize a session. Parameters: task ( str ) \u2013 The name of current task. should_evaluate ( bool ) \u2013 Whether to evaluate the session. id ( int ) \u2013 The id of the session. Source code in module/basic.py 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def __init__ ( self , task : str , should_evaluate : bool , id : int ) -> None : \"\"\" Initialize a session. :param task: The name of current task. :param should_evaluate: Whether to evaluate the session. :param id: The id of the session. \"\"\" self . _should_evaluate = should_evaluate self . _id = id # Logging-related properties self . log_path = f \"logs/ { task } /\" utils . create_folder ( self . log_path ) self . _rounds : Dict [ int , BaseRound ] = {} self . _context = Context () self . _init_context () self . _finish = False self . _results = {} self . _host_agent : HostAgent = AgentFactory . create_agent ( \"host\" , \"HostAgent\" , configs [ \"HOST_AGENT\" ][ \"VISUAL_MODE\" ], configs [ \"HOSTAGENT_PROMPT\" ], configs [ \"HOSTAGENT_EXAMPLE_PROMPT\" ], configs [ \"API_PROMPT\" ], ) application_window property writable Get the application of the session. return: The application of the session. context property Get the context of the session. return: The context of the session. cost property writable Get the cost of the session. return: The cost of the session. current_round property Get the current round of the session. return: The current round of the session. evaluation_logger property Get the logger for evaluation. return: The logger for evaluation. id property Get the id of the session. return: The id of the session. results property writable Get the evaluation results of the session. return: The evaluation results of the session. rounds property Get the rounds of the session. return: The rounds of the session. session_type property Get the class name of the session. return: The class name of the session. step property Get the step of the session. return: The step of the session. total_rounds property Get the total number of rounds in the session. return: The total number of rounds in the session. add_round ( id , round ) Add a round to the session. Parameters: id ( int ) \u2013 The id of the round. round ( BaseRound ) \u2013 The round to be added. Source code in module/basic.py 433 434 435 436 437 438 439 def add_round ( self , id : int , round : BaseRound ) -> None : \"\"\" Add a round to the session. :param id: The id of the round. :param round: The round to be added. \"\"\" self . _rounds [ id ] = round capture_last_snapshot () Capture the last snapshot of the application, including the screenshot and the XML file if configured. Source code in module/basic.py 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 def capture_last_snapshot ( self ) -> None : \"\"\" Capture the last snapshot of the application, including the screenshot and the XML file if configured. \"\"\" # Capture the final screenshot screenshot_save_path = self . log_path + f \"action_step_final.png\" if self . application_window is not None : try : PhotographerFacade () . capture_app_window_screenshot ( self . application_window , save_path = screenshot_save_path ) except Exception as e : utils . print_with_color ( f \"Warning: The last snapshot capture failed, due to the error: { e } \" , \"yellow\" , ) if configs . get ( \"SAVE_UI_TREE\" , False ): step_ui_tree = ui_tree . UITree ( self . application_window ) ui_tree_path = os . path . join ( self . log_path , \"ui_trees\" ) ui_tree_file_name = \"ui_tree_final.json\" step_ui_tree . save_ui_tree_to_json ( os . path . join ( ui_tree_path , ui_tree_file_name , ) ) if configs . get ( \"SAVE_FULL_SCREEN\" , False ): desktop_save_path = self . log_path + f \"desktop_final.png\" # Capture the desktop screenshot for all screens. PhotographerFacade () . capture_desktop_screen_screenshot ( all_screens = True , save_path = desktop_save_path ) # Save the final XML file if configs [ \"LOG_XML\" ]: log_abs_path = os . path . abspath ( self . log_path ) xml_save_path = os . path . join ( log_abs_path , f \"xml/action_step_final.xml\" ) app_agent = self . _host_agent . get_active_appagent () if app_agent is not None : app_agent . Puppeteer . save_to_xml ( xml_save_path ) create_following_round () Create a following round. return: The following round. Source code in module/basic.py 426 427 428 429 430 431 def create_following_round ( self ) -> BaseRound : \"\"\" Create a following round. return: The following round. \"\"\" pass create_new_round () abstractmethod Create a new round. Source code in module/basic.py 411 412 413 414 415 416 @abstractmethod def create_new_round ( self ) -> Optional [ BaseRound ]: \"\"\" Create a new round. \"\"\" pass evaluation () Evaluate the session. Source code in module/basic.py 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def evaluation ( self ) -> None : \"\"\" Evaluate the session. \"\"\" utils . print_with_color ( \"Evaluating the session...\" , \"yellow\" ) is_visual = configs . get ( \"EVALUATION_AGENT\" , {}) . get ( \"VISUAL_MODE\" , True ) evaluator = EvaluationAgent ( name = \"eva_agent\" , app_root_name = self . context . get ( ContextNames . APPLICATION_ROOT_NAME ), is_visual = is_visual , main_prompt = configs [ \"EVALUATION_PROMPT\" ], example_prompt = \"\" , api_prompt = configs [ \"API_PROMPT\" ], ) requests = self . request_to_evaluate () # Evaluate the session, first use the default setting, if failed, then disable the screenshot evaluation. try : result , cost = evaluator . evaluate ( request = requests , log_path = self . log_path , eva_all_screenshots = configs . get ( \"EVA_ALL_SCREENSHOTS\" , True ), ) except Exception as e : result , cost = evaluator . evaluate ( request = requests , log_path = self . log_path , eva_all_screenshots = False , ) # Add additional information to the evaluation result. additional_info = { \"level\" : \"session\" , \"request\" : requests , \"id\" : 0 } result . update ( additional_info ) self . results = result self . cost += cost evaluator . print_response ( result ) self . evaluation_logger . info ( json . dumps ( result )) experience_saver () Save the current trajectory as agent experience. Source code in module/basic.py 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 def experience_saver ( self ) -> None : \"\"\" Save the current trajectory as agent experience. \"\"\" utils . print_with_color ( \"Summarizing and saving the execution flow as experience...\" , \"yellow\" ) summarizer = ExperienceSummarizer ( configs [ \"APP_AGENT\" ][ \"VISUAL_MODE\" ], configs [ \"EXPERIENCE_PROMPT\" ], configs [ \"APPAGENT_EXAMPLE_PROMPT\" ], configs [ \"API_PROMPT\" ], ) experience = summarizer . read_logs ( self . log_path ) summaries , cost = summarizer . get_summary_list ( experience ) experience_path = configs [ \"EXPERIENCE_SAVED_PATH\" ] utils . create_folder ( experience_path ) summarizer . create_or_update_yaml ( summaries , os . path . join ( experience_path , \"experience.yaml\" ) ) summarizer . create_or_update_vector_db ( summaries , os . path . join ( experience_path , \"experience_db\" ) ) self . cost += cost utils . print_with_color ( \"The experience has been saved.\" , \"magenta\" ) initialize_logger ( log_path , log_filename , mode = 'a' , configs = configs ) staticmethod Initialize logging. log_path: The path of the log file. log_filename: The name of the log file. return: The logger. Source code in module/basic.py 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 @staticmethod def initialize_logger ( log_path : str , log_filename : str , mode = \"a\" , configs = configs ) -> logging . Logger : \"\"\" Initialize logging. log_path: The path of the log file. log_filename: The name of the log file. return: The logger. \"\"\" # Code for initializing logging logger = logging . Logger ( log_filename ) if not configs [ \"PRINT_LOG\" ]: # Remove existing handlers if PRINT_LOG is False logger . handlers = [] log_file_path = os . path . join ( log_path , log_filename ) file_handler = logging . FileHandler ( log_file_path , mode = mode , encoding = \"utf-8\" ) formatter = logging . Formatter ( \" %(message)s \" ) file_handler . setFormatter ( formatter ) logger . addHandler ( file_handler ) logger . setLevel ( configs [ \"LOG_LEVEL\" ]) return logger is_error () Check if the session is in error state. return: True if the session is in error state, otherwise False. Source code in module/basic.py 619 620 621 622 623 624 625 626 def is_error ( self ): \"\"\" Check if the session is in error state. return: True if the session is in error state, otherwise False. \"\"\" if self . current_round is not None : return self . current_round . state . name () == AgentStatus . ERROR . value return False is_finished () Check if the session is ended. return: True if the session is ended, otherwise False. Source code in module/basic.py 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 def is_finished ( self ) -> bool : \"\"\" Check if the session is ended. return: True if the session is ended, otherwise False. \"\"\" if ( self . _finish or self . step >= configs [ \"MAX_STEP\" ] or self . total_rounds >= configs [ \"MAX_ROUND\" ] ): return True if self . is_error (): return True return False next_request () abstractmethod Get the next request of the session. return: The request of the session. Source code in module/basic.py 418 419 420 421 422 423 424 @abstractmethod def next_request ( self ) -> str : \"\"\" Get the next request of the session. return: The request of the session. \"\"\" pass print_cost () Print the total cost of the session. Source code in module/basic.py 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 def print_cost ( self ) -> None : \"\"\" Print the total cost of the session. \"\"\" if isinstance ( self . cost , float ) and self . cost > 0 : formatted_cost = \"$ {:.2f} \" . format ( self . cost ) utils . print_with_color ( f \"Total request cost of the session: { formatted_cost } $\" , \"yellow\" ) else : utils . print_with_color ( \"Cost is not available for the model {host_model} or {app_model} .\" . format ( host_model = configs [ \"HOST_AGENT\" ][ \"API_MODEL\" ], app_model = configs [ \"APP_AGENT\" ][ \"API_MODEL\" ], ), \"yellow\" , ) request_to_evaluate () abstractmethod Get the request to evaluate. return: The request(s) to evaluate. Source code in module/basic.py 645 646 647 648 649 650 651 @abstractmethod def request_to_evaluate ( self ) -> str : \"\"\" Get the request to evaluate. return: The request(s) to evaluate. \"\"\" pass run () Run the session. Source code in module/basic.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def run ( self ) -> None : \"\"\" Run the session. \"\"\" while not self . is_finished (): round = self . create_new_round () if round is None : break round . run () if self . application_window is not None : self . capture_last_snapshot () if self . _should_evaluate and not self . is_error (): self . evaluation () if configs . get ( \"LOG_TO_MARKDOWN\" , True ): file_path = self . log_path trajectory = Trajectory ( file_path ) trajectory . to_markdown ( file_path + \"/output.md\" ) self . print_cost ()","title":"Session"},{"location":"modules/session/#session","text":"A Session is a conversation instance between the user and UFO. It is a continuous interaction that starts when the user initiates a request and ends when the request is completed. UFO supports multiple requests within the same session. Each request is processed sequentially, by a Round of interaction, until the user's request is fulfilled. We show the relationship between Session and Round in the following figure:","title":"Session"},{"location":"modules/session/#session-lifecycle","text":"The lifecycle of a Session is as follows:","title":"Session Lifecycle"},{"location":"modules/session/#1-session-initialization","text":"A Session is initialized when the user starts a conversation with UFO. The Session object is created, and the first Round of interaction is initiated. At this stage, the user's request is processed by the HostAgent to determine the appropriate application to fulfill the request. The Context object is created to store the state of the conversation shared across all Rounds within the Session .","title":"1. Session Initialization"},{"location":"modules/session/#2-session-processing","text":"Once the Session is initialized, the Round of interaction begins, which completes a single user request by orchestrating the HostAgent and AppAgent .","title":"2. Session Processing"},{"location":"modules/session/#3-next-round","text":"After the completion of the first Round , the Session requests the next request from the user to start the next Round of interaction. This process continues until there are no more requests from the user. The core logic of a Session is shown below: def run(self) -> None: \"\"\" Run the session. \"\"\" while not self.is_finished(): round = self.create_new_round() if round is None: break round.run() if self.application_window is not None: self.capture_last_snapshot() if self._should_evaluate and not self.is_error(): self.evaluation() self.print_cost()","title":"3. Next Round"},{"location":"modules/session/#4-session-termination","text":"If the user has no more requests or decides to end the conversation, the Session is terminated, and the conversation ends. The EvaluationAgent evaluates the completeness of the Session if it is configured to do so.","title":"4. Session Termination"},{"location":"modules/session/#reference","text":"Bases: ABC A basic session in UFO. A session consists of multiple rounds of interactions and conversations. Initialize a session. Parameters: task ( str ) \u2013 The name of current task. should_evaluate ( bool ) \u2013 Whether to evaluate the session. id ( int ) \u2013 The id of the session. Source code in module/basic.py 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def __init__ ( self , task : str , should_evaluate : bool , id : int ) -> None : \"\"\" Initialize a session. :param task: The name of current task. :param should_evaluate: Whether to evaluate the session. :param id: The id of the session. \"\"\" self . _should_evaluate = should_evaluate self . _id = id # Logging-related properties self . log_path = f \"logs/ { task } /\" utils . create_folder ( self . log_path ) self . _rounds : Dict [ int , BaseRound ] = {} self . _context = Context () self . _init_context () self . _finish = False self . _results = {} self . _host_agent : HostAgent = AgentFactory . create_agent ( \"host\" , \"HostAgent\" , configs [ \"HOST_AGENT\" ][ \"VISUAL_MODE\" ], configs [ \"HOSTAGENT_PROMPT\" ], configs [ \"HOSTAGENT_EXAMPLE_PROMPT\" ], configs [ \"API_PROMPT\" ], )","title":"Reference"},{"location":"modules/session/#module.basic.BaseSession.application_window","text":"Get the application of the session. return: The application of the session.","title":"application_window"},{"location":"modules/session/#module.basic.BaseSession.context","text":"Get the context of the session. return: The context of the session.","title":"context"},{"location":"modules/session/#module.basic.BaseSession.cost","text":"Get the cost of the session. return: The cost of the session.","title":"cost"},{"location":"modules/session/#module.basic.BaseSession.current_round","text":"Get the current round of the session. return: The current round of the session.","title":"current_round"},{"location":"modules/session/#module.basic.BaseSession.evaluation_logger","text":"Get the logger for evaluation. return: The logger for evaluation.","title":"evaluation_logger"},{"location":"modules/session/#module.basic.BaseSession.id","text":"Get the id of the session. return: The id of the session.","title":"id"},{"location":"modules/session/#module.basic.BaseSession.results","text":"Get the evaluation results of the session. return: The evaluation results of the session.","title":"results"},{"location":"modules/session/#module.basic.BaseSession.rounds","text":"Get the rounds of the session. return: The rounds of the session.","title":"rounds"},{"location":"modules/session/#module.basic.BaseSession.session_type","text":"Get the class name of the session. return: The class name of the session.","title":"session_type"},{"location":"modules/session/#module.basic.BaseSession.step","text":"Get the step of the session. return: The step of the session.","title":"step"},{"location":"modules/session/#module.basic.BaseSession.total_rounds","text":"Get the total number of rounds in the session. return: The total number of rounds in the session.","title":"total_rounds"},{"location":"modules/session/#module.basic.BaseSession.add_round","text":"Add a round to the session. Parameters: id ( int ) \u2013 The id of the round. round ( BaseRound ) \u2013 The round to be added. Source code in module/basic.py 433 434 435 436 437 438 439 def add_round ( self , id : int , round : BaseRound ) -> None : \"\"\" Add a round to the session. :param id: The id of the round. :param round: The round to be added. \"\"\" self . _rounds [ id ] = round","title":"add_round"},{"location":"modules/session/#module.basic.BaseSession.capture_last_snapshot","text":"Capture the last snapshot of the application, including the screenshot and the XML file if configured. Source code in module/basic.py 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 def capture_last_snapshot ( self ) -> None : \"\"\" Capture the last snapshot of the application, including the screenshot and the XML file if configured. \"\"\" # Capture the final screenshot screenshot_save_path = self . log_path + f \"action_step_final.png\" if self . application_window is not None : try : PhotographerFacade () . capture_app_window_screenshot ( self . application_window , save_path = screenshot_save_path ) except Exception as e : utils . print_with_color ( f \"Warning: The last snapshot capture failed, due to the error: { e } \" , \"yellow\" , ) if configs . get ( \"SAVE_UI_TREE\" , False ): step_ui_tree = ui_tree . UITree ( self . application_window ) ui_tree_path = os . path . join ( self . log_path , \"ui_trees\" ) ui_tree_file_name = \"ui_tree_final.json\" step_ui_tree . save_ui_tree_to_json ( os . path . join ( ui_tree_path , ui_tree_file_name , ) ) if configs . get ( \"SAVE_FULL_SCREEN\" , False ): desktop_save_path = self . log_path + f \"desktop_final.png\" # Capture the desktop screenshot for all screens. PhotographerFacade () . capture_desktop_screen_screenshot ( all_screens = True , save_path = desktop_save_path ) # Save the final XML file if configs [ \"LOG_XML\" ]: log_abs_path = os . path . abspath ( self . log_path ) xml_save_path = os . path . join ( log_abs_path , f \"xml/action_step_final.xml\" ) app_agent = self . _host_agent . get_active_appagent () if app_agent is not None : app_agent . Puppeteer . save_to_xml ( xml_save_path )","title":"capture_last_snapshot"},{"location":"modules/session/#module.basic.BaseSession.create_following_round","text":"Create a following round. return: The following round. Source code in module/basic.py 426 427 428 429 430 431 def create_following_round ( self ) -> BaseRound : \"\"\" Create a following round. return: The following round. \"\"\" pass","title":"create_following_round"},{"location":"modules/session/#module.basic.BaseSession.create_new_round","text":"Create a new round. Source code in module/basic.py 411 412 413 414 415 416 @abstractmethod def create_new_round ( self ) -> Optional [ BaseRound ]: \"\"\" Create a new round. \"\"\" pass","title":"create_new_round"},{"location":"modules/session/#module.basic.BaseSession.evaluation","text":"Evaluate the session. Source code in module/basic.py 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def evaluation ( self ) -> None : \"\"\" Evaluate the session. \"\"\" utils . print_with_color ( \"Evaluating the session...\" , \"yellow\" ) is_visual = configs . get ( \"EVALUATION_AGENT\" , {}) . get ( \"VISUAL_MODE\" , True ) evaluator = EvaluationAgent ( name = \"eva_agent\" , app_root_name = self . context . get ( ContextNames . APPLICATION_ROOT_NAME ), is_visual = is_visual , main_prompt = configs [ \"EVALUATION_PROMPT\" ], example_prompt = \"\" , api_prompt = configs [ \"API_PROMPT\" ], ) requests = self . request_to_evaluate () # Evaluate the session, first use the default setting, if failed, then disable the screenshot evaluation. try : result , cost = evaluator . evaluate ( request = requests , log_path = self . log_path , eva_all_screenshots = configs . get ( \"EVA_ALL_SCREENSHOTS\" , True ), ) except Exception as e : result , cost = evaluator . evaluate ( request = requests , log_path = self . log_path , eva_all_screenshots = False , ) # Add additional information to the evaluation result. additional_info = { \"level\" : \"session\" , \"request\" : requests , \"id\" : 0 } result . update ( additional_info ) self . results = result self . cost += cost evaluator . print_response ( result ) self . evaluation_logger . info ( json . dumps ( result ))","title":"evaluation"},{"location":"modules/session/#module.basic.BaseSession.experience_saver","text":"Save the current trajectory as agent experience. Source code in module/basic.py 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 def experience_saver ( self ) -> None : \"\"\" Save the current trajectory as agent experience. \"\"\" utils . print_with_color ( \"Summarizing and saving the execution flow as experience...\" , \"yellow\" ) summarizer = ExperienceSummarizer ( configs [ \"APP_AGENT\" ][ \"VISUAL_MODE\" ], configs [ \"EXPERIENCE_PROMPT\" ], configs [ \"APPAGENT_EXAMPLE_PROMPT\" ], configs [ \"API_PROMPT\" ], ) experience = summarizer . read_logs ( self . log_path ) summaries , cost = summarizer . get_summary_list ( experience ) experience_path = configs [ \"EXPERIENCE_SAVED_PATH\" ] utils . create_folder ( experience_path ) summarizer . create_or_update_yaml ( summaries , os . path . join ( experience_path , \"experience.yaml\" ) ) summarizer . create_or_update_vector_db ( summaries , os . path . join ( experience_path , \"experience_db\" ) ) self . cost += cost utils . print_with_color ( \"The experience has been saved.\" , \"magenta\" )","title":"experience_saver"},{"location":"modules/session/#module.basic.BaseSession.initialize_logger","text":"Initialize logging. log_path: The path of the log file. log_filename: The name of the log file. return: The logger. Source code in module/basic.py 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 @staticmethod def initialize_logger ( log_path : str , log_filename : str , mode = \"a\" , configs = configs ) -> logging . Logger : \"\"\" Initialize logging. log_path: The path of the log file. log_filename: The name of the log file. return: The logger. \"\"\" # Code for initializing logging logger = logging . Logger ( log_filename ) if not configs [ \"PRINT_LOG\" ]: # Remove existing handlers if PRINT_LOG is False logger . handlers = [] log_file_path = os . path . join ( log_path , log_filename ) file_handler = logging . FileHandler ( log_file_path , mode = mode , encoding = \"utf-8\" ) formatter = logging . Formatter ( \" %(message)s \" ) file_handler . setFormatter ( formatter ) logger . addHandler ( file_handler ) logger . setLevel ( configs [ \"LOG_LEVEL\" ]) return logger","title":"initialize_logger"},{"location":"modules/session/#module.basic.BaseSession.is_error","text":"Check if the session is in error state. return: True if the session is in error state, otherwise False. Source code in module/basic.py 619 620 621 622 623 624 625 626 def is_error ( self ): \"\"\" Check if the session is in error state. return: True if the session is in error state, otherwise False. \"\"\" if self . current_round is not None : return self . current_round . state . name () == AgentStatus . ERROR . value return False","title":"is_error"},{"location":"modules/session/#module.basic.BaseSession.is_finished","text":"Check if the session is ended. return: True if the session is ended, otherwise False. Source code in module/basic.py 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 def is_finished ( self ) -> bool : \"\"\" Check if the session is ended. return: True if the session is ended, otherwise False. \"\"\" if ( self . _finish or self . step >= configs [ \"MAX_STEP\" ] or self . total_rounds >= configs [ \"MAX_ROUND\" ] ): return True if self . is_error (): return True return False","title":"is_finished"},{"location":"modules/session/#module.basic.BaseSession.next_request","text":"Get the next request of the session. return: The request of the session. Source code in module/basic.py 418 419 420 421 422 423 424 @abstractmethod def next_request ( self ) -> str : \"\"\" Get the next request of the session. return: The request of the session. \"\"\" pass","title":"next_request"},{"location":"modules/session/#module.basic.BaseSession.print_cost","text":"Print the total cost of the session. Source code in module/basic.py 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 def print_cost ( self ) -> None : \"\"\" Print the total cost of the session. \"\"\" if isinstance ( self . cost , float ) and self . cost > 0 : formatted_cost = \"$ {:.2f} \" . format ( self . cost ) utils . print_with_color ( f \"Total request cost of the session: { formatted_cost } $\" , \"yellow\" ) else : utils . print_with_color ( \"Cost is not available for the model {host_model} or {app_model} .\" . format ( host_model = configs [ \"HOST_AGENT\" ][ \"API_MODEL\" ], app_model = configs [ \"APP_AGENT\" ][ \"API_MODEL\" ], ), \"yellow\" , )","title":"print_cost"},{"location":"modules/session/#module.basic.BaseSession.request_to_evaluate","text":"Get the request to evaluate. return: The request(s) to evaluate. Source code in module/basic.py 645 646 647 648 649 650 651 @abstractmethod def request_to_evaluate ( self ) -> str : \"\"\" Get the request to evaluate. return: The request(s) to evaluate. \"\"\" pass","title":"request_to_evaluate"},{"location":"modules/session/#module.basic.BaseSession.run","text":"Run the session. Source code in module/basic.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def run ( self ) -> None : \"\"\" Run the session. \"\"\" while not self . is_finished (): round = self . create_new_round () if round is None : break round . run () if self . application_window is not None : self . capture_last_snapshot () if self . _should_evaluate and not self . is_error (): self . evaluation () if configs . get ( \"LOG_TO_MARKDOWN\" , True ): file_path = self . log_path trajectory = Trajectory ( file_path ) trajectory . to_markdown ( file_path + \"/output.md\" ) self . print_cost ()","title":"run"},{"location":"prompts/api_prompts/","text":"API Prompts The API prompts provide the description and usage of the APIs used in UFO. Shared APIs and app-specific APIs are stored in different directories: Directory Description ufo/prompts/share/base/api.yaml Shared APIs used by multiple applications ufo/prompts/{app_name} APIs specific to an application Info You can configure the API prompt used in the config.yaml file. You can find more information about the configuration file here . Tip You may customize the API prompt for a specific application by adding the API prompt in the application's directory. Example API Prompt Below is an example of an API prompt: click_input: summary: |- \"click_input\" is to click the control item with mouse. class_name: |- ClickInputCommand usage: |- [1] API call: click_input(button: str, double: bool) [2] Args: - button: 'The mouse button to click. One of ''left'', ''right'', ''middle'' or ''x'' (Default: ''left'')' - double: 'Whether to perform a double click or not (Default: False)' [3] Example: click_input(button=\"left\", double=False) [4] Available control item: All control items. [5] Return: None To create a new API prompt, follow the template above and add it to the appropriate directory.","title":"API Prompts"},{"location":"prompts/api_prompts/#api-prompts","text":"The API prompts provide the description and usage of the APIs used in UFO. Shared APIs and app-specific APIs are stored in different directories: Directory Description ufo/prompts/share/base/api.yaml Shared APIs used by multiple applications ufo/prompts/{app_name} APIs specific to an application Info You can configure the API prompt used in the config.yaml file. You can find more information about the configuration file here . Tip You may customize the API prompt for a specific application by adding the API prompt in the application's directory.","title":"API Prompts"},{"location":"prompts/api_prompts/#example-api-prompt","text":"Below is an example of an API prompt: click_input: summary: |- \"click_input\" is to click the control item with mouse. class_name: |- ClickInputCommand usage: |- [1] API call: click_input(button: str, double: bool) [2] Args: - button: 'The mouse button to click. One of ''left'', ''right'', ''middle'' or ''x'' (Default: ''left'')' - double: 'Whether to perform a double click or not (Default: False)' [3] Example: click_input(button=\"left\", double=False) [4] Available control item: All control items. [5] Return: None To create a new API prompt, follow the template above and add it to the appropriate directory.","title":"Example API Prompt"},{"location":"prompts/basic_template/","text":"Basic Prompt Template The basic prompt template is a fixed format that is used to generate prompts for the HostAgent , AppAgent , FollowerAgent , and EvaluationAgent . It include the template for the system and user roles to construct the agent's prompt. Below is the default file path for the basic prompt template: Agent File Path Version HostAgent ufo/prompts/share/base/host_agent.yaml base HostAgent ufo/prompts/share/lite/host_agent.yaml lite AppAgent ufo/prompts/share/base/app_agent.yaml base AppAgent ufo/prompts/share/lite/app_agent.yaml lite FollowerAgent ufo/prompts/share/base/app_agent.yaml base FollowerAgent ufo/prompts/share/lite/app_agent.yaml lite EvaluationAgent ufo/prompts/evaluation/evaluation_agent.yaml - Info You can configure the prompt template used in the config.yaml file. You can find more information about the configuration file here .","title":"Basic Prompts"},{"location":"prompts/basic_template/#basic-prompt-template","text":"The basic prompt template is a fixed format that is used to generate prompts for the HostAgent , AppAgent , FollowerAgent , and EvaluationAgent . It include the template for the system and user roles to construct the agent's prompt. Below is the default file path for the basic prompt template: Agent File Path Version HostAgent ufo/prompts/share/base/host_agent.yaml base HostAgent ufo/prompts/share/lite/host_agent.yaml lite AppAgent ufo/prompts/share/base/app_agent.yaml base AppAgent ufo/prompts/share/lite/app_agent.yaml lite FollowerAgent ufo/prompts/share/base/app_agent.yaml base FollowerAgent ufo/prompts/share/lite/app_agent.yaml lite EvaluationAgent ufo/prompts/evaluation/evaluation_agent.yaml - Info You can configure the prompt template used in the config.yaml file. You can find more information about the configuration file here .","title":"Basic Prompt Template"},{"location":"prompts/examples_prompts/","text":"Example Prompts The example prompts are used to generate textual demonstration examples for in-context learning. The examples are stored in the ufo/prompts/examples directory, with the following subdirectories: Directory Description lite Lite version of demonstration examples non-visual Examples for non-visual LLMs visual Examples for visual LLMs Info You can configure the example prompt used in the config.yaml file. You can find more information about the configuration file here . Example Prompts Below are examples for the HostAgent and AppAgent : HostAgent : Request: |- Summarize and add all to do items on Microsoft To Do from the meeting notes email, and write a summary on the meeting_notes.docx. Response: Observation: |- The current screenshot shows the Microsoft To Do application is visible, and outlook application and the meeting_notes.docx are available in the list of applications. Thought: |- The user request can be decomposed into three sub-tasks: (1) Summarize all to do items on Microsoft To Do from the meeting_notes email, (2) Add all to do items to Microsoft To Do, and (3) Write a summary on the meeting_notes.docx. I need to open the Microsoft To Do application to complete the first two sub-tasks. Each sub-task will be completed in individual applications sequentially. CurrentSubtask: |- Summarized all to do items from the meeting notes email in Outlook. Message: - (1) You need to first search for the meeting notes email in Outlook to summarize. - (2) Only summarize the to do items from the meeting notes email, without any redundant information. ControlLabel: |- 16 ControlText: |- Mail - Outlook - Jim Status: |- CONTINUE Plan: - Add all to do items previously summarized from the meeting notes email to one-by-one Microsoft To Do. - Write a summary about the meeting notes email on the meeting_notes.docx. Comment: |- I plan to first summarize all to do items from the meeting notes email in Outlook. Questions: [] AppAgent : Request: |- How many stars does the Imdiffusion repo have? Sub-task: |- Google search for the Imdiffusion repo on github and summarize the number of stars the Imdiffusion repo page visually. Response: Observation: |- I observe that the Edge browser is visible in the screenshot, with the Google search page opened. Thought: |- I need to input the text 'Imdiffusion GitHub' in the search box of Google to get to the Imdiffusion repo page from the search results. The search box is usually in a type of ComboBox. ControlLabel: |- 36 ControlText: |- \u641c\u7d22 Function: |- set_edit_text Args: {\"text\": \"Imdiffusion GitHub\"} Status: |- CONTINUE Plan: - (1) After input 'Imdiffusion GitHub', click Google Search to search for the Imdiffusion repo on github. - (2) Once the searched results are visible, click the Imdiffusion repo Hyperlink in the searched results to open the repo page. - (3) Observing and summarize the number of stars the Imdiffusion repo page, and reply to the user request. Comment: |- I plan to use Google search for the Imdiffusion repo on github and summarize the number of stars the Imdiffusion repo page visually. SaveScreenshot: {\"save\": false, \"reason\": \"\"} Tips: |- - The search box is usually in a type of ComboBox. - The number of stars of a Github repo page can be found in the repo page visually. These examples regulate the output format of the agent's response and provide a structured way to generate demonstration examples for in-context learning.","title":"Examples Prompts"},{"location":"prompts/examples_prompts/#example-prompts","text":"The example prompts are used to generate textual demonstration examples for in-context learning. The examples are stored in the ufo/prompts/examples directory, with the following subdirectories: Directory Description lite Lite version of demonstration examples non-visual Examples for non-visual LLMs visual Examples for visual LLMs Info You can configure the example prompt used in the config.yaml file. You can find more information about the configuration file here .","title":"Example Prompts"},{"location":"prompts/examples_prompts/#example-prompts_1","text":"Below are examples for the HostAgent and AppAgent : HostAgent : Request: |- Summarize and add all to do items on Microsoft To Do from the meeting notes email, and write a summary on the meeting_notes.docx. Response: Observation: |- The current screenshot shows the Microsoft To Do application is visible, and outlook application and the meeting_notes.docx are available in the list of applications. Thought: |- The user request can be decomposed into three sub-tasks: (1) Summarize all to do items on Microsoft To Do from the meeting_notes email, (2) Add all to do items to Microsoft To Do, and (3) Write a summary on the meeting_notes.docx. I need to open the Microsoft To Do application to complete the first two sub-tasks. Each sub-task will be completed in individual applications sequentially. CurrentSubtask: |- Summarized all to do items from the meeting notes email in Outlook. Message: - (1) You need to first search for the meeting notes email in Outlook to summarize. - (2) Only summarize the to do items from the meeting notes email, without any redundant information. ControlLabel: |- 16 ControlText: |- Mail - Outlook - Jim Status: |- CONTINUE Plan: - Add all to do items previously summarized from the meeting notes email to one-by-one Microsoft To Do. - Write a summary about the meeting notes email on the meeting_notes.docx. Comment: |- I plan to first summarize all to do items from the meeting notes email in Outlook. Questions: [] AppAgent : Request: |- How many stars does the Imdiffusion repo have? Sub-task: |- Google search for the Imdiffusion repo on github and summarize the number of stars the Imdiffusion repo page visually. Response: Observation: |- I observe that the Edge browser is visible in the screenshot, with the Google search page opened. Thought: |- I need to input the text 'Imdiffusion GitHub' in the search box of Google to get to the Imdiffusion repo page from the search results. The search box is usually in a type of ComboBox. ControlLabel: |- 36 ControlText: |- \u641c\u7d22 Function: |- set_edit_text Args: {\"text\": \"Imdiffusion GitHub\"} Status: |- CONTINUE Plan: - (1) After input 'Imdiffusion GitHub', click Google Search to search for the Imdiffusion repo on github. - (2) Once the searched results are visible, click the Imdiffusion repo Hyperlink in the searched results to open the repo page. - (3) Observing and summarize the number of stars the Imdiffusion repo page, and reply to the user request. Comment: |- I plan to use Google search for the Imdiffusion repo on github and summarize the number of stars the Imdiffusion repo page visually. SaveScreenshot: {\"save\": false, \"reason\": \"\"} Tips: |- - The search box is usually in a type of ComboBox. - The number of stars of a Github repo page can be found in the repo page visually. These examples regulate the output format of the agent's response and provide a structured way to generate demonstration examples for in-context learning.","title":"Example Prompts"},{"location":"prompts/overview/","text":"Prompts All prompts used in UFO are stored in the ufo/prompts directory. The folder structure is as follows: \ud83d\udce6prompts \u2523 \ud83d\udcc2apps # Stores API prompts for specific applications \u2523 \ud83d\udcc2excel # Stores API prompts for Excel \u2523 \ud83d\udcc2word # Stores API prompts for Word \u2517 ... \u2523 \ud83d\udcc2demonstration # Stores prompts for summarizing demonstrations from humans using Step Recorder \u2523 \ud83d\udcc2experience # Stores prompts for summarizing the agent's self-experience \u2523 \ud83d\udcc2evaluation # Stores prompts for the EvaluationAgent \u2523 \ud83d\udcc2examples # Stores demonstration examples for in-context learning \u2523 \ud83d\udcc2lite # Lite version of demonstration examples \u2523 \ud83d\udcc2non-visual # Examples for non-visual LLMs \u2517 \ud83d\udcc2visual # Examples for visual LLMs \u2517 \ud83d\udcc2share # Stores shared prompts \u2523 \ud83d\udcc2lite # Lite version of shared prompts \u2517 \ud83d\udcc2base # Basic version of shared prompts \u2523 \ud83d\udcdcapi.yaml # Basic API prompt \u2523 \ud83d\udcdcapp_agent.yaml # Basic AppAgent prompt template \u2517 \ud83d\udcdchost_agent.yaml # Basic HostAgent prompt template Note The lite version of prompts is a simplified version of the full prompts, which is used for LLMs that have a limited token budget. However, the lite version is not fully optimized and may lead to suboptimal performance. Note The non-visual and visual folders contain examples for non-visual and visual LLMs, respectively. Agent Prompts Prompts used an agent usually contain the following information: Prompt Description Basic template A basic template for the agent prompt. API A prompt for all skills and APIs used by the agent. Examples Demonstration examples for the agent for in-context learning. You can find these prompts share directory. The prompts for specific applications are stored in the apps directory. Tip All information is constructed using the agent's Prompter class. You can find more details about the Prompter class in the documentation here .","title":"Overview"},{"location":"prompts/overview/#prompts","text":"All prompts used in UFO are stored in the ufo/prompts directory. The folder structure is as follows: \ud83d\udce6prompts \u2523 \ud83d\udcc2apps # Stores API prompts for specific applications \u2523 \ud83d\udcc2excel # Stores API prompts for Excel \u2523 \ud83d\udcc2word # Stores API prompts for Word \u2517 ... \u2523 \ud83d\udcc2demonstration # Stores prompts for summarizing demonstrations from humans using Step Recorder \u2523 \ud83d\udcc2experience # Stores prompts for summarizing the agent's self-experience \u2523 \ud83d\udcc2evaluation # Stores prompts for the EvaluationAgent \u2523 \ud83d\udcc2examples # Stores demonstration examples for in-context learning \u2523 \ud83d\udcc2lite # Lite version of demonstration examples \u2523 \ud83d\udcc2non-visual # Examples for non-visual LLMs \u2517 \ud83d\udcc2visual # Examples for visual LLMs \u2517 \ud83d\udcc2share # Stores shared prompts \u2523 \ud83d\udcc2lite # Lite version of shared prompts \u2517 \ud83d\udcc2base # Basic version of shared prompts \u2523 \ud83d\udcdcapi.yaml # Basic API prompt \u2523 \ud83d\udcdcapp_agent.yaml # Basic AppAgent prompt template \u2517 \ud83d\udcdchost_agent.yaml # Basic HostAgent prompt template Note The lite version of prompts is a simplified version of the full prompts, which is used for LLMs that have a limited token budget. However, the lite version is not fully optimized and may lead to suboptimal performance. Note The non-visual and visual folders contain examples for non-visual and visual LLMs, respectively.","title":"Prompts"},{"location":"prompts/overview/#agent-prompts","text":"Prompts used an agent usually contain the following information: Prompt Description Basic template A basic template for the agent prompt. API A prompt for all skills and APIs used by the agent. Examples Demonstration examples for the agent for in-context learning. You can find these prompts share directory. The prompts for specific applications are stored in the apps directory. Tip All information is constructed using the agent's Prompter class. You can find more details about the Prompter class in the documentation here .","title":"Agent Prompts"},{"location":"supported_models/azure_openai/","text":"Azure OpenAI (AOAI) Step 1 To use the Azure OpenAI API, you need to create an account on the Azure OpenAI website . After creating an account, you can deploy the AOAI API and access the API key. Step 2 After obtaining the API key, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Azure OpenAI API. The following is an example configuration for the Azure OpenAI API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"aoai\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_BASE: \"YOUR_ENDPOINT\", # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com API_KEY: \"YOUR_KEY\", # The aoai API key API_VERSION: \"2024-02-15-preview\", # The version of the API, \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model name, \"gpt-4-vision-preview\" by default. You may also use \"gpt-4o\" for using the GPT-4O model. API_DEPLOYMENT_ID: \"YOUR_AOAI_DEPLOYMENT\", # The deployment id for the AOAI API If you want to use AAD for authentication, you should also set the following configuration: AAD_TENANT_ID: \"YOUR_TENANT_ID\", # Set the value to your tenant id for the llm model AAD_API_SCOPE: \"YOUR_SCOPE\", # Set the value to your scope for the llm model AAD_API_SCOPE_BASE: \"YOUR_SCOPE_BASE\" # Set the value to your scope base for the llm model, whose format is API://YOUR_SCOPE_BASE, and the only need is the YOUR_SCOPE_BASE Tip If you set VISUAL_MODE to True , make sure the API_DEPLOYMENT_ID supports visual inputs. Step 3 After configuring the HOST_AGENT and APP_AGENT with the OpenAI API, you can start using UFO to interact with the AOAI API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Azure OpenAI"},{"location":"supported_models/azure_openai/#azure-openai-aoai","text":"","title":"Azure OpenAI (AOAI)"},{"location":"supported_models/azure_openai/#step-1","text":"To use the Azure OpenAI API, you need to create an account on the Azure OpenAI website . After creating an account, you can deploy the AOAI API and access the API key.","title":"Step 1"},{"location":"supported_models/azure_openai/#step-2","text":"After obtaining the API key, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Azure OpenAI API. The following is an example configuration for the Azure OpenAI API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"aoai\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_BASE: \"YOUR_ENDPOINT\", # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com API_KEY: \"YOUR_KEY\", # The aoai API key API_VERSION: \"2024-02-15-preview\", # The version of the API, \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model name, \"gpt-4-vision-preview\" by default. You may also use \"gpt-4o\" for using the GPT-4O model. API_DEPLOYMENT_ID: \"YOUR_AOAI_DEPLOYMENT\", # The deployment id for the AOAI API If you want to use AAD for authentication, you should also set the following configuration: AAD_TENANT_ID: \"YOUR_TENANT_ID\", # Set the value to your tenant id for the llm model AAD_API_SCOPE: \"YOUR_SCOPE\", # Set the value to your scope for the llm model AAD_API_SCOPE_BASE: \"YOUR_SCOPE_BASE\" # Set the value to your scope base for the llm model, whose format is API://YOUR_SCOPE_BASE, and the only need is the YOUR_SCOPE_BASE Tip If you set VISUAL_MODE to True , make sure the API_DEPLOYMENT_ID supports visual inputs.","title":"Step 2"},{"location":"supported_models/azure_openai/#step-3","text":"After configuring the HOST_AGENT and APP_AGENT with the OpenAI API, you can start using UFO to interact with the AOAI API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 3"},{"location":"supported_models/claude/","text":"Anthropic Claude Step 1 To use the Claude API, you need to create an account on the Claude website and access the API key. Step 2 You may need to install additional dependencies to use the Claude API. You can install the dependencies using the following command: pip install -U anthropic==0.37.1 Step 3 Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Claude API. The following is an example configuration for the Claude API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"Claude\" , API_KEY: \"YOUR_KEY\", API_MODEL: \"YOUR_MODEL\" Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. Tip API_MODEL is the model name of Claude LLM API. You can find the model name in the Claude LLM model list. Step 4 After configuring the HOST_AGENT and APP_AGENT with the Claude API, you can start using UFO to interact with the Claude API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Claude"},{"location":"supported_models/claude/#anthropic-claude","text":"","title":"Anthropic Claude"},{"location":"supported_models/claude/#step-1","text":"To use the Claude API, you need to create an account on the Claude website and access the API key.","title":"Step 1"},{"location":"supported_models/claude/#step-2","text":"You may need to install additional dependencies to use the Claude API. You can install the dependencies using the following command: pip install -U anthropic==0.37.1","title":"Step 2"},{"location":"supported_models/claude/#step-3","text":"Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Claude API. The following is an example configuration for the Claude API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"Claude\" , API_KEY: \"YOUR_KEY\", API_MODEL: \"YOUR_MODEL\" Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. Tip API_MODEL is the model name of Claude LLM API. You can find the model name in the Claude LLM model list.","title":"Step 3"},{"location":"supported_models/claude/#step-4","text":"After configuring the HOST_AGENT and APP_AGENT with the Claude API, you can start using UFO to interact with the Claude API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 4"},{"location":"supported_models/custom_model/","text":"Customized LLM Models We support and welcome the integration of custom LLM models in UFO. If you have a custom LLM model that you would like to use with UFO, you can follow the steps below to configure the model in UFO. Step 1 Create a custom LLM model and serve it on your local environment. Step 2 Create a python script under the ufo/llm directory, and implement your own LLM model class by inheriting the BaseService class in the ufo/llm/base.py file. We leave a PlaceHolderService class in the ufo/llm/placeholder.py file as an example. You must implement the chat_completion method in your LLM model class to accept a list of messages and return a list of completions for each message. def chat_completion( self, messages, n, temperature: Optional[float] = None, max_tokens: Optional[int] = None, top_p: Optional[float] = None, **kwargs: Any, ): \"\"\" Generates completions for a given list of messages. Args: messages (List[str]): The list of messages to generate completions for. n (int): The number of completions to generate for each message. temperature (float, optional): Controls the randomness of the generated completions. Higher values (e.g., 0.8) make the completions more random, while lower values (e.g., 0.2) make the completions more focused and deterministic. If not provided, the default value from the model configuration will be used. max_tokens (int, optional): The maximum number of tokens in the generated completions. If not provided, the default value from the model configuration will be used. top_p (float, optional): Controls the diversity of the generated completions. Higher values (e.g., 0.8) make the completions more diverse, while lower values (e.g., 0.2) make the completions more focused. If not provided, the default value from the model configuration will be used. **kwargs: Additional keyword arguments to be passed to the underlying completion method. Returns: List[str], None:A list of generated completions for each message and the cost set to be None. Raises: Exception: If an error occurs while making the API request. \"\"\" pass Step 3 After implementing the LLM model class, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the custom LLM model. The following is an example configuration for the custom LLM model: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"custom_model\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_BASE: \"YOUR_ENDPOINT\", # The custom LLM API address. API_MODEL: \"YOUR_MODEL\", # The custom LLM model name. Step 4 After configuring the HOST_AGENT and APP_AGENT with the custom LLM model, you can start using UFO to interact with the custom LLM model for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Custom Model"},{"location":"supported_models/custom_model/#customized-llm-models","text":"We support and welcome the integration of custom LLM models in UFO. If you have a custom LLM model that you would like to use with UFO, you can follow the steps below to configure the model in UFO.","title":"Customized LLM Models"},{"location":"supported_models/custom_model/#step-1","text":"Create a custom LLM model and serve it on your local environment.","title":"Step 1"},{"location":"supported_models/custom_model/#step-2","text":"Create a python script under the ufo/llm directory, and implement your own LLM model class by inheriting the BaseService class in the ufo/llm/base.py file. We leave a PlaceHolderService class in the ufo/llm/placeholder.py file as an example. You must implement the chat_completion method in your LLM model class to accept a list of messages and return a list of completions for each message. def chat_completion( self, messages, n, temperature: Optional[float] = None, max_tokens: Optional[int] = None, top_p: Optional[float] = None, **kwargs: Any, ): \"\"\" Generates completions for a given list of messages. Args: messages (List[str]): The list of messages to generate completions for. n (int): The number of completions to generate for each message. temperature (float, optional): Controls the randomness of the generated completions. Higher values (e.g., 0.8) make the completions more random, while lower values (e.g., 0.2) make the completions more focused and deterministic. If not provided, the default value from the model configuration will be used. max_tokens (int, optional): The maximum number of tokens in the generated completions. If not provided, the default value from the model configuration will be used. top_p (float, optional): Controls the diversity of the generated completions. Higher values (e.g., 0.8) make the completions more diverse, while lower values (e.g., 0.2) make the completions more focused. If not provided, the default value from the model configuration will be used. **kwargs: Additional keyword arguments to be passed to the underlying completion method. Returns: List[str], None:A list of generated completions for each message and the cost set to be None. Raises: Exception: If an error occurs while making the API request. \"\"\" pass","title":"Step 2"},{"location":"supported_models/custom_model/#step-3","text":"After implementing the LLM model class, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the custom LLM model. The following is an example configuration for the custom LLM model: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"custom_model\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_BASE: \"YOUR_ENDPOINT\", # The custom LLM API address. API_MODEL: \"YOUR_MODEL\", # The custom LLM model name.","title":"Step 3"},{"location":"supported_models/custom_model/#step-4","text":"After configuring the HOST_AGENT and APP_AGENT with the custom LLM model, you can start using UFO to interact with the custom LLM model for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 4"},{"location":"supported_models/deepseek/","text":"DeepSeek Model Step 1 DeepSeek is developed by Alibaba DAMO Academy. To use the DeepSeek models, Go to DeepSeek and register an account and get the API key. Step 2 Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the DeepSeek model. The following is an example configuration for the DeepSeek model: VISUAL_MODE: False, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"deepseek\" , # The API type, \"deepseek\" for the DeepSeek model. API_KEY: \"YOUR_KEY\", # The DeepSeek API key API_MODEL: \"YOUR_MODEL\" # The DeepSeek model name Tip Most DeepSeek models don't support visual inputs, rembmer to set VISUAL_MODE to False . Step 3 After configuring the HOST_AGENT and APP_AGENT with the DeepSeek model, you can start using UFO to interact with the DeepSeek model for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"DeepSeek"},{"location":"supported_models/deepseek/#deepseek-model","text":"","title":"DeepSeek Model"},{"location":"supported_models/deepseek/#step-1","text":"DeepSeek is developed by Alibaba DAMO Academy. To use the DeepSeek models, Go to DeepSeek and register an account and get the API key.","title":"Step 1"},{"location":"supported_models/deepseek/#step-2","text":"Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the DeepSeek model. The following is an example configuration for the DeepSeek model: VISUAL_MODE: False, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"deepseek\" , # The API type, \"deepseek\" for the DeepSeek model. API_KEY: \"YOUR_KEY\", # The DeepSeek API key API_MODEL: \"YOUR_MODEL\" # The DeepSeek model name Tip Most DeepSeek models don't support visual inputs, rembmer to set VISUAL_MODE to False .","title":"Step 2"},{"location":"supported_models/deepseek/#step-3","text":"After configuring the HOST_AGENT and APP_AGENT with the DeepSeek model, you can start using UFO to interact with the DeepSeek model for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 3"},{"location":"supported_models/gemini/","text":"Google Gemini Step 1 To use the Google Gemini API, you need to create an account on the Google Gemini website and access the API key. Step 2 You may need to install additional dependencies to use the Google Gemini API. You can install the dependencies using the following command: pip install -U google-genai==1.12.1 Step 3 Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Google Gemini API. The following is an example configuration for the Google Gemini API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"Gemini\" , API_KEY: \"YOUR_KEY\", API_MODEL: \"YOUR_MODEL\" Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. Tip API_MODEL is the model name of Gemini LLM API. You can find the model name in the Gemini LLM model list. If you meet the 429 Resource has been exhausted (e.g. check quota)., it may because the rate limit of your Gemini API. Step 4 After configuring the HOST_AGENT and APP_AGENT with the Gemini API, you can start using UFO to interact with the Gemini API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Gemini"},{"location":"supported_models/gemini/#google-gemini","text":"","title":"Google Gemini"},{"location":"supported_models/gemini/#step-1","text":"To use the Google Gemini API, you need to create an account on the Google Gemini website and access the API key.","title":"Step 1"},{"location":"supported_models/gemini/#step-2","text":"You may need to install additional dependencies to use the Google Gemini API. You can install the dependencies using the following command: pip install -U google-genai==1.12.1","title":"Step 2"},{"location":"supported_models/gemini/#step-3","text":"Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Google Gemini API. The following is an example configuration for the Google Gemini API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"Gemini\" , API_KEY: \"YOUR_KEY\", API_MODEL: \"YOUR_MODEL\" Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. Tip API_MODEL is the model name of Gemini LLM API. You can find the model name in the Gemini LLM model list. If you meet the 429 Resource has been exhausted (e.g. check quota)., it may because the rate limit of your Gemini API.","title":"Step 3"},{"location":"supported_models/gemini/#step-4","text":"After configuring the HOST_AGENT and APP_AGENT with the Gemini API, you can start using UFO to interact with the Gemini API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 4"},{"location":"supported_models/ollama/","text":"Ollama Step 1 If you want to use the Ollama model, Go to Ollama and follow the instructions to serve a LLM model on your local environment. We provide a short example to show how to configure the ollama in the following, which might change if ollama makes updates. ## Install ollama on Linux & WSL2 curl https://ollama.ai/install.sh | sh ## Run the serving ollama serve Step 2 Open another terminal and run the following command to test the ollama model: ollama run YOUR_MODEL Info When serving LLMs via Ollama, it will by default start a server at http://localhost:11434 , which will later be used as the API base in config.yaml . Step 3 After obtaining the API key, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Ollama API. The following is an example configuration for the Ollama API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"ollama\" , API_BASE: \"YOUR_ENDPOINT\", API_KEY: \"ollama\", # not used but required API_MODEL: \"YOUR_MODEL\" Tip API_BASE is the URL started in the Ollama LLM server and API_MODEL is the model name of Ollama LLM, it should be same as the one you served before. In addition, due to model token limitations, you can use lite version of prompt to have a taste on UFO which can be configured in config_dev.yaml . Note To run UFO successfully with Ollama, you must increase the default token limit of 2048 tokens by creating a custom model with a modified Modelfile. Create a new Modelfile that specifies PARAMETER num_ctx 32768 (or your model's maximum context length), then build your custom model with ollama create [model]-max-ctx -f Modelfile . UFO requires at least 20,000 tokens to function properly, so setting the num_ctx parameter to your model's maximum supported context length will ensure optimal performance. For more details on Modelfile configuration, refer to Ollama's official documentation . Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. Step 4 After configuring the HOST_AGENT and APP_AGENT with the Ollama API, you can start using UFO to interact with the Ollama API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Ollama"},{"location":"supported_models/ollama/#ollama","text":"","title":"Ollama"},{"location":"supported_models/ollama/#step-1","text":"If you want to use the Ollama model, Go to Ollama and follow the instructions to serve a LLM model on your local environment. We provide a short example to show how to configure the ollama in the following, which might change if ollama makes updates. ## Install ollama on Linux & WSL2 curl https://ollama.ai/install.sh | sh ## Run the serving ollama serve","title":"Step 1"},{"location":"supported_models/ollama/#step-2","text":"Open another terminal and run the following command to test the ollama model: ollama run YOUR_MODEL Info When serving LLMs via Ollama, it will by default start a server at http://localhost:11434 , which will later be used as the API base in config.yaml .","title":"Step 2"},{"location":"supported_models/ollama/#step-3","text":"After obtaining the API key, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Ollama API. The following is an example configuration for the Ollama API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"ollama\" , API_BASE: \"YOUR_ENDPOINT\", API_KEY: \"ollama\", # not used but required API_MODEL: \"YOUR_MODEL\" Tip API_BASE is the URL started in the Ollama LLM server and API_MODEL is the model name of Ollama LLM, it should be same as the one you served before. In addition, due to model token limitations, you can use lite version of prompt to have a taste on UFO which can be configured in config_dev.yaml . Note To run UFO successfully with Ollama, you must increase the default token limit of 2048 tokens by creating a custom model with a modified Modelfile. Create a new Modelfile that specifies PARAMETER num_ctx 32768 (or your model's maximum context length), then build your custom model with ollama create [model]-max-ctx -f Modelfile . UFO requires at least 20,000 tokens to function properly, so setting the num_ctx parameter to your model's maximum supported context length will ensure optimal performance. For more details on Modelfile configuration, refer to Ollama's official documentation . Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs.","title":"Step 3"},{"location":"supported_models/ollama/#step-4","text":"After configuring the HOST_AGENT and APP_AGENT with the Ollama API, you can start using UFO to interact with the Ollama API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 4"},{"location":"supported_models/openai/","text":"OpenAI Step 1 To use the OpenAI API, you need to create an account on the OpenAI website . After creating an account, you can access the API key from the API keys page . Step 2 After obtaining the API key, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the OpenAI API. The following is an example configuration for the OpenAI API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"openai\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_BASE: \"https://api.openai.com/v1/chat/completions\", # The the OpenAI API endpoint, \"https://api.openai.com/v1/chat/completions\" for the OpenAI API. API_KEY: \"sk-\", # The OpenAI API key, begin with sk- API_VERSION: \"2024-02-15-preview\", # The version of the API, \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model name, \"gpt-4-vision-preview\" by default. You may also use \"gpt-4o\" for using the GPT-4O model. Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. You can find the list of models here . Step 3 After configuring the HOST_AGENT and APP_AGENT with the OpenAI API, you can start using UFO to interact with the OpenAI API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"OpenAI"},{"location":"supported_models/openai/#openai","text":"","title":"OpenAI"},{"location":"supported_models/openai/#step-1","text":"To use the OpenAI API, you need to create an account on the OpenAI website . After creating an account, you can access the API key from the API keys page .","title":"Step 1"},{"location":"supported_models/openai/#step-2","text":"After obtaining the API key, you can configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the OpenAI API. The following is an example configuration for the OpenAI API: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"openai\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_BASE: \"https://api.openai.com/v1/chat/completions\", # The the OpenAI API endpoint, \"https://api.openai.com/v1/chat/completions\" for the OpenAI API. API_KEY: \"sk-\", # The OpenAI API key, begin with sk- API_VERSION: \"2024-02-15-preview\", # The version of the API, \"2024-02-15-preview\" by default API_MODEL: \"gpt-4-vision-preview\", # The OpenAI model name, \"gpt-4-vision-preview\" by default. You may also use \"gpt-4o\" for using the GPT-4O model. Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. You can find the list of models here .","title":"Step 2"},{"location":"supported_models/openai/#step-3","text":"After configuring the HOST_AGENT and APP_AGENT with the OpenAI API, you can start using UFO to interact with the OpenAI API for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 3"},{"location":"supported_models/operator/","text":"OpenAI CUA (Operator) The Opeartor is a specialized agentic model tailored for Computer-Using Agents (CUA). We now support calling via the Azure OpenAI API (AOAI). The following sections provide a comprehensive guide on how to set up and use the AOAI API with UFO. Note that now AOAI only supports the Response API to invoke the model. Step 1 To use the Azure OpenAI API, you need to create an account on the Azure OpenAI website . After creating an account, you can deploy the AOAI API and access the API key. Step 2 After obtaining the API key, you can configure the OPERATOR in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Azure OpenAI API. The following is an example configuration for the Azure OpenAI API: OPERATOR: { SCALER: [1024, 768], # The scaler for the visual input in a list format, [width, height] API_TYPE: \"azure_ad\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_MODEL: \"computer-use-preview-20250311\", #\"gpt-4o-mini-20240718\", #\"gpt-4o-20240513\", # The only OpenAI model by now that accepts visual input API_VERSION: \"2025-03-01-preview\", # \"2024-02-15-preview\" by default API_BASE: \"<YOUR_ENDPOINT>\", # The the OpenAI API endpoint, \"https://api.openai.com/v1/chat/completions\" for the OpenAI API. As for the AAD, it should be your endpoints. } If you want to use AAD for authentication, you should additionally set the following configuration: AAD_TENANT_ID: \"YOUR_TENANT_ID\", # Set the value to your tenant id for the llm model AAD_API_SCOPE: \"YOUR_SCOPE\", # Set the value to your scope for the llm model AAD_API_SCOPE_BASE: \"YOUR_SCOPE_BASE\" # Set the value to your scope base for the llm model, whose format is API://YOUR_SCOPE_BASE, and the only need is the YOUR_SCOPE_BASE Step 3 Now UFO only support to run Operator as a single agent, or as a separate AppAgent that can be called by the HostAgent . Please refer to the documents for how to run Operator within UFO. Note The Opeartor is a visual-only model and use different workflow from the other models. Currently, it does not support reuse the AppAgent workflow. Please refer to the documents for how to run Operator within UFO.","title":"OpenAI CUA (Operator)"},{"location":"supported_models/operator/#openai-cua-operator","text":"The Opeartor is a specialized agentic model tailored for Computer-Using Agents (CUA). We now support calling via the Azure OpenAI API (AOAI). The following sections provide a comprehensive guide on how to set up and use the AOAI API with UFO. Note that now AOAI only supports the Response API to invoke the model.","title":"OpenAI CUA (Operator)"},{"location":"supported_models/operator/#step-1","text":"To use the Azure OpenAI API, you need to create an account on the Azure OpenAI website . After creating an account, you can deploy the AOAI API and access the API key.","title":"Step 1"},{"location":"supported_models/operator/#step-2","text":"After obtaining the API key, you can configure the OPERATOR in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Azure OpenAI API. The following is an example configuration for the Azure OpenAI API: OPERATOR: { SCALER: [1024, 768], # The scaler for the visual input in a list format, [width, height] API_TYPE: \"azure_ad\" , # The API type, \"openai\" for the OpenAI API, \"aoai\" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API. API_MODEL: \"computer-use-preview-20250311\", #\"gpt-4o-mini-20240718\", #\"gpt-4o-20240513\", # The only OpenAI model by now that accepts visual input API_VERSION: \"2025-03-01-preview\", # \"2024-02-15-preview\" by default API_BASE: \"<YOUR_ENDPOINT>\", # The the OpenAI API endpoint, \"https://api.openai.com/v1/chat/completions\" for the OpenAI API. As for the AAD, it should be your endpoints. } If you want to use AAD for authentication, you should additionally set the following configuration: AAD_TENANT_ID: \"YOUR_TENANT_ID\", # Set the value to your tenant id for the llm model AAD_API_SCOPE: \"YOUR_SCOPE\", # Set the value to your scope for the llm model AAD_API_SCOPE_BASE: \"YOUR_SCOPE_BASE\" # Set the value to your scope base for the llm model, whose format is API://YOUR_SCOPE_BASE, and the only need is the YOUR_SCOPE_BASE","title":"Step 2"},{"location":"supported_models/operator/#step-3","text":"Now UFO only support to run Operator as a single agent, or as a separate AppAgent that can be called by the HostAgent . Please refer to the documents for how to run Operator within UFO. Note The Opeartor is a visual-only model and use different workflow from the other models. Currently, it does not support reuse the AppAgent workflow. Please refer to the documents for how to run Operator within UFO.","title":"Step 3"},{"location":"supported_models/overview/","text":"Supported Models UFO supports a variety of LLM models and APIs. You can customize the model and API used by the HOST_AGENT and APP_AGENT in the config.yaml file. Additionally, you can configure a BACKUP_AGENT to handle requests when the primary agent fails to respond. Please refer to the following sections for more information on the supported models and APIs: LLMs Documentation OPENAI OpenAI API Azure OpenAI (AOAI) Azure OpenAI API Gemini Gemini API Claude Claude API QWEN QWEN API Ollama Ollama API Custom Custom API Info Each model is implemented as a separate class in the ufo/llm directory, and uses the functions chat_completion defined in the BaseService class of the ufo/llm/base.py file to obtain responses from the model.","title":"Overview"},{"location":"supported_models/overview/#supported-models","text":"UFO supports a variety of LLM models and APIs. You can customize the model and API used by the HOST_AGENT and APP_AGENT in the config.yaml file. Additionally, you can configure a BACKUP_AGENT to handle requests when the primary agent fails to respond. Please refer to the following sections for more information on the supported models and APIs: LLMs Documentation OPENAI OpenAI API Azure OpenAI (AOAI) Azure OpenAI API Gemini Gemini API Claude Claude API QWEN QWEN API Ollama Ollama API Custom Custom API Info Each model is implemented as a separate class in the ufo/llm directory, and uses the functions chat_completion defined in the BaseService class of the ufo/llm/base.py file to obtain responses from the model.","title":"Supported Models"},{"location":"supported_models/qwen/","text":"Qwen Model Step 1 Qwen (Tongyi Qianwen) is developed by Alibaba DAMO Academy. To use the Qwen model, Go to QWen and register an account and get the API key. More details can be found here (in Chinese). Step 2 Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Qwen model. The following is an example configuration for the Qwen model: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"qwen\" , # The API type, \"qwen\" for the Qwen model. API_KEY: \"YOUR_KEY\", # The Qwen API key API_MODEL: \"YOUR_MODEL\" # The Qwen model name Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. Tip API_MODEL is the model name of Qwen LLM API. You can find the model name in the Qwen LLM model list. Step 3 After configuring the HOST_AGENT and APP_AGENT with the Qwen model, you can start using UFO to interact with the Qwen model for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Qwen"},{"location":"supported_models/qwen/#qwen-model","text":"","title":"Qwen Model"},{"location":"supported_models/qwen/#step-1","text":"Qwen (Tongyi Qianwen) is developed by Alibaba DAMO Academy. To use the Qwen model, Go to QWen and register an account and get the API key. More details can be found here (in Chinese).","title":"Step 1"},{"location":"supported_models/qwen/#step-2","text":"Configure the HOST_AGENT and APP_AGENT in the config.yaml file (rename the config_template.yaml file to config.yaml ) to use the Qwen model. The following is an example configuration for the Qwen model: VISUAL_MODE: True, # Whether to use visual mode to understand screenshots and take actions API_TYPE: \"qwen\" , # The API type, \"qwen\" for the Qwen model. API_KEY: \"YOUR_KEY\", # The Qwen API key API_MODEL: \"YOUR_MODEL\" # The Qwen model name Tip If you set VISUAL_MODE to True , make sure the API_MODEL supports visual inputs. Tip API_MODEL is the model name of Qwen LLM API. You can find the model name in the Qwen LLM model list.","title":"Step 2"},{"location":"supported_models/qwen/#step-3","text":"After configuring the HOST_AGENT and APP_AGENT with the Qwen model, you can start using UFO to interact with the Qwen model for various tasks on Windows OS. Please refer to the Quick Start Guide for more details on how to get started with UFO.","title":"Step 3"}]}